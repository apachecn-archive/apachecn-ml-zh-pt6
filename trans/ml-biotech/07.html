<html><head/><body>
	
		<title>B17761_05_Final_JM_ePub</title>
		
	
<!-- kobo-style -->

<style type="text/css" id="koboSpanStyle">.koboSpan { -webkit-text-combine: inherit; }</style>


	
		<div><h1 id="_idParaDest-81">第五章:理解机器学习</h1>
			<p>在过去的几年里，你可能已经听说过一些流行词汇，如<strong class="bold">人工智能</strong> ( <strong class="bold"> AI </strong>)、<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)和<strong class="bold">深度学习</strong> ( <strong class="bold"> DL </strong>)，这些词汇已经席卷了大多数主要行业。尽管这些短语中有许多在全公司的全体员工和领导会议上可以互换使用，但每个短语实际上都指一个不同的概念。所以，让我们仔细看看这些短语实际上指的是什么。</p>
			<p>人工智能通常是指由软件和机器展示的类人智能的总体领域。我们可以把人工智能看作是包含我们将在本书范围内讨论的许多主题的空间。</p>
			<p>在人工智能领域中，存在一个子域，我们称之为<strong class="bold">机器学习</strong>。ML可以定义为<em class="italic">结合数据研究算法以开发预测模型</em>。</p>
			<p>在ML领域中，还存在另一个子域，我们称之为<strong class="bold">深度学习</strong>。我们将<strong class="bold"> DL </strong>定义为<em class="italic">通过使用人工神经网络</em>来具体应用ML。</p>
			<p>现在我们已经对这些术语之间的区别有了更好的理解，让我们更详细地定义ML的概念。根据你询问的对象，你会遇到几种不同的ML定义。物理学家倾向于将定义与<em class="italic">性能优化</em>中的应用联系起来，而数学家倾向于将定义与<em class="italic">统计概率</em>联系起来，最后，计算机科学家倾向于将定义与<em class="italic">算法</em>和<em class="italic">代码</em>联系起来。在一定程度上，这三者在技术上都是正确的。出于本书的目的，我们将把ML定义为一个研究领域，涉及使用计算机代码开发数学优化模型，这些模型从历史数据中<em class="italic">学习</em>或<em class="italic">概括</em>以获得有用的见解并做出预测。</p>
			<p>虽然这个定义可能看起来很简单，但大多数有经验的面试候选人在定义这个概念时仍然倾向于挣扎。记下我们在这里使用的确切措辞，因为它可能会在未来的设置中有用。</p>
			<p>在这一章的过程中，我们将访问ML的各个方面，我们将回顾开发人员在开发<strong class="bold">预测模型</strong>时必须采取的一些最常见的步骤。</p>
			<p>在本章中，我们将回顾以下主要主题:</p>
			<ul>
				<li>理解ML</li>
				<li>过度拟合和欠拟合</li>
				<li>开发一个ML模型</li>
			</ul>
			<p>考虑到这些，让我们开始吧！</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor083"/>技术要求</h1>
			<p>在本章中，我们将应用我们对<code>pandas</code>和<code>numpy</code>的理解。此外，我们还会用到一些ML库，比如<code>sklearn</code>、<code>tensorflow</code>。回想一下，安装新库的过程可以通过命令行完成:</p>
			<pre>$ pip install library-name</pre>
			<p>我们开始吧！</p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor084"/>了解ML</h1>
			<p>在<a id="_idIndexMarker332"/>介绍中，我们广义地定义了与本书相关的ML概念。记住这个定义，现在让我们看一些例子来详细说明我们的定义。最广义的ML可以分为四个区域:<strong class="bold">分类</strong>、<strong class="bold">回归</strong>、<strong class="bold">聚类</strong>、<strong class="bold">降维</strong>。这四个类别通常被称为<strong class="bold">数据科学</strong>的领域。数据科学是一个非常宽泛的术语，用于指与数据相关的各种应用，以及人工智能领域及其子集。我们可以在<em class="italic">图5.1 </em>中看到这些字段之间的关系:</p>
			<div><div><img src="img/B17761_05_001.jpg" alt="Figure 5.1 – The domain of AI as it relates to other fields&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.1–人工智能领域与其他领域的关系</p>
			<p>记住这些<a id="_idIndexMarker333"/>概念，让我们更详细地讨论这四种ML方法。</p>
			<p><code>X</code>)及其后续输出值(统称为<code>ŷ</code>)用于训练一个分类器。这个分类器可以用来对新的和未知的数据进行预测。我们可以在<em class="italic">图5.2 </em>中直观地表示出来:</p>
			<div><div><img src="img/B17761_05_002.jpg" alt="Figure 5.2 – An example of a classification model&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.2–分类模型示例</p>
			<p><strong class="bold">聚类</strong>在某种意义上类似于<a id="_idIndexMarker336"/>分类，即模型的结果是一个标签(或类别)，但这里的区别在于，聚类模型不是在预定义类别的列表上训练的，而是基于对象之间的相似性。然后，聚类模型将数据点分组到<em class="italic">聚类</em>中。形成的集群的总数<a id="_idIndexMarker337"/>并不总是提前知道的，这在很大程度上取决于模型被训练的参数。在以下示例中，使用原始数据集形成了三个分类:</p>
			<div><div><img src="img/B17761_05_003.jpg" alt="Figure 5.3 – An example of a clustering model&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.3–聚类模型示例</p>
			<p>另一方面，当到达<code>X</code>时，它们随后的输出值(<code>ŷ</code>)用于训练一个<em class="italic">回归变量</em>。然后，该回归变量可用于对新的和未知的数据进行预测:</p>
			<div><div><img src="img/B17761_05_004.jpg" alt="Figure 5.4 – An example of a regression model&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.4-回归模型的一个例子</p>
			<p>最后，当涉及到<a id="_idIndexMarker339"/>到<strong class="bold">维度缩减</strong>时，ML可以不用于预测值的目的，而是用于将数据从<em class="italic">高维</em>表示转换为<em class="italic">低维</em>表示。举个例子，我们在前面的章节中使用了大量的毒性数据集。我们可以应用诸如<strong class="bold">主成分分析</strong> ( <strong class="bold"> PCA </strong>)到<a id="_idIndexMarker340"/>的方法，通过<em class="italic">将<a id="_idIndexMarker341"/>这些特征的重要性</em>结合在一起，将10+列特征减少到只有两三列。我们将在<a href="B17761_07_Final_JM_ePub.xhtml#_idTextAnchor101"> <em class="italic">第7章</em> </a>、<em class="italic">了解监督机器学习</em>中更详细地检验这一点。我们可以在<em class="italic">图5.5 </em>中看到它的直观表示:</p>
			<div><div><img src="img/B17761_05_005.jpg" alt="Figure 5.5 – An example of a dimensionality reduction model&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.5–降维模型示例</p>
			<p>ML领域庞大而复杂，远远超出了我们刚刚提到的四个基本例子。然而，ML模型最常见的应用往往集中在<em class="italic">预测类别</em>、<em class="italic">预测值</em>，或者<em class="italic">揭示数据中隐藏的洞察力</em>。</p>
			<p>作为科学家，我们总是希望尽可能地组织我们的思想，而碰巧的是，我们刚刚讨论的<a id="_idIndexMarker342"/>概念可以分为两大类:<code>X</code>和输出(<code>ŷ</code>)。我们称之为<em class="italic">监督</em>方法，因为模型被教导(<em class="italic">监督</em>)哪个输出标签对应哪个输入值。另一方面，UML包含ML模型，其中只有输入(<code>X</code>)是已知的。回顾我们讨论的四种方法，我们可以将它们分为两种学习方法，即<strong class="bold">分类</strong>和<strong class="bold">回归</strong>属于SML，而<strong class="bold">聚类</strong>和<strong class="bold">维度缩减</strong>属于UML:</p>
			<div><div><img src="img/B17761_05_006.jpg" alt="Figure 5.6 – A representation of supervised and unsupervised machine learning&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.6–监督和非监督机器学习的表示</p>
			<p>在接下来章节的<a id="_idIndexMarker344"/>课程中，我们将探索属于这四大类的许多流行的ML模型和算法。在你继续学习的过程中，我鼓励你开发自己的思维导图，并进一步将四个类别中的每一个扩展到你将要学习的所有不同的模型。例如，我们将在本章的<em class="italic">保存用于部署的模型</em>一节中探索一个<em class="italic">朴素贝叶斯</em>模型，它可以被添加到<em class="italic">图5.6 </em>的<strong class="bold">分类</strong>分支中。也许你可以用一些关于模型本身的注释来扩展每个模型。在准备技术面试时，地图或视觉辅助工具可能会很有用。</p>
			<p>在我们开发的每个模型中，我们将遵循一组特定的步骤来获取数据，对数据进行预处理，构建模型，评估其性能，最后，如果模型足够，将其部署到我们的最终用户或数据工程师。在我们开始<a id="_idIndexMarker345"/>开发我们的模型之前，让我们讨论一下被称为<em class="italic">过拟合</em>和<em class="italic">欠拟合</em>的常见危险。</p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor085"/>过拟合和欠拟合</h1>
			<p>在<a id="_idIndexMarker347"/> SML的<a id="_idIndexMarker346"/>背景下，我们将通过<em class="italic">用历史数据拟合</em>来准备我们的模型。拟合模型的过程通常会输出一个度量值，该度量值表示该模型对与训练该模型所依据的数据相似的数据的概括程度。使用这个输出，通常以<strong class="bold">精度</strong>、<strong class="bold">精度</strong>和<strong class="bold">召回</strong>的形式，我们可以确定我们实现的方法或我们改变的参数是否对我们的模型有积极的影响。如果我们重温一下本章前面的ML模型的定义，我们会特别提到它们是<em class="italic">从历史数据中学习</em>或<em class="italic">概括</em>的模型。能够从历史数据中学习的模型被称为<em class="italic">合适的</em>模型，在某种意义上，它们能够对新的和看不见的数据进行准确的处理。</p>
			<p>存在模型不足的实例。不足的模型通常在数据集上表现不佳，这意味着它们没有学会很好地概括。这些情况通常是由于给定数据集选择了不合适的模型，或者该模型的参数/超参数设置不当。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout"><strong class="bold">参数和超参数</strong>:注意<a id="_idIndexMarker348"/>虽然参数<a id="_idIndexMarker349"/>和超参数是经常互换使用的术语，但两者是有区别的。<em class="italic">超参数</em>是模型估计器不学习的参数，必须手动调整。</p>
			<p>也有模型过度拟合的例子。<em class="italic">过拟合</em>模型是<em class="italic">对</em>数据集了解得有点过的模型，这意味着它们不再是<em class="italic">在学习</em>而是<em class="italic">在记忆</em>。过度拟合通常发生在模型开始从数据集中的噪声中学习，并且不再能够对新数据进行很好的概括时。在<em class="italic">图5.7 </em>中可以看到拟合良好、过度拟合和欠拟合模型之间的差异:</p>
			<div><div><img src="img/B17761_05_007.jpg" alt="Figure 5.7 – A representation of overfitting and underfitting data&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.7-过度拟合和欠拟合数据的表示</p>
			<p>每个数据科学家的<a id="_idIndexMarker350"/>目标<a id="_idIndexMarker351"/>是开发一个平衡的模型，当涉及到您感兴趣的指标时，该模型具有最佳性能。确保您正在开发一个不会欠拟合或过拟合的平衡模型的最佳方法之一是提前拆分数据集，并确保模型仅针对数据的子集进行定型。我们可以把数据集分成两类:<em class="italic">训练数据</em>和<em class="italic">测试数据</em>(也常被称为<em class="italic">验证数据</em>)。我们可以使用训练数据集来训练模型，并且可以使用测试数据集来测试(或验证)模型。用于此目的的最常见的类之一是来自<code>sklearn</code>的<code>train_test_split()</code>类。如果您认为数据集的输入变量是<code>X</code>，输出变量是<code>ŷ</code>，那么您可以使用下面的代码片段分割数据集。首先，我们导入数据。然后，我们分离出我们感兴趣的特征，输出它们各自的变量。然后，我们实现<code>train_test_split()</code>函数来相应地分割数据:</p>
			<pre>import pandas as pd
from sklearn.model_selection import train_test_split
df = pd.read_csv("../../datasets/dataset_wisc_sd.csv")
X = df.drop(columns = ["id", "diagnosis"])
y = df.diagnosis.values
X_train, X_test, y_train, y_test = train_test_split(X, y)</pre>
			<p>我们可以在<em class="italic">图5.8 </em>中看到分割的数据集:</p>
			<div><div><img src="img/B17761_05_008.jpg" alt="Figure 5.8 – A visual representation of data that has been split for training and testing&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.8–为训练和测试而拆分的数据的可视化表示</p>
			<p>以这种方式分割数据后，我们现在可以使用<code>X_train</code>和<code>y_train</code>来训练我们的模型，使用<code>X_test</code>和<code>y_test</code>来测试(或验证)我们的模型。默认的拆分比例是75%的训练数据对25%的测试数据；但是，我们可以通过<code>test_size</code>参数将其更改为任何其他<a id="_idIndexMarker352"/>比率。我们通常希望根据尽可能多的数据进行训练<a id="_idIndexMarker353"/>，但仍然保留大量有意义的未知数据，因此<em class="italic"> 75/25 </em>是业内普遍接受的比率。记住这个概念，让我们继续开发一个完整的ML模型。</p>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor086"/>开发一个ML模型</h1>
			<p>作为最终用户，我们每天都要与无数的ML模型打交道，而我们甚至可能没有意识到这一点。回想一下你今天做的所有活动:浏览社交媒体、查看电子邮件，或者你去了商店或超市。在这些设置中，您很可能与已经部署的ML模型进行了交互。在社交媒体上，出现在你的feed上的帖子很可能是一个监督的<strong class="bold">推荐</strong>模型的输出。您打开的电子邮件可能是使用<strong class="bold">分类</strong>模型过滤的垃圾邮件。最后，杂货店中可用的商品数量可能是一个<strong class="bold">回归</strong>模型的输出，允许他们预测今天的需求。在每个模型中，都投入了大量的时间和精力来确保它们正常运行。在这些情况下，虽然模型的开发很重要，但最重要的是如何提前准备数据。作为科学家，我们总是倾向于尽可能组织我们的思想和过程，所以让我们<a id="_idIndexMarker355"/>为开发ML模型的过程组织一个工作流程:</p>
			<ol>
				<li><strong class="bold">数据采集</strong>:通过SQL查询、本地导入或API请求收集数据</li>
				<li><strong class="bold"> EDA和预处理</strong>:理解和清理数据集</li>
				<li><strong class="bold">模型开发和验证</strong>:训练模型并验证结果</li>
				<li>部署:将你的模型提供给最终用户</li>
			</ol>
			<p>记住这些步骤，让我们继续开发我们的第一个模型。</p>
			<p>我们从导入数据开始。我们将使用一个我们尚未使用过的新数据集，称为<code>Breast Cancer Wisconsin</code>数据集。这是一个多变量数据集，发表于1995年，包含了数百例乳腺癌肿块。这些质量以我们将用作<em class="italic">特征</em> ( <code>X</code>)的测量形式描述。数据集还包括关于每个实例的恶性程度的信息，我们将把这些信息用于我们的输出<em class="italic">标签</em> ( <code>ŷ</code>)。假设我们既有输入数据又有输出数据，这就需要使用一个<em class="italic">分类</em>模型。</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor087"/>数据采集</h2>
			<p>让我们<a id="_idIndexMarker356"/>导入我们的数据并检查它的整体形状:</p>
			<pre>import pandas as pd
import numpy as np
df = pd.read_csv("../../datasets/dataset_wisc_sd.csv")
df.shape</pre>
			<p>我们注意到有569行(我们<a id="_idIndexMarker357"/>通常称之为<em class="italic">观察值</em>)和32列(我们<a id="_idIndexMarker358"/>通常称之为<em class="italic">特性</em>)的数据。我们通常希望我们的数据集有更多的<em class="italic">观察值</em>而不是<em class="italic">特征</em>。这两者之间的理想比例并没有黄金法则，但是您通常希望观察值比特性值至少多10倍。因此，对于32列，您将希望至少有320个观察值——我们在本例中就是这样做的！</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor088"/>探索性数据分析和预处理:</h2>
			<p><strong class="bold">探索性数据分析</strong> ( <strong class="bold"> EDA </strong>)可以说是<a id="_idIndexMarker359"/><a id="_idIndexMarker360"/>任何给定的ML项目中最重要和最耗时的步骤之一。该步骤通常由许多较小的步骤组成，其目标如下:</p>
			<ul>
				<li>理解数据及其特征。</li>
				<li>解决任何不一致或缺少的值。</li>
				<li>检查特征之间的相关性。</li>
			</ul>
			<p>请注意，根据您的数据集，我们执行这些步骤的顺序可能会有所不同。考虑到这些，让我们开始吧！</p>
			<h3>检查数据集</h3>
			<p>导入数据集后的第一步是快速检查数据的质量。回想一下，我们可以使用方括号(<code>[]</code>)来指定感兴趣的列，并且我们可以使用<code>head()</code>或<code>tail()</code>函数来查看前五行或后五行数据:</p>
			<pre>df[["id", "diagnosis", "radius_mean", "texture_mean", "concave points_worst"]].head()</pre>
			<p>我们可以在<em class="italic">图5.9 </em>中看到这段代码的结果:</p>
			<div><div><img src="img/B17761_05_09.jpg" alt="Figure 5.9 – A sample of the Breast Cancer Wisconsin dataset&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.9-乳腺癌威斯康星州数据集的样本</p>
			<p>我们可以很快感觉到数据组织得非常好，并且乍一看，它似乎没有任何有问题的值，例如不寻常的字符或缺少的值。查看这些选择列，我们注意到在开头有一个由整数<em class="italic">组成的唯一标识符</em>，后面是由字符串组成的诊断(<strong class="bold"> M </strong> = <strong class="bold">恶性</strong>和<strong class="bold"> B </strong> = <strong class="bold">良性</strong>)。其余的列都是特征，它们看起来都是<em class="italic"> float </em> (decimals)数据类型。我建议您扩展上表的范围，探索该数据集中的所有其他要素。</p>
			<p>除了研究这些值，我们还可以研究由<code>pandas</code>库中的<code>describe()</code>函数提供的一些汇总统计数据。使用此函数，我们可以了解总计数，以及一些描述性统计数据，如平均值、最大值和最小值:</p>
			<pre>df[["id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "concave points_worst"]].describe()</pre>
			<p>这个函数的输出可以在下面的截图中看到:</p>
			<div><div><img src="img/B17761_05_10.jpg" alt="Figure 5.10 – A table of some summary statistics for a DataFrame&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.10–数据帧的一些汇总统计表</p>
			<p>仔细查看代码，我们注意到我们请求了七列的统计数据，但是只有五列出现在表中。我们可以看到这里汇总了<code>id</code>值(即<em class="italic">主键</em>或<em class="italic">唯一标识符</em>)。这些值没有意义，因为一组主键的平均值、最大值和最小值告诉我们什么。我们可以暂时忽略这个专栏。我们还要求提供<code>diagnosis</code>栏；然而，<code>diagnosis</code>列不使用数值。而是包含<em class="italic">字符串</em>。最后，我们看到<code>concave points_worst</code>特性也没有包含在这个表中，这表明数据类型<a id="_idIndexMarker363"/>由于某种原因而不是数字。当我们清理数据时，我们将在下一节中更详细地了解这一点。</p>
			<h3>清除值</h3>
			<p>清理数据集中的<a id="_idIndexMarker364"/>值是处理ML项目时最重要的步骤之一。数据科学家在描述模型时有一句名言是<em class="italic">垃圾进，垃圾出</em>。如果您想要一个强大的预测模型，那么确保支持它的数据质量良好是重要的第一步。</p>
			<p>首先，让我们仔细看看数据类型，这里可能有一些不一致的地方。使用下面的代码，我们可以了解32列中每一列的数据类型:</p>
			<pre>df.dtypes</pre>
			<p>我们可以在<em class="italic">图5.11 </em>中看到这段代码的输出，其中显示了列名及其各自的数据类型:</p>
			<div><div><img src="img/B17761_05_011.jpg" alt="Figure 5.11 – A list of all of the columns in a dataset with their respective data types&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.11–数据集中所有列及其各自数据类型的列表</p>
			<p>查看<a id="_idIndexMarker365"/>列出的数据类型，我们看到<code>id</code>列被列为一个整数而<code>diagnosis</code>列被列为一个对象，这似乎与<em class="italic">图5.9 </em>中它似乎是一个单字母字符串的事实相一致。看了一下特性，它们都被列为浮动，与我们之前看到的完全一致，除了一个特性:<code>concave points_worst</code>。此特征被列为对象，表明它可能是字符串。我们前面提到过，该列由浮点值组成，因此该列本身应该是浮点类型。让我们来看看这种不一致宜早不宜迟。我们可以尝试<em class="italic">将</em>列转换为浮动类型，而不是使用<code>astype()</code>函数:</p>
			<pre>df['concave points_worst'] = df['concave points_worst'].astype(float)</pre>
			<p>但是，您会发现这段代码会出错，表明有一行中存在<code>\\n</code>字符，它无法将字符串转换为浮点数。这就是众所周知的<a id="_idIndexMarker366"/>换行符，这是你在处理数据集时要处理的最常见的项目或杂质<em class="italic">之一。让我们继续前进，找出这个角色出现的台词，然后决定如何处理。我们可以使用<code>contains()</code>函数来查找特定字符串的所有实例:</em></p>
			<pre>df[df['concave points_worst'].str.contains(r"\\n")]</pre>
			<p>该函数的输出显示只有索引为<code>146</code>的行包含该字符。让我们仔细看看<code>146</code>行中的特定单元格:</p>
			<pre>df["concave points_worst"].iloc[146]</pre>
			<p>我们看到单元格包含了<code>0.1865\\n\\n</code>字符串。看起来好像字符只在这一行打印了两次。我们可以很容易地打开CSV文件，并手动更正这个值，因为它只发生了一次。但是，如果这个<a id="_idIndexMarker368"/>字符串出现了10次，或者100次呢？幸运的是，我们可以用一个<code>replace()</code>函数来用<em class="italic">替换</em>它们。我们可以在<code>df</code>上专门链接这个函数，而不是单个列，以确保该函数解析完整的数据帧:</p>
			<pre>df = df.replace(r'\\n','', regex=True)</pre>
			<p>正则表达式是一个强大的工具，您经常会依赖它来完成各种文本匹配和清理任务。您可以使用regex函数删除空格、数字、字符或不常见的字符组合。我们可以通过再次检查特定单元格的值来仔细检查regex函数是否成功:</p>
			<pre>df["concave points_worst"].iloc[146]</pre>
			<p>该值现在只有<code>0.1865</code>，表明该功能实际上是成功的。我们现在可以使用<code>astype()</code>函数将列的类型转换为浮点型，然后使用<code>df.dtypes</code>确认列出了正确的数据类型。</p>
			<p>到目前为止，我们能够解决无效字符进入数据集的问题。但是，丢失的项目怎么办？我们可以使用<code>isna()</code>函数对数据集进行快速检查，以确定是否有任何值丢失:</p>
			<pre>df.isna().values.sum()</pre>
			<p>返回的值显示有7行数据缺少一个值。回想一下，在第4章 、<em class="italic">用Python可视化数据</em>中，我们查看了几种处理缺失值的方法。假设我们有一个足够大的数据集，使用<code>dropna()</code>函数简单地删除这几行是合适的:</p>
			<pre>df = df.dropna()</pre>
			<p>我们可以在实现函数之前和之后检查数据集的形状，以确保确实删除了适当数量的行。</p>
			<p>总是建议花些时间提前清理你的数据集，因为<a id="_idIndexMarker369"/>这将有助于防止问题和不寻常的错误。检查<em class="italic">数据类型</em>和<em class="italic">缺失值</em>总是很重要的。</p>
			<h3>理解数据的含义</h3>
			<p>现在让我们从第二列中的输出值开始，仔细看看这个数据集中的一些数据。我们知道这些值对应的标签是:恶性的<em class="italic">M</em>和良性的B<em class="italic">B</em>。我们可以使用<code>value_counts()</code>函数来确定每个类别的总和:</p>
			<pre>df['diagnosis'].value_counts()</pre>
			<p>结果显示良性肿块354例，恶性肿块208例。我们可以使用<code>seaborn</code>库来可视化这个比率:</p>
			<pre>sns.countplot(df['diagnosis'])</pre>
			<p>这段代码的输出如下所示:</p>
			<div><div><img src="img/B17761_05_012.png.jpg" alt="Figure 5.12 – A bar plot showing the number of instances for each class&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.12-显示每个类的实例数量的条形图</p>
			<p>在大多数ML模型中，我们试图确保输出列是<em class="italic">平衡的</em>，在某种意义上，类别是<em class="italic">大致等于</em>。在具有例如95行恶性观察值和5行良性观察值的不平衡数据集上训练模型将导致具有较差性能的不平衡模型。在<a id="_idIndexMarker371"/>中，除了可视化诊断或输出列，我们还可以使用我们在<a href="B17761_04_Final_JM_ePub.xhtml#_idTextAnchor066"> <em class="italic">第4章</em> </a>、<em class="italic">使用Python可视化数据</em>中查看的<code>pairplot()</code>函数可视化特征，以获得任何趋势或相关性的感觉。我们可以通过一些功能来实现这一点:</p>
			<pre>sns.pairplot(df[["diagnosis", "radius_mean", "concave points_mean", "texture_mean"]], hue = 'diagnosis')</pre>
			<p>下图显示了此的输出:</p>
			<div><div><img src="img/B17761_05_013.png.jpg" alt="Figure 5.13 – A pair plot of selected features&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.13–选定特征的配对图</p>
			<p>查看最后几张图，我们注意到两组数据之间有明显的区别。从大多数点位于靠近中心的位置，而远离中心的点较少的意义上来说，这些集群似乎呈现出<strong class="bold">正态分布</strong>的一些特征。鉴于这种性质，我们可以在该数据集中尝试的第一个模型是<strong class="bold">朴素贝叶斯分类器</strong>，它往往适用于这种类型的数据。然而，我们将在本章后面更详细地讨论这个模型。</p>
			<p>在每个图中，我们都可以看到这两个类别之间存在一定程度的重叠，这表明仅使用两个色谱柱不足以保持良好的分离度。因此，我们可以确保我们的ML模型利用更多的列，或者我们可以尝试消除任何可能导致这种重叠的潜在异常值——或者我们可以双管齐下！</p>
			<p>首先，我们可以利用一些描述性的<em class="italic">统计数据。具体来说，我们可以使用<code>dfm</code>。然后，我们可以使用<code>radius_mean</code>特性定义第一个四分位数(<code>Q1</code>)和第三个四分位数(<code>Q3</code>):</em></p>
			<pre>dfm = df[df["diagnosis"] == "M"]
Q1 = dfm['radius_mean'].quantile(0.25)
Q3 = dfm['radius_mean'].quantile(0.75)
IQR = Q3 - Q1</pre>
			<p>然后，我们可以打印这些变量的输出，结合<code>mean()</code>和<code>median()</code>函数来确定IQR，从而了解数据的分布<a id="_idIndexMarker374"/>。我们可以使用<code>seaborn</code>中提供的<code>boxplot()</code>函数将这些指标与上限和下限一起可视化:</p>
			<pre>sns.boxplot(x='diagnosis', y='radius_mean', data=df)</pre>
			<p>这给了我们<em class="italic">图5.14 </em>:</p>
			<div><div><img src="img/B17761_05_014.png.jpg" alt="Figure 5.14 – A box-whisker plot of the radius_mean feature&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.14-半径平均值特征的盒须图</p>
			<p>使用上限和下限范围，我们可以使用<code>pandas</code>库中的<code>query()</code>类过滤数据帧，以排除任何超出此范围的数据:</p>
			<pre>df = df.query('(@Q1 - 1.5 * @IQR) &lt;= radius_mean &lt;= (@Q3 + 1.5 * @IQR)')</pre>
			<p>随着代码的执行，我们已经成功地从数据集中移除了几个异常值。如果我们继续使用前面的散点图之一重新绘制数据，我们将会看到，虽然一些重叠确实减少了，但两个类别之间仍然有相当大的重叠，这表明我们开发的任何未来模型都需要利用多个列来确保在我们开始开发稳健的分类器时有足够的分离。在我们开始训练任何分类器之前，我们首先需要解决特征中任何潜在的相关性。</p>
			<h3>寻找相关性</h3>
			<p>过滤掉离群值后，我们现在可以开始仔细观察数据集中的特征之间的相关性。假设这个数据集由30个要素组成，我们可以利用我们在第4章<em class="italic">中实现的<code>corr()</code>类，用Python </em>可视化数据。我们可以从<code>seaborn</code>中<a id="_idIndexMarker377"/>创建一个<code>corr()</code>函数和<code>heatmap()</code>函数:</p>
			<pre>f, ax=plt.subplots( figsize = (20,15))
sns.heatmap(df.corr(), annot= True, fmt = ".1f", ax=ax)
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)
plt.title('Breast Cancer Correlation Map', fontsize=18)
plt.show()</pre>
			<p>此代码的输出可以在<em class="italic">图5.15 </em>中看到，显示了各种特征的热图，其中最相关的特征以较浅的颜色显示，最不相关的特征以较深的颜色显示:</p>
			<div><div><img src="img/B17761_05_015.png.jpg" alt="Figure 5.15 – A heat map showing the correlation of features&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.15–显示特征相关性的热图</p>
			<p>当我们查看这张热图时，我们看到该数据集中的多个特征之间存在大量的相关性。例如，<code>radius_worst</code>特征与<code>perimeter_mean</code>和<code>area_mean</code>特征之间非常强的相关性。当数据集中的独立变量或特征之间存在强相关性时，这就是被称为<code>corr()</code>函数的<a id="_idIndexMarker379"/>，并创建这些值的矩阵。然后我们可以选择上面的三角形(热图的一半)，然后识别相关性大于<code>0.90:</code>的特征</p>
			<pre>corr_matrix = df.corr().abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))
to_drop = [column for column in upper.columns if any(upper[column] &gt; 0.90)]</pre>
			<p><code>to_drop</code>变量<a id="_idIndexMarker380"/>现在表示应该被删除的列的列表，以确保任何高于我们设置的阈值的相关性都被有效地删除。注意，我们使用了<strong class="bold">列表理解</strong>(我们在<a href="B17761_02_Final_JM_ePub.xhtml#_idTextAnchor023"> <em class="italic">第2章</em> </a>、<em class="italic">介绍Python和命令行</em>中谈到的概念)来快速有效地迭代这些值。然后，我们可以从数据集中删除这些列:</p>
			<pre>df.drop(to_drop, axis=1, inplace=True)</pre>
			<p>我们可以再次绘制热图，以确保解决任何潜在的共线性:</p>
			<div><div><img src="img/B17761_05_016.png.jpg" alt="Figure 5.16 – A heat map showing the correlation of features without multicollinearity&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.16-显示无多重共线性的要素相关性的热点图</p>
			<p>注意<a id="_idIndexMarker381"/>高度相关的特征组不再存在。现在解决了相关性问题，我们不仅确保了我们创建的任何潜在模型都不会遇到与<em class="italic">多重共线性</em>相关的任何性能问题，而且我们还无意中将数据集的大小从30列要素减少到只有19列，使其更易于处理和可视化！随着数据集现在完全预处理，我们现在准备开始训练和准备<a id="_idIndexMarker382"/>一些ML模型。</p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor089"/>开发和验证模型</h2>
			<p>现在<a id="_idIndexMarker383"/>数据准备就绪，我们可以探索<a id="_idIndexMarker384"/>几个模型。回想一下，我们在这里的目标是开发一个<em class="italic">分类</em>模型。因此，我们的第一步将是分离我们的<code>X</code>和<em class="italic"> ŷ </em>值。</p>
			<ol>
				<li value="1">We will create a variable, <code>X</code>, representing all of the features within the dataset (excluding the <code>id</code> and <code>diagnosis</code> columns, as these are not features). We will then create a variable, <code>y</code>, representing the output column:<pre>X = df.drop(columns = ["id", "diagnosis"])
y = df.diagnosis.values</pre><p>在我们将使用的大多数数据集内，我们通常会看到值的<em class="italic">量级</em>有很大差异，也就是说，一列可能是1000左右，而另一列可能是0.1左右。这意味着模型会认为值大得多的要素对预测的贡献大得多，但这是不正确的。例如，考虑一个项目，在该项目中，我们试图使用30种不同的特征来预测分子的亲脂性，其中一种特征是分子量——这是一种具有非常大的值但贡献不是那么大的特征。</p></li>
				<li>为了应对这一挑战，数据集中的值必须是来自<code>sklearn</code>库的<code>StandardScaler()</code>函数:<pre>from sklearn.preprocessing import StandardScaler scaler = StandardScaler() X_scaled = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)</pre></li>
				<li>With the features now normalized, our next step is to split the data up into our <em class="italic">training</em> and <em class="italic">testing</em> sets. Recall that the purpose of the training set is to train the model, and the testing set is to test the model. This is done to avoid any <em class="italic">overfitting</em> in the development process:<pre>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=40)</pre><p>随着数据现在被分成四个变量，我们现在准备好训练几个模型，从<strong class="bold">高斯朴素贝叶斯分类器</strong>开始。该模型是基于贝叶斯定理应用的监督算法。该模型被称为<em class="italic">天真</em>是因为它假设每个<em class="italic">观测值</em>的<em class="italic">特征</em>是相互独立的，而这很少<a id="_idIndexMarker385"/>是真实的。不过这款<a id="_idIndexMarker386"/>无论如何都倾向于表现强劲。高斯朴素贝叶斯分类器背后的主要思想可以从<em class="italic">概率</em>的角度来考察。为了解释我们的意思，考虑下面的等式:</p><div><img src="img/Formula_B17761_05_001.jpg" alt=""/></div><p>这表示标签的概率(给定一些数据)等于数据的概率(给定一个标签-高斯，给定正态分布)乘以标签的概率(先验概率)，再除以数据的概率(预测值先验概率)。鉴于这种模型的简单性，相对于更复杂的模型，朴素贝叶斯分类器可以非常快速地使用。</p></li>
				<li>我们来看看它的实现。我们将从导入我们感兴趣的库开始:<pre>   from sklearn.naive_bayes import GaussianNB    from sklearn.metrics import accuracy_score</pre></li>
				<li>接下来，我们可以以变量的形式创建一个实际模型的实例，我们称之为<code>gnb_clf</code> : <pre>   gnb_clf = GaussianNB()</pre></li>
				<li>然后，我们可以使用之前分离的训练数据集来拟合或训练模型:<pre>   gnb_clf.fit(X_train, y_train)</pre></li>
				<li>Finally, we<a id="_idIndexMarker387"/> can use the trained model <a id="_idIndexMarker388"/>to make predictions on the testing data and compare the results with the known values. We can use a simple accuracy score to test the model:<pre>gnb_pred = gnb_clf.predict(X_test)
   print(accuracy_score(gnb_pred, y_test))
  0.95035</pre><p>这样，我们已经成功地开发了一个准确率大约为95%的模型——对于我们的第一个模型来说，这是一个不错的开始！</p></li>
				<li>While accuracy is always a fantastic metric, it is not the only metric we can use to assess the performance of a model. We can also use <code>classification_report()</code> function provided by <code>sklearn</code>:<pre>from sklearn.metrics import classification_report
print(classification_report(gnb_pred, y_test))</pre><p>查看下面的输出，我们可以看到我们感兴趣的两个类(B和M)列出了它们各自的度量:<code>precision</code>、<code>recall</code>和<code>f1-score</code>:</p></li>
			</ol>
			<div><div><img src="img/B17761_05_017.jpg" alt="Figure 5.17 – The classification report of the Naïve Bayes classifier&#10;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.17–朴素贝叶斯分类器的分类报告</p>
			<p>我们将在第7章 、<em class="italic">了解监督机器学习</em>中更加详细地讨论<a id="_idIndexMarker389"/>这些指标。目前，我们可以看到所有这些指标都很高，表明该模型表现得相当好。</p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor090"/>保存用于部署的模型</h2>
			<p>当一个ML <a id="_idIndexMarker391"/>模型已经被训练并且在一个合理的精确度水平上运行时，我们可能希望将这个模型提供给其他人使用。然而，我们不会直接将数据或代码交付给数据工程师来将模型部署到生产中。相反，我们希望提供一个单一的训练有素的模型，他们可以采取和部署，而不必担心任何移动的部分。对我们来说幸运的是，有一个名为<code>pickle</code>的伟大库可以帮助我们<em class="italic">将</em>模型聚集成一个单一的实体，允许我们<em class="italic">保存</em>模型。回想一下我们在<a href="B17761_02_Final_JM_ePub.xhtml#_idTextAnchor023"> <em class="italic">第二章</em> </a>、<em class="italic">Python入门和命令行</em>中探索过<code>pickle</code>库。我们<em class="italic">通过使用<code>dump()</code>函数来处理</em>一个模型，比如我们命名为<code>gnb_clf</code>的模型:</p>
			<pre>import pickle
pickle.dump(gnb_clf, open("../../models/gnb_clf.pickle", 'wb'))</pre>
			<p>为了证明模型确实正确保存，我们可以使用<code>load()</code>函数加载它，并且我们可以再次计算准确性分数:</p>
			<pre>loaded_gnb_clf = pickle.load(open("../../models/gnb_clf.pickle", 'rb'))
loaded_gnb_clf.score(X_test, y_test)</pre>
			<p>请注意，该评分计算的输出结果与我们之前看到的<a id="_idIndexMarker392"/>中的值相同(95%)，这表明该模型确实正确保存了数据！</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor091"/>总结</h1>
			<p>在这一章中，我们朝着理解ML中一些最重要和最有用的概念迈出了一大步。我们查看了用于描述该领域的各种术语，因为它与人工智能的领域相关，检查了ML的主要领域以及管理类别<em class="italic">监督</em>和<em class="italic">非监督</em>学习，然后继续探索为给定数据集开发ML模型的完整过程。</p>
			<p>在开发我们的模型时，我们探索了许多有用的步骤。我们对数据进行了探索和预处理，以消除不一致和缺失值。我们还非常详细地检查了数据，随后我们解决了与<em class="italic">多重共线性</em>相关的问题。接下来，我们开发了一个<em class="italic">高斯朴素贝叶斯</em>分类模型，在我们的第一次尝试中，它的准确率高达95%!最后，我们看了数据科学家将他们完全训练好的模型交给数据工程师以将ML模型投入生产的一种最常见的方式。</p>
			<p>尽管我们在本章中花了时间在监督分类器的范围内理解ML，但在下一章中，当我们训练几个非监督模型时，我们将获得对细微差别和差异的更好理解。</p>
		</div>
	
</body></html>