<html><head/><body>


	
		<title>B16722_10_Final_ASB_ePub</title>
		
	
	
		<div><h1 id="_idParaDest-145"><a id="_idTextAnchor147"/> <em class="italic">第十章</em>:使用XGBoost预测布尔值</h1>
			<p><strong class="bold">极限梯度提升</strong> ( <strong class="bold"> XGBoost </strong>)是最强大的<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)库之一，数据科学家可以利用它以高效灵活的方式解决复杂的用例。它最初是一个研究项目，第一个版本于2014年发布。由于它的功能和可移植性，这个ML库的受欢迎程度增长很快。事实上，它曾被用于重要的Kaggle ML竞赛，现在可用于不同的编程语言和不同的操作系统。</p>
			<p>这个库可以用来处理不同的ML问题，并且是专门为结构化数据设计的。XGBoost最近也为BigQuery ML发布了。由于这种技术，BigQuery用户可以使用这个库实现分类和回归ML模型。</p>
			<p>在这一章中，我们将看到实现XGBoost分类模型以根据纽约市树木的特征将它们分类为不同种类所需的所有步骤。</p>
			<p>使用BigQuery ML SQL方言，我们将浏览以下主题:</p>
			<ul>
				<li>介绍业务场景</li>
				<li>发现XGBoost提升的树分类模型</li>
				<li>探索和理解数据集</li>
				<li>为XGBoost分类模型定型</li>
				<li>评估XGBoost分类模型</li>
				<li>使用XGBoost分类模型</li>
				<li>得出商业结论</li>
			</ul>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor148"/>技术要求</h1>
			<p>本章要求您能够访问网络浏览器，并能够利用以下内容:</p>
			<ul>
				<li>一个<strong class="bold">谷歌云平台</strong> ( <strong class="bold"> GCP </strong>)账户，用于访问谷歌云控制台</li>
				<li>托管BigQuery数据集的GCP项目</li>
			</ul>
			<p>既然我们在技术需求方面已经准备好了，那么让我们开始分析和开发我们的BigQuery ML XGBoost分类模型。</p>
			<p>请看下面的视频，看看代码是如何运行的:<a href="https://bit.ly/3ujnzH3">https://bit.ly/3ujnzH3</a></p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor149"/>介绍业务场景</h1>
			<p>在本节中，我们将介绍使用XGBoost分类算法处理的<a id="_idIndexMarker477"/>业务场景。</p>
			<p>该业务场景与<a href="B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088"> <em class="italic">第6章</em> </a>、<em class="italic">用多类逻辑回归对树进行分类</em>中提出和使用的用例非常相似。在本章中，我们将使用相同的数据集，但将应用更高级的ML算法。</p>
			<p>我们可以总结并记住，ML模型的目标是根据纽约市的树木的特征，如它们的位置、大小和健康状况，将它们自动分类为不同的种类。</p>
			<p>正如我们在<a href="B16722_09_Final_ASB_ePub.xhtml#_idTextAnchor133"> <em class="italic">第9章</em></a><em class="italic">中所做的那样，通过使用矩阵分解</em>建议合适的产品，我们可以将注意力集中在城市中最常见的五种树木上。</p>
			<p>既然我们已经解释并理解了业务场景，那么让我们来看看ML技术，我们可以使用它来根据树的特征对树进行自动分类。</p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor150"/>发现XGBoost提升树分类模型</h1>
			<p>在本节中，我们将了解什么是<strong class="bold"> XGBoost Boosted Trees </strong>分类模型，并且我们将了解哪些分类用例可以用这种ML算法来处理。</p>
			<p>XGBoost是一个开放的<a id="_idIndexMarker478"/>源码库，为不同的语言提供了一个可移植的渐变增强框架。XGBoost库可用于不同的编程语言，如C++、Java、Python、R和Scala，并且可以在不同的操作系统上工作。XGBoost用于处理监督学习用例，其中我们使用标记的训练数据来预测目标变量。</p>
			<p>多年来，XGBoost在ML社区中的知名度不断增长，因为它经常是ML比赛期间许多获胜团队的选择，如2016年的<em class="italic"> Kaggle -高能物理与机器学习奖</em>。</p>
			<p><strong class="bold"> XGBoost Boosted树</strong>的分类功能基于对数据进行分类以实现预测的多个决策树的使用。</p>
			<p>在下图中，您可以看到对动物进行分类的决策树的简单表示:</p>
			<div><div><img src="img/B16722_10_001.jpg" alt=""/>
				</div>
			</div>
			<p class="figure-caption">图10.1-决策树的表示</p>
			<p>XGBoost分类<a id="_idIndexMarker479"/>模型可以回答多类逻辑回归解决的相同问题，例如:</p>
			<ul>
				<li>我的客户<em class="italic">的评论是中立的</em>、<em class="italic">正面的</em>还是<em class="italic">负面的</em>？</li>
				<li>我的客户属于<em class="italic">黄金</em>、<em class="italic">白银</em>还是<em class="italic">青铜</em>级别？</li>
				<li>特定客户<em class="italic">流失的概率是高</em>、<em class="italic">中</em>还是<em class="italic">低</em>？</li>
				<li>图像识别算法是识别一只<em class="italic">猫</em>，一只<em class="italic">狗</em>，一只<em class="italic">老鼠</em>，还是一头<em class="italic">牛</em>？</li>
			</ul>
			<p>在我们的业务场景中，我们可以利用XGBoost Boosted树分类模型将纽约市的树分为五个不同的种类。事实上，我们感兴趣的是根据每棵树的特征来预测物种。</p>
			<p>在XGBoost算法的训练阶段，ML模型试图找到分配给每棵树的最佳值，以便最小化最终的误差度量。</p>
			<p>训练结束后，我们将把这个模型的结果与我们在<a href="B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088"> <em class="italic">第6章</em> </a>、<em class="italic">用多类逻辑回归分类树</em>中得到的结果进行比较。</p>
			<p>现在我们已经<a id="_idIndexMarker480"/>学习了XGBoost Boosted Tree算法的基础，是时候看看我们将用来构建ML模型的数据集了。</p>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor151"/>探索和理解数据集</h1>
			<p>在这一部分，我们将分析并<a id="_idIndexMarker481"/>准备我们用例的数据集。我们将从一些数据质量检查开始，然后我们将数据分成训练、评估和测试表。</p>
			<p>由于数据集已经在<a href="B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088"> <em class="italic">第6章</em> </a>、<em class="italic">用多类逻辑回归对树进行分类</em>中使用，我们就不从头开始分析了。相反，我们将关注与我们的业务场景最相关的查询。</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor152"/>检查数据质量</h2>
			<p>为了开始我们的<a id="_idIndexMarker482"/>数据探索并执行数据质量检查，我们需要做以下工作:</p>
			<ol>
				<li>登录我们的谷歌云控制台，从导航菜单中访问<strong class="bold"> BigQuery </strong> <strong class="bold">用户界面</strong> ( <strong class="bold"> UI </strong>)。</li>
				<li>在我们在<a href="B16722_02_Final_ASB_ePub.xhtml#_idTextAnchor039"> <em class="italic">第2章</em> </a>、<em class="italic">设置您的GCP和BigQuery环境</em>中创建的项目下创建一个新的数据集。对于这个用例，我们将使用默认选项创建一个<code>10_nyc_trees_xgboost</code>数据集。</li>
				<li>First of all, let's check if all the records contain a valid value in the <code>spc_latin</code> field by executing the following query: <pre>SELECT  COUNT(*)
FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
WHERE
         spc_latin is NULL;</pre><p>从下面的截图可以看到，有<code>spc_latin</code>栏。这些记录将在培训阶段被过滤掉:</p><div><img src="img/B16722_10_002.jpg" alt="Figure 10.2 – The query result shows that some records should be filtered out&#13;&#10;"/></div><p class="figure-caption">图10.2-查询结果显示一些记录应该被过滤掉</p></li>
				<li>在第一次检查后，我们<a id="_idIndexMarker483"/>需要验证是否有任何<a id="_idIndexMarker484"/>潜在特征以<code>NULL</code>值为特征。由于<code>sidewalk</code>和<code>health</code>字段中存在<code>NULL</code>值，让我们运行以下三个记录的<code>COUNT</code>。尽管数量很少，我们将在下面的查询中过滤掉这些记录，只使用有意义的记录。</li>
				<li>Then, we can extract the most common five tree species from the BigQuery public dataset. Let's execute the following query:<pre>SELECT   spc_latin,
         COUNT(*) total
FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
WHERE
         spc_latin is NOT NULL
         AND zip_city is NOT NULL
         AND tree_dbh is NOT NULL
         AND boroname is NOT NULL
         AND nta_name is NOT NULL
         AND health is NOT NULL
         AND sidewalk is NOT NULL
GROUP BY
         spc_latin
ORDER BY
         total desc
LIMIT 5; </pre><p>该查询计算每个<code>spc_latin</code>字段的<code>total</code>记录数。一个<code>ORDER BY</code>子句用于从<code>total</code>字段的最大值到最小值对结果进行排序。然后，使用一个<code>LIMIT 5</code>子句只返回前五条记录。</p><p>在下面的屏幕截图中，您可以看到查询的结果，其中显示了数据集中出现频率最高的五个物种:</p><div><img src="img/B16722_10_003.jpg" alt="Figure 10.3 – The most frequent tree species in the dataset&#13;&#10;"/></div><p class="figure-caption">图10.3-数据集中最常见的树种</p></li>
				<li>In order to<a id="_idIndexMarker486"/> materialize these five species into a table, let's execute the following code to create a <code>`10_nyc_trees_xgboost.top5_species`</code> table:<pre>CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.top5_species` AS
      SELECT   spc_latin,
         COUNT(*) total
      FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
      WHERE
               spc_latin is NOT NULL
               AND zip_city is NOT NULL
               AND tree_dbh is NOT NULL
               AND boroname is NOT NULL
               AND nta_name is NOT NULL
               AND health is NOT NULL
               AND sidewalk is NOT NULL
      GROUP BY
               spc_latin
      ORDER BY
               total desc
      LIMIT 5;</pre><p>与前一个<em class="italic">步骤5 </em>中执行的查询的唯一区别在于使用了<code>CREATE OR REPLACE TABLE</code>关键字，这些关键字用于将查询结果具体化到新表中。</p></li>
			</ol>
			<p>在这一节中，我们已经分析了BigQuery公共数据集的数据质量。现在，让我们开始将它分成三个不同的表格，分别用于培训、评估和分类阶段。</p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor153"/>分割数据集</h2>
			<p>在实现我们的XGBoost <a id="_idIndexMarker488"/>分类模型之前，让我们根据ML开发生命周期的主要阶段来划分我们的数据集:培训、评估和使用。为了将记录随机分成三个不同的表，我们将在<code>tree_id</code>数值字段上使用一个<code>MOD</code>函数。请遵循以下步骤:</p>
			<ol>
				<li value="1">First of all, let's create a table that will contain the training dataset. To do this, we execute the following SQL statement:<pre>CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.training_table` AS 
SELECT  *
FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
WHERE
         zip_city is NOT NULL
         AND tree_dbh is NOT NULL
         AND boroname is NOT NULL
         AND nta_name is NOT NULL
         AND health is NOT NULL
         AND sidewalk is NOT NULL
         AND spc_latin in 
         (SELECT spc_latin from `10_nyc_trees_xgboost.top5_species`) 
         AND MOD(tree_id,11)&lt;=8; </pre><p>该查询通过一个<code>SELECT *</code>语句创建一个包含原始数据集中所有可用列的<code>`10_nyc_trees_xgboost.training_table`</code>表。它应用所有必要的过滤器来获得<code>spc_latin</code>标签和所有其他特征的非空值。</p><p>使用一个<code>IN</code>子句，<code>training_table</code>将只包含与我们在数据集中识别的最常见的五个物种相关的记录。</p><p>带有<code>MOD(tree_id,11)&lt;=8</code>子句的查询的最后一行只允许我们从整个数据集中选取80%的记录。<code>MOD</code>代表<em class="italic">对</em>取模，返回<code>tree_id</code>除以11的余数<a id="_idIndexMarker489"/>。使用小于或等于运算符(<code>&lt;=</code>)，我们大约提取了整个数据集的80%。</p></li>
				<li>With a similar approach, we can create a  <code>`10_nyc_trees_xgboost.evaluation_table`</code> table that will be used for the evaluation of our ML model. Let's execute the following <code>CREATE TABLE</code> statement:<pre>CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.evaluation_table` AS 
SELECT  *
FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
WHERE
         zip_city is NOT NULL
         AND tree_dbh is NOT NULL
         AND boroname is NOT NULL
         AND nta_name is NOT NULL
         AND health is NOT NULL
         AND sidewalk is NOT NULL
         AND spc_latin in 
         (SELECT spc_latin from `06_nyc_trees.top5_species`) 
         AND MOD(tree_id,11)=9;</pre><p>与我们<a id="_idIndexMarker490"/>创建训练表时不同，对于<code>evaluation_table</code>表，我们通过应用<code>MOD(tree_id,11)=9</code>过滤器，仅从整个数据集中选取10%的记录。</p></li>
				<li>Finally, we'll execute the following SQL statement in order to create a <code>`10_nyc_trees_xgboost.classification_table`</code> table that will be used to apply our XGBoost classification model:<pre>CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.classification_table` AS 
SELECT  *
FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
WHERE
         zip_city is NOT NULL
         AND tree_dbh is NOT NULL
         AND boroname is NOT NULL
         AND nta_name is NOT NULL
         AND health is NOT NULL
         AND sidewalk is NOT NULL
         AND spc_latin in 
         (SELECT spc_latin from `10_nyc_trees_xgboost.top5_species`) 
         AND MOD(tree_id,11)=10;</pre><p>这个新表与以前的表非常相似，但是由于有了<code>MOD</code>函数，它将包含数据集的剩余10%。</p></li>
			</ol>
			<p>在本节中，我们已经<a id="_idIndexMarker491"/>分析了包含纽约市树木信息的数据集，应用了一些数据质量检查来排除空值，并对数据集进行了分段，重点关注五种最常见的物种。现在我们已经完成了准备步骤，是时候继续前进，开始训练我们的BigQuery ML模型了。</p>
			<h1 id="_idParaDest-152"><a id="_idTextAnchor154"/>训练XGBoost分类模型</h1>
			<p>既然我们已经将<a id="_idIndexMarker492"/>数据集分割成多个表来支持ML模型生命周期的不同阶段，那么让我们将注意力集中在我们的XGBoost分类模型的训练上。请遵循以下步骤:</p>
			<ol>
				<li value="1">Let's start with training our first ML model, <code>xgboost_classification_model_version_1</code>, as follows:<pre>CREATE OR REPLACE MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_1`
OPTIONS
  ( MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',
    BOOSTER_TYPE = 'GBTREE',
    NUM_PARALLEL_TREE = 1,
    MAX_ITERATIONS = 50,
    TREE_METHOD = 'HIST',
    EARLY_STOP = FALSE,
    AUTO_CLASS_WEIGHTS=TRUE
  ) AS
SELECT
  zip_city,
  tree_dbh,
  spc_latin as label
FROM
  `10_nyc_trees_xgboost.training_table` ;</pre><p>在这个BigQuery ML语句中，我们可以看到用于开始模型训练的<code>CREATE OR REPLACE MODEL</code>关键字。这些关键字后面是ML模型的标识符。</p><p>在标识符之后，我们<a id="_idIndexMarker493"/>可以注意到一个<code>OPTIONS</code>子句。对于<code>MODEL_TYPE</code>，我们选择了<code>BOOSTED_TREE_CLASSIFIER</code>选项，这允许我们构建XGBoost分类模型。<code>BOOSTER_TYPE = 'GBTREE'</code>子句被视为训练XGBoost提升树模型的默认选项。</p><p>为了限制训练的复杂性和资源消耗，我们选择了仅用一个<code>NUM_PARALLEL_TREE = 1</code>子句并行训练一棵树，并在<code>50</code>迭代后使用<code>MAX_ITERATIONS</code>停止训练。</p><p>XGBoost文档中为大型数据集建议了一个<code>HIST</code>参数，并且使用了一个<code>EARLY_STOP = FALSE</code>子句来防止训练阶段在第一次迭代后停止。</p><p>最后一个选项<code>AUTO_CLASS_WEIGHTS=TRUE</code>用于平衡权重——在不平衡数据集的情况下——某些树种可能比其他树种出现得更频繁。</p><p>这个模型的第一个版本试图预测每棵树的种类，仅利用树种植的<code>zip_city</code>代码和树的直径<code>tree_dbh</code>。</p></li>
				<li>At the end of the training, we can access the ML model from the BigQuery navigation menu to have a look at the performance of the model. Selecting the <strong class="bold">Evaluation</strong> tab, we can see the <strong class="bold">ROC AUC</strong> value. In this case, the value is <strong class="bold">0.7775</strong>, as we can see in the following screenshot:<div><img src="img/B16722_10_004.jpg" alt="Figure 10.4 – The Evaluation metrics of the XGBoost classification model&#13;&#10;"/></div><p class="figure-caption">图10.4–XG boost分类模型的评估指标</p><p>在同一个<strong class="bold">评估</strong>选项卡中，我们还可以<a id="_idIndexMarker494"/>可视化混淆矩阵，该矩阵显示预测值与实际值相等的次数，如下图所示:</p><div><img src="img/B16722_10_005.jpg" alt="Figure 10.5 – The Evaluation tab shows the confusion matrix for the XGBoost classification model&#13;&#10;"/></div><p class="figure-caption">图10.5–评估选项卡显示了XGBoost分类模型的混淆矩阵</p></li>
				<li>Let's try to improve our ML model by adding features that can be useful to classify the trees into<a id="_idIndexMarker495"/> different species. Let's train the second version of our BigQuery ML model by running the following code:<pre>CREATE OR REPLACE MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_2`
OPTIONS
  ( MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',
    BOOSTER_TYPE = 'GBTREE',
    NUM_PARALLEL_TREE = 1,
    MAX_ITERATIONS = 50,
    TREE_METHOD = 'HIST',
    EARLY_STOP = FALSE,
    AUTO_CLASS_WEIGHTS=TRUE
  ) AS
SELECT
  zip_city,
  tree_dbh,
  boroname,
  nta_name,
  spc_latin as label
FROM
  `10_nyc_trees_xgboost.training_table` ;</pre><p>与之前<em class="italic">步骤1 </em>的第一次尝试相比，我们增加了额外的功能。事实上，我们已经在特性中添加了包含在<code>boroname</code>字段和<code>nta_name</code>字段中的行政区名称，这提供了与树在城市中的位置相关的更具体的信息。</p><p>在执行SQL语句之后，让我们访问新模型的<strong class="bold">评估</strong>选项卡，看看我们是否正在改进它的性能。看一下<strong class="bold"> ROC AUC </strong>值<strong class="bold"> 0.80 </strong>，我们可以看到与第一个版本相比，我们的模型性能略有提高。</p></li>
				<li>Then, we'll try to add to <a id="_idIndexMarker496"/>our ML model other features related to the health of the tree and also to the intrusiveness of its roots, which can damage adjacent sidewalks, as follows:<pre>CREATE OR REPLACE MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`
OPTIONS
  ( MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',
    BOOSTER_TYPE = 'GBTREE',
    NUM_PARALLEL_TREE = 5,
    MAX_ITERATIONS = 50,
    TREE_METHOD = 'HIST',
    EARLY_STOP = FALSE,
    AUTO_CLASS_WEIGHTS=TRUE
  ) AS
SELECT
  zip_city,
  tree_dbh,
  boroname,
  nta_name,
  health,
  sidewalk,
  spc_latin as label
FROM
  `10_nyc_trees_xgboost.training_table`;</pre><p>与以前的ML模型相比，<code>xgboost_classification_model_version_3</code>模型包括一个<code>health</code>字段，用于描述我们的树的健康状态，以及一个<code>sidewalk</code>字段，用于指定树根是否正在破坏邻近的人行道。</p></li>
				<li>在BigQuery UI的<strong class="bold">评估</strong>选项卡中查看我们上一个ML模型的性能<a id="_idIndexMarker497"/>，我们可以注意到我们在<strong class="bold"> ROC AUC </strong>方面又实现了一次增长，值为<strong class="bold"> 0.8121 </strong>。</li>
			</ol>
			<p>在本节中，我们通过尝试在数据集中使用不同的特征来创建不同的ML模型。在接下来的步骤中，我们将使用具有最高<code>xgboost_classification_model_version_3</code>的模型。</p>
			<p>现在，让我们在评估数据集上开始XGBoost分类模型的评估阶段。</p>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor155"/>评估XGBoost分类模型</h1>
			<p>为了评估我们的<a id="_idIndexMarker498"/> BigQuery ML模型，我们将使用一个<code>ML.EVALUATE</code>函数和我们明确创建的表作为评估数据集。</p>
			<p>以下查询将告诉我们该模型是过度拟合，还是能够在新数据上表现良好:</p>
			<pre>SELECT
  roc_auc,
  CASE
    WHEN roc_auc &gt; .9 THEN 'EXCELLENT'
    WHEN roc_auc &gt; .8 THEN 'VERY GOOD'
    WHEN roc_auc &gt; .7 THEN 'GOOD'
    WHEN roc_auc &gt; .6 THEN 'FINE'
    WHEN roc_auc &gt; .5 THEN 'NEEDS IMPROVEMENTS'
  ELSE
  'POOR'
END
  AS model_quality
FROM 
  ML.EVALUATE(MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`,
    (
    SELECT
       zip_city,
       tree_dbh,
       boroname,
       nta_name,
       health,
       sidewalk,
       spc_latin as label
     FROM `10_nyc_trees_xgboost.evaluation_table`));</pre>
			<p><code>SELECT</code>语句<a id="_idIndexMarker499"/>提取了<code>ML.EVALUATE</code>函数返回的<code>roc_auc</code>值，也提供了从<code>'POOR'</code>开始，经过<code>'NEEDS IMPROVEMENTS'</code>、<code>'GOOD'</code>等中间阶段，可以达到<code>'EXCELLENT'</code>等级的模型质量的清晰描述。</p>
			<p>执行查询，我们可以看到分数是<strong class="bold">非常好</strong>，如下图所示:</p>
			<div><div><img src="img/B16722_10_006.jpg" alt="Figure 10.6 – The evaluation stage returns VERY GOOD for the quality of our BigQuery ML model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.6–评估阶段对我们的BigQuery ML模型的质量给出了非常好的评价</p>
			<p>现在我们已经评估了我们的ML模型，让我们看看如何将它应用于其他记录，以获得树的分类。</p>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor156"/>使用XGBoost分类模型</h1>
			<p>在本节中，我们将使用<a id="_idIndexMarker501"/> ML模型根据树木的特征将其分为五个不同的种类。</p>
			<p>为了测试我们的BigQuery ML模型，我们将在<code>classification_table</code>表上使用一个<code>ML.PREDICT</code>函数，如下所示:</p>
			<pre>SELECT
  tree_id,
  actual_label,
  predicted_label_probs,
  predicted_label
FROM
  ML.PREDICT (MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`,
    (
    SELECT
       tree_id,
       zip_city,
       tree_dbh,
       boroname,
       nta_name,
       health,
       sidewalk,
       spc_latin as actual_label
    FROM
      `10_nyc_trees_xgboost.classification_table`
     )
  );</pre>
			<p>该查询由一个<code>SELECT</code>语句组成，该语句提取<code>tree_id</code>值、<a id="_idIndexMarker502"/>树的实际物种、每个预测物种的概率以及预测物种。</p>
			<p>在下面的屏幕截图中，您可以看到查询执行的结果:</p>
			<div><div><img src="img/B16722_10_007.jpg" alt="Figure 10.7 – The output of the query shows the actual and predicted labels &#13;&#10;with the related probabilities&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.7-查询的输出显示了实际和预测的标签以及相关的概率</p>
			<p>在前面的截图中呈现的两行中，标识符为<strong class="bold"> 283502 </strong>和<strong class="bold"> 226929 </strong>的树被很好地分类为<strong class="bold">槭属悬铃木</strong>物种，置信度为61%。</p>
			<p>现在我们已经测试了我们的BigQuery ML模型，让我们通过比较XGBoost分类模型的结果和在<a href="B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088"> <em class="italic">第6章</em> </a>，<em class="italic">用多类逻辑回归分类树</em>中使用的逻辑回归的结果来做一些最后的考虑。</p>
			<h1 id="_idParaDest-155"><a id="_idTextAnchor157"/>得出商业结论</h1>
			<p>在这一节中，我们将使用<a id="_idIndexMarker503"/>我们的ML模型，我们将了解BigQuery ML模型能够对<code>classification_table</code>表中的树进行多少次分类。</p>
			<p>让我们执行以下查询来计算预测物种与实际物种一致的次数:</p>
			<pre>SELECT COUNT(*)
FROM (
      SELECT
        tree_id,
        actual_label,
        predicted_label_probs,
        predicted_label
      FROM
        ML.PREDICT (MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`,
          (
          SELECT
             tree_id,
             zip_city,
             tree_dbh,
             boroname,
             nta_name,
             health,
             sidewalk,
             spc_latin as actual_label
          FROM
            `10_nyc_trees_xgboost.classification_table`
           )
        )
)
WHERE
      actual_label = predicted_label; </pre>
			<p>为了计算这个值，我们引入了一个<code>WHERE</code>子句，只过滤预测值等于实际值的行。</p>
			<p>正如我们在下面的<a id="_idIndexMarker504"/>截图中看到的，<code>SELECT COUNT</code>返回一个<strong class="bold"> 14277 </strong>记录的值:</p>
			<div><div><img src="img/B16722_10_008.jpg" alt="Figure 10.8 – The output of the query shows how many times the classification &#13;&#10;model predicts the right species&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.8-查询的输出显示了分类模型预测正确物种的次数</p>
			<p>在存储在<code>classification_table</code>表中的总共27，182行中，我们可以说我们的模型在52.52%的情况下将树木分类到正确的物种中。</p>
			<p>在下表中，XGBoost分类模型的结果与多类逻辑回归获得的结果进行了比较，应用于<a href="B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088"> <em class="italic">第6章</em> </a>、<em class="italic">用多类逻辑回归对树进行分类</em>:</p>
			<div><div><img src="img/B16722_10_009.jpg" alt=" Figure 10.9 – Comparison of the XGBoost classification model and multiclass logistic regression &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.9-XGBoost分类模型和多类逻辑回归的比较</p>
			<p>查看上表，我们可以说，与多类逻辑回归模型相比，<a id="_idIndexMarker505"/> XGBoost分类模型能够获得更好的结果。</p>
			<h1 id="_idParaDest-156"><a id="_idTextAnchor158"/>总结</h1>
			<p>在这一章中，我们实现了一个XGBoost分类模型。我们还记得已经在<a href="B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088"> <em class="italic">第6章</em></a><em class="italic">中使用的业务场景，基于自动分类纽约市树的需要，使用多类逻辑回归</em>对树进行分类。之后，我们学习了XGBoost提升树分类模型的基础知识。</p>
			<p>为了建立有效的模型，我们执行了数据质量检查，然后根据我们的需要将数据集分成三个表:一个用于存储训练数据，第二个用于评估阶段，最后一个用于应用我们的分类模型。</p>
			<p>在BigQuery ML模型的训练阶段，我们不断改进ML模型的性能，使用ROC AUC作为关键性能指标 ( <strong class="bold"> KPI </strong>)。</p>
			<p>之后，我们在一组新的记录上评估了最佳ML模型，以避免任何过度拟合，对我们的XGBoost分类模型的良好质量更加有信心。</p>
			<p>最后，我们将BigQuery ML模型应用于最后一个记录子集，根据树的特征将树分类。我们发现我们的ML模型能够在52.52%的情况下正确地对树进行分类。然后，我们还将XGBoost模型的性能与我们在<a href="B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088"> <em class="italic">第6章</em> </a>、<em class="italic">使用多类逻辑回归对树进行分类</em>中进行的多类逻辑回归训练进行了比较，并注意到XGBoost超过了多类逻辑回归训练的性能。</p>
			<p>在下一章，我们将学习高级的<strong class="bold">深度神经网络</strong> ( <strong class="bold"> DNNs </strong>)，利用BigQuery SQL语法。</p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor159"/>更多资源</h1>
			<ul>
				<li><strong class="bold">纽约市街道树木普查公共数据集</strong>:<a href="https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tree-census">https://console . cloud . Google . com/market place/product/city-of-new York/NYC-Tree-Census</a></li>
				<li><strong class="bold"> XGBoost首页</strong>:<a href="https://xgboost.ai/">https://xgboost.ai/</a></li>
				<li><strong class="bold"> XGBoost文档</strong>:<a href="https://xgboost.readthedocs.io/en/latest/index.html">https://xgboost.readthedocs.io/en/latest/index.html</a></li>
				<li><code>CREATE MODEL</code><strong class="bold">Boosted树模型语句</strong>:<a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree">https://cloud . Google . com/big query-ml/docs/reference/standard-SQL/bigqueryml-syntax-create-Boosted-Tree</a></li>
				<li><code>ML.EVALUATE</code> <strong class="bold">功能</strong>:<a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate">https://cloud . Google . com/big query-ml/docs/reference/standard-SQL/bigqueryml-syntax-evaluate</a></li>
				<li><code>ML.PREDICT</code> <strong class="bold">功能</strong>:<a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict">https://cloud . Google . com/big query-ml/docs/reference/standard-SQL/bigqueryml-syntax-predict</a></li>
			</ul>
		</div>
	

</body></html>