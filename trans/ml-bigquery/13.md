<title>B16722_10_Final_ASB_ePub</title>

# *第十章*:使用 XGBoost 预测布尔值

**极限梯度提升** ( **XGBoost** )是最强大的**机器学习** ( **ML** )库之一，数据科学家可以利用它以高效灵活的方式解决复杂的用例。它最初是一个研究项目，第一个版本于 2014 年发布。由于它的功能和可移植性，这个 ML 库的受欢迎程度增长很快。事实上，它曾被用于重要的 Kaggle ML 竞赛，现在可用于不同的编程语言和不同的操作系统。

这个库可以用来处理不同的 ML 问题，并且是专门为结构化数据设计的。XGBoost 最近也为 BigQuery ML 发布了。由于这种技术，BigQuery 用户可以使用这个库实现分类和回归 ML 模型。

在这一章中，我们将看到实现 XGBoost 分类模型以根据纽约市树木的特征将它们分类为不同种类所需的所有步骤。

使用 BigQuery ML SQL 方言，我们将浏览以下主题:

*   介绍业务场景
*   发现 XGBoost 提升的树分类模型
*   探索和理解数据集
*   为 XGBoost 分类模型定型
*   评估 XGBoost 分类模型
*   使用 XGBoost 分类模型
*   得出商业结论

# 技术要求

本章要求您能够访问网络浏览器，并能够利用以下内容:

*   一个**谷歌云平台** ( **GCP** )账户，用于访问谷歌云控制台
*   托管 BigQuery 数据集的 GCP 项目

既然我们在技术需求方面已经准备好了，那么让我们开始分析和开发我们的 BigQuery ML XGBoost 分类模型。

请看下面的视频，看看代码是如何运行的:[https://bit.ly/3ujnzH3](https://bit.ly/3ujnzH3)

# 介绍业务场景

在本节中，我们将介绍使用 XGBoost 分类算法处理的业务场景。

该业务场景与 [*第 6 章*](B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088) 、*用多类逻辑回归对树进行分类*中提出和使用的用例非常相似。在本章中，我们将使用相同的数据集，但将应用更高级的 ML 算法。

我们可以总结并记住，ML 模型的目标是根据纽约市的树木的特征，如它们的位置、大小和健康状况，将它们自动分类为不同的种类。

正如我们在 [*第 9 章*](B16722_09_Final_ASB_ePub.xhtml#_idTextAnchor133)*中所做的那样，通过使用矩阵分解*建议合适的产品，我们可以将注意力集中在城市中最常见的五种树木上。

既然我们已经解释并理解了业务场景，那么让我们来看看 ML 技术，我们可以使用它来根据树的特征对树进行自动分类。

# 发现 XGBoost 提升树分类模型

在本节中，我们将了解什么是 **XGBoost Boosted Trees** 分类模型，并且我们将了解哪些分类用例可以用这种 ML 算法来处理。

XGBoost 是一个开放的源码库，为不同的语言提供了一个可移植的渐变增强框架。XGBoost 库可用于不同的编程语言，如 C++、Java、Python、R 和 Scala，并且可以在不同的操作系统上工作。XGBoost 用于处理监督学习用例，其中我们使用标记的训练数据来预测目标变量。

多年来，XGBoost 在 ML 社区中的知名度不断增长，因为它经常是 ML 比赛期间许多获胜团队的选择，如 2016 年的 *Kaggle -高能物理与机器学习奖*。

**XGBoost Boosted 树**的分类功能基于对数据进行分类以实现预测的多个决策树的使用。

在下图中，您可以看到对动物进行分类的决策树的简单表示:

![](img/B16722_10_001.jpg)

图 10.1-决策树的表示

XGBoost 分类模型可以回答多类逻辑回归解决的相同问题，例如:

*   我的客户*的评论是中立的*、*正面的*还是*负面的*？
*   我的客户属于*黄金*、*白银*还是*青铜*级别？
*   特定客户*流失的概率是高*、*中*还是*低*？
*   图像识别算法是识别一只*猫*，一只*狗*，一只*老鼠*，还是一头*牛*？

在我们的业务场景中，我们可以利用 XGBoost Boosted 树分类模型将纽约市的树分为五个不同的种类。事实上，我们感兴趣的是根据每棵树的特征来预测物种。

在 XGBoost 算法的训练阶段，ML 模型试图找到分配给每棵树的最佳值，以便最小化最终的误差度量。

训练结束后，我们将把这个模型的结果与我们在 [*第 6 章*](B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088) 、*用多类逻辑回归分类树*中得到的结果进行比较。

现在我们已经学习了 XGBoost Boosted Tree 算法的基础，是时候看看我们将用来构建 ML 模型的数据集了。

# 探索和理解数据集

在这一部分，我们将分析并准备我们用例的数据集。我们将从一些数据质量检查开始，然后我们将数据分成训练、评估和测试表。

由于数据集已经在 [*第 6 章*](B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088) 、*用多类逻辑回归对树进行分类*中使用，我们就不从头开始分析了。相反，我们将关注与我们的业务场景最相关的查询。

## 检查数据质量

为了开始我们的数据探索并执行数据质量检查，我们需要做以下工作:

1.  登录我们的谷歌云控制台，从导航菜单中访问 **BigQuery** **用户界面** ( **UI** )。
2.  在我们在 [*第 2 章*](B16722_02_Final_ASB_ePub.xhtml#_idTextAnchor039) 、*设置您的 GCP 和 BigQuery 环境*中创建的项目下创建一个新的数据集。对于这个用例，我们将使用默认选项创建一个`10_nyc_trees_xgboost`数据集。
3.  First of all, let's check if all the records contain a valid value in the `spc_latin` field by executing the following query:

    ```
    SELECT  COUNT(*)
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             spc_latin is NULL;
    ```

    从下面的截图可以看到，有`spc_latin`栏。这些记录将在培训阶段被过滤掉:

    ![Figure 10.2 – The query result shows that some records should be filtered out
    ](img/B16722_10_002.jpg)

    图 10.2-查询结果显示一些记录应该被过滤掉

4.  在第一次检查后，我们需要验证是否有任何潜在特征以`NULL`值为特征。由于`sidewalk`和`health`字段中存在`NULL`值，让我们运行以下三个记录的`COUNT`。尽管数量很少，我们将在下面的查询中过滤掉这些记录，只使用有意义的记录。
5.  Then, we can extract the most common five tree species from the BigQuery public dataset. Let's execute the following query:

    ```
    SELECT   spc_latin,
             COUNT(*) total
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             spc_latin is NOT NULL
             AND zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
    GROUP BY
             spc_latin
    ORDER BY
             total desc
    LIMIT 5; 
    ```

    该查询计算每个`spc_latin`字段的`total`记录数。一个`ORDER BY`子句用于从`total`字段的最大值到最小值对结果进行排序。然后，使用一个`LIMIT 5`子句只返回前五条记录。

    在下面的屏幕截图中，您可以看到查询的结果，其中显示了数据集中出现频率最高的五个物种:

    ![Figure 10.3 – The most frequent tree species in the dataset
    ](img/B16722_10_003.jpg)

    图 10.3-数据集中最常见的树种

6.  In order to materialize these five species into a table, let's execute the following code to create a ``10_nyc_trees_xgboost.top5_species`` table:

    ```
    CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.top5_species` AS
          SELECT   spc_latin,
             COUNT(*) total
          FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
          WHERE
                   spc_latin is NOT NULL
                   AND zip_city is NOT NULL
                   AND tree_dbh is NOT NULL
                   AND boroname is NOT NULL
                   AND nta_name is NOT NULL
                   AND health is NOT NULL
                   AND sidewalk is NOT NULL
          GROUP BY
                   spc_latin
          ORDER BY
                   total desc
          LIMIT 5;
    ```

    与前一个*步骤 5* 中执行的查询的唯一区别在于使用了`CREATE OR REPLACE TABLE`关键字，这些关键字用于将查询结果具体化到新表中。

在这一节中，我们已经分析了 BigQuery 公共数据集的数据质量。现在，让我们开始将它分成三个不同的表格，分别用于培训、评估和分类阶段。

## 分割数据集

在实现我们的 XGBoost 分类模型之前，让我们根据 ML 开发生命周期的主要阶段来划分我们的数据集:培训、评估和使用。为了将记录随机分成三个不同的表，我们将在`tree_id`数值字段上使用一个`MOD`函数。请遵循以下步骤:

1.  First of all, let's create a table that will contain the training dataset. To do this, we execute the following SQL statement:

    ```
    CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.training_table` AS 
    SELECT  *
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
             AND spc_latin in 
             (SELECT spc_latin from `10_nyc_trees_xgboost.top5_species`) 
             AND MOD(tree_id,11)<=8; 
    ```

    该查询通过一个`SELECT *`语句创建一个包含原始数据集中所有可用列的``10_nyc_trees_xgboost.training_table``表。它应用所有必要的过滤器来获得`spc_latin`标签和所有其他特征的非空值。

    使用一个`IN`子句，`training_table`将只包含与我们在数据集中识别的最常见的五个物种相关的记录。

    带有`MOD(tree_id,11)<=8`子句的查询的最后一行只允许我们从整个数据集中选取 80%的记录。`MOD`代表*对*取模，返回`tree_id`除以 11 的余数。使用小于或等于运算符(`<=`)，我们大约提取了整个数据集的 80%。

2.  With a similar approach, we can create a ``10_nyc_trees_xgboost.evaluation_table`` table that will be used for the evaluation of our ML model. Let's execute the following `CREATE TABLE` statement:

    ```
    CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.evaluation_table` AS 
    SELECT  *
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
             AND spc_latin in 
             (SELECT spc_latin from `06_nyc_trees.top5_species`) 
             AND MOD(tree_id,11)=9;
    ```

    与我们创建训练表时不同，对于`evaluation_table`表，我们通过应用`MOD(tree_id,11)=9`过滤器，仅从整个数据集中选取 10%的记录。

3.  Finally, we'll execute the following SQL statement in order to create a ``10_nyc_trees_xgboost.classification_table`` table that will be used to apply our XGBoost classification model:

    ```
    CREATE OR REPLACE TABLE `10_nyc_trees_xgboost.classification_table` AS 
    SELECT  *
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
             AND spc_latin in 
             (SELECT spc_latin from `10_nyc_trees_xgboost.top5_species`) 
             AND MOD(tree_id,11)=10;
    ```

    这个新表与以前的表非常相似，但是由于有了`MOD`函数，它将包含数据集的剩余 10%。

在本节中，我们已经分析了包含纽约市树木信息的数据集，应用了一些数据质量检查来排除空值，并对数据集进行了分段，重点关注五种最常见的物种。现在我们已经完成了准备步骤，是时候继续前进，开始训练我们的 BigQuery ML 模型了。

# 训练 XGBoost 分类模型

既然我们已经将数据集分割成多个表来支持 ML 模型生命周期的不同阶段，那么让我们将注意力集中在我们的 XGBoost 分类模型的训练上。请遵循以下步骤:

1.  Let's start with training our first ML model, `xgboost_classification_model_version_1`, as follows:

    ```
    CREATE OR REPLACE MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_1`
    OPTIONS
      ( MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',
        BOOSTER_TYPE = 'GBTREE',
        NUM_PARALLEL_TREE = 1,
        MAX_ITERATIONS = 50,
        TREE_METHOD = 'HIST',
        EARLY_STOP = FALSE,
        AUTO_CLASS_WEIGHTS=TRUE
      ) AS
    SELECT
      zip_city,
      tree_dbh,
      spc_latin as label
    FROM
      `10_nyc_trees_xgboost.training_table` ;
    ```

    在这个 BigQuery ML 语句中，我们可以看到用于开始模型训练的`CREATE OR REPLACE MODEL`关键字。这些关键字后面是 ML 模型的标识符。

    在标识符之后，我们可以注意到一个`OPTIONS`子句。对于`MODEL_TYPE`，我们选择了`BOOSTED_TREE_CLASSIFIER`选项，这允许我们构建 XGBoost 分类模型。`BOOSTER_TYPE = 'GBTREE'`子句被视为训练 XGBoost 提升树模型的默认选项。

    为了限制训练的复杂性和资源消耗，我们选择了仅用一个`NUM_PARALLEL_TREE = 1`子句并行训练一棵树，并在`50`迭代后使用`MAX_ITERATIONS`停止训练。

    XGBoost 文档中为大型数据集建议了一个`HIST`参数，并且使用了一个`EARLY_STOP = FALSE`子句来防止训练阶段在第一次迭代后停止。

    最后一个选项`AUTO_CLASS_WEIGHTS=TRUE`用于平衡权重——在不平衡数据集的情况下——某些树种可能比其他树种出现得更频繁。

    这个模型的第一个版本试图预测每棵树的种类，仅利用树种植的`zip_city`代码和树的直径`tree_dbh`。

2.  At the end of the training, we can access the ML model from the BigQuery navigation menu to have a look at the performance of the model. Selecting the **Evaluation** tab, we can see the **ROC AUC** value. In this case, the value is **0.7775**, as we can see in the following screenshot:![Figure 10.4 – The Evaluation metrics of the XGBoost classification model
    ](img/B16722_10_004.jpg)

    图 10.4–XG boost 分类模型的评估指标

    在同一个**评估**选项卡中，我们还可以可视化混淆矩阵，该矩阵显示预测值与实际值相等的次数，如下图所示:

    ![Figure 10.5 – The Evaluation tab shows the confusion matrix for the XGBoost classification model
    ](img/B16722_10_005.jpg)

    图 10.5–评估选项卡显示了 XGBoost 分类模型的混淆矩阵

3.  Let's try to improve our ML model by adding features that can be useful to classify the trees into different species. Let's train the second version of our BigQuery ML model by running the following code:

    ```
    CREATE OR REPLACE MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_2`
    OPTIONS
      ( MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',
        BOOSTER_TYPE = 'GBTREE',
        NUM_PARALLEL_TREE = 1,
        MAX_ITERATIONS = 50,
        TREE_METHOD = 'HIST',
        EARLY_STOP = FALSE,
        AUTO_CLASS_WEIGHTS=TRUE
      ) AS
    SELECT
      zip_city,
      tree_dbh,
      boroname,
      nta_name,
      spc_latin as label
    FROM
      `10_nyc_trees_xgboost.training_table` ;
    ```

    与之前*步骤 1* 的第一次尝试相比，我们增加了额外的功能。事实上，我们已经在特性中添加了包含在`boroname`字段和`nta_name`字段中的行政区名称，这提供了与树在城市中的位置相关的更具体的信息。

    在执行 SQL 语句之后，让我们访问新模型的**评估**选项卡，看看我们是否正在改进它的性能。看一下 **ROC AUC** 值 **0.80** ，我们可以看到与第一个版本相比，我们的模型性能略有提高。

4.  Then, we'll try to add to our ML model other features related to the health of the tree and also to the intrusiveness of its roots, which can damage adjacent sidewalks, as follows:

    ```
    CREATE OR REPLACE MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`
    OPTIONS
      ( MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',
        BOOSTER_TYPE = 'GBTREE',
        NUM_PARALLEL_TREE = 5,
        MAX_ITERATIONS = 50,
        TREE_METHOD = 'HIST',
        EARLY_STOP = FALSE,
        AUTO_CLASS_WEIGHTS=TRUE
      ) AS
    SELECT
      zip_city,
      tree_dbh,
      boroname,
      nta_name,
      health,
      sidewalk,
      spc_latin as label
    FROM
      `10_nyc_trees_xgboost.training_table`;
    ```

    与以前的 ML 模型相比，`xgboost_classification_model_version_3`模型包括一个`health`字段，用于描述我们的树的健康状态，以及一个`sidewalk`字段，用于指定树根是否正在破坏邻近的人行道。

5.  在 BigQuery UI 的**评估**选项卡中查看我们上一个 ML 模型的性能，我们可以注意到我们在 **ROC AUC** 方面又实现了一次增长，值为 **0.8121** 。

在本节中，我们通过尝试在数据集中使用不同的特征来创建不同的 ML 模型。在接下来的步骤中，我们将使用具有最高`xgboost_classification_model_version_3`的模型。

现在，让我们在评估数据集上开始 XGBoost 分类模型的评估阶段。

# 评估 XGBoost 分类模型

为了评估我们的 BigQuery ML 模型，我们将使用一个`ML.EVALUATE`函数和我们明确创建的表作为评估数据集。

以下查询将告诉我们该模型是过度拟合，还是能够在新数据上表现良好:

```
SELECT
  roc_auc,
  CASE
    WHEN roc_auc > .9 THEN 'EXCELLENT'
    WHEN roc_auc > .8 THEN 'VERY GOOD'
    WHEN roc_auc > .7 THEN 'GOOD'
    WHEN roc_auc > .6 THEN 'FINE'
    WHEN roc_auc > .5 THEN 'NEEDS IMPROVEMENTS'
  ELSE
  'POOR'
END
  AS model_quality
FROM 
  ML.EVALUATE(MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`,
    (
    SELECT
       zip_city,
       tree_dbh,
       boroname,
       nta_name,
       health,
       sidewalk,
       spc_latin as label
     FROM `10_nyc_trees_xgboost.evaluation_table`));
```

`SELECT`语句提取了`ML.EVALUATE`函数返回的`roc_auc`值，也提供了从`'POOR'`开始，经过`'NEEDS IMPROVEMENTS'`、`'GOOD'`等中间阶段，可以达到`'EXCELLENT'`等级的模型质量的清晰描述。

执行查询，我们可以看到分数是**非常好**，如下图所示:

![Figure 10.6 – The evaluation stage returns VERY GOOD for the quality of our BigQuery ML model
](img/B16722_10_006.jpg)

图 10.6–评估阶段对我们的 BigQuery ML 模型的质量给出了非常好的评价

现在我们已经评估了我们的 ML 模型，让我们看看如何将它应用于其他记录，以获得树的分类。

# 使用 XGBoost 分类模型

在本节中，我们将使用 ML 模型根据树木的特征将其分为五个不同的种类。

为了测试我们的 BigQuery ML 模型，我们将在`classification_table`表上使用一个`ML.PREDICT`函数，如下所示:

```
SELECT
  tree_id,
  actual_label,
  predicted_label_probs,
  predicted_label
FROM
  ML.PREDICT (MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`,
    (
    SELECT
       tree_id,
       zip_city,
       tree_dbh,
       boroname,
       nta_name,
       health,
       sidewalk,
       spc_latin as actual_label
    FROM
      `10_nyc_trees_xgboost.classification_table`
     )
  );
```

该查询由一个`SELECT`语句组成，该语句提取`tree_id`值、树的实际物种、每个预测物种的概率以及预测物种。

在下面的屏幕截图中，您可以看到查询执行的结果:

![Figure 10.7 – The output of the query shows the actual and predicted labels 
with the related probabilities
](img/B16722_10_007.jpg)

图 10.7-查询的输出显示了实际和预测的标签以及相关的概率

在前面的截图中呈现的两行中，标识符为 **283502** 和 **226929** 的树被很好地分类为**槭属悬铃木**物种，置信度为 61%。

现在我们已经测试了我们的 BigQuery ML 模型，让我们通过比较 XGBoost 分类模型的结果和在 [*第 6 章*](B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088) ，*用多类逻辑回归分类树*中使用的逻辑回归的结果来做一些最后的考虑。

# 得出商业结论

在这一节中，我们将使用我们的 ML 模型，我们将了解 BigQuery ML 模型能够对`classification_table`表中的树进行多少次分类。

让我们执行以下查询来计算预测物种与实际物种一致的次数:

```
SELECT COUNT(*)
FROM (
      SELECT
        tree_id,
        actual_label,
        predicted_label_probs,
        predicted_label
      FROM
        ML.PREDICT (MODEL `10_nyc_trees_xgboost.xgboost_classification_model_version_3`,
          (
          SELECT
             tree_id,
             zip_city,
             tree_dbh,
             boroname,
             nta_name,
             health,
             sidewalk,
             spc_latin as actual_label
          FROM
            `10_nyc_trees_xgboost.classification_table`
           )
        )
)
WHERE
      actual_label = predicted_label; 
```

为了计算这个值，我们引入了一个`WHERE`子句，只过滤预测值等于实际值的行。

正如我们在下面的截图中看到的，`SELECT COUNT`返回一个 **14277** 记录的值:

![Figure 10.8 – The output of the query shows how many times the classification 
model predicts the right species
](img/B16722_10_008.jpg)

图 10.8-查询的输出显示了分类模型预测正确物种的次数

在存储在`classification_table`表中的总共 27，182 行中，我们可以说我们的模型在 52.52%的情况下将树木分类到正确的物种中。

在下表中，XGBoost 分类模型的结果与多类逻辑回归获得的结果进行了比较，应用于 [*第 6 章*](B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088) 、*用多类逻辑回归对树进行分类*:

![ Figure 10.9 – Comparison of the XGBoost classification model and multiclass logistic regression 
](img/B16722_10_009.jpg)

图 10.9-XGBoost 分类模型和多类逻辑回归的比较

查看上表，我们可以说，与多类逻辑回归模型相比， XGBoost 分类模型能够获得更好的结果。

# 总结

在这一章中，我们实现了一个 XGBoost 分类模型。我们还记得已经在 [*第 6 章*](B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088)*中使用的业务场景，基于自动分类纽约市树的需要，使用多类逻辑回归*对树进行分类。之后，我们学习了 XGBoost 提升树分类模型的基础知识。

为了建立有效的模型，我们执行了数据质量检查，然后根据我们的需要将数据集分成三个表:一个用于存储训练数据，第二个用于评估阶段，最后一个用于应用我们的分类模型。

在 BigQuery ML 模型的训练阶段，我们不断改进 ML 模型的性能，使用 ROC AUC 作为关键性能指标 ( **KPI** )。

之后，我们在一组新的记录上评估了最佳 ML 模型，以避免任何过度拟合，对我们的 XGBoost 分类模型的良好质量更加有信心。

最后，我们将 BigQuery ML 模型应用于最后一个记录子集，根据树的特征将树分类。我们发现我们的 ML 模型能够在 52.52%的情况下正确地对树进行分类。然后，我们还将 XGBoost 模型的性能与我们在 [*第 6 章*](B16722_06_Final_ASB_ePub.xhtml#_idTextAnchor088) 、*使用多类逻辑回归对树进行分类*中进行的多类逻辑回归训练进行了比较，并注意到 XGBoost 超过了多类逻辑回归训练的性能。

在下一章，我们将学习高级的**深度神经网络** ( **DNNs** )，利用 BigQuery SQL 语法。

# 更多资源

*   **纽约市街道树木普查公共数据集**:[https://console . cloud . Google . com/market place/product/city-of-new York/NYC-Tree-Census](https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tree-census)
*   **XGBoost 首页**:[https://xgboost.ai/](https://xgboost.ai/)
*   **XGBoost 文档**:[https://xgboost.readthedocs.io/en/latest/index.html](https://xgboost.readthedocs.io/en/latest/index.html)
*   `CREATE MODEL`**Boosted 树模型语句**:[https://cloud . Google . com/big query-ml/docs/reference/standard-SQL/bigqueryml-syntax-create-Boosted-Tree](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)
*   `ML.EVALUATE` **功能**:[https://cloud . Google . com/big query-ml/docs/reference/standard-SQL/bigqueryml-syntax-evaluate](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate)
*   `ML.PREDICT` **功能**:[https://cloud . Google . com/big query-ml/docs/reference/standard-SQL/bigqueryml-syntax-predict](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict)