<html><head/><body>





<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}</style>
<div><div><h1 id="_idParaDest-62"><em class="italic"> <a id="_idTextAnchor061"/>第二章</em>:构建和使用自己的算法容器映像</h1>
			<p>在前一章中，我们使用名为<strong class="bold">线性学习器</strong>的<strong class="bold">亚马逊SageMaker </strong>内置算法进行了一个简化的端到端机器学习实验。在写的时候有17个内置算法可以选择！根据我们的要求，我们可能会简单地从这17个内置算法中选择一个或多个算法来解决我们的机器学习问题。在现实生活中，我们将处理预训练模型和其他算法，这些算法不在SageMaker的内置算法列表中。Amazon SageMaker的优势之一是它的灵活性，并通过使用自定义容器映像支持自定义模型和算法。比方说，你想使用SageMaker内置算法列表中没有的算法，比如<strong class="bold">支持向量机</strong> ( <strong class="bold"> SVM </strong>)，来解决你的机器学习问题。如果是这样的话，那么这一章就是给你看的！</p>
			<div><div><img src="img/B16850_02_01.jpg" alt="Figure 2.1 – Chapter 2 recipes&#13;&#10;" width="1289" height="791"/>
				</div>
			</div>
			<p class="figure-caption">图2.1–第2章配方</p>
			<p>在这一章中，我们将在亚马逊SageMaker<strong class="bold">中创建和使用我们自己的算法容器映像。通过这种方法，我们可以使用任何定制的脚本、库、框架或算法。本章将告诉我们如何通过定制的容器映像来充分利用亚马逊SageMaker。如上图所示，我们将首先使用<strong class="bold"> AWS Cloud9 </strong>建立一个基于云的集成开发环境，在构建容器映像之前，我们将在其中准备、配置和测试脚本。一旦我们准备好了环境，我们将在这个环境中编码火车和服务脚本。训练脚本将在训练期间使用，而服务脚本将用于部署模型的推理端点。然后，我们将准备一个docker文件，它利用了我们在前面的步骤中生成的train和serve脚本。一旦这个docker文件准备就绪，我们将构建定制的容器映像，并使用容器映像通过<strong class="bold"> SageMaker Python SDK </strong>进行训练和推理。我们将在Python和r中研究这些步骤。</strong></p>
			<p>我们将在本章中介绍以下配方:</p>
			<ul>
				<li>启动和准备<strong class="bold">云9 </strong>环境</li>
				<li>设置Python和R实验环境</li>
				<li>用Python编写和测试训练脚本</li>
				<li>在Python中准备和测试serve脚本</li>
				<li>构建和测试自定义Python算法容器映像</li>
				<li>将定制Python算法容器映像推送到一个<strong class="bold"> Amazon ECR </strong>存储库中</li>
				<li>使用自定义Python算法容器映像，通过<strong class="bold"> Amazon SageMaker本地模式</strong>进行训练和推理</li>
				<li>在R中准备和测试训练脚本</li>
				<li>在R中准备和测试serve脚本</li>
				<li>构建和测试自定义R算法容器映像</li>
				<li>将自定义R算法容器映像推送到一个<strong class="bold"> Amazon ECR </strong>存储库中</li>
				<li>使用自定义的R算法容器图像进行训练和推理，使用<strong class="bold"> Amazon SageMaker本地模式</strong></li>
			</ul>
			<p>在我们完成本章的食谱后，我们将准备在<strong class="bold"> SageMaker </strong>中使用我们自己的算法和自定义容器映像。这将大大扩展我们在内置算法和由<strong class="bold"> SageMaker </strong>提供的容器映像之外所能做的事情。与此同时，本章中使用的技术和概念将为您提供处理类似需求所需的经验，您将在接下来的章节中看到这一点。</p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor062"/>技术要求</h1>
			<p>要完成本章中的食谱，您需要以下内容:</p>
			<ul>
				<li>一个正在运行的<strong class="bold">亚马逊SageMaker </strong>笔记本实例(例如ml.t2.large)。请随意使用我们在第一章 、<em class="italic">的<em class="italic">启动亚马逊SageMaker笔记本实例</em>配方<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020">、<em class="italic">中启动的SageMaker笔记本实例。</em></a></em></li>
				<li>管理<strong class="bold">亚马逊SageMaker </strong>、<strong class="bold">亚马逊S3 </strong>和<strong class="bold"> AWS Cloud9 </strong>资源的权限，如果你正在使用一个带有自定义URL的<strong class="bold"> AWS IAM </strong>用户。在大多数情况下，建议以AWS IAM用户身份登录，而不是使用root帐户。有关更多信息，请随意查看<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">https://docs . AWS . Amazon . com/IAM/latest/user guide/best-practices . html</a>。</li>
			</ul>
			<p>本书的GitHub资源库中提供了Jupyter笔记本、源代码和每章使用的CSV文件:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/tree/master/Chapter02">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/tree/master/chapter 02</a>。</p>
			<p>请点击以下链接查看动作视频中的相关代码:</p>
			<p>https://bit.ly/38Uvemc<a href="https://bit.ly/38Uvemc"/></p>
			<h1 id="_idParaDest-64"><a id="_idTextAnchor063"/>启动和准备Cloud9环境</h1>
			<p>在这个菜谱中，我们<a id="_idIndexMarker196"/>将启动并配置一个运行<strong class="bold"> Ubuntu </strong>服务器的<strong class="bold"> AWS Cloud9 </strong>实例<a id="_idIndexMarker197"/>。这将作为本章中其他配方的实验和模拟环境。之后，我们将调整附加到实例的卷的大小，以便我们可以在以后构建容器映像。这将确保我们在使用Docker容器和容器映像时不必担心磁盘空间问题。在接下来的菜谱中，我们将准备我们的train和serve脚本在自定义容器中时所期望的文件和目录结构。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">为什么要花这么大力气准备一个实验环境呢？一旦我们完成了实验环境的准备，我们将能够快速准备、测试和更新定制脚本，而不必在编写脚本的初始阶段使用来自<strong class="bold"> SageMaker Python SDK </strong>的fit()和deploy()函数。使用这种方法，反馈循环要快得多，我们甚至可以在培训和部署过程中尝试使用<strong class="bold"> SageMaker Python SDK </strong>之前，检测到脚本和容器映像中的问题。</p>
			<h2 id="_idParaDest-65">准备就绪</h2>
			<p>如果你使用一个有自定义URL的<strong class="bold"> AWS IAM </strong>用户，确保你<a id="_idIndexMarker198"/>有权限管理<strong class="bold"> AWS Cloud9 </strong>和<strong class="bold"> EC2 </strong>资源。建议以AWS IAM用户的身份登录<a id="_idIndexMarker199"/>，而不是在大多数情况下使用root帐户。</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor065"/>怎么做……</h2>
			<p>该配方中的步骤可分为三个部分:</p>
			<ul>
				<li>启动<strong class="bold">云9 </strong>环境</li>
				<li>增加环境的磁盘空间</li>
				<li>确保通过重新启动与<strong class="bold"> Cloud9 </strong>环境相关的实例来反映卷配置的变化</li>
			</ul>
			<p>我们将借助以下步骤启动Cloud9环境:</p>
			<ol>
				<li>Click <strong class="bold">Services</strong> on the navigation bar. A list of services will be shown in the menu. Under <strong class="bold">Developer Tools</strong>, look for <strong class="bold">Cloud9</strong> and then click the link to navigate to the Cloud9 console:<div><img src="img/B16850_02_02.jpg" alt="Figure 2.2 – Looking for the AWS Cloud9 service under Developer Tools&#13;&#10;" width="658" height="544"/></div><p class="figure-caption">图2.2–在开发者工具下寻找AWS Cloud9服务</p><p>在前面的<a id="_idIndexMarker200"/>截图中，我们可以看到在导航栏上点击<a id="_idIndexMarker201"/>的<strong class="bold">服务</strong>链接后的服务。</p></li>
				<li>In the Cloud9 console, navigate to <strong class="bold">Your environments</strong> using the sidebar and click <strong class="bold">Create environment</strong>:<div><img src="img/B16850_02_03.jpg" alt="Figure 2.3 – Create environment button&#13;&#10;" width="1057" height="160"/></div><p class="figure-caption">图2.3–创建环境按钮</p><p>在这里，我们可以看到<strong class="bold">创建环境</strong>按钮位于页面右上角附近。</p></li>
				<li>Specify the environment's name (for example, Cookbook Experimentation Environment) and, optionally, a description for your environment. Click <strong class="bold">Next step</strong> afterward:<div><img src="img/B16850_02_04.jpg" alt="" width="1163" height="692"/></div><p class="figure-caption">图2.4–名称环境表单</p><p>这里，我们有<a id="_idIndexMarker202"/><strong class="bold">Name environment</strong>表单，在这里我们可以<a id="_idIndexMarker203"/>指定我们的Cloud9环境的名称和描述。</p></li>
				<li>Select the <strong class="bold">Create a new EC2 instance for environment (direct access)</strong> option under <strong class="bold">Environment type</strong>, <strong class="bold">t3.small</strong> under <strong class="bold">Instance type</strong>, and <strong class="bold">Ubuntu Server 18.04 LTS</strong> under <strong class="bold">Platform</strong>:<div><img src="img/B16850_02_05.jpg" alt="Figure 2.5 – Environment settings&#13;&#10;" width="1179" height="893"/></div><p class="figure-caption">图2.5–环境设置</p><p>我们可以在这里看到<a id="_idIndexMarker204"/>不同的配置设置。根据需要随意选择不同的实例类型。</p></li>
				<li>Under <strong class="bold">Cost-saving setting</strong>, select <strong class="bold">After one hour</strong>. Leave the other settings as-is and click <strong class="bold">Next step</strong>:<div><img src="img/B16850_02_06.jpg" alt="Figure 2.6 – Other configuration settings&#13;&#10;" width="1003" height="815"/></div><p class="figure-caption">图2.6–其他配置设置</p><p>这里我们可以看到<a id="_idIndexMarker206"/>在一个小时后我们选择了<strong class="bold">的一个<strong class="bold">节约成本设置</strong>。这意味着在一个小时的不活动后，链接到<a id="_idIndexMarker207"/>cloud 9环境的EC2实例将自动关闭以节省成本。</strong></p></li>
				<li>Review the configuration you selected in the previous steps and then click <strong class="bold">Create environment</strong>:<div><img src="img/B16850_02_07.jpg" alt="Figure 2.7 – Create environment button&#13;&#10;" width="648" height="554"/></div><p class="figure-caption">图2.7–创建环境按钮</p><p>点击<a id="_idIndexMarker208"/><strong class="bold">创建环境</strong>按钮后，可能需要一分钟左右的时间<a id="_idIndexMarker209"/>让环境准备就绪。环境准备就绪后，检查IDE的不同部分:</p><div><img src="img/B16850_02_08.jpg" alt="Figure 2.8 – AWS Cloud9 development environment&#13;&#10;" width="1650" height="958"/></div><p class="figure-caption">图2.8–AWS cloud 9开发环境</p><p>如你所见，我们在左侧有<strong class="bold">文件树</strong>。在屏幕的底部，我们有<strong class="bold">终端</strong>，在这里我们可以运行Bash命令。屏幕中央最大的部分是<strong class="bold">编辑器</strong>，我们可以在这里编辑文件。</p><p>现在，我们需要<a id="_idIndexMarker210"/>增加磁盘空间。</p></li>
				<li>Using the <a id="_idIndexMarker211"/>Terminal at the bottom section of the IDE, run the following command:<pre><strong class="bold">lsblk</strong></pre><p>使用lsblk命令，我们将获得有关可用块设备的信息，如下面的屏幕截图所示:</p><div><img src="img/B16850_02_09.jpg" alt="Figure 2.9 – Result of the lsblk command&#13;&#10;" width="1034" height="297"/></div><p class="figure-caption">图2.9–ls blk命令的结果</p><p>在这里，我们可以看到lsblk命令的结果。此时，根卷只有10G的磁盘空间(减去卷中已有的空间)。</p></li>
				<li>At the top left section of the screen, click <strong class="bold">AWS Cloud9</strong>. From the dropdown list, click <strong class="bold">Go To Your Dashboard</strong>:<div><img src="img/B16850_02_10.jpg" alt="Figure 2.10 – How to go back to the AWS Cloud9 dashboard&#13;&#10;" width="906" height="359"/></div><p class="figure-caption">图2.10–如何返回AWS Cloud9仪表板</p><p>这将<a id="_idIndexMarker213"/>打开一个<a id="_idIndexMarker214"/>新标签，显示Cloud9仪表盘。</p></li>
				<li>Navigate to the <a id="_idIndexMarker215"/>EC2 console using the search bar. Type ec2 in the search bar and click the <strong class="bold">EC2</strong> service from the list of results:<div><img src="img/B16850_02_11.jpg" alt="Figure 2.11 – Using the search bar to navigate to the EC2 console&#13;&#10;" width="747" height="364"/></div><p class="figure-caption">图2.11–使用搜索栏导航到EC2控制台</p><p>在这里，我们可以看到，在我们输入ec2之后，搜索栏很快给了我们一个搜索结果列表。</p></li>
				<li>In the EC2 console, click <strong class="bold">Instances (running)</strong> under <strong class="bold">Resources</strong>:<div><img src="img/B16850_02_12.jpg" alt="Figure 2.12 – Instances (running) link under Resources&#13;&#10;" width="914" height="199"/></div><p class="figure-caption">图2.12–资源下的实例(运行中)链接</p><p>我们应该在<strong class="bold">资源</strong>窗格下看到我们需要点击的<a id="_idIndexMarker216"/>链接，如前面截图中的<a id="_idIndexMarker217"/>所示。</p></li>
				<li>选择与我们在前面一组步骤中启动的Cloud9环境相对应的EC2实例。它应该包含aws-cloud9和我们在创建环境时指定的名称。在显示详细信息的底部窗格中，单击<strong class="bold">存储</strong>选项卡以显示<strong class="bold">根设备详细信息</strong>和<strong class="bold">块设备</strong>。</li>
				<li>Inside the <strong class="bold">Storage</strong> tab, scroll down to the bottom of the page to locate the volumes under <strong class="bold">Block devices</strong>:<div><img src="img/B16850_02_13.jpg" alt="Figure 2.13 – Storage tab &#13;&#10;" width="721" height="290"/></div><p class="figure-caption">图2.13–存储选项卡</p><p>在这里，我们可以看到<strong class="bold">存储</strong>选项卡显示<strong class="bold">根设备细节</strong>和<strong class="bold">块设备</strong>。</p></li>
				<li>您应该看到一个附加的卷，卷大小为10 GiB。点击<code>10 GiB</code>下的链接。</li>
				<li>Click <strong class="bold">Actions</strong> and then <strong class="bold">Modify Volume</strong>:<div><img src="img/B16850_02_16.jpg" alt="Figure 2.16 – Modify Volume&#13;&#10;" width="760" height="353"/></div><p class="figure-caption">图2.16–修改体积</p><p>这就是<a id="_idIndexMarker220"/>我们可以<a id="_idIndexMarker221"/>找到<strong class="bold">修改卷</strong>选项的地方。</p></li>
				<li>Set <strong class="bold">Size</strong> to 100 and click <strong class="bold">Modify</strong>:<div><img src="img/B16850_02_17.jpg" alt="Figure 2.17 – Modifying the volume&#13;&#10;" width="649" height="370"/></div><p class="figure-caption">图2.17–修改卷</p><p>如您所见，我们指定了100 GiB的新卷大小。这应该足以帮助我们完成本章并构建我们的自定义算法容器映像。</p></li>
				<li>Click <strong class="bold">Yes</strong> to confirm the volume modification action:<div><img src="img/B16850_02_18.jpg" alt="Figure 2.18 – Modify Volume confirmation dialog&#13;&#10;" width="646" height="293"/></div><p class="figure-caption">图2.18–修改卷确认对话框</p><p>在前面的<a id="_idIndexMarker223"/>步骤中点击<strong class="bold">修改</strong>后，我们应该会看到一个<a id="_idIndexMarker222"/>确认界面。</p></li>
				<li>Click <strong class="bold">Close</strong> upon seeing the confirmation dialog:<div><img src="img/B16850_02_19.jpg" alt="Figure 2.19 – Modify Volume Request Succeeded message&#13;&#10;" width="810" height="236"/></div><p class="figure-caption">图2.19–修改卷请求成功消息</p><p>在这里，我们可以看到一条消息，说明<strong class="bold">修改卷请求成功</strong>。此时，卷修改仍处于挂起状态，我们需要等待大约10-15分钟才能完成。在等待的时候，请随意查看这个食谱的<em class="italic">工作原理……</em>部分。</p></li>
				<li>Click the refresh button (the two rotating arrows) so that the volume state will change to the correct state accordingly:<div><img src="img/B16850_02_20.jpg" alt="Figure 2.20 – Refresh button&#13;&#10;" width="957" height="272"/></div><p class="figure-caption">图2.20-刷新按钮</p><p>点击<a id="_idIndexMarker224"/>刷新<a id="_idIndexMarker225"/>按钮会将<strong class="bold">状态</strong>从<strong class="bold">使用中</strong>(绿色)更新为<strong class="bold">使用中——优化</strong>(黄色):</p><div><img src="img/B16850_02_21.jpg" alt="Figure 2.21 – In-use state – optimizing (yellow)&#13;&#10;" width="557" height="152"/></div><p class="figure-caption">图2.21-使用状态-优化(黄色)</p><p>在这里，我们可以看到卷修改步骤尚未完成。</p></li>
				<li>After a few minutes, <strong class="bold">State</strong> of the volume will go back to <strong class="bold">in-use</strong> (green):<div><img src="img/B16850_02_22.jpg" alt="Figure 2.22 – In-use state (green)&#13;&#10;" width="513" height="150"/></div><p class="figure-caption">图2.22–使用中状态(绿色)</p><p>当我们看到前面截图中显示的内容时，我们应该庆祝一下，因为这意味着卷修改步骤已经完成！</p><p>现在，卷修改步骤已经完成，我们的下一个目标是确保这种变化反映在我们的环境中。</p></li>
				<li>Navigate back to the browser tab of the AWS Cloud9 IDE. In the Terminal, run lsblk:<pre><strong class="bold">lsblk</strong></pre><p>运行lsblk应该会产生以下输出:</p><div><img src="img/B16850_02_23.jpg" alt="Figure 2.23 – Partition not yet reflecting the size of the root volume&#13;&#10;" width="840" height="235"/></div><p class="figure-caption">图2.23–分区尚未反映根卷的大小</p><p>如您所见，根卷/dev/nvme0n1的<a id="_idIndexMarker226"/>大小反映了新的大小100G，而/dev/nvme0n1p1分区的大小反映了原始大小10G。</p><p>有多种方法可以增加分区，但是我们将通过简单地重新启动EC2实例来继续，这样/dev/nvme0n1p1分区的大小将反映根卷的大小，即100G。</p></li>
				<li>Navigate back to the <strong class="bold">EC2 Volumes</strong> page and select the EC2 volume attached to the Cloud9 instance. At the bottom portion of the screen showing the volume's details, locate the <strong class="bold">Attachment information</strong> value under the <strong class="bold">Description</strong> tab. Click the <strong class="bold">Attachment information</strong> link:<div><img src="img/B16850_02_24.jpg" alt="Figure 2.24 – Attachment information&#13;&#10;" width="808" height="248"/></div><p class="figure-caption">图2.24–附件信息</p><p>点击这个链接<a id="_idIndexMarker228"/>会将我们重定向到<strong class="bold"> EC2实例</strong>页面。它<a id="_idIndexMarker229"/>将自动选择我们的Cloud9环境的EC2实例:</p><div><img src="img/B16850_02_25.jpg" alt="Figure 2.25 – EC2 instance of the Cloud9 environment&#13;&#10;" width="961" height="125"/></div><p class="figure-caption">图2.25–cloud 9环境的EC2实例</p><p>前面的截图显示了链接到我们的Cloud9环境的EC2实例。</p></li>
				<li>Click <strong class="bold">Instance state</strong> at the top right of the screen and click <strong class="bold">Reboot instance</strong>:<div><img src="img/B16850_02_26.jpg" alt="Figure 2.26 – Reboot instance&#13;&#10;" width="1377" height="308"/></div><p class="figure-caption">图2.26–重新启动实例</p><p>在这里我们可以找到<strong class="bold">重启实例</strong>选项。</p></li>
				<li>Navigate back to the browser tab showing the AWS Cloud9 environment IDE. It should take a minute or two to complete the reboot step:<div><img src="img/B16850_02_27.jpg" alt="Figure 2.27 – Instance is still rebooting&#13;&#10;" width="882" height="467"/></div><p class="figure-caption">图2.27–实例仍在重新启动</p><p>我们应该会看到一个类似于前面的<a id="_idIndexMarker230"/>屏幕。</p></li>
				<li>Once <a id="_idIndexMarker231"/>connected, run lsblk in the Terminal:<pre><strong class="bold">lsblk</strong></pre><p>我们应该会得到一组类似于下面截图所示的结果:</p></li>
			</ol>
			<div><div><img src="img/B16850_02_28.jpg" alt="Figure 2.28 – Partition now reflecting the size of the root instance&#13;&#10;" width="651" height="201"/>
				</div>
			</div>
			<p class="figure-caption">图2.28–分区现在反映了根实例的大小</p>
			<p>如我们所见,/dev/nvme0n1p1分区现在反映了根卷的大小，为100G。</p>
			<p>这是一个很大的设置工作，但这绝对是值得的，正如你将在本章接下来的几个食谱中看到的。现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor066"/>工作原理……</h2>
			<p>在这个菜谱中，我们启动了一个<strong class="bold"> Cloud9 </strong>环境，我们将在其中准备定制的容器映像。在构建Docker容器映像时，需要注意的是每个容器映像都会消耗一点磁盘空间。这就是为什么我们必须通过几个步骤来增加我们的Cloud9环境的EC2实例的容量。这个方法由三部分组成:启动一个新的Cloud9环境、修改挂载的卷，以及重启实例。</p>
			<p>启动一个新的<a id="_idIndexMarker232"/> Cloud9环境需要在幕后使用一个<strong class="bold">云形成</strong>模板<a id="_idIndexMarker233"/>。这个<strong class="bold"> CloudFormation </strong>模板被<a id="_idIndexMarker234"/>用作创建EC2实例时的蓝图:</p>
			<div><div><img src="img/B16850_02_29.jpg" alt="Figure 2.29 – CloudFormation stack&#13;&#10;" width="770" height="526"/>
				</div>
			</div>
			<p class="figure-caption">图2.29–云形成堆栈</p>
			<p>这里，我们有一个成功创建的<strong class="bold"> CloudFormation </strong>堆栈。什么是云形成？<strong class="bold"> AWS CloudFormation </strong>是一项<a id="_idIndexMarker235"/>服务，帮助开发人员和DevOps专业人员使用JSON或YAML编写的模板管理资源。使用<strong class="bold"> CloudFormation </strong>服务将这些模板转换成AWS资源。</p>
			<p>此时，EC2实例应该已经在运行，我们也可以使用Cloud9环境了:</p>
			<div><div><img src="img/B16850_02_30.jpg" alt="Figure 2.30 – AWS Cloud9 environment&#13;&#10;" width="1650" height="958"/>
				</div>
			</div>
			<p class="figure-caption">图2.30–AWS cloud 9环境</p>
			<p>一旦Cloud9 <a id="_idIndexMarker237"/>环境准备就绪，我们应该能够<a id="_idIndexMarker236"/>看到前面的输出。如果我们马上使用这个环境，我们会遇到磁盘空间问题，因为我们将使用Docker映像，它会占用一些空间。为了防止以后出现这些问题，我们修改了这个配方中的卷，并重新启动了EC2实例，以便卷的修改能够立即得到反映。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">在这个菜谱中，我们采取了一个快捷方式，简单地重启了EC2实例。如果我们运行的是生产环境，我们应该避免重新启动，而是遵循本指南:<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/recognize-expanded-volume-linux.html">https://docs . AWS . Amazon . com/AWS C2/latest/user guide/recognize-expanded-volume-Linux . html</a>。</p>
			<p>注意，在SageMaker中使用自定义脚本和容器映像之前，我们还可以使用一个配置了root访问权限的SageMaker Notebook实例作为潜在的实验环境。这里的问题是，当使用SageMaker Notebook实例时，每次我们关闭并重新启动实例时，它都会恢复到最初的配置。这使得我们丢失了某些目录和已安装的包，这是不理想的。</p>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor067"/>建立Python和R实验环境</h1>
			<p>在之前的<a id="_idIndexMarker238"/>菜谱中，我们推出了一个<strong class="bold"> Cloud9 </strong>环境。在这个<a id="_idIndexMarker239"/>方法中，我们将在这个环境中准备预期的文件和目录结构。这将帮助我们准备和测试我们的train和serve脚本，然后在容器中运行它们，并在将它们与<strong class="bold"> SageMaker Python SDK </strong>一起使用之前:</p>
			<div><div><img src="img/B16850_02_31.jpg" alt="Figure 2.31 – Expected file and directory structure inside /opt/ml&#13;&#10;" width="1215" height="567"/>
				</div>
			</div>
			<p class="figure-caption">图2.31–在/opt/ml中预期的文件和目录结构</p>
			<p>我们可以在上图中看到预期的目录结构。我们将在/opt/ml中准备预期的目录结构。之后，我们将准备hyperparameters.json、inputdataconfig.json和training_data.csv文件。在接下来的菜谱中，我们将在准备和测试train和serve脚本时使用这些文件。</p>
			<h2 id="_idParaDest-69">做好准备</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>这个方法延续了<em class="italic">启动和准备Cloud9环境</em>的做法。</li>
				<li>我们将需要来自<em class="italic">的S3桶准备亚马逊S3桶和用于第1章</em> 的<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">配方的线性回归实验</em>的训练数据集。我们还需要这个S3桶中的training_data.csv文件。在执行了训练-测试分割之后，我们将CSV文件上传到了第一章 </a>的<em class="italic">用Python<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"><em class="italic">的</em>方法训练你的第一个模型中的S3桶。如果你跳过了这个食谱，你可以从这本书的GitHub资源库(</a><a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook</a>)上传training_data.csv文件到S3桶。</em></li>
			</ul>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor069"/>怎么做……</h2>
			<p>在这个菜谱的第一组<a id="_idIndexMarker240"/>步骤中，我们将使用终端运行<a id="_idIndexMarker241"/>命令。我们将继续上一次<em class="italic">发布和准备Cloud9环境</em>的工作:</p>
			<ol>
				<li value="1">使用pwd命令查看当前工作目录:<pre><strong class="bold">pwd</strong></pre></li>
				<li>导航到/opt目录:<pre><strong class="bold">cd /opt</strong></pre></li>
				<li>使用mkdir命令创建/opt/ml目录。在运行sudo mkdir ml命令之前，请确保您位于/opt目录中。使用chown命令修改/opt/ml目录的所有权配置。这将允许我们管理这个目录的内容，而不需要在后续步骤中反复使用sudo:<pre><strong class="bold">sudo mkdir -p ml</strong> <strong class="bold">sudo chown ubuntu:ubuntu ml</strong></pre></li>
				<li>Navigate to the ml directory using the cd Bash command. Run the following commands to prepare the expected directory structure inside the /opt/ml directory. Make sure that you are inside the ml directory before running these commands. The -p flag will automatically create the required parent directories first, especially if some of the directories in the specified path do not exist yet. In this case, if the input directory does not exist, the mkdir -p input/config command will create it first before creating the config directory inside it:<pre><strong class="bold">cd ml</strong>
<strong class="bold">mkdir -p input/config</strong>
<strong class="bold">mkdir -p input/data/train</strong>
<strong class="bold">mkdir -p output/failure</strong>
<strong class="bold">mkdir -p model</strong></pre><p>正如我们将在后面看到的，这些目录将包含文件和配置数据，当我们初始化评估器时，我们将把它们作为参数值传递。</p><p class="callout-heading">重要说明</p><p class="callout">同样，如果你想知道我们为什么创建这些目录，答案是我们正在准备一个环境，在使用<strong class="bold"> SageMaker Python SDK </strong>和<strong class="bold"> API </strong>之前，我们可以先在那里测试和迭代构建我们的定制脚本。很难知道一个脚本是否在工作，除非我们在一个有相似目录和文件的环境中运行它。如果我们跳过这一步，直接在<strong class="bold"> SageMaker Python SDK </strong>中使用定制的训练脚本，我们将花费大量时间调试潜在的问题，因为我们必须等待整个训练过程完成(至少5-10分钟)，然后才能修复脚本错误，并再次尝试查看修复是否有效。有了这个模拟环境，我们将能够测试我们的定制脚本，并在几秒钟内得到结果。如你所见，如果我们有一个模拟环境，我们可以快速迭代。</p><p>以下是预期的目录结构:</p><div><img src="img/B16850_02_32.jpg" alt="Figure 2.32 – Expected file and folder structure after running the mkdir commands&#13;&#10;" width="1170" height="594"/></div><p class="figure-caption">图2.32-运行mkdir命令后预期的文件和文件夹结构</p><p>在这里，我们可以看到/input目录中有/config和/data目录。/config目录将包含hyperparameters.json文件和inputdataconfig.json文件，我们将在后面看到。在本章的菜谱中，我们将不使用/output目录，但在这里我们可以创建一个名为failure的文件，以防训练作业<a id="_idIndexMarker244"/>失败。失败文件应描述<a id="_idIndexMarker245"/>为什么培训工作失败，以帮助我们在失败场景发生时进行调试和调整。</p></li>
				<li>Install and use the tree command:<pre><strong class="bold">sudo apt install tree</strong>
<strong class="bold">tree</strong></pre><p>我们应该得到一个类似如下的树形结构:</p><div><img src="img/B16850_02_33.jpg" alt="Figure 2.33 – Result of the tree command&#13;&#10;" width="606" height="166"/></div><p class="figure-caption">图2.33-树命令的结果</p><p>在这里，我们可以看到<a id="_idIndexMarker246"/>预期的目录结构。</p></li>
				<li>使用mkdir创建/home/ubuntu/environment/opt目录，并在其中创建两个名为ml-python和ml-r: <pre><strong class="bold">mkdir -p /home/ubuntu/environment/opt</strong> <strong class="bold">cd /home/ubuntu/environment/opt</strong> <strong class="bold">mkdir -p ml-python ml-r</strong></pre>的<a id="_idIndexMarker247"/>目录</li>
				<li>Create a soft symbolic link to make it easier to manage the files and directories using the <strong class="bold">AWS Cloud9</strong> interface:<pre><strong class="bold">sudo ln -s /opt/ml  /home/ubuntu/environment/opt/ml</strong></pre><p>假设我们在一个<strong class="bold"> Cloud9 </strong>环境中执行这个步骤，我们将能够使用可视化编辑器轻松地创建和修改文件，而不是在命令行中使用vim或nano。这意味着在/home/Ubuntu/environment/opt/ml目录中所做的更改也将反映在/opt/ml目录中。这将允许我们使用可视化编辑器轻松创建和修改文件:</p><div><img src="img/B16850_02_34.jpg" alt="Figure 2.34 – File tree showing the symlinked /opt/ml directory&#13;&#10;" width="518" height="214"/></div><p class="figure-caption">图2.34–显示符号链接/opt/ml目录的文件树</p><p>我们应该在文件树中的/opt/ml目录<a id="_idIndexMarker249"/>中看到<a id="_idIndexMarker248"/>目录，如前面的截图所示。</p><p>下一组步骤集中在将虚拟文件添加到实验环境中。</p></li>
				<li>Using the file tree, navigate to the /opt/ml/input/config directory. Right-click on the <strong class="bold">config</strong> directory and select <strong class="bold">New File</strong>:<div><img src="img/B16850_02_35.jpg" alt="Figure 2.35 – Creating a new file inside the config directory&#13;&#10;" width="473" height="726"/></div><p class="figure-caption">图2.35–在配置目录中创建新文件</p></li>
				<li>Name the new file hyperparameters.json. Double-click the new file to open it in the <strong class="bold">Editor</strong> pane:<div><img src="img/B16850_02_36.jpg" alt="Figure 2.36 – Empty hyperparameters.json file&#13;&#10;" width="860" height="446"/></div><p class="figure-caption">图2.36–空的hyperparameters.json文件</p><p>这里，/opt/ml/input/config目录中有一个空的hyperparameters.json文件<a id="_idIndexMarker251"/>。</p></li>
				<li>Set the content of the hyperparameters.json file to the following line of code:<pre>{"a": 1, "b": 2}</pre><p>您的Cloud9环境IDE的文件树和<strong class="bold">编辑器</strong>窗格应该如下所示:</p><div><img src="img/B16850_02_37.jpg" alt="Figure 2.37 – Specifying a sample JSON value to the hyperparameters.json file&#13;&#10;" width="650" height="330"/></div><p class="figure-caption">图2.37–为hyperparameters.json文件指定一个样本JSON值</p><p>确保通过点击<strong class="bold">文件</strong>菜单，然后点击<strong class="bold">保存</strong>来保存。您也可以使用<em class="italic"> Cmd </em> + <em class="italic"> S </em>或<em class="italic"> Ctrl </em> + <em class="italic"> S </em>来<a id="_idIndexMarker252"/>保存文件，这取决于您正在使用的操作系统<a id="_idIndexMarker253"/>。</p></li>
				<li>In a similar fashion, create a new file called inputdataconfig.json inside /opt/ml/input/config. Open the inputdataconfig.json file in the <strong class="bold">Editor</strong> pane and set its content to the following line of code:<pre>{"train": {"ContentType": "text/csv", "RecordWrapperType": "None", "S3DistributionType": "FullyReplicated", "TrainingInputMode": "File"}}</pre><p>你的Cloud9环境IDE的文件树和<strong class="bold">编辑器</strong>面板应该如下所示:</p><div><img src="img/B16850_02_38.jpg" alt="Figure 2.38 – The inputdataconfig.json file&#13;&#10;" width="1032" height="333"/></div><p class="figure-caption">图2.38–输入数据配置文件</p><p>在下一组步骤中，我们将从<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第1章</em> </a>、<em class="italic">使用亚马逊SageMaker </em>开始机器学习下载training_data.csv文件到实验环境。在第一章<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"><em class="italic"/></a>，<em class="italic">使用亚马逊SageMaker </em>，<em class="italic"> </em>的<em class="italic">用Python训练你的第一个模型</em>配方中，我们上传了一个training_data.csv文件到亚马逊S3桶:</p><div><img src="img/B16850_02_39.jpg" alt="Figure 2.39 – The training_data.csv file inside the S3 bucket&#13;&#10;" width="1472" height="594"/></div><p class="figure-caption">图2.39–S3存储桶中的training_data.csv文件</p><p>如果你<a id="_idIndexMarker254"/>跳过了<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第一章</em> </a>中的这些食谱，确保你<a id="_idIndexMarker255"/>查看了这本书的GitHub资源库(<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook</a>)，并将training_data.csv文件上传到S3木桶。请注意，本章中的配方假设training_data.csv文件位于s3://s3_BUCKET/PREFIX/input中，其中S3_BUCKET是S3存储桶的名称，PREFIX是文件夹的名称。如果您尚未创建S3存储桶，请按照第1章 的<em class="italic">准备亚马逊S3存储桶和线性回归实验的训练数据集</em>中的步骤进行操作，因为我们将需要本书所有章节的S3存储桶。</p></li>
				<li>In the Terminal of the Cloud9 IDE, run the following commands to download the training_data.csv file from S3 to the /opt/ml/input/data/train directory:<pre><strong class="bold">cd /opt/ml/input/data/train</strong>
<strong class="bold">S3_BUCKET="&lt;insert bucket name here&gt;"</strong>
<strong class="bold">PREFIX="chapter01"</strong>
<strong class="bold">aws s3 cp s3://$S3_BUCKET/$PREFIX/input/training_data.csv training_data.csv</strong></pre><p>确保将S3 _桶值设置为您在第1章 的<em class="italic">准备亚马逊S3桶和线性回归实验</em>配方的<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">中创建的S3桶的名称。</em></a></p></li>
				<li>In the file<a id="_idIndexMarker256"/> tree, double-click the training_data.csv file <a id="_idIndexMarker257"/>inside the /opt/ml/input/data/train directory to open it in the <strong class="bold">Editor</strong> pane:<div><img src="img/B16850_02_40.jpg" alt="Figure 2.40 – The training_data.csv file inside the experimentation environment&#13;&#10;" width="821" height="348"/></div><p class="figure-caption">图2.40–实验环境中的training_data.csv文件</p><p>如前面的屏幕截图所示，training_data.csv文件在第一列中包含y值，在第二列中包含x值。</p><p>在接下来的几个步骤中，我们将在终端中安装一些先决条件。</p></li>
				<li>在终端中，运行以下脚本，使R食谱在本章的后半部分发挥作用:<pre><strong class="bold">sudo apt-get -y update</strong> <strong class="bold">sudo apt-get install -y --no-install-recommends wget</strong> <strong class="bold">sudo apt-get install -y --no-install-recommends r-base</strong> <strong class="bold">sudo apt-get install -y --no-install-recommends r-base-dev</strong> <strong class="bold">sudo apt-get install -y --no-install-recommends ca-certificates</strong></pre></li>
				<li>Install the command-line JSON processor; that is, jq:<pre><strong class="bold">sudo apt install -y jq</strong></pre><p>在这个菜谱的最后一组步骤<a id="_idIndexMarker258"/>中，我们将在<a id="_idIndexMarker259"/>ml-python和ml-r目录中创建文件。在<em class="italic">构建和测试自定义Python算法容器映像</em>和<em class="italic">构建和测试自定义R算法容器映像</em>的方法中，我们将在使用docker build命令构建容器映像的同时在容器内部复制这些文件。</p></li>
				<li>Right-click on the ml-python directory and then click <strong class="bold">New File</strong> from the menu to create a new file, as shown here. Name the new file train:<div><img src="img/B16850_02_41.jpg" alt="Figure 2.41 – Creating a new file inside the ml-python directory&#13;&#10;" width="440" height="453"/></div><p class="figure-caption">图2.41–在ml-python目录中创建新文件</p><p>再执行两次这个步骤，这样ml-python目录中就有三个文件，分别叫做train、serve和Dockerfile。请注意，这些文件现在是空的:</p><div><img src="img/B16850_02_42.jpg" alt="Figure 2.42 – Files inside the ml-python directory&#13;&#10;" width="508" height="90"/></div><p class="figure-caption">图2.42–ml-python目录中的文件</p><p>前面的截图<a id="_idIndexMarker260"/>显示了这三个空文件。我们将在本章稍后的Python食谱中使用这些。</p></li>
				<li>类似地，在ml-r目录中创建四个新文件，分别名为train、serve、api.r和Dockerfile:</li>
			</ol>
			<div><div><img src="img/B16850_02_43.jpg" alt="Figure 2.43 – Files inside the ml-r directory&#13;&#10;" width="485" height="111"/>
				</div>
			</div>
			<p class="figure-caption">图2.43–ml-r目录中的文件</p>
			<p>前面的屏幕截图显示了这四个空文件。我们将在本章后面的R食谱中用到这些。</p>
			<p>让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor070"/>工作原理……</h2>
			<p>在这个菜谱中，我们准备了实验环境，在这里我们将迭代地构建训练和服务脚本。准备培训和服务脚本是一个迭代过程。我们需要一个实验环境来确保脚本在运行容器中使用之前能够工作。如果没有预期的目录结构和虚拟文件，就很难测试和开发训练和服务脚本，从而无缝地转换到SageMaker上使用。</p>
			<p>让我们讨论并快速描述训练脚本<a id="_idIndexMarker262"/>应该如何工作。训练脚本可以加载以下一项或多项:</p>
			<ul>
				<li>hyperparameters.json:包含Estimator中的超参数配置数据集</li>
				<li>json:包含存储训练数据集的信息</li>
				<li><directory> / <data file="">:包含训练数据集的输入(例如，train/training.csv)</data></directory></li>
			</ul>
			<p>我们将在本章的<em class="italic">准备和测试Python中的训练脚本</em>和<em class="italic">准备和测试R </em>配方中的训练脚本中详细了解准备和测试训练脚本。</p>
			<p>现在，我们来谈谈发球脚本。服务脚本<a id="_idIndexMarker263"/>需要/opt/ml/model目录中的模型文件。请注意，这些文件中的一个或多个可能不存在，这取决于我们使用<strong class="bold"> SageMaker Python SDK </strong>设置的配置参数和自变量。这也取决于我们写剧本需要什么。我们将在本章后面的<em class="italic">在Python中准备和测试serve脚本</em>和<em class="italic">在R </em> recipes中准备和测试serve脚本中详细了解准备和测试serve脚本。</p>
			<h2 id="_idParaDest-72"><a id="_idTextAnchor071"/>还有更多……</h2>
			<p>由于我们将要研究Python和R的特定配方，我们需要对这些如何组合在一起有一个高层次的概念。在接下来的菜谱中，我们将构建一个包含train和serve脚本的定制容器映像。在使用<strong class="bold"> SageMaker Python SDK </strong>进行培训和部署的过程中，将会用到这个容器映像。在这一节中，我们将简要讨论在使用自定义容器映像的同时运行fit()函数时会发生什么。我相信在这里重申一下会很有启发性，我们构建这些目录和虚拟文件是为了创建fit()和deploy()命令将运行的train和serve脚本。</p>
			<p>如果你想知道训练和服务脚本文件的用途，当使用来自<strong class="bold"> SageMaker Python SDK </strong>的fit()和deploy()函数时，这些脚本文件由<strong class="bold"> SageMaker </strong>在后台的容器内执行。我们将在本章的后面编写并测试这些脚本。当我们使用<a id="_idIndexMarker265"/>fit()功能时，<strong class="bold"> SageMaker </strong>开始训练工作。在幕后，<strong class="bold"> SageMaker </strong>执行以下步骤:</p>
			<p><strong class="bold">准备和配置</strong></p>
			<ol>
				<li value="1">启动一个或多个ML <a id="_idIndexMarker266"/>实例。训练作业的ML实例的数量和类型取决于初始化估计器类时指定的instance_count和instance_type参数:<pre>container="&lt;insert image uri of the custom container image&gt;" estimator = sagemaker.estimator.Estimator(     container,     instance_count=1,      instance_type='local',     ... ) estimator.fit({'train': train})</pre></li>
				<li>使用set_hyperparameters()函数指定的超参数被复制并存储为/opt/ml/input/config目录中名为hyperparameters.json的JSON文件。请注意，我们的定制容器在开始时没有这个文件，当培训作业开始时，<strong class="bold"> SageMaker </strong>会自动为我们创建这个文件。</li>
			</ol>
			<p><strong class="bold">培训</strong></p>
			<ol>
				<li value="1">我们<a id="_idIndexMarker267"/>在fit()函数中指定的输入数据将由<strong class="bold"> SageMaker </strong>加载(例如，从指定的S3桶)并复制到/opt/ml/input/data/。对于每个输入数据通道，将在/opt/ml/input/data目录中创建一个包含相关文件的目录。例如，如果我们使用下面的代码行，并使用了<strong class="bold"> SageMaker Python SDK </strong>，那么当train脚本开始运行时，我们将会看到/opt/ml/input/data/apple和/opt/ml/data/banana目录:<pre>estimator.fit({'<strong class="bold">apple</strong>': TrainingInput(...),'<strong class="bold">banana</strong>': TrainingInput(...)})</pre></li>
				<li>Next, your custom train script runs. It loads the configuration files, hyperparameters, and the data files from the directories inside /opt/ml. It then trains a model using the training dataset and, optionally, a validation dataset. The model is then serialized and stored inside the /opt/ml/model<strong class="bold"> </strong>directory.<p class="callout-heading">注意</p><p class="callout">如果您不知道火车脚本是什么样子，请不要担心，因为我们将在后面的食谱中详细讨论火车脚本。</p></li>
				<li><strong class="bold"> SageMaker </strong>需要/opt/ml/model目录中的模型输出文件。训练脚本执行完成后，<strong class="bold"> SageMaker </strong>自动复制/opt/ml/model目录的内容，并将其存储在目标S3桶和路径中(model.tar.gz内)。请注意，在使用<strong class="bold"> SageMaker Python SDK </strong>初始化估计器时，我们可以通过设置output_path参数来指定目标S3桶和路径。</li>
				<li>如果运行脚本时出现错误，<strong class="bold"> SageMaker </strong>将在/opt/ml/output目录中查找失败文件。如果存在，当使用DescribeTrainingJob API时，将加载存储在该文件中的文本输出。</li>
				<li>创建的ML实例被删除。将可计费时间返回给用户。</li>
			</ol>
			<p><strong class="bold">部署</strong></p>
			<p>当我们使用deploy()函数时，<strong class="bold"> SageMaker </strong>开始模型部署步骤。运行deploy()函数时的假设是model.tar.gz文件存储在目标S3存储桶路径中。</p>
			<ol>
				<li value="1">启动一个或多个ML实例。部署步骤的ML实例的数量和类型取决于使用deploy()函数时指定的instance_count和instance_type参数:<pre>predictor = estimator.<strong class="bold">deploy</strong>(     initial_instance_count=1,      instance_type='local',      endpoint_name="custom-local-py-endpoint")</pre></li>
				<li>model.tar.gz文件是从S3存储桶中复制的，文件被提取到/opt/ml/model目录中。</li>
				<li>接下来，您的定制服务脚本运行。它使用/opt/ml/model目录中的模型文件来反序列化和加载模型。然后，serve脚本使用所需的/ping和/invocations端点运行API web服务器。</li>
			</ol>
			<p><strong class="bold">推论</strong></p>
			<ol>
				<li value="1">在<a id="_idIndexMarker269"/>部署之后，predict()函数调用/invocations端点来使用加载的模型进行推理。</li>
			</ol>
			<p>这应该会让我们更好地理解我们在这个菜谱中准备的文件和目录的用途。如果你对这一部分的细节感到有点不知所措，不要担心，因为随着我们在本章接下来的几个食谱中的工作，事情会变得更清楚！</p>
			<h1 id="_idParaDest-73"><a id="_idTextAnchor072"/>用Python编写和测试训练脚本</h1>
			<p>在这个菜谱中，我们将用Python编写一个<a id="_idIndexMarker270"/>训练脚本，允许我们用scikit-learn训练一个线性<a id="_idIndexMarker271"/>模型。在这里，我们可以看到一个正在运行的定制容器中的train脚本利用了超参数、输入数据和使用<strong class="bold"> SageMaker Python SDK </strong>在Estimator实例中指定的配置:</p>
			<div><div><img src="img/B16850_02_44.jpg" alt="Figure 2.44 – How the train script is used to produce a model &#13;&#10;" width="1133" height="673"/>
				</div>
			</div>
			<p class="figure-caption">图2.44–如何使用训练脚本生成模型</p>
			<p>运行训练作业时有多种选择——使用内置算法、使用自定义训练脚本和自定义Docker容器映像，或者使用自定义训练脚本和预构建的Docker映像。在本食谱中，我们将重点关注第二个选项，我们将准备并测试Python中的一个最基本的训练脚本，该脚本为一个特定的回归问题构建一个线性模型。</p>
			<p>一旦我们完成了这个食谱，我们将会对SageMaker的幕后工作有更好的理解。我们将看到在哪里以及如何加载和使用我们在<strong class="bold">SageMaker Python SDK</strong>Estimator中指定的配置和参数。</p>
			<h2 id="_idParaDest-74">做好准备</h2>
			<p>确保你已经完成了<em class="italic">设置Python和R实验环境</em>的菜谱。</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor074"/>怎么做……</h2>
			<p>该配方中的第一组步骤主要是准备培训脚本。让我们开始吧:</p>
			<ol>
				<li value="1">Inside the ml-python directory, double-click the train file to open the file inside the <strong class="bold">Editor</strong> pane:<div><img src="img/B16850_02_45.jpg" alt="Figure 2.45 – Empty ml-python/train file&#13;&#10;" width="631" height="247"/></div><p class="figure-caption">图2.45–空的ml-python/train文件</p><p>这里，我们有一个空的火车文件。在<strong class="bold">编辑器</strong>窗格的右下角，您可以将语法高亮设置更改为Python。</p></li>
				<li>Add the following lines of code to start the train script to import the required packages and libraries:<pre>#!/usr/bin/env python3
import <strong class="bold">json</strong>
import <strong class="bold">pprint</strong>
import <strong class="bold">pandas</strong> as pd
from sklearn.linear_model import <strong class="bold">LinearRegression</strong>
from <strong class="bold">joblib</strong> import dump, load
from os import <strong class="bold">listdir</strong></pre><p>在前面的代码块中，我们导入了以下内容:</p><ul><li>使用json数据时用于实用函数的JSON</li><li>pprint帮助我们“漂亮地打印”嵌套结构，如字典</li><li>熊猫帮助我们阅读CSV文件和处理数据帧</li><li>来自sklearn库的LinearRegression，用于在运行训练脚本时训练线性模型</li><li>用于保存和加载模型的joblib</li><li>操作系统模块中的listdir来帮助我们列出目录中的文件</li></ul></li>
				<li>Define the PATHS constant<a id="_idIndexMarker274"/> and the get_path() function. The get_path() function will be handy in helping us manage the paths and <a id="_idIndexMarker275"/>locations of the primary files and directories used in the script:<pre>PATHS = {
    'hyperparameters': 'input/config/hyperparameters.json',
    'input': 'input/config/inputdataconfig.json',
    'data': 'input/data/',
    'model': 'model/'
}
    
def <strong class="bold">get_path</strong>(key):
    return '/opt/ml/' + PATHS[key]</pre><p>如果我们想要获得hyperparameters.json文件的路径，我们可以使用get _ path(“hyperparameters”)而不是在我们的代码中使用绝对路径。</p><p class="callout-heading">重要说明</p><p class="callout">在本章中，我们将有意地使用get_path作为函数名。如果您使用Python已经有一段时间了，您可能会注意到这绝对不是Python代码！我们的目标是让我们很容易地找到Python和R脚本之间的相似之处和不同之处，所以我们在很大程度上让函数名相同。</p></li>
				<li>接下来，在上一步的get_path()函数<a id="_idIndexMarker277"/>定义之后添加下面的<a id="_idIndexMarker276"/>行。一旦我们需要加载和打印将要使用的JSON文件的内容(例如，hyperparameters.json)，这些额外的函数将会对我们有所帮助</li>
				<li>Include the following functions as well in the train script (after the print_json() function definition):<pre>def <strong class="bold">inspect_hyperparameters</strong>():
    print('[inspect_hyperparameters]')
    hyperparameters_json_path = get_path(
        'hyperparameters'
    )
    print(hyperparameters_json_path)
    
    hyperparameters = load_json(
        hyperparameters_json_path
    )
    print_json(hyperparameters)
    
def <strong class="bold">list_dir_contents</strong>(target_path):
    print('[list_dir_contents]')
    output = listdir(target_path)
    print(output)
    
    return output</pre><p>inspect_hyperparameters()函数允许我们检查/opt/ml/input/config目录中hyperparameters.json文件的内容。另一方面，list_dir_contents()函数允许我们显示目标目录的内容。我们稍后将使用它来检查培训输入目录的内容。</p></li>
				<li>之后，定义inspect_input()函数。这允许我们检查/opt/ml/input/config目录中inputdataconfig.json的内容:<pre>def <strong class="bold">inspect_input</strong>():     print('[inspect_input]')     input_config_json_path = get_path('input')     print(input_config_json_path)     input_config = load_json(input_config_json_path)     print_json(input_config)</pre></li>
				<li>Define the load_training_data() function. This function accepts a string value pointing to the <a id="_idIndexMarker280"/>input data directory and returns the contents<a id="_idIndexMarker281"/> of a CSV file inside that directory:<pre>def <strong class="bold">load_training_data</strong>(input_data_dir):
    print('[load_training_data]')    
    files = list_dir_contents(input_data_dir)
    training_data_path = input_data_dir + files[0]
    print(training_data_path)
    
    df = pd.read_csv(
        training_data_path, header=None
    )
    print(df)
    
    y_train = df[0].values
    X_train = df[1].values
    return (X_train, y_train)</pre><p>load_training_data()函数内部的流程可以分为两个部分——获取包含训练数据的CSV文件的特定路径，然后使用pd.read_csv()函数读取CSV文件的内容，并在一组列表中返回结果。</p><p class="callout-heading">注意</p><p class="callout">当然，我们在这里实现的load_training_data()函数假设该目录中只有一个CSV文件，所以当您在所提供的目录中处理多个CSV文件时，可以随意修改下面的实现。同时，这个函数实现只支持CSV文件，如果需要支持多种输入文件类型，一定要调整代码块。</p></li>
				<li>定义<a id="_idIndexMarker282"/>get _ input _ data _ dir()函数:<pre>def <strong class="bold">get_input_data_dir</strong>():     print('[get_input_data_dir]')     key = 'train'     input_data_dir = get_path('data') + key + '/'     return input_data_dir</pre></li>
				<li>定义<a id="_idIndexMarker283"/>train _ model()函数:<pre>def <strong class="bold">train_model</strong>(X_train, y_train):     print('[train_model]')     <strong class="bold">model</strong> = LinearRegression()     <strong class="bold">model</strong>.fit(X_train.reshape(-1, 1), y_train)     return <strong class="bold">model</strong></pre></li>
				<li>定义save_model()函数:<pre>def <strong class="bold">save_model</strong>(model):     print('[save_model]')     filename = get_path('model') + 'model'     print(filename)     <strong class="bold">dump</strong>(model, filename)     print('Model Saved!')</pre></li>
				<li>Create<a id="_idIndexMarker284"/> the main() function, which executes the<a id="_idIndexMarker285"/> functions we created in the previous steps:<pre>def <strong class="bold">main</strong>():
    inspect_hyperparameters()
    inspect_input()
    input_data_dir = <strong class="bold">get_input_data_dir</strong>()
    X_train, y_train = <strong class="bold">load_training_data</strong>(
        input_data_dir
    )
    model = <strong class="bold">train_model</strong>(X_train, y_train)
    <strong class="bold">save_model</strong>(model)</pre><p>该函数只是检查超参数和输入配置，使用从输入数据目录加载的数据训练线性模型，并使用save_model()函数保存模型。</p></li>
				<li>Finally, run the main() function:<pre>if __name__ == "__main__":
    <strong class="bold">main</strong>()</pre><p>当脚本作为主程序执行时，__name__变量被设置为“__main__”。如果我们将脚本作为主程序使用，这个if条件只是告诉脚本运行。如果这个脚本被另一个脚本导入，那么main()函数将不会运行。</p><p class="callout-heading">小费</p><p class="callout">您可以在<em class="italic">Machine Learning with Amazon sage maker Cookbook</em>GitHub存储库中访问训练脚本文件的工作副本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/blob/master/Chapter02/ml-python/train">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/blob/master/chapter 02/ml-python/train</a>。</p><p>现在我们已经完成了训练脚本，我们将使用终端来执行这个菜谱中的最后一组步骤。</p><p>最后一组<a id="_idIndexMarker286"/>步骤集中在<a id="_idIndexMarker287"/>安装一些脚本先决条件:</p></li>
				<li>Open a new Terminal:<div><img src="img/B16850_02_46.jpg" alt="Figure 2.46 – New Terminal&#13;&#10;" width="899" height="237"/></div><p class="figure-caption">图2.46–新终端</p><p>在这里，我们可以看到如何创建一个新的终端标签。我们只需点击加号(<strong class="bold"> + </strong>)按钮，然后选择<strong class="bold">新建终端</strong>。</p></li>
				<li>In the Terminal at the bottom pane, run python3 --version:<pre><strong class="bold">python3 --version</strong></pre><p>运行这行代码应该会返回与下面的屏幕截图类似的结果:</p><div><img src="img/B16850_02_47.jpg" alt="Figure 2.47 – Result of running python3 --version in the Terminal&#13;&#10;" width="564" height="427"/></div><p class="figure-caption">图2.47–在终端中运行python3 - version的结果</p><p>在这里，我们可以<a id="_idIndexMarker288"/>看到我们的环境使用的是Python版本3.6.9。</p></li>
				<li>使用pip安装pandas。<strong class="bold"> pandas </strong>库是<a id="_idIndexMarker289"/>在处理<a id="_idIndexMarker290"/>数据帧(表格)时使用的:<pre><strong class="bold">pip3 install pandas</strong></pre></li>
				<li>使用pip安装sklearn。<strong class="bold"> scikit-learn </strong>库<a id="_idIndexMarker291"/>是一个机器学习库，它的特色是几个用于分类、回归和聚类问题的算法:<pre><strong class="bold">pip3 install sklearn</strong></pre></li>
				<li>导航到ml-python目录:<pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-python</strong></pre></li>
				<li>要使训练脚本可执行，在终端中运行以下命令:<pre><strong class="bold">chmod +x train</strong></pre></li>
				<li>Test the train script in your <strong class="bold">AWS Cloud9</strong> environment by running the following command in the Terminal:<pre><strong class="bold">./train</strong></pre><p>运行前面的<a id="_idIndexMarker292"/>行代码<a id="_idIndexMarker293"/>将产生类似如下的结果:</p></li>
			</ol>
			<div><div><img src="img/B16850_02_48.jpg" alt="Figure 2.48 – Result of running the train script&#13;&#10;" width="428" height="378"/>
				</div>
			</div>
			<p class="figure-caption">图2.48–运行训练脚本的结果</p>
			<p>在这里，我们可以看到由训练脚本生成的日志。在成功执行训练脚本之后，我们希望模型文件存储在/opt/ml/model目录中。</p>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor075"/>工作原理……</h2>
			<p>在这个菜谱中，我们使用Python准备了一个定制的训练脚本。该脚本首先识别输入路径并加载重要文件，以帮助设置执行的上下文。这个训练脚本演示了输入和输出值如何在<strong class="bold"> SageMaker Python SDK </strong>(或API)和定制容器之间传递。它还演示了如何加载定型数据、定型模型和保存模型。</p>
			<p>在初始化和配置Estimator对象时，在调用fit()函数时，一些指定的值(包括超参数)会在API调用中从Python字典转换为JSON格式。然后，SageMaker平台上的API调用在运行train脚本的环境中创建和挂载JSON文件。它的工作方式与训练脚本文件加载的其他文件相同，比如inputdataconfig.json文件。</p>
			<p>如果您想知道inputdataconfig.json文件中有什么，请参考下面的代码<a id="_idIndexMarker294"/>块，查看它的<a id="_idIndexMarker295"/>示例:</p>
			<pre>{"&lt;channel name&gt;": {"<strong class="bold">ContentType</strong>": "text/csv", 
       "<strong class="bold">RecordWrapperType</strong>": "None",
       "<strong class="bold">S3DistributionType</strong>": "FullyReplicated",
       "<strong class="bold">TrainingInputMode</strong>": "File"}} </pre>
			<p>对于每个输入通道，在该文件中指定了一组相应的属性。以下是该文件中使用的一些常见属性和值。当然，这里的值取决于数据类型和实验中使用的算法:</p>
			<ul>
				<li>content type-<strong class="bold">有效值</strong> : text/csv、image/jpeg、application/x-recordio-proto buf等等。</li>
				<li>RecordWrapperType-<strong class="bold">有效值</strong>:无或RecordIO。仅当TrainingInputMode值设置为Pipe时，才设置RecordIO值。定型算法要求输入数据采用RecordIO格式，但输入数据尚未采用RecordIO格式。</li>
				<li>S3 distribution type-<strong class="bold">有效值</strong> : FullyReplicated或ShardedByS3Key。如果该值被设置为FullyReplicated，则整个数据集被复制到在模型训练期间启动的每个ML实例上。另一方面，当值设置为ShardedByS3Key时，在模型训练期间启动和使用的每台机器都使用所提供的训练数据的子集。</li>
				<li>TrainingInputMode-<strong class="bold">有效值</strong>:文件或管道。当使用文件输入模式时，在训练作业开始之前，首先下载整个数据集。另一方面，管道输入模式用于加速训练作业，启动速度更快，需要的磁盘空间更少。这在处理大型数据集时非常有用。如果您计划在自定义容器中支持管道输入模式，那么/opt/ml/input/data目录中的目录会有所不同，并且将采用&lt;通道名称&gt; _ &lt;纪元编号&gt;的格式。如果我们在我们的实验环境中使用这个例子，我们将拥有名为D1、D2…的目录，而不是在/opt/ml/input/data目录中。确保您处理的场景处理的是尚不存在的数据文件，因为您需要在train脚本中添加一些重试逻辑。</li>
			</ul>
			<p>除了存储在几个特定目录中的<a id="_idIndexMarker296"/>文件之外，注意还有几个<a id="_idIndexMarker297"/>环境变量也可以被火车脚本加载和使用。其中包括培训工作名称和培训工作ARN。</p>
			<p>这些环境变量的值可以通过使用以下几行Python代码来加载:</p>
			<pre>import os
training_job_name = os.environ['<strong class="bold">TRAINING_JOB_NAME</strong>']</pre>
			<p>我们可以通过在终端中运行以下代码来测试我们的脚本:</p>
			<pre>TRAINING_JOB_NAME=abcdef ./train</pre>
			<p>可以随意查看以下关于<a id="_idIndexMarker298"/>sage maker如何提供训练信息的参考:<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-running-container.html">https://docs . AWS . Amazon . com/sage maker/latest/DG/your-algorithms-training-algo-running-container . html</a>。</p>
			<h2 id="_idParaDest-77">还有更多…</h2>
			<p>如果您正在处理分布式训练，其中数据集被自动拆分到不同的实例以实现数据并行和模型并行，则训练脚本可以加载的另一个配置文件是resourceconfig.json文件。这个文件可以在/opt/ml/input/config目录中找到。该文件包含有关训练作业运行时所有正在运行的容器的详细信息，并提供有关当前主机、主机和网络接口名称的信息。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">请注意，resourceconfig.json文件仅在使用分布式培训时存在，因此在执行加载操作之前，请检查该文件(以及其他文件)是否存在。</p>
			<p>如果您想要更新您的train脚本，使其正确支持分布式训练，只需使用<em class="italic">中的实验环境设置Python和R实验环境</em>方法，并在/opt/ml/input/config目录下创建一个名为resourceconfig.json的虚拟文件:</p>
			<pre>{
    "<strong class="bold">current_host</strong>": "host-1",
    "<strong class="bold">hosts</strong>": ["host-1","host-2"],
    "<strong class="bold">network_interface_name</strong>":"eth1"
}</pre>
			<p>前面的代码将帮助您创建这个虚拟文件。</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor077"/>用Python编写和测试serve脚本</h1>
			<p>在这个菜谱中，我们将使用Python创建一个<a id="_idIndexMarker299"/>样本服务脚本，该脚本加载<a id="_idIndexMarker300"/>模型并设置一个Flask服务器来返回预测。这将为我们提供一个模板来处理和测试端到端的培训和部署流程，然后再增加serve脚本的复杂性。下图显示了我们将在本菜谱中准备的Python serve脚本的预期行为。Python serve脚本从/opt/ml/model目录加载模型文件，并在端口8080上运行一个<strong class="bold"> Flask </strong> web服务器:</p>
			<div><div><img src="img/B16850_02_49.jpg" alt="Figure 2.49 – The Python serve script loads and deserializes the model and runs &#13;&#10;a Flask API server that acts as the inference endpoint&#13;&#10;" width="1453" height="536"/>
				</div>
			</div>
			<p class="figure-caption">图2.49–Python serve脚本加载并反序列化模型，并运行一个充当推理端点的Flask API服务器</p>
			<p>web服务器<a id="_idIndexMarker301"/>应该有/ping和/invocations端点。这个<a id="_idIndexMarker302"/>独立的Python脚本将在一个定制的容器中运行，该容器允许Python train和serve脚本运行。</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor078"/>准备就绪</h2>
			<p>确保您已经完成了<em class="italic">准备和测试Python </em>配方中的训练脚本。</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor079"/>怎么做……</h2>
			<p>我们将从准备发球脚本开始:</p>
			<ol>
				<li value="1">Inside the ml-python directory, double-click the serve file to open it inside the <strong class="bold">Editor</strong> pane:<div><img src="img/B16850_02_50.jpg" alt="Figure 2.50 –  Locating the empty serve script inside the ml-python directory&#13;&#10;" width="955" height="166"/></div><p class="figure-caption">图2.50–在ml-python目录中定位空的服务器脚本</p><p>在这里，我们可以看到ml-python目录下的三个文件。记得在<em class="italic">设置Python和R实验环境</em>的方法中，我们准备了一个空的serve脚本:</p><div><img src="img/B16850_02_51.jpg" alt="Figure 2.51 – Empty serve file&#13;&#10;" width="458" height="301"/></div><p class="figure-caption">图2.51–空的服务文件</p><p>在接下来的几个步骤中，我们将添加serve脚本的代码行。</p></li>
				<li>将下面的<a id="_idIndexMarker303"/>代码添加到serve脚本中，以导入并初始化<a id="_idIndexMarker304"/>先决条件:<pre>#!/usr/bin/env python3 import <strong class="bold">numpy</strong> as np from flask import <strong class="bold">Flask</strong> from flask import Response from flask import request      from <strong class="bold">joblib</strong> import dump, load</pre></li>
				<li>初始化Flask应用程序。之后，定义get_path()函数:<pre>app = <strong class="bold">Flask</strong>(__name__)           PATHS = {     'hyperparameters': 'input/config/hyperparameters.json',     'input': 'input/config/inputdataconfig.json',     'data': 'input/data/',     'model': 'model/' }      def <strong class="bold">get_path</strong>(key):     return '/opt/ml/' + PATHS[key]</pre></li>
				<li>Define<a id="_idIndexMarker305"/> the load_model() function by adding the following lines <a id="_idIndexMarker306"/>of code to the serve script:<pre>def <strong class="bold">load_model</strong>():
    model = None
    
    filename = get_path('model') + 'model'
    print(filename)
    
    model = load(filename)
    return model</pre><p>请注意，这里的模型文件名是model，因为我们在使用Python 方法中的<em class="italic">准备和测试训练脚本中的dump()函数保存模型时指定了这个模型工件文件名。</em></p><p class="callout-heading">重要说明</p><p class="callout">请注意，在保存和加载机器学习模型时，选择正确的方法非常重要。在某些情况下，来自不可信来源的机器学习模型可能包含导致安全问题<a id="_idIndexMarker307"/>的恶意指令，例如<strong class="bold">任意代码执行</strong>！关于这个话题的更多信息，请随时查看https://joblib.readthedocs.io/en/latest/persistence.html。</p></li>
				<li>Define a<a id="_idIndexMarker308"/> function <a id="_idIndexMarker309"/>that accepts the POST requests for the /invocations route:<pre>@app.route("<strong class="bold">/invocations</strong>", methods=["POST"])
def <strong class="bold">predict</strong>():
    model = <strong class="bold">load_model</strong>()
    post_body = <strong class="bold">request.get_data</strong>().decode("utf-8")
    payload_value = float(post_body)
    
    X_test = np.array(
        [<strong class="bold">payload_value</strong>]
    ).reshape(-1, 1)
    y_test = model.<strong class="bold">predict</strong>(X_test)
    
    return Response(
        response=str(y_test[0]), 
        status=200
    )</pre><p>这个函数有五个部分:使用load_model()函数加载训练好的模型，使用request.get_data()函数读取POST请求数据并将其存储在post_body变量中，使用float()、np.array()和shape()函数将预测负载转换为适当的结构和类型，使用predict()函数进行预测，并在响应对象中返回预测值。</p><p class="callout-heading">重要说明</p><p class="callout">请注意，前面代码块中的predict()函数的实现只能处理涉及单个有效负载值的预测。同时，它不能像内置算法处理CSV、JSON和其他类型的请求格式那样处理不同类型的输入。如果您需要为此提供支持，需要向predict()函数的实现中添加额外的代码行。</p></li>
				<li>通过将下面几行<a id="_idIndexMarker311"/>代码添加到serve脚本来准备<a id="_idIndexMarker310"/>/ping路由和处理程序:<pre>@app.route("<strong class="bold">/ping</strong>") def <strong class="bold">ping</strong>():     return Response(response="OK", status=200)</pre></li>
				<li>Finally, use the app.run() method and bind the web server to port 8080:<pre>app.run(host="0.0.0.0", port=8080)</pre><p class="callout-heading">小费</p><p class="callout">您可以在本书的GitHub存储库中访问serve脚本文件的工作副本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/blob/master/Chapter02/ml-python/serve">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/blob/master/chapter 02/ml-python/serve</a>。</p></li>
				<li>Create a new Terminal in the bottom pane, below the <strong class="bold">Editor</strong> pane:<div><img src="img/B16850_02_52.jpg" alt="Figure 2.52 – New Terminal&#13;&#10;" width="954" height="457"/></div><p class="figure-caption">图2.52–新终端</p><p>在这里，我们<a id="_idIndexMarker312"/>可以看到一个已经打开的端子标签。如果需要创建一个<a id="_idIndexMarker313"/>新端子，只需点击加号(<strong class="bold"> + </strong>)，然后点击<strong class="bold">新端子</strong>。我们将在这个终端选项卡中运行下面几个命令。</p></li>
				<li>使用pip安装烧瓶框架。我们将使用Flask作为我们的推理API端点:<pre><strong class="bold">pip3 install flask</strong></pre></li>
				<li>导航到ml-python目录:<pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-python</strong></pre></li>
				<li>使用chmod: <pre><strong class="bold">chmod +x serve</strong></pre>使服务器脚本可执行</li>
				<li>Test the serve script using the following command:<pre><strong class="bold">./serve</strong></pre><p>这将启动Flask应用程序，如下所示:</p><div><img src="img/B16850_02_53.jpg" alt="Figure 2.53 – Running the serve script&#13;&#10;" width="627" height="471"/></div><p class="figure-caption">图2.53–运行服务脚本</p><p>在这里，我们<a id="_idIndexMarker314"/>可以看到我们的serve脚本已经成功地在端口8080上运行了一个flask API <a id="_idIndexMarker315"/> web服务器。</p><p>最后，我们将触发这个正在运行的web服务器。</p></li>
				<li>Open a new Terminal window:<div><img src="img/B16850_02_54.jpg" alt="Figure 2.54 – New Terminal&#13;&#10;" width="816" height="255"/></div><p class="figure-caption">图2.54–新终端</p><p>如我们所见，我们正在创建一个新的终端选项卡，因为第一个选项卡已经在运行serve脚本。</p></li>
				<li>In a separate Terminal window, test the ping endpoint URL using the curl command:<pre><strong class="bold">SERVE_IP=localhost</strong>
<strong class="bold">curl http://$SERVE_IP:8080/ping</strong></pre><p>运行前一行代码应该会从/ping端点产生一条OK消息。</p></li>
				<li>Test the invocations endpoint URL using the curl command:<pre><strong class="bold">curl -d "1" -X POST http://$SERVE_IP:8080/invocations</strong></pre><p>在调用调用端点之后，我们应该得到一个类似于或接近于881.3428400857507的值。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor080"/>工作原理……</h2>
			<p>在这个菜谱中，我们<a id="_idIndexMarker316"/>用Python编写了serve脚本。serve脚本让<a id="_idIndexMarker317"/>使用<strong class="bold"> Flask </strong>框架来生成一个API，该API允许对/ping路由的GET请求和对/invocations路由的POST请求。</p>
			<p>serve脚本应该从/opt/ml/model目录中加载模型文件，并在定制容器中运行后端API服务器。它应该提供一个/ping路由和一个/调用路由。考虑到这些，我们的最小Flask应用程序模板可能如下所示:</p>
			<pre>from flask import Flask
app = Flask(__name__)
    
@app.route("<strong class="bold">/ping</strong>")
def <strong class="bold">ping</strong>():
    return &lt;RETURN VALUE&gt;
    
@app.route<strong class="bold">("/invocations</strong>", methods=["POST"])
def <strong class="bold">predict</strong>():
    return &lt;RETURN VALUE&gt;</pre>
			<p>app.route()装饰器将指定的URL映射到一个函数。在此模板代码中，每当访问/ping URL时，都会执行ping()函数。类似地，每当POST请求访问/invocations URL时，就会执行predict()函数。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">请注意，我们可以自由使用任何其他的网络框架(例如，<strong class="bold">金字塔网络框架</strong>)来实现这个菜谱。只要定制容器映像拥有已安装脚本所需的库，那么我们就可以在脚本文件中导入和使用这些库。</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor081"/>构建和测试定制Python算法容器映像</h1>
			<p>在这个菜谱中，我们<a id="_idIndexMarker318"/>将为定制Python容器映像准备一个docker文件。我们将利用我们在前面的食谱中准备的train和serve脚本。之后，我们将运行docker build命令来准备图像，然后将它推送到一个<strong class="bold"> Amazon ECR </strong>存储库。</p>
			<p class="callout-heading">小费</p>
			<p class="callout">等等！什么是Dockerfile？它是一个文本文档，包含用于准备<a id="_idIndexMarker319"/>和构建容器映像的指令(命令)。这个容器映像在运行容器时充当蓝图。想了解更多关于Dockerfiles的信息，请随意查看https://docs.docker.com/engine/reference/builder/。</p>
			<h2 id="_idParaDest-83">准备就绪</h2>
			<p>确保您已经完成了Python 配方中的<em class="italic">准备和测试serve脚本。</em></p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor083"/>怎么做……</h2>
			<p>该配方<a id="_idIndexMarker320"/>的初始步骤主要是准备docker文件。让我们开始吧:</p>
			<ol>
				<li value="1">Double-click the Dockerfile file in the file tree to open it in the <strong class="bold">Editor</strong> pane. Make sure that this is the same Dockerfile that's inside the ml-python directory:<div><img src="img/B16850_02_55.jpg" alt="Figure 2.55 – Opening the Dockerfile inside the ml-python directory&#13;&#10;" width="902" height="164"/></div><p class="figure-caption">图2.55–打开ml-python目录中的Dockerfile文件</p><p>在这里，我们可以看到ml-python目录中的Dockerfile。记得我们在<em class="italic">中创建了一个空的Dockerfile文件来设置Python和R实验环境</em>的配方。在文件树中点击它应该会在<strong class="bold">编辑器</strong>窗格中打开一个空文件:</p><div><img src="img/B16850_02_56.jpg" alt="Figure 2.56 – Empty Dockerfile in the Editor pane&#13;&#10;" width="575" height="249"/></div><p class="figure-caption">图2.56–编辑器窗格中的空Dockerfile</p><p>这里，我们有一个空的Dockerfile文件。在下一步中，我们将通过添加三行代码来更新它。</p></li>
				<li>Update Dockerfile with the following block of configuration code: <pre>FROM <strong class="bold">arvslat/amazon-sagemaker-cookbook-python-base</strong>:1
COPY train /usr/local/bin/train
COPY serve /usr/local/bin/serve</pre><p>在这里，我们计划在一个名为Amazon-sage maker-cookbook-python-base的现有映像的基础上进行构建。这个映像已经安装了一些先决条件。这些库包括Flask、pandas和Scikit-learn库，因此您不必担心如何让安装步骤在这个菜谱中正常工作。关于这张图片的更多细节，请查看<a href="https://hub.docker.com/r/arvslat/amazon-sagemaker-cookbook-python-base">https://hub . docker . com/r/ARV slat/Amazon-sage maker-cookbook-python-base</a>:</p><div><img src="img/B16850_02_57.jpg" alt="Figure 2.57 – Docker Hub page for the base image&#13;&#10;" width="1591" height="976"/></div><p class="figure-caption">图2.57–基本映像的Docker Hub页面</p><p>在这里，我们可以看到<strong class="bold">Amazon-sagemaker-cookbook-python-base</strong>图像的<strong class="bold"> Docker Hub </strong>页面。</p><p class="callout-heading">小费</p><p class="callout">您可以在<em class="italic">Machine Learning with Amazon sage maker Cookbook</em>GitHub存储库中访问此docker文件的工作副本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/blob/master/Chapter02/ml-python/serve">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/blob/master/chapter 02/ml-python/serve</a>。</p><p>准备好docker文件后，我们<a id="_idIndexMarker322"/>将继续使用终端，直到本配方结束:</p></li>
				<li>You can use a new Terminal tab or an existing one to run the next set of commands:<div><img src="img/B16850_02_058.jpg" alt="Figure 2.58 – New Terminal&#13;&#10;" width="685" height="325"/></div><p class="figure-caption">图2.58–新终端</p><p>在这里，我们可以看到如何创建新的终端。请注意，在AWS Cloud9 IDE中，<strong class="bold">终端</strong>窗格位于<strong class="bold">编辑器</strong>窗格之下。</p></li>
				<li>导航到包含Dockerfile: <pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-python</strong></pre>的ml-python目录</li>
				<li>指定图像名称和标签号:<pre><strong class="bold">IMAGE_NAME=chap02_python</strong> <strong class="bold">TAG=1</strong></pre></li>
				<li>Build the <strong class="bold">Docker</strong> container using the docker build command:<pre><strong class="bold">docker build --no-cache -t $IMAGE_NAME:$TAG .</strong></pre><p>docker build命令利用了我们docker文件中的内容。我们从FROM指令中指定的映像开始，然后将文件复制到容器映像中。</p></li>
				<li>Use the docker run command <a id="_idIndexMarker323"/>to test if the train script works:<pre><strong class="bold">docker run --name pytrain --rm -v /opt/ml:/opt/ml $IMAGE_NAME:$TAG train</strong></pre><p>让我们快速讨论一下该命令中使用的一些不同选项。rm标志使Docker在容器退出后清理容器。-v标志允许我们将/opt/ml目录从主机系统挂载到容器的/opt/ml目录:</p><div><img src="img/B16850_02_59.jpg" alt="Figure 2.59 – Result of the docker run command (train)&#13;&#10;" width="511" height="395"/></div><p class="figure-caption">图2.59-docker run命令的结果(训练)</p><p>在这里，我们可以看到运行docker run命令后的结果。它应该显示类似于我们在<em class="italic">准备和测试Python </em>脚本中的日志。</p></li>
				<li>Use the docker run command to test if the serve script works:<pre><strong class="bold">docker run --name pyserve --rm -v /opt/ml:/opt/ml $IMAGE_NAME:$TAG serve</strong></pre><p>运行该命令后，Flask API服务器成功启动。我们应该会看到类似于我们在<em class="italic">准备和测试Python中的serve脚本</em>的日志:</p><div><img src="img/B16850_02_60.jpg" alt="Figure 2.60 – Result of the docker run command (serve)&#13;&#10;" width="631" height="162"/></div><p class="figure-caption">图2.60–docker运行命令(serve)的结果</p><p>在这里，我们可以看到API正在端口8080上运行。在我们使用的基本映像中，我们添加了EXPOSE 8080，以允许我们访问正在运行的容器中的这个端口。</p></li>
				<li>Open a new Terminal tab:<div><img src="img/B16850_02_61.jpg" alt="Figure 2.61 – New Terminal&#13;&#10;" width="794" height="225"/></div><p class="figure-caption">图2.61–新终端</p><p>由于API已经在第一个终端中运行，我们创建了一个新的终端。</p></li>
				<li>In the new Terminal tab, run the following command to get the IP address of the running Flask app:<pre><strong class="bold">SERVE_IP=$(docker network inspect bridge | jq -r ".[0].Containers[].IPv4Address" | awk -F/ '{print $1}')</strong>
<strong class="bold">echo $SERVE_IP</strong></pre><p>我们应该得到一个等于或类似于172.17.0.2的IP地址。当然，我们可能会得到不同的IP地址值。</p></li>
				<li>Next, test the ping endpoint URL using the curl command: <pre><strong class="bold">curl http://$SERVE_IP:8080/ping</strong></pre><p>运行这个命令后，我们应该会得到一个OK。</p></li>
				<li>Finally, test the <a id="_idIndexMarker325"/>invocations endpoint URL using the curl command:<pre><strong class="bold">curl -d "1" -X POST http://$SERVE_IP:8080/invocations</strong></pre><p>在调用调用端点之后，我们应该得到一个类似于或接近于881.3428400857507的值。</p></li>
			</ol>
			<p>现在，可以肯定地说，我们在这个菜谱中准备的定制容器图像已经准备好了。现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-85">它是如何工作的…</h2>
			<p>在这个菜谱中，我们使用我们指定的Dockerfile配置构建了一个定制的容器映像。当您有一个docker文件时，标准的步骤是使用docker build命令构建docker映像，使用ECR进行身份验证以获得必要的权限，使用docker tag命令适当地标记映像，并使用docker push命令将Docker映像推送到ECR存储库。</p>
			<p>让我们讨论一下docker文件中的内容。如果这是您第一次听说Dockerfiles，它们只是包含构建映像命令的文本文件。在我们的docker文件中，我们执行了以下操作:</p>
			<ul>
				<li>我们使用ARV slat/Amazon-sage maker-cookbook-python-base作为基础映像。查看<a href="https://hub.docker.com/repository/docker/arvslat/amazon-sagemaker-cookbook-python-base">https://hub . docker . com/repository/docker/ARV slat/Amazon-sage maker-cookbook-python-base</a>以了解关于该图像的更多详细信息。</li>
				<li>我们将train和serve脚本复制到容器映像中的/usr/local/bin目录。这些脚本是在我们使用docker run时执行的。</li>
			</ul>
			<p>使用ARV slat/Amazon-sage maker-cookbook-python-base映像作为基本映像允许我们编写一个较短的Dockerfile，它只关注将train和serve文件复制到容器映像内的目录。在幕后，我们已经在这个容器映像中预装了flask、pandas、scikit-learn和joblib包，以及它们的先决条件<a id="_idIndexMarker326"/>,这样我们在构建定制容器映像时就不会遇到问题。下面是我们在这个食谱中用作基础图像的Dockerfile文件的快速浏览:</p>
			<pre>FROM <strong class="bold">ubuntu:18.04</strong>
    
RUN apt-get -y update
RUN apt-get install -y <strong class="bold">python3.6</strong>
RUN apt-get install -y --no-install-recommends <strong class="bold">python3-pip</strong>
RUN apt-get install -y <strong class="bold">python3-setuptools</strong>
    
RUN ln -s /usr/bin/python3 /usr/bin/python &amp; \
    ln -s /usr/bin/pip3 /usr/bin/pip
    
RUN pip install <strong class="bold">flask</strong>
RUN pip install <strong class="bold">pandas</strong>
RUN pip install <strong class="bold">scikit-learn</strong>
RUN pip install <strong class="bold">joblib</strong>
    
WORKDIR /usr/local/bin
EXPOSE 8080</pre>
			<p>在这个Dockerfile文件中，我们可以看到我们正在使用Ubuntu:18.04作为基础映像。注意，我们也可以使用其他基本映像，这取决于我们希望安装在容器映像中的库和框架。</p>
			<p>一旦我们构建了<a id="_idIndexMarker327"/>容器映像，下一步将是测试一旦我们使用docker run，train和serve脚本是否能在容器内工作。获取正在运行的容器的IP地址可能是最棘手的部分，如下面的代码块所示:</p>
			<pre>SERVE_IP=$(docker network inspect bridge | jq -r ".[0].Containers[].IPv4Address" | awk -F/ '{print $1}')</pre>
			<p>我们可以将其分为以下几个部分:</p>
			<ul>
				<li>docker network inspect bridge:它以JSON格式提供了关于网桥网络的详细信息。它应该返回一个结构类似于以下JSON值的输出:<pre>[     {         ...         "Containers": {             "1b6cf4a4b8fc5ea5...": {                 "Name": "pyserve",                 "EndpointID": "ecc78fb63c1ad32f0...",                 "MacAddress": "02:42:ac:11:00:02",                 "IPv4Address": "<strong class="bold">172.17.0.2</strong>/16",                 "IPv6Address": ""             }         },         ...     } ]</pre></li>
				<li>jq -r”。[0].containers[][IP v4 address]:解析来自docker network inspect bridge的JSON响应值<a id="_idIndexMarker328"/>。在第一个命令之后通过管道传输这个命令将产生类似于172.17.0.2/16的输出。</li>
				<li>awk -F/ '{print $1} ':这使用/分隔符分割jq命令的结果，并返回/之前的值。从前面的命令中获得AA.BB.CC.DD/16值后，我们得到AA。BB.CC.DD在使用awk命令之后。</li>
			</ul>
			<p>一旦我们有了正在运行的容器的IP地址，我们就可以ping/ping和/invocations端点，类似于我们在<em class="italic">中使用Python </em>方法准备和测试serve脚本时所做的。</p>
			<p>在本章的下一个菜谱中，当我们使用<strong class="bold"> SageMaker Python SDK </strong>进行培训和部署时，我们将使用这个定制容器映像。</p>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor085"/>将定制Python算法容器映像推送到Amazon ECR存储库</h1>
			<p>在前面的菜谱中，我们<a id="_idIndexMarker329"/>已经使用docker build命令准备并构建了定制容器映像。在<a id="_idIndexMarker330"/>这个菜谱中，我们将把定制容器映像推送到一个<strong class="bold"> Amazon ECR </strong>存储库中。如果这是你第一次听说<strong class="bold">亚马逊ECR </strong>，它只是一个完全管理的容器注册表，帮助我们管理我们的容器图像。</p>
			<p>在将容器映像推送到Amazon ECR存储库之后，我们可以使用该映像在<em class="italic">中进行训练和部署，使用定制Python算法容器映像通过Amazon SageMaker本地模式</em>配方进行训练和推理。</p>
			<h2 id="_idParaDest-87">准备就绪</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>该方法延续了<em class="italic">构建和测试定制Python算法容器映像</em>的方法。</li>
				<li>如果你使用一个有自定义URL的AWS IAM用户，你将需要必要的权限来管理亚马逊ECR T21资源。</li>
			</ul>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor087"/>怎么做……</h2>
			<p>该方法的最初步骤集中在创建ECR存储库。让我们开始吧:</p>
			<ol>
				<li value="1">Use the <a id="_idIndexMarker331"/>search bar in<a id="_idIndexMarker332"/> the <strong class="bold">AWS Console</strong> to navigate to the <strong class="bold">Elastic Container Registry</strong> console. Click <strong class="bold">Elastic Container Registry</strong> when it appears in the search results:<div><img src="img/B16850_02_62.jpg" alt="Figure 2.62 – Navigating to the ECR console&#13;&#10;" width="590" height="409"/></div><p class="figure-caption">图2.62–导航至ECR控制台</p><p>如您所见，我们可以使用搜索栏快速导航到<strong class="bold">弹性容器注册中心</strong>服务。如果我们输入ecr，搜索结果中的<strong class="bold">弹性容器注册</strong>服务可能会出现在第三或第四位。</p></li>
				<li>Click the <strong class="bold">Create repository</strong> button:<div><img src="img/B16850_02_63.jpg" alt="Figure 2.63 – Create repository button&#13;&#10;" width="734" height="90"/></div><p class="figure-caption">图2.63–创建存储库按钮</p><p>这里，<strong class="bold">创建存储库</strong>按钮位于屏幕的右上角。</p></li>
				<li>In <a id="_idIndexMarker333"/>the <strong class="bold">Create repository</strong> form, specify a <strong class="bold">Repository name</strong>. Use the value of $IMAGE_NAME from<a id="_idIndexMarker334"/> the <em class="italic">Building and testing the custom Python algorithm container image</em> recipe. In this case, we will use chap02_python:<div><img src="img/B16850_02_64.jpg" alt="Figure 2.64 – Create repository form&#13;&#10;" width="1034" height="743"/></div><p class="figure-caption">图2.64–创建存储库表单</p><p>这里，我们有<strong class="bold">创建存储库</strong>表单。对于<strong class="bold">可见性设置</strong>，我们将选择<strong class="bold">私有</strong>并将<strong class="bold">标签不变性</strong>配置设置为<strong class="bold">禁用</strong>。</p></li>
				<li>Scroll down until you see the <strong class="bold">Create repository</strong> button. Leave the other configuration settings as-is and click <strong class="bold">Create repository</strong>:<div><img src="img/B16850_02_65.jpg" alt="Figure 2.65 – Create repository button&#13;&#10;" width="1024" height="395"/></div><p class="figure-caption">图2.65–创建存储库按钮</p><p>正如我们<a id="_idIndexMarker335"/>所见，<strong class="bold">创建存储库</strong>按钮<a id="_idIndexMarker336"/>位于页面底部。</p></li>
				<li>Click <strong class="bold">chap02_python</strong>:<div><img src="img/B16850_02_66.jpg" alt="Figure 2.66 – Link to the ECR repository page&#13;&#10;" width="830" height="141"/></div><p class="figure-caption">图2.66–ECR存储库页面的链接</p><p>这里，我们在<strong class="bold">存储库名称</strong>列下有一个链接。单击此链接应该会将我们重定向到存储库的详细信息页面。</p></li>
				<li>Click <strong class="bold">View push commands</strong>:<div><img src="img/B16850_02_67.jpg" alt="Figure 2.67 – View push commands button (upper right)&#13;&#10;" width="1470" height="402"/></div><p class="figure-caption">图2.67–查看按钮命令按钮(右上)</p><p>正如我们可以看到的,<a id="_idIndexMarker337"/>视图按钮<strong class="bold">命令按钮</strong>在页面的右上角，在<a id="_idIndexMarker338"/>编辑按钮旁边。</p></li>
				<li>You may optionally copy the first command, aws ecr get-login-password …, from the dialog box.<div><img src="img/B16850_02_68.jpg" alt="Figure 2.68 – Push commands dialog box&#13;&#10;" width="1026" height="910"/></div><p class="figure-caption">图2.68–推送命令对话框</p><p>在这里，我们可以看到我们可以使用的多个命令。我们将只需要第一个(aws ecr get-login-password …)。单击代码框右侧带有两个重叠框的图标，将整行复制到剪贴板。</p></li>
				<li>Navigate<a id="_idIndexMarker339"/> back to the <a id="_idIndexMarker340"/>AWS Cloud9 environment IDE and create a new Terminal. You may also reuse an existing one:<div><img src="img/B16850_02_69.jpg" alt="Figure 2.69 – New Terminal&#13;&#10;" width="867" height="282"/></div><p class="figure-caption">图2.69–新终端</p><p>前面的截图向我们展示了如何创建一个新的终端。点击绿色加号按钮，然后从选项列表中选择<strong class="bold">新端子</strong>。请注意，绿色加号按钮位于<strong class="bold">编辑器</strong>窗格的正下方。</p></li>
				<li>导航到ml-python目录:<pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-python</strong></pre></li>
				<li>使用以下命令获取帐户ID:<pre><strong class="bold">ACCOUNT_ID=$(aws sts get-caller-identity | jq -r ".Account")</strong> <strong class="bold">echo $ACCOUNT_ID</strong></pre></li>
				<li>指定IMAGE_URI值，并使用我们在此配方中创建存储库时指定的ECR存储库名称。在这种情况下，我们将运行IMAGE_URI="chap02_python": <pre><strong class="bold">IMAGE_URI="&lt;insert ECR Repository URI&gt;"</strong> <strong class="bold">TAG="1"</strong></pre></li>
				<li>Authenticate with <strong class="bold">Amazon ECR</strong> so that we can push our <strong class="bold">Docker</strong> container image to an <strong class="bold">Amazon ECR</strong> repository in our account later:<pre><strong class="bold">aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com</strong></pre><p class="callout-heading">重要说明</p><p class="callout">请注意，我们已经假设我们的存储库位于us-east-1地区。如果需要，可以随意修改命令中的区域。这适用于本章中的所有命令。</p></li>
				<li>使用<a id="_idIndexMarker341"/>docker标签命令:<pre><strong class="bold">docker tag $IMAGE_URI:$TAG $ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/$IMAGE_URI:$TAG</strong></pre></li>
				<li>Push the image<a id="_idIndexMarker342"/> to the <strong class="bold">Amazon ECR</strong> repository using the docker push command:<pre><strong class="bold">docker push $ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/$IMAGE_URI:$TAG</strong></pre><p>此时，我们的定制容器映像应该已经被成功地推送到ECR存储库中了。</p></li>
			</ol>
			<p>现在我们已经完成了这个菜谱，在下一个菜谱中，我们可以继续使用这个定制的容器映像进行训练和推断。但在此之前，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor088"/>工作原理……</h2>
			<p>在前面的菜谱中，我们使用了docker build命令来准备定制容器映像。在这个菜谱中，我们创建了一个<strong class="bold"> Amazon ECR </strong>存储库，并将我们的定制容器映像推送到该存储库。有了Amazon ECR，我们可以在任何地方存储、管理、共享和运行定制的容器映像。这包括在培训和部署期间在SageMaker中使用这些容器映像。</p>
			<p>当将自定义容器映像推送到Amazon ECR存储库时，我们需要帐户ID、区域、存储库名称和标签。一旦我们有了这些，docker push命令将看起来像这样:</p>
			<pre>docker push &lt;ACCOUNT_ID&gt;.dkr.ecr.&lt;REGION&gt;.amazonaws.com/&lt;REPOSITORY NAME&gt;:&lt;TAG&gt;</pre>
			<p>当使用容器映像版本时，确保每次修改docker文件时更改版本号，并将新版本推送到<strong class="bold"> ECR </strong>存储库。当您需要使用以前版本的容器映像时，这将很有帮助。</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor089"/>使用定制Python算法容器映像，通过Amazon SageMaker本地模式进行训练和推理</h1>
			<p>在这个配方中，我们将使用自定义容器映像执行<strong class="bold"> Amazon Sagemaker </strong>中的<a id="_idIndexMarker345"/>培训和部署步骤，我们在<em class="italic">中将自定义Python算法容器映像推送到Amazon ECR仓库</em>配方中将其推送到ECR仓库。在<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第一章</em> </a>，<em class="italic">使用亚马逊SageMaker </em>进行机器学习入门中，我们使用了内置<strong class="bold">线性学习器</strong>的容器图像的图像URI。在本章中，我们将使用自定义容器图像的图像URI。</p>
			<p>下图显示了当我们将fit()和predict()函数与<strong class="bold"> SageMaker Python SDK </strong>一起使用时，<strong class="bold"> SageMaker </strong>如何将数据、文件和配置传入和传出每个自定义容器:</p>
			<div><div><img src="img/B16850_02_70.jpg" alt="Figure 2.70 – The train and serve scripts inside the custom container make use of the hyperparameters, input data, and config specified using the SageMaker Python SDK&#13;&#10;" width="1489" height="793"/>
				</div>
			</div>
			<p class="figure-caption">图2.70–定制容器中的训练和服务脚本利用了超参数、输入数据和使用SageMaker Python SDK指定的配置</p>
			<p>我们也将看看<a id="_idIndexMarker346"/>如何在这个食谱中使用<strong class="bold">本地模式</strong>。SageMaker的这一功能允许我们在本地环境中测试和模拟CPU和GPU培训工作。当我们开发、增强和测试我们的定制算法容器图像和脚本时，使用<strong class="bold">本地模式</strong>是很有用的。一旦我们准备好推出容器映像的稳定版本，我们就可以很容易地切换到使用支持训练和部署步骤的ML实例。</p>
			<p>一旦我们完成了这个配方，我们将能够运行训练作业，并使用Python和定制容器中的定制训练和服务脚本部署推理端点。</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor090"/>准备就绪</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>这个方法从<em class="italic">将定制Python算法容器映像推送到Amazon ECR存储库</em>开始。</li>
				<li>我们将使用来自<em class="italic">的SageMaker笔记本实例启动一个Amazon SageMaker笔记本实例，并准备<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第1章</em> </a>、<em class="italic">使用Amazon SageMaker </em>开始机器学习的先决条件</em>配方。</li>
			</ul>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor091"/>怎么做……</h2>
			<p>这个菜谱的前几个步骤主要是使用conda_python3内核准备Jupyter笔记本:</p>
			<ol>
				<li value="1">Inside your SageMaker Notebook instance, create a new directory called chapter02 inside the my-experiments directory. As shown in the following screenshot, we can perform this step by clicking the <strong class="bold">New</strong> button and then choosing <strong class="bold">Folder</strong> (under <strong class="bold">Other</strong>):<div><img src="img/B16850_02_71.jpg" alt="Figure 2.71 – New &gt; Folder&#13;&#10;" width="731" height="273"/></div><p class="figure-caption">图2.71–新建&gt;文件夹</p><p>这将创建一个名为无标题文件夹的目录。</p></li>
				<li>Click the checkbox and then click <strong class="bold">Rename</strong>. Change the name to chapter02:<div><img src="img/B16850_02_72.jpg" alt="Figure 2.72 – Renaming &quot;Untitled Folder&quot; to &quot;chapter02&quot;&#13;&#10;" width="817" height="314"/></div><p class="figure-caption">图2.72–将“无标题文件夹”重命名为“第2章”</p><p>之后，我们<a id="_idIndexMarker348"/>应该会得到想要的目录结构，如前面的截图所示。现在，让我们看看下面的目录结构:</p><div><img src="img/B16850_02_73.jpg" alt="Figure 2.73 – Directory structure&#13;&#10;" width="593" height="149"/></div><p class="figure-caption">图2.73–目录结构</p><p>此屏幕截图显示了我们希望如何组织我们的文件和笔记本。在我们阅读每一章时，我们将使用相同的命名约定添加更多的目录，以保持组织有序。</p></li>
				<li>点击<strong class="bold">第02章</strong>目录，导航至<strong class="bold">/我的-实验/第02章</strong>。</li>
				<li>Create a new notebook by clicking <strong class="bold">New</strong> and then clicking <strong class="bold">conda_python3</strong>:<div><img src="img/B16850_02_74.jpg" alt="Figure 2.74 – Creating a new notebook using the conda_python3 kernel&#13;&#10;" width="298" height="582"/></div><p class="figure-caption">图2.74–使用conda_python3内核创建新笔记本</p><p>现在我们有了一个使用conda_python3内核的全新Jupyter笔记本，我们将继续<a id="_idIndexMarker349"/>准备培训和部署步骤的先决条件。</p></li>
				<li>In the first cell of the Jupyter Notebook, use pip install to upgrade sagemaker[local]:<pre>!pip install 'sagemaker[local]' --upgrade</pre><p>这将允许我们使用<strong class="bold">本地模式</strong>。在处理框架映像(如<strong class="bold"> TensorFlow </strong>、<strong class="bold"> PyTorch </strong>、<strong class="bold"> scikit-learn </strong>和<strong class="bold"> MXNet </strong>)以及我们自己构建的自定义映像时，我们可以使用本地模式。</p><p class="callout-heading">重要说明</p><p class="callout">注意我们不能在<strong class="bold"> SageMaker Studio </strong>中使用<strong class="bold">本地模式</strong>。我们也不能使用内置算法的本地模式。</p></li>
				<li>Specify the bucket <a id="_idIndexMarker350"/>name where the training_data.csv file is stored. Use the bucket name we created in the <em class="italic">Preparing the Amazon S3 bucket and the training dataset for the linear regression experiment</em> recipe of <a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"><em class="italic">Chapter 1</em></a><em class="italic">, Getting Started with Machine Learning Using Amazon SageMaker</em>:<pre>s3_bucket = "<strong class="bold">&lt;insert bucket name here&gt;</strong>"
prefix = "chapter01"</pre><p>请注意，我们的training_data.csv文件应该已经存在于S3存储桶中，并且应该具有以下路径:</p><pre><strong class="bold">s3://&lt;S3 BUCKET NAME&gt;/&lt;PREFIX&gt;/input/training_data.csv</strong></pre></li>
				<li>设置训练_ S3 _输入_位置和训练_ S3 _输出_位置的变量值:<pre><strong class="bold">training_s3_input_location</strong> = \ f"s3://{s3_bucket}/{prefix}/input/training_data.csv" <strong class="bold">training_s3_output_location</strong> = \ f"s3://{s3_bucket}/{prefix}/output/custom/"</pre></li>
				<li>Import the <strong class="bold">SageMaker Python SDK</strong> and check its version:<pre>import sagemaker
sagemaker.<strong class="bold">__version__</strong></pre><p>在运行前面的代码块后，我们应该得到一个等于或接近2.31.0的值。</p></li>
				<li>Set the value of the container image. Use the value from the <em class="italic">Pushing the custom Python algorithm container image to an Amazon ECR repository</em> recipe. The container variable should be set to a value similar to &lt;ACCOUNT_ID&gt;.dkr.ecr.us-east-1.amazonaws.com/chap02_python:1. Make sure to replace &lt;ACCOUNT_ID&gt; with your AWS account ID:<pre>container="&lt;insert image uri and tag here&gt;"</pre><p>要获得<account_id>的值，运行ACCOUNT _ ID = $(AWS STS get-caller-identity | jq-r "。Account”)，然后在终端中回显ACCOUNT _ ID。请记住，我们在<em class="italic">中将定制Python算法容器映像推送到Amazon ECR存储库</em>配方中执行了这一步骤，因此您应该为ACCOUNT_ID获得相同的值。</account_id></p></li>
				<li>导入一些<a id="_idIndexMarker351"/>先决条件，如角色和会话。你可能会注意到这个食谱和第一章  <em class="italic">《使用亚马逊SageMaker </em>开始机器学习》中的食谱的一个主要区别LocalSession的用法。LocalSession类允许我们在训练和部署步骤<pre>import boto3 from sagemaker import get_execution_role  role = get_execution_role() from sagemaker.local import <strong class="bold">LocalSession</strong> session = LocalSession() session.config = {'local': {'local_code': True}}</pre>中使用<strong class="bold">本地模式</strong></li>
				<li>Initialize the TrainingInput object for the train data channel:<pre>from sagemaker.inputs import TrainingInput
train = <strong class="bold">TrainingInput</strong>(training_s3_input_location, content_type="text/csv")</pre><p>既然我们有了<a id="_idIndexMarker352"/>先决条件，我们将继续初始化Estimator并使用fit()和predict()函数。</p></li>
				<li>Initialize Estimator and use container, role, session, and training_s3_output_location as the parameter values when initializing the Estimator object:<pre>estimator = sagemaker.estimator.<strong class="bold">Estimator</strong>(
    container,
    role, 
    instance_count=1, 
    instance_type='<strong class="bold">local</strong>',
    output_path=training_s3_output_location,
    sagemaker_session=<strong class="bold">session</strong>)</pre><p>这里，我们将instance_type值设置为local，将sagemaker_session值设置为session(这是一个LocalSession对象)。这意味着当我们稍后运行fit()函数时，训练作业将在本地执行，并且不会为训练作业提供任何ML实例。</p><p class="callout-heading">重要说明</p><p class="callout">如果我们想在一个专用的ml实例中执行训练任务，只需用ml.m5.xlarge(或一个替代的ML实例类型)替换instance_type值，用session对象替换sagemaker_session值。为了确保我们不会遇到培训作业名称验证问题(因为我们在ECR存储库名称中使用了下划线)，请在初始化Estimator时使用适当的值指定base_job_name参数值。</p></li>
				<li>使用set_hyperparameters()函数设置几个虚拟超参数。在后台，这些值将被传递到/opt/ml/input/config目录中的hyperparameters.json文件，当我们稍后运行fit()函数时，train脚本将加载并使用这些值:<pre>estimator.<strong class="bold">set_hyperparameters</strong>(a=1, b=2, c=3)</pre></li>
				<li>Start the <a id="_idIndexMarker353"/>training job using fit():<pre>estimator.<strong class="bold">fit</strong>({'train': train})</pre><p>这将生成一组日志，如下所示:</p><div><img src="img/B16850_02_75.jpg" alt="Figure 2.75 – Using fit() with local mode&#13;&#10;" width="817" height="370"/></div><p class="figure-caption">图2.75–在本地模式下使用fit()</p><p>在这里，我们可以看到，当我们在实验环境中运行train脚本时，生成了一组类似的日志。正如第一章  <em class="italic">中的<em class="italic">在Python中训练你的第一个模型一样，使用Amazon SageMaker </em>开始机器学习，fit()命令将在训练作业期间准备一个实例来训练模型。在这个配方中，我们使用<strong class="bold">本地模式</strong>，所以没有创建实例。</em></p><p class="callout-heading">重要说明</p><p class="callout">为了与我们在第1章  <em class="italic">【亚马逊SageMaker </em>机器学习入门】的<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">中所做的进行比较，我们在第1章</em> </a>的<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">模型类中使用了fit()函数，而在本章中我们在估计器类中使用了fit()函数。从技术上讲，我们可以使用这两种方法中的任何一种，但是在这个方法中，我们直接在估计器对象初始化之后使用fit()函数，而没有初始化单独的模型对象。</em></a></p></li>
				<li>Use the deploy() function to deploy the inference endpoint:<pre>predictor = estimator.<strong class="bold">deploy</strong>(
    initial_instance_count=1, 
    instance_type='local', 
    endpoint_name="custom-local-py-endpoint")</pre><p>由于我们是使用<strong class="bold">本地模式</strong>的<a id="_idIndexMarker354"/>，所以没有创建实例，容器在SageMaker Notebook实例中运行:</p><div><img src="img/B16850_02_76.jpg" alt="Figure 2.76 – Using deploy() with local mode&#13;&#10;" width="929" height="168"/></div><p class="figure-caption">图2.76–在本地模式下使用deploy()</p><p>正如我们所看到的，我们以类似于在<em class="italic">构建和测试定制Python算法容器映像</em>的方法中获取日志消息的方式获取日志消息。这意味着如果我们不能让容器在那个配方中运行，那么我们也不能让容器在这个配方中运行。</p></li>
				<li>Once the endpoint is ready, we can use the predict() function to test if the inference endpoint is working as expected. This will trigger the /invocations endpoint behind the scenes and pass a value of "1" in the POST body:<pre>predictor.<strong class="bold">predict</strong>("1")</pre><p>这应该会生成一组类似于以下内容的日志:</p><div><img src="img/B16850_02_77.jpg" alt="Figure 2.77 – Using predict() with local mode&#13;&#10;" width="844" height="43"/></div><pre>@app.route("/invocations", methods=["POST"])
def <strong class="bold">predict()</strong>:
    model = load_model()
    ...
    return Response(..., status=200)</pre><p>如果我们回过头来查看本章中的<em class="italic">在Python中准备和测试serve脚本</em>方法，我们将会看到，通过修改serve脚本中predict()函数内的代码，我们可以完全控制调用端点的工作方式。为了方便起见，我们复制了前面代码块中函数的某一部分。</p></li>
				<li>Use delete_endpoint() to delete the local prediction endpoint:<pre>predictor.delete_endpoint()</pre><p>我们应该会得到类似如下的消息:</p></li>
			</ol>
			<div><div><img src="img/B16850_02_78.jpg" alt="Figure 2.78 – Using delete_endpoint() with local mode&#13;&#10;" width="657" height="28"/>
				</div>
			</div>
			<p class="figure-caption">图2.78–在本地模式下使用delete_endpoint()</p>
			<p>正如我们所看到的，使用delete_endpoint()将导致<strong class="bold">优雅地停止… </strong>消息。假设我们在这个配方中使用了<strong class="bold">本地模式</strong>，delete_endpoint()函数将停止SageMaker Notebook实例中正在运行的API服务器。如果不使用<strong class="bold">本地模式</strong>，SageMaker推理端点和支持它的ML计算实例将被删除。</p>
			<p>现在，让我们来看看这是如何工作的！</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor092"/>工作原理…</h2>
			<p>在这个菜谱中，我们使用了<a id="_idIndexMarker356"/>我们在前面的部分中在训练和部署Python时准备的定制容器映像，而不是<strong class="bold"> SageMaker </strong>的内置算法。所有的步骤都类似于我们为内置算法所遵循的步骤；您需要注意的唯一变化是容器图像、输入参数和超参数。</p>
			<p>请注意，我们完全控制可以在Estimator中指定的超参数，因为这取决于我们的自定义脚本所期望的超参数。如果你需要这些超参数的更真实的例子，这里有来自<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第一章</em> </a> <em class="italic">的超参数，使用亚马逊SageMaker </em>开始机器学习:</p>
			<pre>estimator.set_hyperparameters(
    <strong class="bold">predictor_type='regressor'</strong>,
    <strong class="bold">mini_batch_size=4</strong>)</pre>
			<p>在此示例中，hyperparameters.json文件包含以下内容，是在调用fit()函数时创建的:</p>
			<pre>{"predictor_type": "regressor", "mini_batch_size": 4}</pre>
			<p>我们在这个配方中可以使用和配置的参数与我们在SageMaker的内置算法中使用的参数大致相同。唯一的主要区别是，我们使用ECR存储库的容器映像URI，而不是内置算法的容器映像URI。</p>
			<p>当我们使用自定义容器映像时，我们可以选择在执行培训和部署时使用<strong class="bold">本地模式</strong>。在本地模式下，除了SageMaker Notebook实例之外，不会创建其他实例。这使我们能够测试定制容器映像是否工作，与使用真实实例(例如ml.m5.xlarge)相比，无需等待几分钟。一旦使用本地模式一切正常，我们可以通过替换Estimator中的session和instance_type来轻松地切换到使用真实的实例。</p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor093"/>在R准备和测试列车脚本</h1>
			<p>在这个菜谱中，我们将用R编写一个<a id="_idIndexMarker357"/>定制训练脚本，允许我们在训练过程中检查输入<a id="_idIndexMarker358"/>和由<strong class="bold"> Amazon SageMaker </strong>设置的配置参数。下图显示了自定义容器中的训练脚本，该脚本利用了超参数、输入数据和使用<strong class="bold"> SageMaker Python SDK </strong>和reticulate包的Estimator实例中指定的配置:</p>
			<div><div><img src="img/B16850_02_79.jpg" alt="Figure 2.79 – The R train script inside the custom container makes use of the input parameters, configuration, and data to train and output a model&#13;&#10;" width="1180" height="720"/>
				</div>
			</div>
			<p class="figure-caption">图2.79–自定义容器中的R train脚本利用输入参数、配置和数据来训练和输出模型</p>
			<p>运行训练作业时有几个选项–使用内置算法、使用自定义训练脚本和自定义Docker映像，或者使用自定义训练脚本和预构建的Docker映像。在这个菜谱中，我们将关注第二个选项，在这里我们将准备并测试一个最简单的R训练脚本，它为一个特定的回归问题建立一个线性模型。</p>
			<p>一旦我们完成了这个食谱，我们将会对SageMaker的幕后工作有更好的理解。我们将看到在哪里以及如何加载和使用我们在<strong class="bold">SageMaker Python SDK</strong>Estimator实例中指定的配置和参数。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">稍后，你会注意到本章中Python和R食谱之间的一些相似之处。这里最关键的是注意和识别Python和R食谱中某些部分的主要和细微差别。例如，在本章中使用serve脚本时，我们将在R中处理两个文件(api.r和serve ),而不是在Python中处理一个文件(serve)。正如我们将在本书的其他配方中看到的，研究R配方将有助于我们更好地理解SageMaker功能的内部，因为我们很有可能必须准备定制解决方案来解决某些需求。随着我们接触到更多的机器学习需求，我们会发现R中有一些用于机器学习的包，而Python中没有直接对应的包。也就是说，我们必须熟悉如何让定制的R算法代码在SageMaker中工作。敬请关注更多内容！</p>
			<h2 id="_idParaDest-95">准备就绪</h2>
			<p>确保您已经完成了<em class="italic">设置Python和R实验环境</em>的步骤。</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor095"/>怎么做...</h2>
			<p>该配方中的第一组步骤主要是准备培训脚本。让我们开始吧:</p>
			<ol>
				<li value="1">Inside the ml-r directory, double-click the train file to open it inside the <strong class="bold">Editor</strong> pane:<div><img src="img/B16850_02_80.jpg" alt="Figure 2.80 – Empty ml-r/train file&#13;&#10;" width="699" height="250"/></div><p class="figure-caption">图2.80–空的ml-r/train文件</p><p>这里，我们有一个空的火车文件。在<strong class="bold">编辑器</strong>窗格的右下角，您可以将语法高亮设置更改为r</p></li>
				<li>添加以下代码行来启动train脚本，以便导入所需的包和库:<pre>#!/usr/bin/Rscript library("rjson")</pre></li>
				<li>Define the prepare_paths() function, which we will use to initialize the PATHS variable. This <a id="_idIndexMarker361"/>will help us manage the paths of the primary files<a id="_idIndexMarker362"/> and directories used in the script:<pre><strong class="bold">prepare_paths</strong> &lt;- function() {
    keys &lt;- c('hyperparameters', 
              'input', 
              'data',
              'model')
    
    values &lt;- c('input/config/hyperparameters.json', 
                'input/config/inputdataconfig.json', 
                'input/data/',
                'model/')
    
    paths &lt;- as.list(values)
    names(paths) &lt;- keys
    
    return(paths);
} 
    
PATHS &lt;- prepare_paths()</pre><p>这个函数允许我们用一个类似字典的数据结构初始化PATHS变量，在这个数据结构中我们可以获得所需文件的绝对路径。</p></li>
				<li>Next, define<a id="_idIndexMarker363"/> the get_path() function, which makes use of<a id="_idIndexMarker364"/> the PATHS variable from the previous step:<pre><strong class="bold">get_path</strong> &lt;- function(key) {
    output &lt;- paste('/opt/ml/', PATHS[[key]],
                    sep="")
    
    return(output);
}</pre><p>当引用特定文件的位置时，比如hyperparameters.json，我们将使用get_path('hyperparameters ')而不是绝对路径。</p></li>
				<li>接下来，将以下代码行添加到上一步中的get_path()函数定义之后。这些函数将用于加载和打印我们稍后将使用的JSON文件的内容:<pre><strong class="bold">load_json</strong> &lt;- function(target_file) {     result &lt;- fromJSON(file = target_file) } <strong class="bold">print_json</strong> &lt;- function(target_json) {     print(target_json) }</pre></li>
				<li>After that, define <a id="_idIndexMarker365"/>the inspect_hyperparameters() and list_dir_contents() functions after the print_json() function<a id="_idIndexMarker366"/> definition:<pre><strong class="bold">inspect_hyperparameters</strong> &lt;- function() {
    hyperparameters_json_path &lt;- get_path(
        'hyperparameters'
    )
    print(hyperparameters_json_path)
    hyperparameters &lt;- load_json(
        hyperparameters_json_path
    )
    print(hyperparameters)
}
<strong class="bold">list_dir_contents</strong> &lt;- function(target_path) {
    print(list.files(target_path))
}</pre><p>inspect_hyperparameters()函数检查/opt/ml/input/config目录中hyperparameters.json文件的内容。另一方面，list_dir_contents()函数显示目标目录的内容。</p></li>
				<li>Define the inspect_input() function. It will help us inspect the contents of inputdataconfig.json inside the /opt/ml/input/config directory:<pre><strong class="bold">inspect_input</strong> &lt;- function() {
    input_config_json_path &lt;- get_path('input')
    print(input_config_json_path)
    <strong class="bold">input_config</strong> &lt;- load_json(
        input_config_json_path
    )
    print_json(input_config)
    
    for (key in names(<strong class="bold">input_config</strong>)) {
        print(key)
        
        input_data_dir &lt;- paste(get_path('data'), 
                                key, '/', sep="")
        print(input_data_dir)
        <strong class="bold">list_dir_contents</strong>(input_data_dir)
    }
}</pre><p>这将用于<a id="_idIndexMarker367"/>在main()函数中列出训练输入目录<a id="_idIndexMarker368"/>的内容。</p></li>
				<li>Define the load_training_data() function:<pre><strong class="bold">load_training_data</strong> &lt;- function(input_data_dir) {
    print('[load_training_data]')
    files &lt;- <strong class="bold">list_dir_contents</strong>(input_data_dir)
    training_data_path &lt;- paste0(
        input_data_dir, files[[1]])
    print(training_data_path)
    
    df &lt;- <strong class="bold">read.csv</strong>(training_data_path, header=FALSE)
    colnames(df) &lt;- c("y","X")
    print(df)
    return(df)
}</pre><p>该功能可被<a id="_idIndexMarker369"/>分为两部分——准备指向包含训练数据的CSV文件的特定<a id="_idIndexMarker370"/>路径，并使用read.csv()函数读取CSV文件的内容。这个函数的返回值是一个R DataFrame(一个二维的类似表格的结构)。</p></li>
				<li>接下来，定义get_input_data_dir()函数:<pre><strong class="bold">get_input_data_dir</strong> &lt;- function() {     print('[get_input_data_dir]')     key &lt;- 'train'     input_data_dir &lt;- paste0(         get_path('data'), key, '/')          return(input_data_dir) }</pre></li>
				<li>After that, define the train_model() function:<pre><strong class="bold">train_model</strong> &lt;- function(data) {
    model &lt;- <strong class="bold">lm</strong>(<strong class="bold">y ~ X</strong>, data=data)    
    print(summary(model))
    return(model)
}</pre><p>该函数利用lm()函数来拟合和准备线性模型，然后<a id="_idIndexMarker371"/>可用于回归任务。它接受一个公式<a id="_idIndexMarker372"/>，比如y ~ X作为第一个参数值，训练数据集作为第二个参数值。</p><p class="callout-heading">注意</p><p class="callout">R中的公式包含一个波浪号(~)和一个或多个位于波浪号(~)右侧的独立变量，例如X1 + X2 + X3。在这个配方的例子中，我们只有一个变量位于波形符(~)的右侧，这意味着这个模型只有一个预测变量。波浪号(~)的左侧是我们试图使用预测变量进行预测的因变量。也就是说，y ~ X公式简单地表达了预测变量X和我们试图预测的y变量之间的关系。由于我们处理的数据集与我们在第一章  <em class="italic">【使用亚马逊SageMaker </em>开始机器学习】中处理的食谱相同，这里的y变量映射到monthly_salary，而X映射到management_experience_months。</p></li>
				<li>Define the save_model() function:<pre><strong class="bold">save_model</strong> &lt;- function(model) {
    print('[save_model]')
    filename &lt;- paste0(get_path('model'), 'model')
    print(filename)
    <strong class="bold">saveRDS</strong>(model, file=filename)
    print('Model Saved!')
}</pre><p>这里，我们使用saveRDS()函数，它接受一个R对象并将其写入一个文件。在这种情况下，我们将接受一个经过训练的模型对象，并将其保存在/opt/ml/model目录中。</p></li>
				<li>Define the main() function, as shown here. This function triggers the functions defined in the previous steps:<pre><strong class="bold">main</strong> &lt;- function() {
    inspect_hyperparameters()
    inspect_input()
    input_data_dir = <strong class="bold">get_input_data_dir</strong>()
    print(input_data_dir)
    data &lt;- <strong class="bold">load_training_data</strong>(input_data_dir)
    model &lt;- <strong class="bold">train_model</strong>(data)
    <strong class="bold">save_model</strong>(model)
}</pre><p>该main()函数可<a id="_idIndexMarker373"/>分为四个部分——检查<a id="_idIndexMarker374"/>超参数和输入，加载训练数据，使用train_model()函数训练模型，以及使用save_model()函数保存模型。</p></li>
				<li>Finally, call the main() function at the end of the script:<pre>main()</pre><p class="callout-heading">小费</p><p class="callout">您可以在<em class="italic">Machine Learning with Amazon sage maker Cookbook</em>GitHub存储库中访问train文件的工作副本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/blob/master/Chapter02/ml-r/train">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/blob/master/chapter 02/ml-r/train</a>。</p><p>现在我们已经完成了训练脚本，我们将使用终端来执行这个菜谱中的最后一组步骤。最后一组步骤集中在安装一些脚本先决条件。</p></li>
				<li>Open a new Terminal:<div><img src="img/B16850_02_81.jpg" alt="Figure 2.81 – New Terminal&#13;&#10;" width="952" height="275"/></div><p class="figure-caption">图2.81–新终端</p><p>在这里，我们可以看到如何创建一个新的终端标签。我们只需点击加号(<strong class="bold"> + </strong>)按钮，然后选择<strong class="bold">新建终端</strong>。</p></li>
				<li>Check<a id="_idIndexMarker375"/> the version of <a id="_idIndexMarker376"/>R in the Terminal:<pre><strong class="bold">R --version</strong></pre><p>运行这行代码应该会返回一组与此处所示类似的结果:</p><div><img src="img/B16850_02_82.jpg" alt="Figure 2.82 – Result of the R --version command in the Terminal&#13;&#10;" width="813" height="450"/></div><p class="figure-caption">图2.82–终端中R - version命令的结果</p><p>在这里，我们可以<a id="_idIndexMarker377"/>看到我们的环境使用的是R版本3.4.4。</p></li>
				<li>Install <a id="_idIndexMarker378"/>the rjson package:<pre><strong class="bold">sudo R -e "install.packages('rjson',repos='https://cloud.r-project.org')"</strong></pre><p>rjson包提供了在r中处理json数据的工具。</p></li>
				<li>Use the following commands to make the train script executable and then run the train script:<pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-r</strong>
<strong class="bold">chmod +x train</strong>
<strong class="bold">./train</strong></pre><p>运行前面几行代码将产生类似于下面所示的结果:</p></li>
			</ol>
			<div><div><img src="img/B16850_02_83.jpg" alt="Figure 2.83 – R train script output&#13;&#10;" width="525" height="322"/>
				</div>
			</div>
			<p class="figure-caption">图2.83–R列车脚本输出</p>
			<p>在这里，我们可以看到由训练脚本生成的日志。一旦成功执行了训练脚本，我们希望模型文件存储在/opt/ml/model目录中。</p>
			<p>至此，我们已经完成了火车脚本的准备和测试。现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-97">它是如何工作的…</h2>
			<p>这个配方中的训练脚本<a id="_idIndexMarker379"/>演示了输入和输出值如何在SageMaker API和定制容器之间传递。它还执行一组相当简单的步骤，使用提供的训练数据来训练线性模型。</p>
			<p>当您需要处理更真实的示例时，训练脚本将执行以下操作:</p>
			<ul>
				<li>使用r中的Sys.getenv()函数加载和使用一些环境变量，我们可以自动加载由<strong class="bold"> SageMaker </strong>设置的环境变量，比如TRAINING_JOB_NAME和TRAINING_JOB_ARN。</li>
				<li>使用fromJSON()函数加载hyperparameters.json文件的内容。</li>
				<li>使用fromJSON()函数加载inputdataconfig.json文件的内容。该文件包含每个输入数据通道的属性，例如文件类型以及文件或管道模式的用法。</li>
				<li>将数据文件加载到/opt/ml/input/data目录中。请注意，在实际文件本身之前的路径中，有一个以输入数据通道命名的父目录。例如/opt/ml/input/data/ <channel name=""> / <filename>。</filename></channel></li>
				<li>使用<a id="_idIndexMarker382"/>在之前步骤中加载的超参数和训练数据执行模型<a id="_idIndexMarker381"/>训练。</li>
				<li>将模型保存在/opt/ml/model目录下:<pre>saveRDS(model, file="/opt/ml/model/model.RDS")</pre></li>
				<li>我们可以选择使用验证数据评估模型，并记录结果。</li>
			</ul>
			<p>现在我们已经完成了R语言中的训练脚本的准备工作，让我们快速地讨论一下我们可以利用在这个菜谱中学到的知识准备的一些可能的解决方案。</p>
			<h2 id="_idParaDest-98">还有更多…</h2>
			<p>值得注意的是，我们可以自由地使用训练脚本中的任何算法来训练我们的模型。当我们需要处理更复杂的例子时，这种灵活性给了我们优势。如果在train脚本中使用了neuralnet R包，下面是train函数的一个简单示例:</p>
			<pre><strong class="bold">train</strong> &lt;- function(df.training_data, <strong class="bold">hidden_layers</strong>=4) {
    <strong class="bold">model</strong> &lt;- <strong class="bold">neuralnet</strong>(
        label ~ ., 
        df.training_data, 
        hidden=c(<strong class="bold">hidden_layers</strong>,1),
        linear.output = FALSE, 
        threshold=0.02,
        stepmax=1000000,
        act.fct = "logistic")
    return(<strong class="bold">model</strong>)
}</pre>
			<p>在本例中，我们允许在使用set_hyperparameters()函数配置Estimator对象时设置隐藏层数。以下示例显示了如何实现train函数来准备R中的时间序列预测模型:</p>
			<pre><strong class="bold">train</strong> &lt;- function(data) {
    <strong class="bold">model</strong> &lt;- <strong class="bold">snaive</strong>(data) 
    print(summary(model))
    return(<strong class="bold">model</strong>)
}</pre>
			<p>这里，我们简单地使用了预测包中的snaive()函数来准备模型。当然，我们也可以自由使用其他函数，比如预测包中的ets()和auto.arima()。</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor098"/>在R中准备和测试serve脚本</h1>
			<p>在这个菜谱中，我们将<a id="_idIndexMarker383"/>使用R创建一个serve脚本，它使用plumber包运行推理API <a id="_idIndexMarker384"/>。该API在初始化期间加载模型，并在端点调用期间使用该模型执行预测。</p>
			<p>下图显示了我们将在这个菜谱中准备的R serve脚本的预期行为。R serve脚本从/opt/ml/model目录中加载模型文件，并在端口8080上运行plumber web服务器:</p>
			<div><div><img src="img/B16850_02_84.jpg" alt="Figure 2.84 – The R serve script loads and deserializes the model and &#13;&#10;runs a plumber API server that acts as the inference endpoint&#13;&#10;" width="1104" height="595"/>
				</div>
			</div>
			<p class="figure-caption">图2.84–R serve脚本加载并反序列化模型，并运行一个充当推理端点的管道工API服务器</p>
			<p>web服务器<a id="_idIndexMarker385"/>应该有/ping和/invocations端点。这个<a id="_idIndexMarker386"/>独立的R后端API服务器稍后将在一个定制的容器中运行。</p>
			<h2 id="_idParaDest-100"><a id="_idTextAnchor099"/>准备就绪</h2>
			<p>确保您已经完成了R 配方中的<em class="italic">准备和测试训练脚本。</em></p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor100"/>怎么做...</h2>
			<p>我们将从准备api.r文件开始:</p>
			<ol>
				<li value="1">Double-click the api.r file inside the ml-r directory in the file tree:<div><img src="img/B16850_02_85.jpg" alt="Figure 2.85 – An empty api.r file inside the ml-r directory&#13;&#10;" width="934" height="191"/></div><p class="figure-caption">图2.85–ml-r目录中的一个空api.r文件</p><p>在这里，我们可以看到ml-r目录下的四个文件。请记住，我们在<em class="italic">中创建了一个空的api.r文件，用于设置Python和R实验环境</em>配方:</p><div><img src="img/B16850_02_86.jpg" alt="Figure 2.86 – Empty api.r file&#13;&#10;" width="658" height="338"/></div><p class="figure-caption">图2.86–空的api.r文件</p><p>在接下来的几个步骤中，我们将在这个api.r文件中添加几行代码。稍后，我们将<a id="_idIndexMarker388"/>学习如何使用<strong class="bold">水管工</strong>包<a id="_idIndexMarker389"/>从这个api.r文件生成一个API。</p></li>
				<li>定义prepare_paths()函数，我们将使用它来初始化paths变量。这将帮助我们管理脚本中使用的主要文件和目录的路径。这个函数允许我们用一个类似字典的数据结构初始化PATHS变量，我们可以用它来获得所需文件的绝对路径:<pre><strong class="bold">prepare_paths</strong> &lt;- function() {     <strong class="bold">keys</strong> &lt;- c('hyperparameters',                'input',                'data',               'model')     <strong class="bold">values</strong> &lt;- c('input/config/hyperparameters.json',                  'input/config/inputdataconfig.json',                  'input/data/',                 'model/')     paths &lt;- as.list(values)     names(paths) &lt;- keys     return(paths); }      <strong class="bold">PATHS</strong> &lt;- <strong class="bold">prepare_paths</strong>()</pre></li>
				<li>接下来，定义<a id="_idIndexMarker390"/>get _ path()函数，它利用了上一步中的路径变量<a id="_idIndexMarker391"/>:<pre><strong class="bold">get_path</strong> &lt;- function(key) {     output &lt;- paste(         '/opt/ml/', PATHS[[key]], sep="")     return(output); }</pre></li>
				<li>Create the following function (including the comments), which responds with "OK" when triggered from the /ping endpoint:<pre>#* @get <strong class="bold">/ping</strong>
function(res) {
  res$body &lt;- "OK"
  return(res)
}</pre><p>包含#* @get /ping的行告诉plumber我们将使用这个函数来处理带有/ping路由的get请求。</p></li>
				<li>定义load_model()函数:<pre><strong class="bold">load_model</strong> &lt;- function() {   model &lt;- NULL   filename &lt;- paste0(get_path('model'), 'model')   print(filename)   model &lt;- <strong class="bold">readRDS</strong>(filename)   return(model) }</pre></li>
				<li>Define the <a id="_idIndexMarker392"/>following /invocations function, which loads the model<a id="_idIndexMarker393"/> and uses it to perform a prediction on the input value from the request body:<pre>#* @post <strong class="bold">/invocations</strong>
function(req, res) {
  print(req$postBody)
  model &lt;- load_model()
  payload_value &lt;- as.double(req$postBody)
  X_test &lt;- data.frame(payload_value)
  colnames(X_test) &lt;- "X"
  
  print(summary(model))
  y_test &lt;- <strong class="bold">predict</strong>(model, X_test)
  output &lt;- y_test[[1]]
  print(output)
  
  res$body &lt;- toString(output)
  return(res)
}</pre><p>这里，我们使用load_model()函数加载模型，在将输入<a id="_idIndexMarker394"/>有效负载传递给predict()函数之前对其进行转换和准备，在给定X输入值时使用<a id="_idIndexMarker395"/>predict()函数执行实际预测，并在请求体中返回预测值。</p><p class="callout-heading">小费</p><p class="callout">你可以在<em class="italic">Machine Learning with Amazon sage maker Cookbook</em>GitHub资源库中访问api.r文件的工作副本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/blob/master/Chapter02/ml-r/api.r">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/blob/master/chapter 02/ml-r/API . r</a>。</p><p>现在api.r文件已经准备好了，让我们准备serve脚本:</p></li>
				<li>Double-click the serve file inside the ml-r directory in the file tree:<div><img src="img/B16850_02_87.jpg" alt="Figure 2.87 – The serve file inside the ml-r directory&#13;&#10;" width="1107" height="234"/></div><p class="figure-caption">图2.87–ml-r目录中的serve文件</p><p>它应该会打开一个空的serve文件，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_02_88.jpg" alt="Figure 2.88 – The serve file inside the ml-r directory&#13;&#10;" width="752" height="324"/></div><p class="figure-caption">图2.88–ml-r目录中的serve文件</p><p>在下一组步骤中，我们将向这个空的serve文件添加必要的代码。</p></li>
				<li>Start the serve script <a id="_idIndexMarker396"/>with the following lines of code. Here, we are <a id="_idIndexMarker397"/>loading the plumber and here packages:<pre>#!/usr/bin/Rscript
suppressWarnings(library(<strong class="bold">plumber</strong>))
library('<strong class="bold">here</strong>')</pre><p>here包提供了实用函数来帮助我们轻松地构建文件路径(例如，api.r)。</p></li>
				<li>Add the following lines of code to start the plumber API server:<pre>path &lt;- paste0(here(), "/api.r")
pr &lt;- <strong class="bold">plumb</strong>(path)
pr$<strong class="bold">run</strong>(host="0.0.0.0", port=<strong class="bold">8080</strong>)</pre><p>这里，我们使用了plumb()和run()函数来启动web服务器。需要注意的是，web服务器端点需要在端口8080上运行，这样才能正常工作。</p><p class="callout-heading">小费</p><p class="callout">您可以在<em class="italic">Machine Learning with Amazon sage maker Cookbook</em>GitHub存储库中访问serve脚本的工作副本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/blob/master/Chapter02/ml-r/serve">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/blob/master/chapter 02/ml-r/serve</a>。</p></li>
				<li>Open a new Terminal tab:<div><img src="img/B16850_02_89.jpg" alt="Figure 2.89 – Locating the Terminal&#13;&#10;" width="533" height="484"/></div><p class="figure-caption">图2.89–定位终端</p><p>这里，我们看到<a id="_idIndexMarker398"/>一个终端标签已经打开。如果您需要创建一个新的，只需<a id="_idIndexMarker399"/>点击加号(<strong class="bold"> + </strong>)，然后点击<strong class="bold">新建终端</strong>。</p></li>
				<li>使用apt-get install安装libcurl4-openssl-dev和libna-dev。以下是安装水管工软件包的一些先决条件:<pre><strong class="bold">sudo apt-get install -y --no-install-recommends libcurl4-openssl-dev</strong> <strong class="bold">sudo apt-get install -y --no-install-recommends libsodium-dev</strong></pre></li>
				<li>Install the here package:<pre><strong class="bold">sudo R -e "install.packages('here',repos='https://cloud.r-project.org')"</strong></pre><p>here包帮助我们获得定位特定文件(例如，api.r)所需的字符串路径值。如需更多信息，请随时查看https://cran.r-project.org/web/packages/here/index.html的<a href="https://cran.r-project.org/web/packages/here/index.html">。</a></p></li>
				<li>Install the plumber package:<pre><strong class="bold">sudo R -e "install.packages('plumber',repos='https://cloud.r-project.org')"</strong></pre><p><strong class="bold">水管工</strong>包<a id="_idIndexMarker400"/>允许我们在r中生成HTTP API。要了解更多信息，请随时查看<a href="https://cran.r-project.org/web/packages/plumber/index.html">https://cran.r-project.org/web/packages/plumber/index.html</a>。</p></li>
				<li>导航<a id="_idIndexMarker401"/>到ml-r目录:<pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-r</strong></pre></li>
				<li>使用chmod: <pre><strong class="bold">chmod +x serve</strong></pre>使服务器脚本<a id="_idIndexMarker402"/>可执行</li>
				<li>Run the serve script:<pre><strong class="bold">./serve</strong></pre><p>这将生成类似于以下内容的日志消息:</p><div><img src="img/B16850_02_90.jpg" alt="Figure 2.90 – The serve script running&#13;&#10;" width="595" height="132"/></div><p class="figure-caption">图2.90–服务器脚本运行</p><p>在这里，我们可以看到我们的serve脚本已经成功地在端口8080上运行了一个plumber API web服务器。</p><p>最后，我们<a id="_idIndexMarker403"/>必须触发<a id="_idIndexMarker404"/>这个正在运行的web服务器。</p></li>
				<li>Open a new Terminal tab:<div><img src="img/B16850_02_91.jpg" alt="Figure 2.91 – New Terminal&#13;&#10;" width="765" height="333"/></div><p class="figure-caption">图2.91–新终端</p><p>这里，我们创建一个新的终端选项卡，因为第一个选项卡已经在运行serve脚本。</p></li>
				<li>将SERVE_IP变量的值设置为localhost: <pre><strong class="bold">SERVE_IP=localhost</strong></pre></li>
				<li>Check if the ping endpoint is available with curl:<pre><strong class="bold">curl http://$SERVE_IP:8080/ping</strong></pre><p>运行前一行代码应该会从/ping端点产生一个OK。</p></li>
				<li>Test the invocations endpoint with curl:<pre><strong class="bold">curl -d "1" -X POST http://$SERVE_IP:8080/invocations</strong></pre><p>我们应该得到一个接近于881的值。58881 . 68888888881</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor101"/>工作原理……</h2>
			<p>在这个菜谱中，我们在r中准备了serve脚本。serve脚本利用plumber包来提供一个API，该API允许对/ping路由的GET请求和对/invocations路由的POST请求。serve脚本应该从指定的模型目录中加载模型文件，并在定制容器中运行后端API服务器。这应该提供一个/ping路由和一个/invocations路由。</p>
			<p>与Python配方<a id="_idIndexMarker405"/>相比，我们处理两个文件而不是一个，因为这就是我们<a id="_idIndexMarker406"/>在这个配方中使用<strong class="bold">水管工</strong>的方式:</p>
			<ul>
				<li>api.r文件定义了api的外观和行为方式。</li>
				<li>serve脚本使用api.r文件初始化web服务器，并使用plumber包中的plumb()函数启动web服务器。注意，使用<strong class="bold">烧瓶</strong>，不需要创建单独的文件来定义API路径。</li>
			</ul>
			<p>当使用plumber包时，我们从描述API行为的R文件开始(例如，api.r)。这个R文件遵循以下格式:</p>
			<pre>#* @get <strong class="bold">/ping</strong>
function(res) {
  res$body &lt;- "OK"
  return(&lt;RETURN VALUE&gt;)
}
     
#* @post <strong class="bold">/invocations</strong>
function(req, res) {
  return(&lt;RETURN VALUE&gt;)
}</pre>
			<p>一旦这个R文件准备好了，我们只需创建一个R脚本，它利用了plumber包中的plumb()函数。这将使用api.r文件中编码的配置和行为启动web服务器:</p>
			<pre>pr &lt;- <strong class="bold">plumb</strong>(&lt;PATH TO API.R&gt;)
pr$run(host="0.0.0.0", port=8080)</pre>
			<p>这样，每当访问<a id="_idIndexMarker407"/>/ping URL时，就会执行api.r文件中定义的映射函数<a id="_idIndexMarker408"/>。类似地，每当POST请求访问/invocations URL时，就会执行相应的映射函数。如需了解更多关于水管工套餐的信息，请随时<a id="_idIndexMarker409"/>查看<a href="https://www.rplumber.io/">https://www.rplumber.io/</a>。</p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor102"/>构建和测试自定义R算法容器映像</h1>
			<p>在前两个菜谱中，我们<a id="_idIndexMarker410"/>准备并测试了train、serve和api.r文件。准备好这些之后，我们现在可以继续制作docker文件和构建定制算法容器映像了。</p>
			<p class="callout-heading">小费</p>
			<p class="callout">等等！什么是Dockerfile？它是一个<a id="_idIndexMarker411"/>文本文档，包含用于准备和构建容器映像的指令(命令)。这个容器映像在运行容器时充当蓝图。请随意查看https://docs.docker.com/engine/reference/builder/<a href="https://docs.docker.com/engine/reference/builder/">了解更多信息。</a></p>
			<p>在这个菜谱中，我们将为定制的R容器映像准备一个docker文件。我们将使用api.r文件，以及我们在<em class="italic">准备和测试R </em>中的训练脚本和<em class="italic">准备和测试R </em>配方中的服务脚本中准备的训练和服务脚本。之后，我们将使用docker build命令来准备图像，然后将它推送到一个<strong class="bold"> Amazon ECR </strong>存储库。</p>
			<h2 id="_idParaDest-104">做好准备</h2>
			<p>确保您已经完成了R 食谱中的<em class="italic">准备和测试发球脚本。</em></p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor104"/>怎么做...</h2>
			<p>该配方的初始步骤<a id="_idIndexMarker412"/>集中于准备docker文件。让我们开始吧:</p>
			<ol>
				<li value="1">Double-click the Dockerfile file in the file tree to open it in the <strong class="bold">Editor</strong> pane. Make sure that this is the same Dockerfile that's inside the ml-r directory:<div><img src="img/B16850_02_92.jpg" alt="Figure 2.92 – Opening the Dockerfile inside the ml-r directory&#13;&#10;" width="1003" height="197"/></div><p class="figure-caption">图2.92–打开ml-r目录中的Dockerfile文件</p><p>在这里，我们可以看到ml-r目录中有一个Dockerfile。请记住，我们在<em class="italic">中创建了一个空Dockerfile文件来设置Python和R实验环境</em>的方法。在文件树中点击它应该会在<strong class="bold">编辑器</strong>窗格中打开一个空文件:</p><div><img src="img/B16850_02_93.jpg" alt="Figure 2.93 – Empty Dockerfile&#13;&#10;" width="666" height="234"/></div><p class="figure-caption">图2.93–空Dockerfile文件</p><p>这里，我们有一个空的Dockerfile文件。在下一步中，我们将通过添加四行代码来更新它。</p></li>
				<li>Update the Dockerfile with the following block of configuration code:<pre>FROM <strong class="bold">arvslat/amazon-sagemaker-cookbook-r-base</strong>:1
COPY train /usr/local/bin/train
COPY serve /usr/local/bin/serve
COPY api.r /usr/local/bin/api.r</pre><p>在这里，我们计划在一个名为Amazon-sage maker-cookbook-r-base的现有图像的基础上进行构建。这个映像已经安装了一些先决条件。这些<a id="_idIndexMarker413"/>包括rjson、here和plumber包，这样你就不必担心如何让安装步骤在这个菜谱中正常工作。关于这张图片的更多细节，请查看<a href="https://hub.docker.com/r/arvslat/amazon-sagemaker-cookbook-r-base">https://hub . docker . com/r/ARV slat/Amazon-sage maker-cookbook-r-base</a>:</p><div><img src="img/B16850_02_94.jpg" alt="Figure 2.94 – Docker Hub page for the amazon-sagemaker-cookbook-r-base image&#13;&#10;" width="1580" height="1030"/></div><p class="figure-caption">图2.94-亚马逊-sagemaker-cookbook-r-base图片的Docker Hub页面</p><p>在这里，我们可以看到亚马逊-sagemaker-cookbook-r-base图像的<strong class="bold"> Docker Hub </strong>页面。</p><p class="callout-heading">小费</p><p class="callout">您可以在<em class="italic">Amazon sage maker Cookbook</em>GitHub存储库中访问此Dockerfile的工作副本:<a href="https://github.com/PacktPublishing/Machine-Learining-with-Amazon-SageMaker-Cookbook/blob/master/Chapter02/ml-r/Dockerfile">https://GitHub . com/packt publishing/Machine-learning-with-Amazon-sage maker-Cookbook/blob/master/chapter 02/ml-r/docker file</a>。</p><p>准备好docker文件后，我们将继续使用终端，直到本食谱结束。</p></li>
				<li>You may use a new <a id="_idIndexMarker414"/>Terminal tab or an existing one to run the next set of commands:<div><img src="img/B16850_02_95.jpg" alt="Figure 2.95 – New Terminal&#13;&#10;" width="844" height="345"/></div><p class="figure-caption">图2.95–新终端</p><p>前面的屏幕截图显示了如何创建新的终端。请注意，在AWS Cloud9 IDE中,<strong class="bold">终端</strong>窗格位于<strong class="bold">编辑器</strong>窗格的正下方。</p></li>
				<li>导航到包含Dockerfile: <pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-r</strong></pre>的ml-python目录</li>
				<li>指定图像名称和标签号:<pre><strong class="bold">IMAGE_NAME=chap02_r</strong> <strong class="bold">TAG=1</strong></pre></li>
				<li>Build the Docker container using the docker build command:<pre><strong class="bold">docker build --no-cache -t $IMAGE_NAME:$TAG .</strong></pre><p>docker build命令利用了我们docker文件中的内容。我们从FROM指令中指定的映像开始，然后将文件复制到容器映像中。</p></li>
				<li>Use the docker run command to test if the train script works:<pre><strong class="bold">docker run --name rtrain --rm -v /opt/ml:/opt/ml $IMAGE_NAME:$TAG train</strong></pre><p>让我们快速地<a id="_idIndexMarker415"/>讨论一下这个命令中使用的不同选项。- rm标志使Docker在容器退出后清理容器，而-v标志允许我们将/opt/ml目录从主机系统挂载到容器的/opt/ml目录:</p><div><img src="img/B16850_02_96.jpg" alt="Figure 2.96 – Result of the docker run command (train)&#13;&#10;" width="710" height="312"/></div><p class="figure-caption">图2.96–docker run命令(训练)的结果</p><p>在这里，我们可以看到运行docker run命令后的日志和结果。</p></li>
				<li>Use the docker run command to test if the serve script works:<pre><strong class="bold">docker run --name rserve --rm -v /opt/ml:/opt/ml $IMAGE_NAME:$TAG serve</strong></pre><p>运行该命令后，plumber API服务器将成功启动，如下面的屏幕截图所示:</p><div><img src="img/B16850_02_97.jpg" alt="Figure 2.97 – Result of the docker run command (serve)&#13;&#10;" width="596" height="128"/></div><p class="figure-caption">图2.97–docker运行命令(serve)的结果</p><p>在这里，我们可以看到API正在端口8080上运行。在我们使用的基本映像中，我们添加了EXPOSE 8080，以允许我们访问正在运行的容器中的这个端口。</p></li>
				<li>Open a new Terminal tab:<div><img src="img/B16850_02_98.jpg" alt="Figure 2.98 – New Terminal&#13;&#10;" width="690" height="413"/></div><p class="figure-caption">图2.98–新终端</p><p>由于API<a id="_idIndexMarker416"/>已经在第一个终端中运行，我们在这里创建了一个新的终端。</p></li>
				<li>In the new Terminal tab, run the following command to get the IP address of the running Plumber API:<pre><strong class="bold">SERVE_IP=$(docker network inspect bridge | jq -r ".[0].Containers[].IPv4Address" | awk -F/ '{print $1}')</strong>
<strong class="bold">echo $SERVE_IP</strong></pre><p>这里发生了什么？查看这个菜谱的<em class="italic">如何工作……</em>部分，获得对前面代码块中发生的事情的详细解释！同时，让我们把这一行想象成使用多个命令来获取正在运行的API服务器的IP地址。我们应该得到一个等于或类似于172.17.0.2的IP地址。当然，我们可能会得到完全不同的IP地址值。</p></li>
				<li>Next, test the ping endpoint URL using the curl command:<pre><strong class="bold">curl http://$SERVE_IP:8080/ping</strong></pre><p>在运行这个命令之后，我们应该会得到<a id="_idIndexMarker417"/>一个OK。</p></li>
				<li>Finally, test the invocations endpoint URL using the curl command:<pre><strong class="bold">curl -d "1" -X POST http://$SERVE_IP:8080/invocations</strong></pre><p>在调用调用端点之后，我们应该得到一个类似于或接近于881.342840085751的值。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor105"/>工作原理…</h2>
			<p>在这个菜谱中，我们用docker文件构建了一个定制的容器图像。在我们的docker文件中，我们执行了以下操作:</p>
			<ul>
				<li>我们使用ARV slat/Amazon-sage maker-cookbook-r-base图像作为基本图像。查看<a href="https://hub.docker.com/repository/docker/arvslat/amazon-sagemaker-cookbook-r-base">https://hub . docker . com/repository/docker/ARV slat/Amazon-sage maker-cookbook-r-base</a>了解更多关于这张图片的详细信息。</li>
				<li>我们将train、serve和api.r文件复制到容器映像中的/usr/local/bin目录。这些脚本是在我们使用docker run时执行的。</li>
			</ul>
			<p>使用ARV slat/Amazon-sage maker-cookbook-r-base映像作为基本映像允许我们编写一个较短的Dockerfile，它只关注于将train、serve和api.r文件复制到容器映像内的目录。在幕后，我们已经在这个容器映像中预安装了rjson、plumber和here包及其先决条件，这样我们在构建定制容器映像时就不会遇到问题。这里快速浏览一下我们在这个食谱中使用的基础图像的Dockerfile文件<a id="_idIndexMarker419"/>:</p>
			<pre>FROM <strong class="bold">r-base:4.0.2</strong>
<strong class="bold">RUN</strong> apt-get -y update 
<strong class="bold">RUN</strong> apt-get install -y --no-install-recommends <strong class="bold">wget</strong>
<strong class="bold">RUN</strong> apt-get install -y --no-install-recommends <strong class="bold">libcurl4-openssl-dev</strong>
<strong class="bold">RUN</strong> apt-get install -y --no-install-recommends <strong class="bold">libsodium-dev</strong>
    
<strong class="bold">RUN</strong> R -e "install.packages('<strong class="bold">rjson</strong>',repos='https://cloud.r-project.org')"
<strong class="bold">RUN</strong> R -e "install.packages('<strong class="bold">plumber</strong>',repos='https://cloud.r-project.org')"
<strong class="bold">RUN</strong> R -e "install.packages('<strong class="bold">here</strong>',repos='https://cloud.r-project.org')"
    
<strong class="bold">ENV PATH</strong> "/opt/ml:$PATH"
<strong class="bold">WORKDIR</strong> /usr/local/bin
<strong class="bold">EXPOSE</strong> 8080</pre>
			<p>在这个Dockerfile文件中，我们可以看到我们使用r-base:4.0.2作为基础映像。如果我们要使用更高的版本，有可能水管工软件包将无法正确安装，这就是为什么我们必须坚持使用这个基础映像的较低版本。</p>
			<p>排除了这些潜在的障碍后，我们能够在很短的时间内构建一个定制的容器映像。在本章的<em class="italic">使用定制R算法容器映像通过Amazon SageMaker本地模式</em>进行训练和推理中，我们将在使用reticulate进行训练和部署时使用这个定制容器映像，这样我们就可以将<strong class="bold"> SageMaker Python SDK </strong>用于我们的R代码。</p>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor106"/>将自定义R算法容器映像推送到Amazon ECR存储库中</h1>
			<p>在前面的配方中，我们<a id="_idIndexMarker420"/>使用docker build命令准备并<a id="_idIndexMarker421"/>构建了自定义容器映像。在这个菜谱中，我们将把定制容器映像推送到一个<strong class="bold"> Amazon ECR </strong>存储库中。如果这是你第一次听说<strong class="bold"> Amazon ECR </strong>，它只是一个完全托管的容器注册表，帮助我们管理我们的容器映像。在将容器映像推送到Amazon ECR存储库之后，我们将使用该映像在<em class="italic">中进行训练和部署，使用自定义R算法容器映像对Amazon SageMaker本地模式</em>配方进行训练和推理。</p>
			<h2 id="_idParaDest-108">做好准备</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>该配方上接<em class="italic">构建和测试自定义R算法容器映像</em>配方。</li>
				<li>如果你使用的是一个拥有自定义URL的AWS IAM用户，那么你拥有管理亚马逊ECR资源的权限。</li>
			</ul>
			<h2 id="_idParaDest-109">如何去做...</h2>
			<p>该方法的最初步骤集中在创建ECR存储库。让我们开始吧:</p>
			<ol>
				<li value="1">Use the search bar in the <strong class="bold">AWS Console</strong> to navigate to the <strong class="bold">Elastic Container Registry</strong> console. Click <strong class="bold">Elastic Container Registry</strong> when you see it in the search results:<div><img src="img/B16850_02_99.jpg" alt="Figure 2.99 – Navigating to the ECR console&#13;&#10;" width="667" height="409"/></div><p class="figure-caption">图2.99–导航至ECR控制台</p><p>正如我们所看到的，我们<a id="_idIndexMarker422"/>可以使用<a id="_idIndexMarker423"/>搜索栏快速导航到<strong class="bold">弹性容器注册表</strong>服务。</p></li>
				<li>Click the <strong class="bold">Create repository</strong> button:<div><img src="img/B16850_02_100.jpg" alt="Figure 2.100 – Create repository button&#13;&#10;" width="694" height="88"/></div><p class="figure-caption">图2.100–创建存储库按钮</p><p>这里，<strong class="bold">创建存储库</strong>按钮位于屏幕的右上角。</p></li>
				<li>In the <strong class="bold">Create repository</strong> form, specify a <strong class="bold">Repository name</strong>. Use the value of $IMAGE_NAME from the <em class="italic">Building and testing the custom R algorithm container image</em> recipe. In this case, we will use chap02_r:<div><img src="img/B16850_02_101.jpg" alt="Figure 2.101 – Create repository form&#13;&#10;" width="1039" height="740"/></div><p class="figure-caption">图2.101–创建存储库表单</p><p>这里，我们有<a id="_idIndexMarker424"/><strong class="bold">创建存储库</strong>表单。对于<strong class="bold">可见性设置</strong>，我们选择<strong class="bold">私有</strong>并将<strong class="bold">标签不变性</strong>配置设置为<strong class="bold">禁用</strong>。</p></li>
				<li>Scroll down until <a id="_idIndexMarker425"/>you see the <strong class="bold">Create repository</strong> button. Leave the other configuration settings as-is and click <strong class="bold">Create repository</strong>:<div><img src="img/B16850_02_102.jpg" alt="Figure 2.102 – Create repository button&#13;&#10;" width="1025" height="387"/></div><p class="figure-caption">图2.102–创建存储库按钮</p><p>最后，要完成存储库创建过程，请单击页面底部的<strong class="bold">创建存储库</strong>按钮。</p></li>
				<li>Click <strong class="bold">chap02_r</strong>:<div><img src="img/B16850_02_103.jpg" alt="Figure 2.103 – Link to the ECR repository page&#13;&#10;" width="931" height="145"/></div><p class="figure-caption">图2.103–ECR存储库页面的链接</p><p>这里，我们在<strong class="bold">存储库名称</strong>列下有一个<a id="_idIndexMarker426"/>链接。点击这个链接应该会将我们重定向到一个包含关于存储库的详细信息的页面。</p></li>
				<li>Click <strong class="bold">View push commands</strong>:<div><img src="img/B16850_02_104.jpg" alt="Figure 2.104 – View push commands button (upper right)&#13;&#10;" width="1477" height="395"/></div><p class="figure-caption">图2.104–查看按钮命令按钮(右上)</p><p>页面右上角有<strong class="bold">查看按钮</strong>按钮。</p></li>
				<li>You can optionally copy the first command, aws ecr get-login-password …, from the dialog box:<div><img src="img/B16850_02_105.jpg" alt="Figure 2.105 – Push commands dialog box&#13;&#10;" width="722" height="513"/></div><p class="figure-caption">图2.105–推送命令对话框</p><p>在这里，我们可以看到我们可以使用的多个<a id="_idIndexMarker429"/>命令。我们将只需要第一个(aws ecr get-login-password …)。单击代码框右侧带有两个重叠框的图标，将整行复制到剪贴板。</p></li>
				<li>Navigate back to the AWS Cloud9 environment IDE and create a new Terminal. You can also reuse an existing one:<div><img src="img/B16850_02_106.jpg" alt="Figure 2.106 – New Terminal&#13;&#10;" width="479" height="282"/></div><p class="figure-caption">图2.106–新终端</p><p>前面的截图向我们展示了如何创建一个新的终端。我们点击绿色加号按钮，然后从选项列表中选择<strong class="bold">新端子</strong>。注意绿色加号按钮就在<strong class="bold">编辑器</strong>窗格的正下方。</p></li>
				<li>导航到ml-r目录:<pre><strong class="bold">cd /home/ubuntu/environment/opt/ml-r</strong></pre></li>
				<li>使用以下命令获取帐户ID:<pre><strong class="bold">ACCOUNT_ID=$(aws sts get-caller-identity | jq -r ".Account")</strong> <strong class="bold">echo $ACCOUNT_ID</strong></pre></li>
				<li>指定图像_URI值<a id="_idIndexMarker430"/>，并使用我们在此配方中创建<a id="_idIndexMarker431"/>储存库时指定的ECR储存库名称。在这种情况下，我们将运行IMAGE_URI="chap02_r": <pre><strong class="bold">IMAGE_URI="&lt;insert ECR Repository URI&gt;"</strong> <strong class="bold">TAG="1"</strong></pre></li>
				<li>Authenticate with <strong class="bold">Amazon ECR</strong> so that we can push our <strong class="bold">Docker</strong> container image to an <strong class="bold">Amazon ECR</strong> repository in our account later:<pre><strong class="bold">aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com</strong></pre><p class="callout-heading">重要说明</p><p class="callout">请注意，我们已经假设我们的存储库位于us-east-1地区。如果需要，可以在命令中随意修改这个区域。这适用于本章中的所有命令。</p></li>
				<li>使用docker标签命令:<pre><strong class="bold">docker tag $IMAGE_URI:$TAG $ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/$IMAGE_URI:$TAG</strong></pre></li>
				<li>使用docker push命令将图像推送到<strong class="bold"> Amazon ECR </strong>存储库:<pre><strong class="bold">docker push $ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/$IMAGE_URI:$TAG</strong></pre></li>
			</ol>
			<p>现在我们已经完成了这个配方，我们可以在下一个配方中继续使用这个带有SageMaker的定制算法容器图像。但在此之前，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor109"/>工作原理…</h2>
			<p>在<em class="italic">构建和测试自定义R算法容器映像</em>配方中，我们使用docker build来<a id="_idIndexMarker432"/>准备<a id="_idIndexMarker433"/>自定义容器映像。在这个菜谱中，我们创建了一个<strong class="bold"> Amazon ECR </strong>存储库，并将我们的定制容器映像推送到其中。我们还使用docker push命令将我们构建的定制容器映像推送到ECR存储库。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">在编写这个docker文件和运行构建步骤时，不要忘记在容器中包含api.r文件。Python对应的方法将train和serve脚本复制到容器内的/opt/ml目录，而R方法将train、serve和api.r文件复制到/opt/ml目录。如果不包含api.r文件，serve脚本文件中的以下行将触发错误并导致脚本失败:pr </p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor110"/>使用自定义R算法容器映像通过Amazon SageMaker本地模式进行训练和推理</h1>
			<p>在前面的配方中，我们<a id="_idIndexMarker434"/>将定制的R容器映像推送到Amazon ECR存储库中。在这个菜谱中，我们将使用这个定制容器映像在<strong class="bold"> Amazon SageMaker </strong>中执行培训和部署步骤。在第一章中，我们使用了内置<strong class="bold">线性学习器</strong>算法的容器图像的图像URI。在本章中，我们将使用自定义容器图像的图像URI:</p>
			<div><div><img src="img/B16850_02_107.jpg" alt="Figure 2.107 – The train and serve scripts inside the custom container make use of the &#13;&#10;hyperparameters, input data, and config specified using the SageMaker Python SDK&#13;&#10;" width="1456" height="739"/>
				</div>
			</div>
			<p class="figure-caption">图2.107–定制容器中的训练和服务脚本利用了超参数、输入数据和使用SageMaker Python SDK指定的配置</p>
			<p>上图显示了当我们在R代码中使用fit()和predict()函数时，SageMaker如何在每个定制容器之间传递数据、文件和配置，这是我们用<strong class="bold"> reticulate </strong>包和<strong class="bold"> SageMaker Python SDK </strong>完成的。</p>
			<p>我们还将看看如何在这个食谱中使用<strong class="bold">本地模式</strong>。SageMaker的这一功能允许我们在本地环境中测试和模拟CPU和GPU培训工作。当我们开发、增强和测试我们的定制算法容器图像和脚本时，使用<strong class="bold">本地模式</strong>是很有用的。一旦我们准备好推出容器映像的稳定版本，我们就可以很容易地切换到使用支持训练和部署步骤的ML实例。</p>
			<p>一旦我们完成了<a id="_idIndexMarker435"/>这个配方，我们将能够运行训练作业，并使用R在定制容器内使用定制的训练和服务脚本部署推理端点。</p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor111"/>准备就绪</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>这个配方从<em class="italic">将自定义R算法容器映像推送到Amazon ECR存储库</em>配方继续。</li>
				<li>我们将使用第一章  <em class="italic">中的<em class="italic">SageMaker Notebook实例启动亚马逊sage maker Notebook实例并准备先决条件</em>配方<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">【使用亚马逊SageMaker </em>开始机器学习。</a></em></li>
			</ul>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor112"/>怎么做...</h2>
			<p>这个方法的前几个步骤集中在使用内核准备Jupyter笔记本上。让我们开始吧:</p>
			<ol>
				<li value="1">Inside your SageMaker Notebook instance, create a new directory called chapter02 inside the my-experiments directory if it does not exist yet:<div><img src="img/B16850_02_108.jpg" alt="Figure 2.108 – Preferred directory structure&#13;&#10;" width="563" height="148"/></div><p class="figure-caption">图2.108–首选目录结构</p><p>前面的屏幕截图显示了我们希望如何组织我们的文件和笔记本。在我们阅读每一章时，我们将使用相同的命名约定添加更多的目录，以保持组织有序。</p></li>
				<li>单击chapter02目录导航到/my-experiments/chapter02。</li>
				<li>Create a new notebook by clicking <strong class="bold">New</strong> and then clicking <strong class="bold">R</strong>:<div><img src="img/B16850_02_109.jpg" alt="Figure 2.109 – Creating a new notebook using the R kernel&#13;&#10;" width="1167" height="234"/></div><p class="figure-caption">图2.109–使用R内核创建新笔记本</p><p>前面的截图<a id="_idIndexMarker436"/>展示了如何使用<strong class="bold"> R </strong>内核创建一个新的Jupyter笔记本。</p><p>既然我们已经有了一个使用<strong class="bold"> R </strong>内核的全新Jupyter笔记本，我们将继续准备培训和部署步骤的先决条件。</p></li>
				<li>Prepare the cmd function, which will help us run the Bash commands in the subsequent steps:<pre><strong class="bold">cmd</strong> &lt;- function(bash_command) {
    output &lt;- <strong class="bold">system</strong>(bash_command, intern=TRUE)
    last_line = ""
    for (line in output) { 
        cat(line)
        cat("\n")
        <strong class="bold">last_line</strong> = line 
    }
    return(<strong class="bold">last_line</strong>) 
}</pre><p>鉴于我们使用的是R内核，我们将无法使用！运行Bash命令的前缀。相反，我们创建了一个cmd()函数来帮助我们执行类似的操作。这个cmd()函数利用system()函数来调用系统命令。</p></li>
				<li>Next, let's use the cmd function to run the pip install command to install and upgrade sagemaker[local]:<pre>cmd("<strong class="bold">pip install 'sagemaker[local]' --upgrade</strong>")</pre><p>这将允许我们使用<strong class="bold">本地模式</strong>。当处理框架<a id="_idIndexMarker437"/>映像，如<strong class="bold"> TensorFlow </strong>、<strong class="bold"> PyTorch </strong>和<strong class="bold"> MXNet </strong>以及我们自己构建的自定义容器映像时，我们可以使用本地模式。</p><p class="callout-heading">重要说明</p><p class="callout">在撰写本文时，我们无法在<strong class="bold"> SageMaker工作室</strong>中使用<strong class="bold">本地模式</strong>。我们也不能使用内置算法的<strong class="bold">本地模式</strong>。</p></li>
				<li>Specify the values for s3.bucket and s3.prefix. Make sure that you set the s3.bucket value to the name of the S3 bucket we created in the <em class="italic">Preparing the Amazon S3 bucket and the training dataset for the linear regression experiment</em> recipe of <a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"><em class="italic">Chapter 1</em></a><em class="italic">, Getting Started with Machine Learning Using Amazon SageMaker</em>:<pre>s3.bucket &lt;- <strong class="bold">"&lt;insert S3 bucket name here&gt;</strong>"
s3.prefix &lt;- "chapter01"</pre><p>请记住，我们的training_data.csv文件应该已经存在于S3存储桶中，它应该具有以下路径:</p><pre><strong class="bold">s3://&lt;S3 BUCKET NAME&gt;/&lt;PREFIX&gt;/input/training_data.csv</strong></pre></li>
				<li>现在，让我们分别在training.s3_input_location和training.s3_output_location中指定输入和输出位置:<pre><strong class="bold">training.s3_input_location</strong> &lt;- paste0('s3://', s3.bucket, '/', s3.prefix, '/input/training_data.csv') <strong class="bold">training.s3_output_location</strong> &lt;- paste0('s3://', s3.bucket, '/', s3.prefix, '/output/custom/')</pre></li>
				<li>Load the reticulate package using the library() function. The reticulate package allows us to use the <strong class="bold">SageMaker Python SDK</strong> and other libraries in Python inside R. This gives us a more powerful arsenal of libraries in R. We can use these with other R packages such as ggplot2, dplyr, and caret:<pre>library('<strong class="bold">reticulate</strong>')
sagemaker &lt;- import('<strong class="bold">sagemaker</strong>')</pre><p class="callout-heading">小费</p><p class="callout">关于网状包装的更多信息，请随意查看本食谱末尾的<em class="italic">它是如何工作的……</em>部分。</p></li>
				<li>Check<a id="_idIndexMarker438"/> the <strong class="bold">SageMaker Python SDK</strong> version:<pre>sagemaker[['__version__']]</pre><p>我们应该得到一个等于或大于2.31.0的值。</p></li>
				<li>Set the value of the container image. Use the value from the <em class="italic">Pushing the custom R algorithm container image to an Amazon ECR repository</em> recipe. The container variable should be set to a value similar to &lt;ACCOUNT_ID&gt;.dkr.ecr.us-east-1.amazonaws.com/chap02_r:1. Make sure that you replace &lt;ACCOUNT_ID&gt; with your AWS account ID:<pre>container &lt;- "<strong class="bold">&lt;insert container image URI here&gt;</strong>"</pre><p class="callout-heading">小费</p><p class="callout">要获得<account_id>的值，运行ACCOUNT _ ID = $(AWS STS get-caller-identity | jq-r "。Account”)，然后在终端中回显ACCOUNT _ ID。记住，我们在<em class="italic">中将自定义R算法容器映像推送到Amazon ECR存储库</em> recipe中执行了这个步骤，所以您应该为ACCOUNT_ID获得相同的值。</account_id></p></li>
				<li>导入一些先决条件，例如角色和会话。对于会话，我们将使用LocalSession类，这将允许我们在训练和部署步骤中使用<strong class="bold">本地模式</strong>:<pre>role &lt;- sagemaker$get_execution_role() LocalSession &lt;- sagemaker$local$LocalSession session &lt;- <strong class="bold">LocalSession</strong>() session$config &lt;- list(local=list(local_code=TRUE))</pre></li>
				<li>Prepare<a id="_idIndexMarker439"/> the train input so that it points to the <strong class="bold">Amazon S3</strong> path with content_type="text/csv":<pre>TrainingInput &lt;- sagemaker$inputs$TrainingInput
sagemaker.train_input &lt;- <strong class="bold">TrainingInput</strong>(training.s3_input_location, content_type="text/csv")</pre><p>现在我们已经准备好了先决条件，我们将继续初始化Estimator并使用fit()和predict()函数。</p></li>
				<li>用相关参数初始化Estimator，如下面的代码块所示。注意，容器变量包含定制R容器图像:<pre>Estimator &lt;- sagemaker$estimator$Estimator estimator &lt;- <strong class="bold">Estimator</strong>(     container,     role,      instance_count=1L,      instance_type="<strong class="bold">local</strong>",     output_path=training.s3_output_location,     sagemaker_session=session)</pre>的<strong class="bold"> Amazon ECR </strong>图像URI</li>
				<li>Set a few dummy hyperparameters using the set_hyperparameters() function:<pre>estimator$<strong class="bold">set_hyperparameters</strong>(a=1L, b=2L, c=3L)</pre><p>在后台，这些值将被传递到/opt/ml/input/config目录中的hyperparameters.json文件，当我们稍后运行fit()函数时，train脚本将加载并使用这个文件<a id="_idIndexMarker440"/>。</p></li>
				<li>Perform the training step by calling the fit() function with the train argument set to the sagemaker.train_input variable value from the previous step:<pre>estimator$<strong class="bold">fit</strong>(list(train = sagemaker.train_input))</pre><p>与我们在<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第1章</em> </a> <em class="italic">中的实验相比，使用Amazon SageMaker </em>开始机器学习，这个配方中的fit()函数将在SageMaker笔记本实例中运行训练作业，因为<strong class="bold">是本地模式</strong>。假设我们没有使用本地模式，我们将启动支持训练作业的ML实例。正如我们在第1章 的<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">中所讨论的，这些ML实例通常会在训练任务完成后自动删除。</em></a></p><p class="callout-heading">重要说明</p><p class="callout">即使我们使用的是<strong class="bold">本地模式</strong>，训练脚本生成的模型文件也不会存储在SageMaker notebook实例中。包含模型文件的model.tar.gz文件仍然上传到亚马逊S3中指定的output_path。您可以检查estimator$model_data的值来验证这一点！</p></li>
				<li>Deploy the model using the deploy() function. We set instance_type to 'local' and initial_instance_count to 1L. Note that the L makes the number an explicit integer:<pre>predictor &lt;- estimator$<strong class="bold">deploy</strong>(
    initial_instance_count=1L,
    instance_type="<strong class="bold">local</strong>",
    endpoint_name="custom-local-r-endpoint"
)</pre><p>鉴于<a id="_idIndexMarker441"/>我们使用的是<strong class="bold">本地模式</strong>，deploy()函数将在SageMaker Notebook实例中运行容器和服务器脚本。</p><p class="callout-heading">重要说明</p><p class="callout">请注意，如果我们将instance_type更改为诸如“ml.m5.xlarge”之类的值(除了不使用LocalSession对象之外)，我们将在SageMaker Notebook实例之外为推理端点启动一个专用的ml实例。当然，最佳实践是首先使用<strong class="bold">本地模式</strong>让事情正常工作。一旦我们解决了细节并修复了错误，我们就可以将模型部署到由专用ML实例支持的推理端点。</p></li>
				<li>Finally, test the predict() function. This triggers the invocations API endpoint you prepared in the previous step and passes "1" as the parameter value:<pre>predictor$<strong class="bold">predict</strong>("1")</pre><p>在使用<strong class="bold"> predict() </strong>函数调用调用端点之后，我们应该得到一个类似于或接近于881.342840085751的值。预计这里的预测值类似于我们在<em class="italic">构建和测试自定义R算法容器映像</em>配方中得到的值。</p><p>现在我们有了一个模型和一个推理端点，我们可以使用R和包(如ggplot2、dplyr和Metrics)执行一些后处理、可视化和评估步骤。</p></li>
				<li>Delete the<a id="_idIndexMarker442"/> endpoint:<pre>predictor$<strong class="bold">delete_endpoint</strong>()</pre><p>假设我们在这个配方中使用了<strong class="bold">本地模式</strong>，delete_endpoint()函数将停止SageMaker Notebook实例中正在运行的API服务器。如果<strong class="bold">本地模式</strong>没有被使用，SageMaker推理端点和支持它的ML计算实例将被删除。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor113"/>工作原理……</h2>
			<p>在这个菜谱中，我们使用reticulate R包来在我们的R代码中使用<strong class="bold"> SageMaker Python SDK </strong>。这将帮助我们训练和部署我们的机器学习模型。我们没有使用<strong class="bold"> Amazon SageMaker </strong>的内置算法，而是使用了我们在之前的菜谱中准备的自定义容器映像。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">如果您需要使用定制容器映像的训练作业如何工作的快速解释，请随意查看<em class="italic">的<em class="italic">如何工作……</em>部分，使用定制Python算法容器映像进行训练和推理，使用Amazon SageMaker本地模式</em>方法。</p>
			<p>为了帮助我们更好地理解这个方法，这里有一些使用reticulate时需要熟悉的从Python到R的常见转换:</p>
			<ul>
				<li>点(。)到美元符号($): estimator.fit()到estimator$fit()</li>
				<li>Python字典到R列表:{'train': train}到列表(train=train)</li>
				<li>整数值:1到1L</li>
				<li>内置常量:无到空，真到真，假到假</li>
			</ul>
			<p>当您可以使用Python代替时，为什么要花费精力尝试在R中执行机器学习实验呢？这可能有几个原因:</p>
			<ul>
				<li>数据科学家使用R编写的论文和例子可能会使用某些在Python中没有适当对应库的包。</li>
				<li>已经熟悉R语言并使用多年的专业人员和团队应该能够从头到尾完成整个ML实验，而不必学习另一种语言，尤其是在时间有限的情况下。这在现实生活中经常发生，由于时间限制和语言熟悉程度，团队不容易从一种语言转换到另一种语言。</li>
				<li>由于时间限制，以及R和Python中现有库的实现差异，将现有代码从R迁移到Python可能不切实际或不可能。</li>
			</ul>
			<p>其他数据科学家和ML工程师只是更喜欢使用R而不是Python。也就是说，重要的是准备好允许我们在执行端到端机器学习和机器学习工程任务时使用R的解决方案。请参考下图，快速比较在Python和R中执行端到端实验时使用的工具和库:</p>
			<div><div><img src="img/B16850_02_110.jpg" alt="Figure 2.110 – Sample guide for tech stack selection when using Python and R &#13;&#10;in machine learning experiments&#13;&#10;" width="1441" height="808"/>
				</div>
			</div>
			<p class="figure-caption">图2.110–在机器学习实验中使用Python和R时技术堆栈选择的示例指南</p>
			<p>正如我们所看到的，我们<a id="_idIndexMarker444"/>可以使用reticulate包在我们的R代码中使用<strong class="bold"> Boto3 AWS SDK </strong>和<strong class="bold"> SageMaker Python SDK </strong>。“请注意，该图并不意味着在Python和R中呈现的示例库和包是一对一的映射。”正如我们所看到的，我们可以使用reticulate包在R代码中使用Boto3 AWS SDK和SageMaker Python SDK我们在这个例子中使用了Amazon Athena，因为它是我们可以用来帮助我们在训练阶段之前准备和查询数据的服务之一。有了reticulate包，我们可以在R代码中无缝地使用boto3来执行Athena查询。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">我们将在第四章 、<em class="italic">准备、处理和分析数据</em>的<em class="italic">使用SQL查询调用Amazon Athena的机器学习模型</em>中，了解如何使用Amazon Athena和已部署的模型进行数据准备和处理。</p>
			<p>使用R时，dplyr、tidyr和ggplot2等包可以很容易地与reticulate和<strong class="bold">AWS SDK</strong>一起使用，以从头到尾解决机器学习需求。也就是说，已经在工作场所使用R的机器学习从业者和团队可能不再需要学习另一种语言(例如，Python)并将现有代码从R迁移到Python。</p>
		</div>
		<div><p class="hidden">使用自定义Python算法容器图像</p>
			<p class="hidden">用Amazon SageMaker本地模式进行训练和推理</p>
		</div>
		<div><p class="hidden">使用自定义Python算法容器图像</p>
			<p class="hidden">用Amazon SageMaker本地模式进行训练和推理</p>
		</div>
		<div><p class="hidden">使用自定义Python算法容器图像</p>
			<p class="hidden">用Amazon SageMaker本地模式进行训练和推理</p>
		</div>
		<div><p class="hidden">使用自定义Python算法容器图像</p>
			<p class="hidden">用Amazon SageMaker本地模式进行训练和推理</p>
		</div>
		<div><p class="hidden">使用自定义Python算法容器图像</p>
			<p class="hidden">用Amazon SageMaker本地模式进行训练和推理</p>
		</div>
		<div><p class="hidden">使用自定义的R算法容器图像进行训练和推理</p>
			<p class="hidden">使用亚马逊SageMaker本地模式</p>
		</div>
		<div><p class="hidden">使用自定义的R算法容器图像进行训练和推理</p>
			<p class="hidden">使用亚马逊SageMaker本地模式</p>
		</div>
		<div><p class="hidden">使用自定义的R算法容器图像进行训练和推理</p>
			<p class="hidden">使用亚马逊SageMaker本地模式</p>
		</div>
		<div><div/>
		</div>
		<div><p class="hidden">使用自定义的R算法容器图像进行训练和推理</p>
			<p class="hidden">使用亚马逊SageMaker本地模式</p>
		</div>
		<div><p class="hidden">使用自定义的R算法容器图像进行训练和推理</p>
			<p class="hidden">使用亚马逊SageMaker本地模式</p>
		</div>
	</div>
</body></html>