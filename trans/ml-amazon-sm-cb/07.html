<html><head/><body>





<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}</style>
<div><div><h1 id="_idParaDest-293"><em class="italic"> <a id="_idTextAnchor602"/>第七章</em>:使用SageMaker功能商店、SageMaker Clarify和SageMaker模型监视器</h1>
			<p>在前一章中，我们通过使用<strong class="bold"> SageMaker自动驾驶仪</strong>和<strong class="bold">自动模型调整</strong>来准备高质量的模型，第一次看到了<strong class="bold"> SageMaker工作室</strong>，以及它的自动机器学习能力。在这一章中，我们将重点介绍SageMaker的另外几个功能，这些功能与<strong class="bold">sage maker Studio</strong>–<strong class="bold">sage maker特征存储</strong>、<strong class="bold"> SageMaker Clarify </strong>和<strong class="bold"> SageMaker模型监视器</strong>有很好的集成。这些功能可以帮助数据科学家和机器学习实践者在进行生产级机器学习实验和部署时处理特定但相关的需求。</p>
			<p>这些包括使用在线和离线特征存储，检测数据中的偏差，实现机器学习的可解释性，以及监控部署的模型。下图显示了如何在机器学习过程的不同阶段使用这些功能:</p>
			<div><div><img src="img/B16850_07_01.jpg" alt="Figure 7.1 – Working with SageMaker Feature Store, Clarify, and Model Monitor&#13;&#10;" width="931" height="521"/>
				</div>
			</div>
			<p class="figure-caption">图7.1–使用SageMaker功能存储、澄清和模型监视器</p>
			<p>我们将首先使用<strong class="bold"> SageMaker特征库</strong>来存储和管理我们数据集中的ML特征。我们还将进一步了解如何使用<strong class="bold"> SageMaker Clarify </strong>来检测我们数据中的训练前和训练后偏差。除此之外，我们还将学习如何使用<strong class="bold"> SageMaker Clarify </strong>生成ML可解释性报告。然后我们将学习如何使用<strong class="bold"> SageMaker模型监视器</strong>来捕获和分析我们的推理端点中的数据。最后，我们将了解如何使用<strong class="bold"> SageMaker模型监视器</strong>来自动检测数据质量漂移。</p>
			<p>我们将在本章中介绍以下配方:</p>
			<ul>
				<li>生成合成数据集并使用<strong class="bold"> SageMaker特征库</strong>进行存储和管理</li>
				<li>从<strong class="bold"> SageMaker特色店</strong>的线下店查询数据并上传到亚马逊S3</li>
				<li>用<strong class="bold"> SageMaker Clarify </strong>检测训练前偏差</li>
				<li>用<strong class="bold"> SageMaker Clarify </strong>检测训练后偏差</li>
				<li>使用<strong class="bold"> SageMaker Clarify </strong>启用ML可解释性</li>
				<li>从模型中部署一个端点，并使用<strong class="bold"> SageMaker模型监视器</strong>启用数据捕获</li>
				<li>使用<strong class="bold"> SageMaker型号监控器</strong>进行基线和预定监控</li>
			</ul>
			<p>一旦我们完成了本章的配方，我们将会更好地理解这些能力和特性是如何帮助ML实验和部署成功的。</p>
			<p>现在，让我们继续本章的食谱吧！</p>
			<h1 id="_idParaDest-294"><a id="_idTextAnchor603"/>技术要求</h1>
			<p>要执行本章中的食谱，确保你有一个亚马逊S3桶，以及管理<strong class="bold">亚马逊SageMaker </strong>和<strong class="bold">亚马逊S3 </strong>资源的权限，如果你使用的是一个带有自定义URL的<strong class="bold"> AWS IAM </strong>用户。如果您使用的是root帐户，那么您应该能够继续本章中的食谱。但是，建议您以AWS IAM用户的身份登录，而不是在大多数情况下使用root帐户。有关更多信息，请随意查看<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">https://docs . AWS . Amazon . com/IAM/latest/user guide/best-practices . html</a>。</p>
			<p>由于本章中的食谱涉及到一些代码，我们在本书的GitHub资源库中提供了必要的脚本和笔记本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/tree/master/Chapter07">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/tree/master/chapter 07</a>。在开始本章的每个食谱之前，确保my-experiments/chapter07目录已经准备好。如果它还没有创建，请现在就创建，因为这将有助于我们在学习本书中的每一个食谱时保持事物的有序。</p>
			<p>请点击以下链接查看动作视频中的相关代码:</p>
			<p><a href="https://bit.ly/3nfR8Zg">https://bit.ly/3nfR8Zg</a></p>
			<h1 id="_idParaDest-295"><a id="_idTextAnchor604"/>生成合成数据集并使用SageMaker特征库进行存储和管理</h1>
			<p>在这个菜谱中，我们将生成一个类似于下面截图所示的合成数据集。在这里，我们将模拟一个示例场景，其中一所学校计划构建一个二元分类器<a id="_idIndexMarker1328"/>模型，该模型根据某些属性自动批准或拒绝申请奖学金的候选人，例如<a id="_idIndexMarker1329"/>他们在数学、科学和技术考试中的分数:</p>
			<div><div><img src="img/B16850_07_02.jpg" alt="Figure 7.2 – Synthetic dataset&#13;&#10;" width="587" height="360"/>
				</div>
			</div>
			<p class="figure-caption">图7.2–合成数据集</p>
			<p>该数据集将有四个主要预测值列，分别称为性别、数学、科学和技术，以及<a id="_idIndexMarker1330"/>，还有两个包含随机值的列，分别称为random1和random2。这些栏目将帮助我们验证<strong class="bold"> SageMaker Clarify </strong>在<em class="italic">中使用SageMaker Clarify </em>配方启用ML可解释性所生成的特性重要性报告是否有效。除此之外，生成的数据集<a id="_idIndexMarker1331"/>将有两个额外的列，称为event_time和index，因为我们将使用<strong class="bold"> SageMaker Feature Store </strong>来接收和管理我们的要素组和已处理的数据集。</p>
			<p><strong class="bold"> SageMaker特征库</strong>将作为存储已处理特征的集中存储库。这些存储的记录将在本章的后续配方中加载用于训练和推理。正如我们将在<em class="italic">使用SageMaker Clarify </em>方法检测训练前偏差中看到的，我们将在此方法中生成的合成数据集被认为是不平衡的，因为它在每个类中的实例数量不相等—“女性”(性别=0)类的记录明显少于“男性”(性别=1)类。在<em class="italic">使用SageMaker Clarify </em>方法检测训练后偏差中，我们还将看到，使用我们将在该方法中生成的数据集，我们将使用该数据集训练的模型将生成训练后偏差报告。这将表明该模型批准男性申请人的几率高于女性申请人。<a id="_idTextAnchor605"/></p>
			<h2 id="_idParaDest-296">准备就绪</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>在你制作这个食谱之前，SageMaker Studio 需要设置好并准备好。如果你还没有在亚马逊SageMaker 中设置<a href="B16850_06_Final_ASB_ePub.xhtml#_idTextAnchor435"> <em class="italic">第六章</em></a><em class="italic">自动机器学习的<em class="italic">到SageMaker工作室</em>的方法，你可以随意查看。</em></li>
				<li>确保与<strong class="bold"> SageMaker Studio </strong>关联的<a id="_idIndexMarker1333"/>执行角色拥有将文件上传到<strong class="bold">亚马逊S3 </strong>的必要权限。您可以将AmazonS3FullAccess策略附加到上述执行角色。</li>
			</ul>
			<h2 id="_idParaDest-297">如何做<a id="_idTextAnchor607"/>它…</h2>
			<p>我们将在<strong class="bold"> SageMaker Studio </strong>中运行以下步骤:</p>
			<ol>
				<li>Create a <a id="_idIndexMarker1334"/>new notebook using the Python 3 (Data Science) kernel inside the <em class="italic">my-experiments/chapter07</em> directory and rename it so <a id="_idIndexMarker1335"/>that it's the name of this recipe (Generating a synthetic dataset and using SageMaker Feature Store for storage and management):<div><img src="img/B16850_07_03.jpg" alt="Figure 7.3 – Creating a new notebook&#13;&#10;" width="453" height="222"/></div><p class="figure-caption">图7.3–创建新笔记本</p><p>前面的截图显示了如何从<strong class="bold">文件</strong>菜单创建一个新的<strong class="bold">笔记本</strong>。当提示使用内核时，选择Python 3(数据科学)。</p></li>
				<li>Use the %load magic command to load the data_generator.py script file from the <em class="italic">Machine-Learning-with-Amazon-SageMaker-Cookbook</em> GitHub reposit<a id="_idTextAnchor608"/>ory:<pre><strong class="bold">%load</strong> \ 
https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/master/Chapter07/scripts/generator.py</pre><p>这应该会神奇地用指定脚本文件中的代码替换原始单元格内容，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_07_04.jpg" alt="Figure 7.4 – Using %load to load the data_generator.py script from this book's GitHub repository&#13;&#10;" width="779" height="537"/></div><p class="figure-caption">图7.4–使用%load从本书的GitHub存储库中加载data_generator.py脚本</p><p>正如我们所看到的，generator.py脚本文件利用generate_list_of_random_scores()为数学、科学、技术、random1和random2列生成分数。除此之外，该脚本还利用generate_event_time_records()函数来生成event_time列的值。</p></li>
				<li>Run the cell <a id="_idIndexMarker1336"/>containing the code from the previous step to start generating the synthetic dataset. This should generate a set of logs <a id="_idIndexMarker1337"/>and a DataFrame of values, similar to what is shown in the following screenshot:<div><img src="img/B16850_07_05.jpg" alt="Figure 7.5 – DataFrame containing the generated synthetic dataset&#13;&#10;" width="591" height="464"/></div><p class="figure-caption">图7.5–包含生成的合成数据集的数据帧</p><p>在这里，我们可以<a id="_idIndexMarker1338"/>看到我们已经为合成数据集生成了1000条记录。这个数据集中的每个记录都有以下字段的值:批准(目标变量)、性别、数学、科学、技术、随机1、随机2、索引和事件<a id="_idTextAnchor609"/>_时间。</p></li>
				<li>在下一个单元格中，导入并准备一些先决条件，包括boto3、sagemaker和session: <pre>import <strong class="bold">boto3</strong> import <strong class="bold">sagemaker</strong> from sagemaker.session import Session <strong class="bold">region</strong> = boto3.Session().region_name <strong class="bold">session</strong> = boto3.Session(region_name=r<a id="_idTextAnchor610"/>egion)</pre></li>
				<li>初始化名为feature_store_session的会话对象:<pre>client = session.client(     service_name='sagemaker',      region_name=region ) runtime = session.client(     service_name='<strong class="bold">sagemaker-featurestore-runtime</strong>',      region_name=region ) <strong class="bold">feature_store_session</strong> = Session(     boto_session=session,     sagemaker_client=client,     sagemaker_featurestore_runtime_client=run<a id="_idTextAnchor611"/>time )</pre></li>
				<li>指定存储数据<a id="_idIndexMarker1341"/>的S3 <a id="_idIndexMarker1340"/>桶名和前缀。确保将“&lt; insert s3 bucket name here &gt;的值替换为我们在<em class="italic">准备亚马逊s3 bucket和线性回归实验的训练数据集</em>第1章 、<em class="italic">使用亚马逊SageMaker开始机器学习</em> : <pre>s3_bucket_name = "<strong class="bold">&lt;insert s3 bucket name here&gt;</strong>" prefix = "ch<a id="_idTextAnchor612"/>apter07"</pre>中创建的bucket的名称</li>
				<li>初始化执行角色和boto3 S3客户端:<pre>from sagemaker import get_execution_role <strong class="bold">role</strong> = get_execution_role() <strong class="bold">s3_client</strong> = boto3.client('s3', region_name<a id="_idTextAnchor613"/>=region)</pre></li>
				<li>在特征组名变量中指定特征组名:<pre><strong class="bold">feature_group_name</strong> = 'cookbook-featur<a id="_idTextAnchor614"/>e-group'</pre></li>
				<li>接下来，初始化FeatureGroup对象，并将feature_group_name和feature_store_session变量作为参数值传递:<pre>from sagemaker.feature_store.feature_group import FeatureGroup feature_group = <strong class="bold">FeatureGroup</strong>(     name=feature_group_name,      sagemaker_session=feature_store_s<a id="_idTextAnchor615"/>ession )</pre></li>
				<li>Use the load_feature_definitions() function to have SageMaker automatically <a id="_idIndexMarker1342"/>detect the data types for the features <a id="_idIndexMarker1343"/>in the feature group from a specified DataFrame:<pre>feature_group.<strong class="bold">load_feature_definitions</strong>(
    data_frame=<strong class="bold">all_df</strong>
)
sleep(1)</pre><p class="callout-heading">重要说明</p><p class="callout">在继续下一步之前，确保与<strong class="bold"> SageMaker Studio </strong>关联的执行角色拥有将文件上传到<strong class="bold">亚马逊S3 </strong>的必要权限。您可以将AmazonS3FullAccess策略附加到上述执行角色。</p></li>
				<li>Use the create() function to create the feature group. Make sure to set the enable_online_store parameter value to True:<pre>feature_group.create(
    s3_uri=f"s3://{s3_bucket_name}/{prefix}/input",
    <strong class="bold">record_identifier_name="index"</strong>,
    <strong class="bold">event_time_feature_name="event_time"</strong>,
    role_arn=role,
    <strong class="bold">enable_online_store=True</strong>
)<a id="_idTextAnchor617"/>
sleep(60)</pre><p>请注意，在这一步中，我们已经指定索引列将作为记录的唯一标识符。稍后，我们将看到<a id="_idIndexMarker1345"/>我们可以通过指定索引列，使用get_record()函数从特性组中获取特定的记录。除此之外，我们还指定event_time列作为与记录的created_at或updated_at值相对应的字段，这将允许我们在使用离线存储时获得记录的特定版本。最后，我们使用sleep()函数阻塞并等待一分钟，让这些变化对<a id="_idTextAnchor618"/>产生<a id="_idTextAnchor619"/>效果。</p><p class="callout-heading">注意</p><p class="callout">在线商店和线下商店的一个主要区别是，在线商店只存储最新版本的记录，而线下商店包含所有记录，包括p <a id="_idTextAnchor620"/>以前的记录。离线存储一般用于存储几个月或几年的特征数据，这意味着在对某些记录执行查询时可能会有重复的信息。我们将在<em class="italic">的<em class="italic">还有更多… </em>部分更详细地讨论这个问题，从SageMaker Feature Store的线下商店查询数据，并将其上传到亚马逊S3 </em> recipe。</p></li>
				<li>Inspect the feature group's status using the following code:<pre>feature_group.<strong class="bold">describe()</strong></pre><p>这应该<a id="_idIndexMarker1346"/>给我们一个值的字典，类似于下面的截图所示:</p><div><img src="img/B16850_07_06.jpg" alt="Figure 7.6 – Result of feature_group.describe()&#13;&#10;" width="725" height="400"/></div><p class="figure-caption">图7.6–feature _ group . describe()的结果</p><p>在前面的<a id="_idIndexMarker1347"/>截图中，我们可以看到调用feature_group.describe()函数后特性组的属性。其中包括FeatureDefinitions、OnlineStoreConfig和FeatureGroupStatus的值，以及其他属性。</p></li>
				<li>Inspect the feature group's status using the following code:<pre>feature_group.describe().get("<strong class="bold">FeatureGroupStatus</strong>")</pre><p>这将返回一个“C<a id="_idTextAnchor621"/>re<a id="_idTextAnchor622"/>T33】ated”状态。</p></li>
				<li>Now that we have prepared everything, we will use the ingest() function with the all_df DataFrame as the value of the data_frame parameter:<pre>%%time
feature_group.<strong class="bold">ingest</strong>(
    <strong class="bold">data_frame=all_df</strong>, max_workers=3, wait=True
)</pre><p>该函数只是将all_df数据帧中的记录加载到特征存储中。等待大约<a id="_idIndexMarker1348"/>分钟左右，让这个第<a id="_idTextAnchor624"/> <a id="_idTextAnchor625"/> ep完成。请注意，运行此代码块时，当特性组定义与数据帧内的<a id="_idIndexMarker1349"/>值的数据类型不匹配时，您可能会遇到问题或错误。通过确保将<strong class="bold"> SageMaker Python SDK </strong>和其他相关库的版本更新到最新版本，或者通过将<strong class="bold"> pandas </strong> DataFrame的列值转换为适当的类型(例如，使用asty <a id="_idTextAnchor626"/> pe()函数)，您也许能够解决这个问题。</p></li>
				<li>To test if the records have been ingested properly in the online store, use the get_record() function and load the last value in the DataFrame that was ingested by specifying 300 as the record identifier value:<pre>runtime.<strong class="bold">get_record</strong>(
    FeatureGroupName=feature_group.name, 
    <strong class="bold">RecordIdentifierValueA<a id="_idTextAnchor627"/>sString="300"</strong>
)</pre><p>这将返回一个嵌套的值字典，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_07_07.jpg" alt="Figure 7.7 – Result after using the get_record() function&#13;&#10;" width="599" height="274"/></div><p class="figure-caption">图7.7–使用get_record()函数后的结果</p><p>在这里，我们可以<a id="_idIndexMarker1350"/>看到我们能够检索索引等于300的记录的特征值。</p></li>
				<li>Use the %store magic to store the variable values for feature_group_name, s3_bucket_name, and prefix:<pre>%store <strong class="bold">feature_group_name</strong>
%store <strong class="bold">s3_bucket_name</strong>
%store <strong class="bold">prefix</strong></pre><p>我们将在本章后面的食谱中使用这些变量。</p></li>
			</ol>
			<p>让我们看看这是如何运作的！</p>
			<h2 id="_idParaDest-298"><a id="_idTextAnchor629"/>工作原理……</h2>
			<p>在这个配方中，我们生成了一个可用于分类问题的合成数据集。它包含以下几列:</p>
			<ul>
				<li>包含目标变量的批准列。</li>
				<li>性别、数学、科学和技术列，由generate_list_of_random_scores()函数生成。</li>
				<li>random1和random2列，包含一组随机数字，用于在使用<em class="italic">使用SageMaker Clarify </em>配方启用ML解释能力中的<strong class="bold"> SHAP </strong>值时，帮助识别<a id="_idIndexMarker1352"/>每个特征对预测目标标签的贡献。</li>
				<li>event_time和index列，这是我们在使用<strong class="bold"> SageMaker特性库</strong>时需要的。在generator.py脚本的末尾，我们更新了DataFrame中的<a id="_idIndexMarker1353"/>几行，以在我们的数据集中引入偏差，这使得“男性”(性别=1)候选人比“女性”(性别=0)候选人更有可能获得批准。</li>
			</ul>
			<p>一旦我们生成并准备好包含目标和预测变量值的数据帧，我们就使用<strong class="bold"> SageMaker特征库</strong>来摄取它。有两种<a id="_idIndexMarker1354"/>类型的店铺——<strong class="bold">线上</strong>和<strong class="bold">线下</strong>。在线商店通常用于实时加载记录，并且在涉及加载记录以测试推断端点的用例中运行良好。另一方面，离线存储在涉及加载一批在训练阶段使用的记录的场景中很有用。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">正如我们在<em class="italic">中提到的如何去做...</em>节，在线商店和线下商店的一个主要区别是，在线商店只存储最新版本的记录，而线下商店可能包含所有记录，包括以前的记录。例如，离线商店会有客户每月购买数据的以前快照的副本，而在线商店只有最新版本。这些属性，以及帮助机器学习实践者节省组织功能时间的其他好处，使在线和离线商店成为比单纯使用亚马逊S3进行存储更好的选择。</p>
			<p>处理功能存储时，该过程通常包括以下步骤:</p>
			<ol>
				<li value="1">将加载特征组属性和特征定义配置。</li>
				<li>将创建特征组。</li>
				<li>数据被吸收到特征组中。</li>
				<li>为训练数据从脱机存储区加载了多条记录。</li>
				<li>从在线商店为推断测试数据加载记录。</li>
			</ol>
			<p>在这个方法中，我们执行了前三个步骤来获取特性组的数据帧值。在<em class="italic">从SageMaker功能商店的线下商店查询数据并将其上传到亚马逊S3 </em>食谱中，我们将执行第四步并在训练阶段之前准备训练、验证和测试数据集时加载<a id="_idIndexMarker1356"/>多条记录。最后，我们将执行<em class="italic">中的第五个<a id="_idIndexMarker1357"/>步骤，从一个模型中部署一个端点，并使用SageMaker Model Monitor </em>方法启用数据捕获，当加载一个测试记录以验证推断端点是否正确地配置了<a id="_idTextAnchor630"/> <a id="_idTextAnchor631"/> <a id="_idTextAnchor632"/>。</p>
			<h1 id="_idParaDest-299"><a id="_idTextAnchor633"/>从SageMaker特色店的线下店查询数据，上传到亚马逊S3</h1>
			<p>在之前的配方中，我们生成了一个合成数据集，并使用摄取()函数将其存储在<strong class="bold"> SageMaker特征库</strong>中。在本配方中，我们将演示如何从<a id="_idIndexMarker1358"/>离线商店的功能组中加载数据，数据存储在<a id="_idIndexMarker1359"/>之前的配方中。正如我们在<em class="italic">生成合成数据集和使用SageMaker特性存储进行存储和管理</em>配方中所讨论的，离线<a id="_idIndexMarker1360"/>存储对于<a id="_idIndexMarker1361"/>涉及加载一批在训练阶段使用的记录的用例非常有用。也就是说，训练、验证和测试数据集将从离线商店加载，以CSV格式导出，然后上传到S3。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">请注意，如果您刚刚将数据输入到<em class="italic">生成合成数据集的要素组中，并使用SageMaker要素存储来存储<a id="_idTextAnchor634"/>年龄和管理</em>配方，您可能需要等待几分钟才能查询离线存储数据。</p>
			<h2 id="_idParaDest-300">准备就绪</h2>
			<p>该配方延续了<em class="italic">生成合成数据集并使用SageMaker特征库存储<a id="_idTextAnchor636"/>和管理<a id="_idTextAnchor637"/>配方。</em></p>
			<h2 id="_idParaDest-301"><a id="_idTextAnchor638"/>怎么做……</h2>
			<p>下一组步骤集中在<a id="_idIndexMarker1362"/>从<strong class="bold"> SageMaker功能商店</strong>离线商店加载<a id="_idIndexMarker1363"/>训练、验证和测试数据集，并将它们存储在S3。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter07目录中使用Python 3(数据科学)内核创建一个新的<a id="_idIndexMarker1364"/>笔记本，并将其重命名为该食谱的名称(从SageMaker Feature Store的离线商店中查询数据并上传到亚马逊S3)。当提示使用内核时，选择Python 3(数据科学)。</li>
				<li>从<strong class="bold">SageMaker Python SDK<a id="_idTextAnchor639"/></strong>和boto3 Session对象:<pre>import boto3 import sagemaker from sagemaker.session import <strong class="bold">Session</strong> from sagemaker.feature_store.feature_group import <strong class="bold">FeatureGroup</strong> <strong class="bold">region</strong> = boto3.Session().region_name <strong class="bold">session</strong> = boto3.Session(region_name=region)</pre>导入和<a id="_idIndexMarker1365"/>准备一些先决条件，如Session和FeatureGroup类</li>
				<li>接下来，初始化feature_store_session会话:<pre>client = session.client(     service_name='sagemaker',      region_name=region ) runtime = session.client(     service_name='<strong class="bold">sagemaker-featurestore-runtime</strong>',      region_name=region ) <strong class="bold">feature_store_session</strong> = Session(     boto_session=session,     sagemaker_client=client,     sagemaker_featurestore_runtime_client=runtime )</pre></li>
				<li>使用%store magic <a id="_idIndexMarker1366"/>加载feature_group_name的变量值，并使用它<a id="_idIndexMarker1367"/>加载我们在<em class="italic">中创建的<a id="_idIndexMarker1368"/>特征组，生成合成数据集并使用SageMaker特征库进行存储和管理</em>方法:<pre>%store -r <strong class="bold">feature_group_name</strong> feature_group = <strong class="bold">FeatureGroup</strong>(     name=<strong class="bold">feature_group_name</strong>,      sagemaker_session=feature_store_session )</pre></li>
				<li>Run the following <a id="_idIndexMarker1369"/>block of code to store the Athena table name in the table variable:<pre>table = <strong class="bold">feat<a id="_idTextAnchor640"/>u<a id="_idTextAnchor641"/>re_group.athena_query().table_name</strong></pre><p class="callout-heading">注意</p><p class="callout">注意，离线商店利用Amazon Athena通过SQL查询获取数据。</p></li>
				<li>Get the S3 <a id="_idIndexMarker1370"/>URI from the response nested dictionary value after using the describe() function of the feature_group object:<pre>describe_response = feature_group.describe()
offline_config = describe_response['<strong class="bold">OfflineStoreConfig</strong>']
<strong class="bold">s3_uri</strong> = offline_config['S3StorageConfig']['S3Uri']
!aws s3 ls {<strong class="bold">s3_uri</strong>} --recursive</pre><p>这应该会给我们一个拼花文件列表，这些文件对应于我们已经存储在离线特征存储中的数据。分栏拼花格式与亚马逊Athena合作得很好，因为对以这种格式存储的数据的查询通常比CSV或TSV文件有更好的性能。</p></li>
				<li>Use the %store magic to load the variable values for s3_bucket_name and prefix. Using these <a id="_idIndexMarker1372"/>values, prepare the S3 output path stored in the output_location variable:<pre>%store -r <strong class="bold">s3_bucket_name</strong>
%store -r <strong class="bold">prefix</strong>
base = f's3://{s3_bucket_name}/{prefix}'
output_location = f'{base}/query_results/'</pre><p>在随后的<a id="_idIndexMarker1373"/>步骤中，我们将看到Athena查询的结果被存储在这个输出位置中。</p></li>
				<li>Define the query_data() function, which we will use to load the DataFrame containing <a id="_idIndexMarker1374"/>the results of the Athena query:<pre>def <strong class="bold">query_data</strong>(query_string):
    print(f"QUERY: {query_string}\n")
    query = feature_group.athena_query()
    <strong class="bold">query.run</strong>(query_string=query_string, 
              output_location=output_location)
    
    <strong class="bold">query.wait<a id="_idTextAnchor644"/>()</strong>
    
    return query.as_dataframe()</pre><p>接下来的几个<a id="_idIndexMarker1375"/>步骤涉及<a id="_idIndexMarker1376"/>通过使用我们在上一步中定义的query_data() <a id="_idTextAnchor645"/>函数查询数据来加载训练、验证和测试数据集:</p></li>
				<li>Use the query_data() function to load the first 600 records for the training dataset <a id="_idIndexMarker1377"/>using Amazon Athena:<pre>query = f"""<strong class="bold">SELECT approved, sex, math, science, technology, random1, random2 FROM "{table}" ORDER BY index ASC LIMIT 600</strong>"""
training_df = query_data(query)
training_df</pre><p>这将为我们提供一个类似于下面截图所示的数据框架:</p><div><img src="img/B16850_07_08.jpg" alt="" width="437" height="363"/></div><p class="figure-caption">图7.8–训练数据集</p><p>这里，我们<a id="_idIndexMarker1378"/>有一个包含训练数据的数据帧。</p><p class="callout-heading">重要说明</p><p class="callout">如果在运行之前的查询后没有得到任何结果，请等待几分钟，然后重试。</p></li>
				<li>使用<a id="_idIndexMarker1379"/>query _ data()函数为验证数据集加载接下来的200条记录:<pre>query = f"""<strong class="bold">SELECT approved, sex, math, science, technology, random1, random2 FROM "{table}" WHERE index &gt; 600 ORDER BY index ASC LIM<a id="_idTextAnchor647"/>IT 200</strong>""" validation_df = query_data(query)</pre></li>
				<li>以类似的<a id="_idIndexMarker1380"/>方式，使用query_data()函数为测试数据集<pre>query = f"""<strong class="bold">SELECT approved, sex, math, science, technology, random1, random2 FROM "{table}" WHERE index &gt; 800 ORDER BY index<a id="_idTextAnchor648"/> ASC LIMIT 200</strong>""" test_df = query_data(query)</pre>加载最后200条记录<a id="_idIndexMarker1381"/></li>
				<li>创建<a id="_idIndexMarker1382"/>tmp目录<a id="_idTextAnchor649"/>工厂<a id="_idIndexMarker1383"/>如果它还不存在:<pre>!mkdir -p <strong class="bold">tmp</strong></pre></li>
				<li>使用to_csv()函数<a id="_idIndexMarker1384"/>从数据帧:<pre><strong class="bold">training_df</strong>.to_csv('tmp/<strong class="bold">training_data.csv</strong>',                     header=True,                     index=False) <strong class="bold">validation_df</strong>.to_csv('tmp/<strong class="bold">validation_data.csv</strong>',                       header=True,                       index=False) <strong class="bold">test_df</strong>.to_csv('tmp/<strong class="bold">test_data.csv</strong>',          <a id="_idTextAnchor650"/>       header=True,                 index=False)</pre>生成csv文件</li>
				<li>使用aws s3 cp命令将我们在上一步中生成的CSV文件上传到S3:<pre>path = f"s3://{s3_bucket_name}/{prefix}" <strong class="bold">training_data_path</strong> = f"{path}/input/<strong class="bold">training_data.csv</strong>" <strong class="bold">validation_data_path</strong> = f"{path}/input/<strong class="bold">validation_data.cs<a id="_idTextAnchor651"/>v</strong>" <strong class="bold">test_data_path</strong> = f"{path}/input/<strong class="bold">test_data.csv</strong>" !aws s3 cp tmp/training_data.csv {training_data_path} !aws s3 cp tmp/validation_data.csv {validation_data_pa<a id="_idTextAnchor652"/>th} !aws s3 cp tmp/test_data.csv {test_data_path}</pre></li>
				<li>使用to_csv()函数<a id="_idIndexMarker1386"/>生成不带头文件的csv文件:<pre>target = 'tmp/<strong class="bold">training_data_no_header.csv</strong>' <strong class="bold">training_df</strong>.to_csv(target,                     header=False,                     index=False) target = 'tmp/<strong class="bold">validation_data_no_header.csv</strong>' <strong class="bold">validation_df</strong>.to_csv(target,                       header=False,                       index=False) <strong class="bold">test_df</strong>.to_csv('tmp/<strong class="bold">test_data_no_header.csv</strong>',                 header=False,                 index=False)</pre></li>
				<li>使用aws s3 cp命令<pre><strong class="bold">training_data_path_nh</strong> = f"{path}/input/training_data_no_header.csv" <strong class="bold">validation_data_path_nh</strong> = f"{path}/input/validation_data_no_header.csv" <strong class="bold">test_d<a id="_idTextAnchor653"/>ata_path_nh</strong> = f"{path}/input/test_data_no_header.csv" !aws s3 cp tmp/<strong class="bold">training_data_no_header.csv</strong> {training_data_path_nh} !aws s3 cp tmp/<strong class="bold">validation_data_no_header.csv</strong> {validation_data_path_nh} !aws s3 cp tmp/<strong class="bold">test_data_no_header.csv</strong> {test_data_path_nh}</pre>将<a id="_idIndexMarker1387"/>我们在前面的<a id="_idIndexMarker1389"/>步骤中生成的CSV文件<a id="_idIndexMarker1388"/>上传到S3</li>
				<li>Finally, use <a id="_idIndexMarker1390"/>the %store magic <a id="_idIndexMarker1391"/>to store the variable values for training_data_path, validation_data_path, test_data_path, training_data_path_nh, validation_data_path_nh, and test_data_path_nh:<pre>%store <strong class="bold">training_data_path</strong>
%store <strong class="bold">validation_data_path</strong>
%store <strong class="bold">test_data_path</strong>
%store <strong class="bold">training_data_path_nh</strong>
<a id="_idTextAnchor654"/>%store <strong class="bold">validation_data_path_nh</strong>
%store <strong class="bold">test_data_path_nh</strong></pre><p>我们<a id="_idIndexMarker1392"/>将在su <a id="_idTextAnchor655"/>成功配方中使用一个或多个这些存储的变量值。</p></li>
			</ol>
			<p>让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-302">它是如何工作的…</h2>
			<p>在这个菜谱中，我们使用<strong class="bold"> Amazon Athena </strong>和SQL查询来查询和加载数据，从SageMaker功能商店的离线商店加载记录。在<em class="italic">生成合成数据集并使用SageMaker功能商店进行存储和管理的</em>方法中，我们将数据摄取到离线和在线商店中。离线<a id="_idIndexMarker1394"/>商店数据存储在<strong class="bold">亚马逊S3 </strong>中，这个食谱中的步骤只是加载存储在离线商店中的数据。当特征组被定义和创建时，相应的<strong class="bold">粘合数据目录</strong>被创建。这充当了数据的模式，因此我们可以使用Amazon Athena执行查询。</p>
			<p>这个配方中使用的SQL查询包括确保训练、验证和测试数据集<a id="_idIndexMarker1395"/>是互斥的。为训练数据集加载前600条(60%)记录，为验证数据集加载后200条(20%)记录，为测试数据集加载后200条(20%)记录<a id="_idIndexMarker1396"/>。注意，<strong class="bold">亚马逊雅典娜</strong>不支持偏移关键字<a id="_idIndexMarker1397"/>，这就是为什么<a id="_idIndexMarker1398"/>我们使用<a id="_idTextAnchor658"/>替代方法<a id="_idTextAnchor659"/>从线下商店提取记录。</p>
			<h2 id="_idParaDest-303"><a id="_idTextAnchor660"/>还有更多……</h2>
			<p>该配方中的示例包含了如何使用<strong class="bold"> SageMaker特征库</strong>的简化示例。我们可以利用功能商店做更多的事情，包括:</p>
			<ul>
				<li>从两个要素组连接和提取数据</li>
				<li>使用Athena查询加载以前版本的数据集并移除重复和已删除的记录，这涉及到在WHERE子句中使用event_time和is_deleted列</li>
			</ul>
			<p>这个方法只涉及具有相同event_time值的单层记录。在实际示例中，一个要素组可能包含索引相同但event_time值不同的单个记录的副本。分析和处理数据时，会提取指定时间的数据集版本，并且仅从要素存储中加载指定时间戳之前的记录的最新版本。</p>
			<p>如果需要在某个时间戳之前加载记录的最新版本，请使用以下SQL语句:</p>
			<pre>SELECT * FROM
    (SELECT *, row_number() OVER (PARTITION BY index
        ORDER BY event_time desc) AS row_num
        FROM <strong class="bold">&lt;table name&gt;</strong>
        where event_time &lt;= timestamp '<strong class="bold">&lt;timestamp&gt;</strong>')
WHERE row_num = 1 and
NOT is_deleted</pre>
			<p>注意，index和event_time列名只是这组配方中使用的名称/键。这些可以在摄取步骤之前初始化功能组时设置。</p>
			<h1 id="_idParaDest-304"><a id="_idTextAnchor662"/>使用SageMaker Clarify检测训练前偏差</h1>
			<p>随着我们处理更多真实世界的例子，我们将开始遇到涉及检测和<a id="_idIndexMarker1400"/>管理ML偏差的需求。例如，部署的机器学习模型可能会拒绝来自不受欢迎或代表性不足的群体的申请，因为用于训练这些<a id="_idIndexMarker1401"/>模型的训练数据已经从一开始就对不受欢迎的群体有偏见。这减少了这些不受欢迎的群体的机会，从而使他们长期不适合某个应用程序。也就是说，一旦我们开始意识到确保机器学习公平的重要性，我们就会开始寻找能够帮助我们处理法律、道德和技术问题的解决方案。好消息是<strong class="bold"> SageMaker Clarify </strong>可以帮助我们检测数据和模型中的ML偏差！</p>
			<p>AI和ML偏差可能存在于机器学习管道的特定阶段——训练之前、期间和之后。在本食谱中，我们将使用<strong class="bold"> SageMaker Clarify </strong>来帮助检测给定数据集的训练前偏差，特别是<strong class="bold">类别不平衡</strong>。在<strong class="bold"> SageMaker Clarify </strong>处理作业执行完毕后，我们将能够分析处理作业已经计算并作为输出返回的度量值。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">如果数据集的每个类没有相同数量的实例，则认为该数据集是不平衡的。当处理不平衡类问题时，我们需要小心，因为一些分类算法假设每个类的样本数量相等。除此之外，即使算法没有为每个类假设相同数量的样本，极端的类不平衡也会导致模型不起作用-如果数据集有90%的数据属于类A，剩余的10%属于类B，则模型每次只预测类A就可以获得表面上可接受的90%的准确性。也就是说，未能正确检测和管理这一点可能会导致不正确和错误的结论，特别是在对代表性不足的群体进行预测时。</p>
			<h2 id="_idParaDest-305">做好准备</h2>
			<p>这个菜谱上接<em class="italic">查询SageMaker特色店的线下店铺<a id="_idTextAnchor665"/>的数据，上传到亚马逊S3 </em>菜谱。</p>
			<h2 id="_idParaDest-306"><a id="_idTextAnchor666"/>怎么做……</h2>
			<p>该配方中的第一组<a id="_idIndexMarker1402"/>步骤主要是为<strong class="bold"> SageMaker Clarify </strong>加工作业准备先决条件<a id="_idTextAnchor667"/>位点。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter07目录中使用Python 3(数据科学)内核创建一个<a id="_idIndexMarker1403"/>新笔记本，并将其重命名为该食谱的名称(使用SageMaker Clarify检测训练前偏差)。当提示使用内核时，选择Python 3(数据科学)。</li>
				<li>指定s3_bucket_name和前缀值:<pre>%st<a id="_idTextAnchor668"/>ore -r <strong class="bold">s3_bucket_name</strong> %store -r <strong class="bold">prefix</strong> %store -r <strong class="bold">training_data_path</strong></pre></li>
				<li>导入、准备和加载一些先决条件，例如会话、区域和角色:<pre>import sagemaker session = sagemaker.Session() regi<a id="_idTextAnchor669"/>on = session.boto_region_name role = sagemaker.get_execution_rol<a id="_idTextAnchor670"/>e()</pre></li>
				<li>进口熊猫和熊猫宝贝:<pre>import pandas as pd import numpy as <a id="_idTextAnchor671"/>np</pre></li>
				<li>如果tmp目录尚不存在，则创建该目录:<pre>!mkdir -p <strong class="bold">tmp</strong></pre></li>
				<li>指定s3_training_data_path和s3_output_path值:<pre><strong class="bold">s3_training_data_path</strong> = training_<a id="_idTextAnchor672"/>data_path <strong class="bold">s3_output_path</strong> = f"s3://{s3_bucket_name}/{prefix}/output"</pre></li>
				<li>使用AWS CLI将文件复制到tmp <a id="_idTextAnchor673"/>目录:<pre>!<strong class="bold">aws s3 cp</strong> {<strong class="bold">s3_training_data_path</strong>} tmp/<strong class="bold">training_data.csv</strong></pre></li>
				<li>Load the training data using the read_c<a id="_idTextAnchor674"/>sv() function:<pre>training_data = pd.read_csv("tmp/<strong class="bold">training_data.csv</strong>")</pre><p>既然我们已经<a id="_idIndexMarker1404"/>准备好了先决条件，我们可以专注于让<strong class="bold"> SageMaker Clarify </strong>处理作业在下一组步骤中运行:</p></li>
				<li>初始化SageMakerClarifyProcessor类。这个类只是一个专门构建的<a id="_idIndexMarker1405"/>包装类，它利用了<strong class="bold"> SageMaker处理</strong>功能:<pre>from sagemaker import clarify processor = clarify.<strong class="bold">SageMakerClarifyProcessor</strong>(     role=role,     instance_cou<a id="_idTextAnchor675"/>n<a id="_idTextAnchor676"/>t=1,     instance_type='ml.m5.large',     sagemaker_session=session )</pre></li>
				<li>初始化数据配置对象:<pre>data_config = clarify.DataConfig(     s3_data_input_path=s3_training_data_path,     s3_output_path=s3_output_path,     label='<strong class="bold">approved</strong>',     h<a id="_idTextAnchor677"/>eaders=<strong class="bold">training_data.columns.to_list()</strong>,     dataset_type='text/csv' )</pre></li>
				<li>Initialize the BiasConfig object:<pre>bias_config = clarify.BiasConfig(
    label_values_or_threshold=[<strong class="bold">1</strong>],
    facet_name='<strong class="bold">sex</strong>',
)</pre><p>如果你想知道这些配置值的含义，不要担心——我们将在<em class="italic">如何工作… </em>部分解释这个配置如何工作。</p></li>
				<li>Use the run_pre_training_bias() function and wait a few minutes for the job to complete. In the following code block, we are specifying the data_config and the bias_config objects we initialized in the previous steps as arguments when calling the run_pre_training_bias() function:<pre>%%time
processor.<strong class="bold">run_pre_training_bias</strong>(
    data_config=data_config, 
    data_bias_config=bias_config,
    methods=['<strong class="bold">CI</strong>']
)</pre><p>注意<a id="_idIndexMarker1408"/>该步骤可能需要大约5到10分钟才能完成。调用run_pre_training_bias()将触发一个<strong class="bold"> SageMaker Clarify </strong>处理作业。这将使用一个预构建的<strong class="bold"> SageMaker Clarify </strong>容器映像运行一个<a id="_idTextAnchor679"/> <a id="_idTextAnchor680"/>容器。</p></li>
				<li>一旦<a id="_idIndexMarker1409"/>处理任务完成，我们就获得了输出目的地，并可以将URI字符串值存储在output_uri变量中:<pre>output <a id="_idTextAnchor681"/>= processor.latest_job.outputs[0] output_destination = output.destination</pre></li>
				<li>使用AWS CLI将生成的文件复制到tmp di <a id="_idTextAnchor682"/>目录:<pre>!<strong class="bold">aws s3 cp</strong> {output_destination}/ tmp/ --recursive !ls -lahF tmp/</pre></li>
				<li>Inspect the content of the analysis.json file:<pre>!cat tmp/<strong class="bold">analysis.json</strong></pre><p>这将为我们提供一个嵌套的值结构，类似于下面的屏幕截图所示:</p></li>
			</ol>
			<div><div><img src="img/B16850_07_09.jpg" alt="Figure 7.9 – Content of the tmp/analysis.json file&#13;&#10;" width="471" height="465"/>
				</div>
			</div>
			<p class="figure-caption">图7.9–tmp/analysis . JSON文件的内容</p>
			<p>在这里，我们可以<a id="_idIndexMarker1410"/>看到预训练偏差作业的结果。仅仅通过查看th <a id="_idTextAnchor683"/> e tmp/analysis.json文件中CI的指标<a id="_idIndexMarker1411"/>值，我们就可以推断出w <a id="_idTextAnchor684"/> e有一个不平衡的数据集。</p>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-307"><a id="_idTextAnchor685"/>工作原理…</h2>
			<p><strong class="bold"> SageMaker Clarify </strong>利用<strong class="bold"> SageMaker Processing </strong>运行一个评估数据的作业。在这种情况下，我们<a id="_idIndexMarker1412"/>指定<a id="_idIndexMarker1413"/>我们只想从<a id="_idIndexMarker1414"/>一个更大的预训练偏差度量列表<a id="_idIndexMarker1415"/>中获取<strong class="bold">类不平衡</strong> ( <strong class="bold"> CI </strong>)度量。除了<a id="_idIndexMarker1416"/>类别不平衡指标，我们还可以使用<strong class="bold"> SageMaker Clarify </strong>计算<a id="_idIndexMarker1417"/>其他偏差指标。其中包括<strong class="bold">标签中的正比例差异</strong>(<strong class="bold">DPL</strong>)<strong class="bold">库尔贝克-利布勒散度</strong>(<strong class="bold">KL</strong>)<strong class="bold">詹森-香农散度</strong>(<strong class="bold">JS</strong>)<strong class="bold">LP范数</strong>(<strong class="bold">LP</strong>)<strong class="bold">总变异距离</strong> ( <strong class="bold"> TVD </strong>)，</p>
			<p><strong class="bold">科莫戈罗夫-斯米尔诺夫</strong> ( <strong class="bold"> KS </strong>)，以及<strong class="bold">标签中的条件人口差异</strong> ( <strong class="bold"> CDDL </strong>)。这些<a id="_idIndexMarker1418"/>预训练偏差指标是模型不可知的，这意味着<a id="_idIndexMarker1419"/>我们可以在训练步骤之前对原始数据集进行计算。</p>
			<p>那么，我们如何解释下图所示的内容呢？对于类不平衡度量，接近1或-1的正分数(如0.5933333334)意味着性别方面在数据集中对于给定值(如1)有更多的训练样本。这意味着在所提供的数据集中，男性和女性的数量不平衡:</p>
			<div><div><img src="img/B16850_07_10.jpg" alt="Figure 7.10 – Interpreting the class imbalance score&#13;&#10;" width="685" height="501"/>
				</div>
			</div>
			<p class="figure-caption">图7.10–解释班级失衡分数</p>
			<p>正如我们所看到的，类不平衡度量的可能得分范围在-1和1之间。接近1或-1的分数意味着数据集不平衡。另一方面，接近0的分数意味着数据集中男性和女性的分布接近相等。用不平衡的<a id="_idIndexMarker1421"/>数据集训练的模型对代表性不足的群体的预测可能不太准确。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">我们如何处理<a id="_idIndexMarker1422"/>这个<strong class="bold">阶级不平衡</strong>的问题？有不同的方法来处理数据集中的类不平衡。一种可能的方法是对优势组执行下采样，然后对调整后的数据集使用<strong class="bold">sage maker Clarify</strong>run _ pre _ training _ bias()函数，以查看修改(例如，下采样)如何影响CI指标得分。如果我们获得的CI指标分数非常接近零，这意味着我们已经解决了数据集中存在的类别不平衡问题。关于这个话题的更多信息，请随意查看这里的白皮书:<a href="https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf">https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf</a>。</p>
			<h2 id="_idParaDest-308">还有更多……</h2>
			<p>我们实际上可以使用run_bias()函数在处理作业中同时运行训练前和训练后分析:</p>
			<pre>clarify_processor.<strong class="bold">run_bias</strong>(
    data_config=bias_data_config, 
    data_bias_config=bias_config,<a id="_idTextAnchor687"/>
    ...
    <strong class="bold">pre_training_methods</strong>=['CI'],
    <strong class="bold">post_training_methods</strong>=['DPPL', 'RD']
)</pre>
			<p>当然，这种方法可能涉及更多的配置参数值和先决条件。但是，它也有自己的优势，例如运行单个处理作业来进行训练前和训练后的偏差检测和分析。</p>
			<p>现在，让我们仔细看看如何检测训练后偏差！</p>
			<h1 id="_idParaDest-309"><a id="_idTextAnchor688"/>用SageMaker Clarify检测训练后偏差</h1>
			<p>在之前的配方中，我们使用<strong class="bold"> SageMaker Clarify </strong>来帮助我们检测数据中的训练前偏差。在本<a id="_idIndexMarker1423"/>配方中，我们将使用<strong class="bold"> SageMaker Clarify </strong>来检测我们在之前配方中使用的同一数据集<a id="_idIndexMarker1424"/>中的训练后偏差。除此之外，我们将使用该数据集训练一个模型，并使用它来计算<a id="_idIndexMarker1425"/>训练后偏差指标。具体来说，我们将计算预测标签 ( <strong class="bold"> DPPL </strong>)和<strong class="bold">召回差异</strong> ( <strong class="bold"> RD </strong>)度量值<a id="_idIndexMarker1426"/>中的正比例<strong class="bold">差异，并在加工作业完成运行后检查结果<a id="_idIndexMarker1427"/>。</strong></p>
			<p class="callout-heading">注意</p>
			<p class="callout">为什么这很重要？如果<strong class="bold"> DPPL </strong>的度量值表明对弱势群体有偏见，这意味着机器学习模型有更高的机会预测优势群体的积极结果。例如，如果优势群体涉及男性申请人，而弱势群体涉及女性申请人，则机器学习模型可能会接受优势群体比弱势群体更多的奖学金申请。同样，如果<strong class="bold"> RD </strong>的度量值表明对弱势群体有偏见，这意味着机器学习模型有更高的机会<em class="italic">正确预测优势群体相对于弱势群体的</em>可能结果。使用相同的应用示例，机器学习模型有更高的机会正确接受30岁以上申请人的奖学金申请。最后，请注意<strong class="bold"> DPPL </strong>和<strong class="bold"> RD </strong>测量的是不同的东西。RD测量两组之间的<strong class="bold">真P <a id="_idTextAnchor689"/>阳性率</strong>的差异，这可能意味着另一组的假阴性率更高。</p>
			<h2 id="_idParaDest-310">做好准备</h2>
			<p><a id="_idTextAnchor691"/>该配方延续了<em class="italic">用SageMaker Clarify </em>配方检测训练前偏差。</p>
			<h2 id="_idParaDest-311"><a id="_idTextAnchor692"/>怎么做……</h2>
			<p>该配方中的第一组步骤<a id="_idIndexMarker1428"/>主要是使用<strong class="bold"> SageMaker Python SDK </strong>准备模型。请注意，在运行训练后偏差作业之前，我们需要准备好模型。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter07目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为该食谱的名称(使用SageMaker Clarify检测训练后偏差)。当提示使用内核时，选择Python 3(数据科学)。</li>
				<li>使用%store magic加载s3_bucket_name、prefix和<a id="_idTextAnchor694"/> training_data_path: <pre>%store -r <strong class="bold">s3_bucket_name</strong> %store -r <strong class="bold">prefix</strong> %store -r <strong class="bold">training_data_path</strong></pre>的变量值</li>
				<li>使用<strong class="bold">SageMaker Python SDK</strong>:<pre>import sagemaker session = <a id="_idTextAnchor695"/>sagemaker.Session() region = session.boto_region_name role = sagemaker.get_execution_role()</pre>导入、准备和<a id="_idIndexMarker1429"/>加载一些先决条件，比如会话、区域和角色</li>
				<li>初始化<a id="_idIndexMarker1430"/>S3 _ training _ data _ path和s3_output_path的变量值:<pre><strong class="bold">s3_train<a id="_idTextAnchor696"/>ing_data_path</strong> = training_data_path <strong class="bold">s3_output_path</strong> = f"s3://{s3_bucket_name}/{prefix}/output"</pre></li>
				<li>使用AWS CLI将测试数据集CSV文件从<a id="_idTextAnchor697"/>S3存储桶下载到tmp目录:<pre>!aws s3 cp {s3_training_data_path} tmp/training_data.csv</pre></li>
				<li>使用函数<pre>import pandas as pd training_data = pd.read_csv("tmp/<strong class="bold">training_data.csv</strong>")</pre>加载训练数据集</li>
				<li>使用retrieve()函数获取容器URI: <pre>from s<a id="_idTextAnchor699"/>agemaker.image_uris import retrieve container = <strong class="bold">retrieve</strong>('<strong class="bold">xgboost</strong>', region, version='1.2-1')</pre></li>
				<li>初始化<a id="_idIndexMarker1431"/>评估器对象:<pre>from sagemaker.estimator import Estimator estimator = <strong class="bold">Estimator</strong>(     container,    <a id="_idTextAnchor700"/> role,     instance_count=1,     instance_type='ml.m5.large',     sagemaker_session=session )</pre></li>
				<li>使用set_hyperparameters()函数指定<a id="_idIndexMarker1432"/>超参数:<pre>estimator.<strong class="bold">set_hyperparameters</strong>(     objectiv<a id="_idTextAnchor701"/>e='binary:logistic',     max_depth=8,     eta=0.1,     min_child_weight=4,     num_round=500 )</pre></li>
				<li>使用训练输入:<pre>from sagemaker.inputs import T<a id="_idTextAnchor702"/>rainingInput train_input = <strong class="bold">TrainingInput</strong>(     s3_training_data_path,      content_type='csv' )</pre></li>
				<li>Call the fit() function to start the training job:<pre>%%time
estimat<a id="_idTextAnchor703"/>or.<strong class="bold">fit</strong>({'train': train_input}, wait='True')</pre><p>这应该需要<a id="_idIndexMarker1433"/>大约4到7分钟来完成。</p></li>
				<li>定义generate_model_name()函数:<pre>import random from string import ascii_uppercase def <strong class="bold">generate_model_name</strong>():     chars = random.choices(ascii_uppercase, k=5)     output = 'model-' + ''.join(chars)     return output</pre></li>
				<li>Use the generate_model() function to generate the model name:<pre>model_name = <strong class="bold">generate_model_name</strong>()</pre><p>这应该<a id="_idIndexMarker1434"/>给我们一个类似于‘model-RV jml’的值。</p><p class="callout-heading">注意</p><p class="callout">为什么我们要为模型名称生成一个随机字符串？在下一步中，我们将使用create_model()函数，它接受name参数值。您可能已经猜到了，这个name参数值应该是惟一的。</p></li>
				<li>Use the create_model() function from the Estimator object to create the model entity:<pre>model = estimator.<strong class="bold">create_model</strong>(name=model_name)</pre><p>此时，模型已经完成了训练，并为后续步骤做好了准备。</p><p>下一组<a id="_idIndexMarker1435"/>步骤集中在<a id="_idIndexMarker1436"/>上，使用<a id="_idTextAnchor704"/>该配方前半部分的先决条件来运行训练后偏差检测作业:</p></li>
				<li>使用prepare_container_def()函数，将带有Image、environ<a id="_idTextAnchor705"/>ent和ModelDataUrl值的字典存储在container_def变量:<pre>container_def = model.<strong class="bold">prepare_container_def</strong>()</pre>中</li>
				<li>使用会话<pre>session.<strong class="bold">create_model</strong>(     model_name,     role,     container_def )</pre>中的create_mode <a id="_idTextAnchor706"/> l()函数</li>
				<li>初始化SageMakerClarifyProcessor对象:<pre>from sagemaker.clarify import SageMakerClarifyProcessor processor = <strong class="bold">SageMakerClarifyProcessor</strong>(     role=role,            instance_count=1,           instance_type='ml.m5.large',     sagemaker_session=session )</pre></li>
				<li>用我们在前面步骤中准备的先决条件初始化<a id="_idIndexMarker1437"/>data config对象:<pre>from sagemaker.clarify import DataConfig data_config = <strong class="bold">DataConfig</strong>(     s3_data_input_path=<strong class="bold">s3_training_data_path</strong>,     s3_output_path=<strong class="bold">s3_output_pat<a id="_idTextAnchor707"/>h</strong>,     label=<strong class="bold">'approved'</strong>,     headers=<strong class="bold">training_data.columns.to_list()</strong>,     dataset_type=<strong class="bold">'text/csv'</strong> )</pre></li>
				<li>初始化<a id="_idIndexMarker1438"/>模型配置和模型预测标签配置对象:<pre>from sagemaker.clarify import ModelConfig model_config = <strong class="bold">ModelConfig</strong>(     model_name=<strong class="bold">model_name</strong>,     instance_type='ml.c5.xlarge',     instance_count=1,     accept_type='text/csv' )</pre></li>
				<li>Initialize the ModelPredictedLabelConfig object with a probability threshold of 0.5:<pre>from sagemaker.clarify import ModelPredictedLabelConfig
predictions_config = <strong class="bold">ModelPredictedLabelConfig</strong>(
    <strong class="bold">probability_threshold</strong>=<strong class="bold">0.5</strong>
)</pre><p>根据预测值，为probability_threshold参数指定的值用于选择<a id="_idIndexMarker1439"/>二进制标签。例如，<a id="_idTextAnchor708"/>如果预测值为0.4，那么<a id="_idIndexMarker1440"/>由于0.4小于0.5，预测值将被设置为0。</p></li>
				<li>Initialize the BiasConfig object:<pre>from sagemaker.clarify import BiasConfig
bias_config = <strong class="bold">BiasConfig</strong>(
    <strong class="bold">label_values_or_threshold</strong>=[<strong class="bold">1</strong>],              
    <strong class="bold">facet_name</strong>='<strong class="bold">sex</strong>'                             
)</pre><p>请注意，这种配置目前可能没有意义！不过不要担心，我们将在<em class="italic">工作原理……</em>部分详细讨论这些值。</p></li>
				<li>Call the run_post_training_bias() function and use the configuration objects we initialized in the previous steps as the parameter values:<pre>%%time
processor.<strong class="bold">run_post_training_bias</strong>(
    data_config=data_config, 
    data_bias_config=bias_config,
    methods=<strong class="bold">['DPPL', 'RD']</strong>,
    model_config=model_config,
    model_predicted_label_config=predictions_config
)</pre><p>这里，我们已经配置了培训后偏差检测作业，将重点放在DPPL和研发上。如果您想知道这些是什么，不要担心-我们将在<em class="italic">它如何工作……</em>部分详细解释这些。</p><p class="callout-heading">注意</p><p class="callout">完成此步骤大约需要10到15分钟。在等待的时候，请随意喝杯咖啡或茶！</p></li>
				<li>将加工作业输出文件的S3 <a id="_idIndexMarker1441"/>位置存储在输出<a id="_idTextAnchor710"/>_目的变量:<pre>output = processor.latest_job.outputs[0] output_destination = output.destination</pre></li>
				<li>Download <a id="_idIndexMarker1442"/>and inspect the analysis.json file that was generated by the <strong class="bold">SageMaker Clarify</strong> processing job:<pre>!aws s3 cp {output_destination}/ tmp/ --recursive
!cat tmp/<strong class="bold">analysis.json</strong></pre><p>这将为我们提供一个嵌套结构，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_07_11.jpg" alt="Figure 7.11 – Post-training bias metric values for DDPL and RD&#13;&#10;" width="704" height="569"/></div><p class="figure-caption">图7.11-DDPL和研发的训练后偏差度量值</p><p>这里我们可以<a id="_idIndexMarker1443"/>看到<strong class="bold">预测标签正比例差异</strong> ( <strong class="bold"> DDPL </strong>)度量值为-0.33541395157418197，而<strong class="bold">召回差异</strong> ( <strong class="bold"> RD </strong>)度量值为0.0。如果您<a id="_idIndexMarker1444"/>想知道这些值<a id="_idIndexMarker1445"/>是什么意思，不要担心——我们将在<em class="italic">它是如何工作的……</em>部分讨论这个问题！</p></li>
				<li>Finally, use <a id="_idIndexMarker1446"/>the %store magic to store the variable value for model_name:<pre>%store <strong class="bold">model_name</strong></pre><p>我们将在使用SageMaker Clarify 配方的<em class="italic">中使用该值。</em></p></li>
			</ol>
			<p>让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-312"><a id="_idTextAnchor712"/>工作原理……</h2>
			<p><strong class="bold"> SageMaker Clarify </strong>让<a id="_idIndexMarker1447"/>使用<strong class="bold"> SageMaker Processing </strong>来运行一个评估数据的任务。在这种情况下，我们指定了<a id="_idIndexMarker1448"/>，我们希望<a id="_idIndexMarker1449"/>只从一个更大的<a id="_idIndexMarker1450"/>训练后偏差指标列表中获取<strong class="bold"> DPPL </strong>和<strong class="bold"> RD </strong>指标。<a id="_idTextAnchor713"/> <a id="_idTextAnchor714"/>除了<a id="_idIndexMarker1451"/>这些指标，我们还可以使用<strong class="bold"> SageMaker Clarify </strong>计算其他<a id="_idIndexMarker1452"/>偏差指标<a id="_idIndexMarker1453"/>。其中包括<strong class="bold">全异影响</strong> ( <strong class="bold">迪</strong>)<strong class="bold">有条件接受差异</strong>(<strong class="bold">DCA</strong>)<strong class="bold">有条件拒绝差异</strong>(<strong class="bold">DCR</strong>)<strong class="bold">接受率差异</strong>(<strong class="bold">DAR</strong>)<strong class="bold">拒绝率差异</strong>(<strong class="bold">DRR</strong>)<strong class="bold">准确度差异这些<a id="_idIndexMarker1454"/>度量值<a id="_idIndexMarker1455"/>有助于量化<a id="_idIndexMarker1456"/>并检测模型和数据偏差:</strong></p>
			<div><div><img src="img/B16850_07_12.jpg" alt="Figure 7.12 – How to interpret the DPPL metric score&#13;&#10;" width="688" height="518"/>
				</div>
			</div>
			<p class="figure-caption">图7.12-如何解释DPPL指标得分</p>
			<p>那么，我们如何<a id="_idIndexMarker1457"/>解释上图中显示的内容呢？正的<strong class="bold"> DPPL </strong>值，例如0.335414，意味着对于给定的数值(例如1)，性别方面具有相对较高的预测可能结果比例。这意味着在奖学金申请方面，男性的批准率高于女性。</p>
			<p>另一方面，<strong class="bold"> RD </strong>的值为0.0意味着在进行正确预测时，没有检测到对不受欢迎的群体<a id="_idIndexMarker1458"/>的偏见。由于<strong class="bold"> RD </strong>的公式涉及两个相关组的真实阳性率的差异(例如，TPR(a) - TPR(b))，值0.0表示模型对两个组具有相等的真实阳性率。这意味着该模型对于男性和女性都有同样的机会做出正确的预测。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">有关训练数据的<a id="_idIndexMarker1459"/>后处理偏差度量的更多信息，请随意查看这里的白皮书:<a href="https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf">https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf</a>。</p>
			<h1 id="_idParaDest-313"><a id="_idTextAnchor715"/>使用SageMaker Clarify启用ML可解释性</h1>
			<p>在前两个食谱中，我们使用<strong class="bold"> SageMaker Clarify </strong>来检测训练前和训练后的偏差。在这个食谱中，我们将仔细研究ML可解释性，以及如何使用<strong class="bold"> SageMaker Clarify </strong>生成ML可解释性报告。</p>
			<p>当我们处理伦理和法律问题时，我们会看到ML可解释性的重要性。例如，客户将希望更好地了解他们的信息如何被机器学习系统用来执行推荐或预测。除此之外，ML explainability使数据科学家和机器学习从业者能够做出更准确和公平的模型。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">区分<strong class="bold">模型可解释性</strong>和<strong class="bold">模型可解释性</strong>是很重要的。<strong class="bold">模型可解释性</strong>专注于理解机器学习模型内部在做什么。另一方面，<strong class="bold">模型可解释性</strong>涉及理解机器学习模型如何使用人类术语中的某些特征值来执行预测。</p>
			<p>有了<strong class="bold"> SageMaker Clarify </strong>，我们将能够自动<a id="_idTextAnchor716"/>计算SHAP值，这有助于我们<a id="_idIndexMarker1462"/>确定与模型做出的预测相关的每个特征的重要性。</p>
			<h2 id="_idParaDest-314"><a id="_idTextAnchor718"/>做好准备</h2>
			<p>该配方<a id="_idIndexMarker1463"/>延续了<em class="italic">中的<a id="_idTextAnchor719"/>使用SageMaker Clarify </em>配方检测训练后偏差。</p>
			<h2 id="_idParaDest-315"><a id="_idTextAnchor720"/>怎么做……</h2>
			<p>该配方的步骤如下:</p>
			<ol>
				<li value="1">在my-experiments/chapter07目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为该食谱的名称(使用SageMaker Clarify启用ML explainability)。当提示使用内核时，选择Python 3(数据科学)。</li>
				<li>使用%store magic加载s3_bucket_name、prefix、training_data_path、test_data_path和model <a id="_idTextAnchor721"/> _name: <pre>%store -r <strong class="bold">s3_bucket_name</strong> %store -r <strong class="bold">prefix</strong> %store -r <strong class="bold">training_data_path</strong> %store -r <strong class="bold">test_data_path</strong> %store -r <strong class="bold">model_name</strong></pre>的变量值</li>
				<li>从<strong class="bold">SageMaker Python<a id="_idTextAnchor722"/>SDK</strong>:<pre>import sagemaker session = sagemaker.Session() region = session.boto_region_name role = sagemaker.get_execution_role()</pre>中导入、准备和加载一些先决条件，比如会话、区域和角色</li>
				<li>准备<a id="_idIndexMarker1464"/>S3目标路径:<pre><strong class="bold">s3_training<a id="_idTextAnchor723"/>_data_path</strong> = training_data_path <strong class="bold">s3_test_data_path</strong> = test_data_path <strong class="bold">s3_output_path</strong> = f"s3://{s3_bucket_name}/{prefix}/output"</pre></li>
				<li>使用<strong class="bold"> AWS CLI </strong>复制包含训练<a id="_idTextAnchor724"/> ing和测试集:<pre>!aws s3 cp {s3_training_data_path} tmp/<strong class="bold">training_data.csv</strong> !aws s3 cp {s3_test_data_path} tmp/<strong class="bold">test_data.csv</strong></pre>的CSV文件</li>
				<li>Load the <a id="_idIndexMarker1465"/>training and test datasets and then generate the features CSV file:<pre>import pandas as pd
<strong class="bold">training_data</strong> = pd.read_csv("tmp/<strong class="bold">training_data.csv</strong>")
<strong class="bold">test_data</strong> = pd.read_csv("tmp/<strong class="bold">test_data.csv</strong>")
target = test_data['<strong class="bold">approved</strong>']
<strong class="bold">features</strong> = test_data.<strong class="bold">drop</strong>(columns=['<strong class="bold">approved</strong>'])
features.to_csv('tmp/<strong class="bold">test_features.csv</strong>', 
                index=False, 
                header=F<a id="_idTextAnchor725"/><a id="_idTextAnchor726"/><a id="_idTextAnchor727"/>alse)</pre><p>请注意，我们使用测试数据集减去批准的列作为test_features.csv文件的数据源。</p></li>
				<li>将test_features.csv文件复制到亚马逊S3存储桶:<pre>base = f"s3://{s3_<a id="_idTextAnchor728"/>bucket_name}/{prefix}/input" s3_feature_path = f"{base}/<strong class="bold">test_features.csv</strong>" !aws s3 cp tmp/<strong class="bold">test_features.csv</strong> {s3_feature_path}</pre></li>
				<li>初始化ModelConfig对象并指定model_name参数值。注意<a id="_idIndexMarker1466"/>在运行下面几行代码之前，必须已经存在一个同名的模型。如果您已经使用了<em class="italic">使用SageMaker Clarify </em>方法检测训练后偏差中的create_model()函数，那么我们运行下一组指令将不会有任何问题。否则，确保你从一个已完成的培训工作中找到并得到一个符合这个食谱的模特的名字:<pre>from sagemaker.clarify import ModelConfig model_config<a id="_idTextAnchor729"/> = <strong class="bold">ModelConfig</strong>(     model_name=<strong class="bold">model_name</strong>,     instance_type='ml.c5.xlarge',     instance_count=1,     accept_type='text/csv' )</pre></li>
				<li>初始化SageMakerClarifyProcessor对象:<pre>from sagemaker.clarify import SageMakerClarifyProcessor processor = <strong class="bold">S<a id="_idTextAnchor730"/>ageMakerClarifyProcessor</strong>(     role=role,     instance_count=1,     instance_type='ml.m5.large',     sagemaker_session=session )</pre></li>
				<li>Prepare the baseline variabl<a id="_idTextAnchor731"/>e:<pre><strong class="bold">baseline = features.iloc[0:200].values.tolist()</strong></pre><p>这里，我们<a id="_idIndexMarker1468"/>使用特征数据帧中的200条记录作为基线。</p></li>
				<li>Initialize the SHAPConfig object and pass the baseline as one of the parameter <a id="_idIndexMarker1469"/>values. Specify the number of samples and the aggregation method for the global SHAP values:<pre>from sagemaker.clarify import SHAPConfig
shap_config = <strong class="bold">SHAPConfig</strong>(
    baseline=baseline,
    num_samples=50,
    agg_method='median'
)</pre><p>agg_method参数有三个可能的值–mean _ ab<a id="_idTextAnchor732"/>s、median和mean_sq。该配置参数简单地告诉训练作业它如何聚集和累加SHAP值。</p></li>
				<li>准备s3 _输出_路径。一旦处理工作完成，输出文件将存储在S3输出路径:<pre>headers = training_data.columns.to_list()</pre></li>
				<li>初始化DataConfig对象。使用我们在上一步中准备和初始化的变量和对象作为这个初始化步骤的参数:<pre>from sagemaker.clarify import DataConfig data_config = <strong class="bold">DataConfig</strong>(     s3_data_input_path=s<a id="_idTextAnchor734"/>3_training_data_path,     s3_output_path=s3_output_path,     label='<strong class="bold">approved</strong>',     headers=headers,     dataset_type='text/csv' )</pre></li>
				<li>Call the run_explainability() function and pass the data_config, model_config, and shap_config variable values when calling the function. This step <a id="_idIndexMarker1470"/>should about 12 to 18 minutes to complete:<pre>%%time
processor.<strong class="bold">run_explainability</strong>(
    data_config=data_config,       
    model_config=model_config,             
    explainability_config=shap_config
)</pre><p>这应该会产生一组日志，类似于下面的截图所示:</p></li>
			</ol>
			<div><div><img src="img/B16850_07_13.jpg" alt="Figure 7.13 – Logs after calling the run_explainability() function&#13;&#10;" width="627" height="344"/>
				</div>
			</div>
			<p class="figure-caption">图7.13–调用run _ explainability()函数后的日志</p>
			<p>在这里，我们可以从我们的预测列表中看到，性、科学和技术具有最高的SHAP值。鉴于SHAP值量化了每个预测者<a id="_idTextAnchor735"/> <a id="_idTextAnchor736"/> <a id="_idTextAnchor737"/> r获得<a id="_idIndexMarker1473"/>批准与否的贡献，我们可以说，基于它们的SHAP值，性、科学和技术是最重要的特征。</p>
			<p>让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-316"><a id="_idTextAnchor738"/>工作原理…</h2>
			<p>有时，模型具有良好的预测性能是不够的。在这个菜谱中，我们使用<strong class="bold"> SageMaker Clarify </strong>来生成一个有助于解释模型的报告。<strong class="bold"> SageMaker Clarify </strong>使用<strong class="bold"> Shapley值</strong>来解释机器学习模型，并提供关于<a id="_idIndexMarker1474"/>数据集中每个特征重要性的细节。进行预测时，每个特性的重要性映射到特性对目标值的相对<a id="_idIndexMarker1475"/>贡献。</p>
			<p>这个食谱可以分为六个主要部分:</p>
			<ol>
				<li value="1">正在初始化SageMakerClarifyProcessor对象</li>
				<li>初始化配置对象</li>
				<li>创建基线</li>
				<li>正在初始化SHAPConfig对象</li>
				<li>调用run _ explainability()函数</li>
				<li>检查结果</li>
			</ol>
			<p>一旦加工工作接近尾声<em class="italic">该怎么做...</em>部分，我们得到了全局SHAP值，如前面的截图所示。鉴于SHAP值量化了每个预测器对预测目标标签的边际贡献，这意味着预测器的SHAP值越高，其对<a id="_idIndexMarker1476"/>预测目标标签的贡献就越大。也就是说，我们可以看到数学、随机1和随机2的特征没有性别、科学和技术特征<a id="_idIndexMarker1477"/>重要，正如它们的分数所表明的那样。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">如果您还记得我们如何在<em class="italic">生成合成数据集并使用SageMaker功能存储进行存储和管理</em>的方法中生成合成数据集，random1和random2列实际上对预测目标标签没有帮助。这意味着，如果我们更改random1和random2的值，与更改性别、科学和技术的值相比，这一组更改很可能不会显著影响批准的目标标签的值。</p>
			<h1 id="_idParaDest-317"><a id="_idTextAnchor739"/>从模型部署端点，并使用SageMaker模型监视器实现数据捕获</h1>
			<p>在这个配方中，我们将把我们在使用SageMaker Clarify 配方的<em class="italic">检测训练后偏差中训练的<a id="_idIndexMarker1478"/>模型部署到一个推理端点。我们<a id="_idIndexMarker1479"/>必须意识到，机器<a id="_idIndexMarker1480"/>的学习过程并没有在<a id="_idIndexMarker1481"/>一个模型被部署到生产之后结束。只有当部署的模型接触到更多以前没有见过的<a id="_idIndexMarker1483"/>数据时，我们才能知道它的真实性能。也就是说，我们必须在调用推理端点时捕获请求和响应对。这使我们能够分析在<a id="_idIndexMarker1484"/>部署的模型中是否有问题，或者在作为有效负载传递给推理端点的数据中是否有问题。</em></p>
			<p>使用<strong class="bold"> Amazon SageMaker </strong>的好处在于我们不必自己构建，因为这些挑战和潜在问题已经可以使用<strong class="bold"> SageMaker模型监视器</strong>解决和处理。最后，我们将演示如何使用<strong class="bold">的<a id="_idTextAnchor740"/> ageMaker特性商店</strong>在线商店，在模型已经被部署<a id="_idTextAnchor741"/>并且数据捕获已经被启用之后，提取测试记录进行推断。</p>
			<h2 id="_idParaDest-318">正在准备中</h2>
			<p>该配方延续了<em class="italic">用SageMaker Clarify </em>配方实现ML解释。</p>
			<h2 id="_idParaDest-319"><a id="_idTextAnchor743"/>怎么做……</h2>
			<p>在第一个步骤中，我们将重点部署我们在<em class="italic">中创建的模型，使用SageMaker Clarify </em>方法检测训练后偏差。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter07目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为这个配方的名称(从一个模型部署一个端点，并使用SageMaker Model Monitor启用数据捕获)。当提示使用内核时，选择Python 3(数据科学)。</li>
				<li>从<a id="_idTextAnchor745"/>的<strong class="bold">SageMaker Python SDK</strong>:<pre>import sagemaker <strong class="bold">session</strong> = sagemaker.Session() <strong class="bold">region</strong> = ses<a id="_idTextAnchor746"/>sion.boto_region_name <strong class="bold">role</strong> = sagemaker.get_execution_role()</pre>中导入、准备和加载一些先决条件，比如会话、区域和角色</li>
				<li>使用%store magic <a id="_idIndexMarker1486"/>来lo<a id="_idTextAnchor747"/>ad model _ name:<pre>%store -r <strong class="bold">model_name</strong></pre>的变量值</li>
				<li>初始化<a id="_idIndexMarker1487"/>Sagemaker boto 3客户端:<pre>import boto3 client = boto3.cl<a id="_idTextAnchor748"/>ient('sagemaker')</pre></li>
				<li>使用<a id="_idIndexMarker1488"/>describe _ model()函数加载模型的细节:<pre>response = client.<strong class="bold">describe_model</strong>(     ModelName=<strong class="bold">m<a id="_idTextAnchor749"/>odel_name</strong> )</pre></li>
				<li>从得到的嵌套响应字典值中提取<a id="_idIndexMarker1489"/>容器图像URI:<pre>container = response['<strong class="bold">PrimaryContainer</strong>']['<strong class="bold">Image</strong>']</pre></li>
				<li>从得到的嵌套响应字典值中提取<a id="_idTextAnchor750"/>模型数据URL:<pre>container = response['<strong class="bold">PrimaryContainer</strong>'] model_data = container['<strong class="bold">ModelDataUrl</strong>']</pre></li>
				<li>Initialize the Model object and use the model_name, container, model_data, role, and session variables as the arguments when initializing the Model object:<pre>model = sagemaker.model.<strong class="bold">Model</strong>(
    name=<strong class="bold">model_name</strong>,
    image_uri=<strong class="bold">container</strong>,
    model_data=<strong class="bold">model_data</strong>,
    role=role,
    sagemaker_session=session
)</pre><p class="callout-heading">注意</p><p class="callout">我们还可以加上predictor_cls=sagemaker。初始化sagemaker.model.Model时的Predictor .这将使下一步<a id="_idTextAnchor751"/>中的model.deploy()函数调用返回一个Predictor对象。这将允许我们跳过使用model.endpoint_name值单独初始化预测器对象的步骤。</p></li>
				<li>Deploy the <a id="_idIndexMarker1490"/>model using the deploy() function. Wait a few minut<a id="_idTextAnchor752"/>es for the model to be deployed <a id="_idIndexMarker1491"/>into an inference endpoint:<pre>%%time
model.<strong class="bold">deploy</strong>(
    initial_instance_count = 1, 
    instance_type = 'ml.m5.large'
)</pre><p>如果您想知道我们在这里部署的是什么<a id="_idIndexMarker1492"/>型号，我们将部署我们在<em class="italic">检测培训后bi <a id="_idTextAnchor753"/>中培训的<strong class="bold"> XGBoost </strong>型号<a id="_idIndexMarker1493"/>与SageMaker Clarify </em>配方一样。</p><p class="callout-heading">注意</p><p class="callout">完成此步骤大约需要7到15分钟。在等待的时候，请随意喝杯咖啡或茶！</p></li>
				<li>Initialize <a id="_idIndexMarker1494"/>the Predictor object by specifying the endpoint name from t<a id="_idTextAnchor754"/>he previous step as the parameter value for endpoint_name:<pre>from sagemaker import Predictor
predictor = <strong class="bold">Predictor</strong>(
    endpoint_name=<strong class="bold">model.endpoint_name</strong>
)</pre><p>下一组步骤<a id="_idIndexMarker1495"/>集中在从在线特征存储中加载记录，然后使用加载的数据作为有效负载来测试已经部署的推理端点:</p></li>
				<li>确保一些<a id="_idIndexMarker1496"/>变量值，比如s3_bucket_name、prefix和s3_capture_upload_path已经准备好:<pre>%store -r <strong class="bold">s3_bucket_name</strong> %store -r <strong class="bold">prefix</strong> base = f"s3://{s3_bucket_name}/{prefix}" <strong class="bold">s3_capture_upload_path</strong> = f"{base}/model-monitor"</pre></li>
				<li>初始化DataCaptureConfig对象并对其进行配置，以便它在端点调用期间捕获100%的<a id="_idIndexMarker1497"/>请求和响应对:<pre>from sagemaker.model_monitor import DataCaptureConfig data_capture_config = DataCaptureConfig(     enable_capture = True,     sampling_percentage=100,     destination_s3_uri=s3_capture_upload_path,     kms_key_id=None,     capture_options=["REQUEST", "RESPONSE"],     csv_content_types=["text/csv"],     json_content_types=["application/json"] )</pre></li>
				<li>Use the update_data_capture_config() function to enable data capture in <a id="_idIndexMarker1498"/>our inference endpoint:<pre>%%time
predictor.<strong class="bold">update_data_capture_config</strong>(
    data_capture_config=data_capture_config
)</pre><p>这应该需要<a id="_idIndexMarker1499"/>大约7到10分钟才能完成。</p><p>现在<a id="_idTextAnchor755"/>我们已经<a id="_idIndexMarker1500"/>部署了模型并启用了数据捕获，我们将从在线商店获取一条记录，并使用它作为有效负载来测试<a id="_idIndexMarker1501"/>推断端点:</p></li>
				<li>初始化boto_session和运行时变量</li>
				<li>Get one of <a id="_idIndexMarker1502"/>the records inside <a id="_idIndexMarker1503"/>the online feature store using the get_record() function:<pre>feature_group_name = 'cookbook-feature-group'
record_response = runtime.<strong class="bold">get_record</strong>(
    FeatureGroupName=feature_group_name, 
    RecordIdentifierValueAsString="<strong class="bold">950</strong>"
)</pre><p>这里，我们利用了我们在本章开始的<em class="italic">中创建的特征库生成合成数据集，并使用SageMaker特征库进行存储和管理</em>。</p><p class="callout-heading">注意</p><p class="callout">当使用<strong class="bold"> SageMaker特征库</strong>时，我们需要为写入、读取和存储特征库中的数据付费。作为免费层的一部分，当使用<strong class="bold"> SageMaker功能库</strong>时，我们可以免费使用1000万个写单元、1000万个读单元和25 GB的st <a id="_idTextAnchor758"/>存储空间。更多信息，请随时查看定价页面:<a href="https://aws.amazon.com/sagemaker/pricing/">https://aws.amazon.com/sagemaker/pricing/</a>。</p></li>
				<li>Inspect the record_response structure and internal values:<pre>record_response['Record']</pre><p>这应该<a id="_idIndexMarker1504"/>给我们一个类似于<a id="_idTextAnchor759"/>的结构，下面截图中的<a id="_idIndexMarker1505"/>是什么:</p><div><img src="img/B16850_07_14.jpg" alt="Figure 7.14 – Value of record_response['Record']&#13;&#10;" width="517" height="161"/></div><p class="figure-caption">图7.14-记录响应['记录']的值</p><p>在这里，我们可以看到存储在功能组中的记录。</p></li>
				<li>Extract the <a id="_idIndexMarker1506"/>values from the record_response nested dictionary and store the feature values inside the test_record_list list. Note that we will not include the value of the approved variable <a id="_idIndexMarker1507"/>as we will only be needing the values of the predictor columns – sex, math, science, technology, random1, and random2 – when testing the inference endpoint:<pre><strong class="bold">test_record_list</strong> = [
    record_response['Record'][1]['ValueAsString'],
    record_response['Record'][2]['ValueAsString'],
    record_response['Record'][3]['ValueAsString'],
    record_response['Record'][4]['ValueAsString'],
    record_response['Record'][5][<a id="_idTextAnchor760"/>'ValueAsString'],
    record_response['Record'][6]['ValueAsString'],
]
test_record_list</pre><p>我们应该<a id="_idIndexMarker1508"/>得到一个类似于['1 '，' 92 '，' 83 '，' 86 '，' 96 '，' 67']的输出值。</p></li>
				<li>Once we have the test_record_list list ready, we must prepare the csv_input s<a id="_idTextAnchor761"/>tring <a id="_idIndexMarker1509"/>value by joining the elements of test_record_list:<pre>csv_input = ','.join(<strong class="bold">test_record_list</strong>)
csv_input</pre><p>我们应该得到类似于“1，92，83，86，96，67”的输出值。</p></li>
				<li>更新预测器对象的序列化程序和反序列化程序属性:<pre>from sagemaker.d<a id="_idTextAnchor762"/>eserializers import JSONDeserializer from sagemaker.serializers import CSVSerializer predictor.serializer = CSV<a id="_idTextAnchor763"/>Serializer() predictor.deserializer = JSONDeserializer()</pre></li>
				<li>使用predict()函数<a id="_idIndexMarker1510"/>并检查推理端点是否按预期工作:<pre>predictor.<strong class="bold">predict</strong>(csv_input)</pre></li>
				<li>Use the %store magic to store the variable values for endpoint_name and csv_input:<pre>endpoint_name = predictor.endpoint_name
%store <strong class="bold">endpoint_name</strong>
%store <strong class="bold">csv_input</strong></pre><p>此时，<a id="_idIndexMarker1511"/>请求和响应对数据应该被记录并存储在S3桶中。这是因为<a id="_idIndexMarker1512"/>在<a id="_idIndexMarker1513"/>执行测试预测之前，我们用<strong class="bold">模型监视器</strong> be <a id="_idTextAnchor764"/>启用了数据捕捉。</p><p class="callout-heading">重要说明</p><p class="callout">暂时不要删除这个端点，因为我们将在下一个配方中使用它。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-320"><a id="_idTextAnchor765"/>工作原理……</h2>
			<p>在<a id="_idTextAnchor766"/>这个配方中，我们利用<a id="_idIndexMarker1514"/>SageMaker的几个功能<a id="_idIndexMarker1515"/>，比如<strong class="bold"> SageMaker模型监视器</strong>和<strong class="bold">ageMaker特征库</strong>，来完成我们需要做的事情。这样，我们可以将这个食谱分成三个主要部分:</p>
			<ol>
				<li value="1">使用模型对象的deploy()函数将现有模型部署到推理端点</li>
				<li>使用<strong class="bold"> SageMaker型号监视器</strong>启用数据采集</li>
				<li>使用predict()函数时，使用在线要素存储中的记录作为有效负载</li>
			</ol>
			<p>在<em class="italic">使用SageMaker Clarify </em>方法检测训练后偏差中，我们使用create_model()函数创建了模型实体。在这个菜谱中，我们用名称、容器图像和使用describe_model()函数获得的模型数据初始化了一个模型对象。接下来，我们使用deploy()函数将模型<a id="_idIndexMarker1516"/>部署到推理端点中。</p>
			<p>在部署步骤之后，我们配置了一个DataCaptureConfig对象来在端点调用期间捕获100%的请求-响应<a id="_idIndexMarker1517"/>对。然后，我们使用update_data_capture_config()函数将这个配置应用到现有的推理端点。走向后面的部分<em class="italic">怎么做...</em>部分，我们将<strong class="bold"> SageMaker FeatureStore运行时客户端</strong>与boto3一起使用，从在线功能商店加载单个记录。最后，在使用predict()函数时，我们将该记录用作有效负载。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">为什么不用线下商店呢？离线存储旨在加载用于模型定型和批量预测的数据。使用在线商店更适合这个用例，因为它被设计为支持低毫秒延迟读取。</p>
			<p>由于我们已经在这个配方中启用了数据捕获，我们希望在初始化DataCaptureConfig对象时，我们在destination_s3_uri参数中指定的S3上传路径将包含捕获的请求和响应对，类似于下面的屏幕截图中显示的<a id="_idIndexMarker1518"/>:</p>
			<div><div><img src="img/B16850_07_15.jpg" alt="Figure 7.15 – Captured data downloaded from the S3 upload path&#13;&#10;" width="790" height="246"/>
				</div>
			</div>
			<p class="figure-caption">图7.15–从S3上传路径下载的捕获数据</p>
			<p>在这里，我们可以看到在调用predict()函数时用作有效负载的记录在S3上传路径中存储了它的对应jsonl文件。也就是说，随着我们更多地尝试调用端点，S3上传路径将包含更多的jsonl文件。当然，收集<a id="_idIndexMarker1520"/>请求和响应对只是第一步，因为这些可以用来自动<a id="_idIndexMarker1521"/>使用<strong class="bold"> SageMaker模型监视器</strong>检测不同的问题和违规。也就是说，让我们继续下一个食谱吧！</p>
			<h1 id="_idParaDest-321"><a id="_idTextAnchor768"/>使用SageMaker模型监控器进行基线和计划监控</h1>
			<p>在<a id="_idIndexMarker1522"/>之前的配方中，我们使用<strong class="bold"> SageMaker模型监视器</strong>将模型部署到推理<a id="_idIndexMarker1523"/>端点和<a id="_idIndexMarker1524"/>启用数据捕获。这允许我们在推断过程中调用<a id="_idIndexMarker1525"/>端点时收集请求和响应对。请注意，就我们可以用<strong class="bold"> SageMaker模型监视器</strong>做什么而言，我们只是触及了表面。使用<strong class="bold"> SageMaker型号监视器</strong>，我们还可以自动监视和检测以下问题:</p>
			<ul>
				<li>数据质量的漂移</li>
				<li>模型质量度量值的漂移</li>
				<li>预测期间的偏差漂移</li>
				<li>特征归因漂移</li>
			</ul>
			<p>这很重要<a id="_idIndexMarker1526"/>,因为在我们的模型被部署到生产中之后<a id="_idIndexMarker1527"/>会发生很多事情。</p>
			<p>在这个方案中，我们将<a id="_idIndexMarker1528"/>集中精力检测<strong class="bold">数据质量漂移</strong>。我们将首先准备一个基线，然后创建一个调度的<a id="_idIndexMarker1529"/>监控作业，该作业处理由<strong class="bold">模型监控器</strong>捕获的<a id="_idTextAnchor769"/>数据，并输出汇总统计数据和违规报告。这将帮助我们在生产环境中使用数据和模型时调试数据和模型中的问题。</p>
			<h2 id="_idParaDest-322"><a id="_idTextAnchor771"/>准备就绪</h2>
			<p>该方法上接<em class="italic">从模型部署端点，并使用SageMaker模型监视器</em>方法实现数据捕获。</p>
			<h2 id="_idParaDest-323"><a id="_idTextAnchor772"/>怎么做……</h2>
			<p>该方法中的第一组步骤集中于运行<strong class="bold">模型监视器</strong>基线作业，以生成建议的约束配置，以及基线统计报告。让我们开始吧:</p>
			<ol>
				<li value="1">使用my-experiments/chapter07目录中的<a id="_idTextAnchor773"/> Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为该配方的名称(使用SageMaker Model Monitor进行基线和预定监控)。</li>
				<li>使用%store魔术加载s3_bucket_name和prefix的变量值。之后，准备存储在baseline_data_uri和baseline_results_uri变量中的S3路径:<pre>%store -r <strong class="bold">s3_bucket_name</strong> %store -r <strong class="bold">prefix</strong> base = f's3://{<strong class="bold">s3_bucket_name</strong>}/{<strong class="bold">prefix</strong>}' <strong class="bold">baseline_data_uri</strong> = f'{base}/input/training_data.csv' <strong class="bold">baseline_results_uri</strong> = f"{base}/model-monitor/baseline-results"</pre></li>
				<li>加载包含<a id="_idIndexMarker1531"/>基线<a id="_idIndexMarker1532"/>数据:<pre><strong class="bold">local_file</strong> = "<strong class="bold">tmp/baseline.csv</strong>" !<strong class="bold">aws s3 cp</strong> {<strong class="bold">baseline_data_uri</strong>} {<strong class="bold">local_file</strong>} import pandas as pd baseline_df = pd.read_csv(<strong class="bold">local_file</strong>)</pre>的CSV文件的<a id="_idIndexMarker1530"/> c <a id="_idTextAnchor774"/>内容</li>
				<li>初始化<a id="_idIndexMarker1533"/>DefaultModelMonitor对象:<pre>import sagemaker <strong class="bold">role</strong> = sagemaker.get_execution_role() from sagemaker.model_monitor impor<a id="_idTextAnchor775"/>t<a id="_idTextAnchor776"/> <strong class="bold">DefaultModelMonitor</strong> default_monitor = <strong class="bold">DefaultModelMonitor</strong>(     role=<strong class="bold">role</strong>,     instance_count=1,     instance_type='ml.m5.large',     volume_size_in_gb=20,     max_runtime_in_seconds=3600, )</pre></li>
				<li>Run the <strong class="bold">Model Monitor</strong> baselining job using the suggest_baseline() function. We are using the baseline_data_uri and baseline_results_uri variables we prepared in the previous steps as the parameter <a id="_idIndexMarker1534"/>values for baseline_dataset and output_s3_uri, respectively, when <a id="_idIndexMarker1535"/>calling the suggest_baseline() function:<pre>%%time
from sagemaker.model_monitor import dataset_format
<strong class="bold">dsf</strong> = dataset<a id="_idTextAnchor777"/>_format.DatasetFormat.csv(header=True)
<strong class="bold">default_monitor</strong>.<strong class="bold">suggest_baseline</strong>(
    baseline_dataset=<strong class="bold">baseline_data_uri</strong>,
    dataset_format=<strong class="bold">dsf</strong>,
    output_s3_uri=<strong class="bold">baseline_results_uri</strong>,
    wait=True
)</pre><p>当<a id="_idIndexMarker1536"/>调用suggest_baseline()函数时，<strong class="bold"> SageMaker处理</strong>作业<a id="_idIndexMarker1537"/>使用sage maker-model-monitor<a id="_idTextAnchor778"/>-<a id="_idTextAnchor779"/>分析器容器，该容器创建基线并建议约束。</p><p class="callout-heading">注意</p><p class="callout">完成此步骤大约需要5到7分钟。在等待的时候，请随意喝杯咖啡或茶！</p></li>
				<li>Use the baseline_statistics() function of the DefaultModelMonitor object and the json_normalize() function from pandas to inspect <a id="_idTextAnchor780"/>the baseline statistics generated by the baselining job:<pre>baseline_job = default_monitor.latest_baselining_job
stats = baseline_job.<strong class="bold">baseline_statistics</strong>()
schema_dict = stats.body_dict["features"]
     
import pandas as pd
schema_df = pd.<strong class="bold">json_normalize</strong>(schema_dict)
schema_df.head(5)</pre><p>这应该<a id="_idIndexMarker1538"/>给我们一个<a id="_idIndexMarker1539"/>值的数据框架，类似于下面的截图所示:</p><div><img src="img/B16850_07_16.jpg" alt="Figure 7.16 – Value schema_df&#13;&#10;" width="859" height="239"/></div><p class="figure-caption">图7.16–值模式_df</p><p>这里，我们<a id="_idTextAnchor781"/>有<a id="_idIndexMarker1540"/>模式字典<a id="_idIndexMarker1541"/>和基线统计。我们能够使用json_normalize()函数将包含基线统计信息的字典结果转换成数据帧。</p></li>
				<li>Use the suggested_constraints() function to get the suggested constraints. Then, use the json<a id="_idTextAnchor782"/>_normalize() function from pandas to convert the dictionary results into a DataFrame as well:<pre>constraints = baseline_job.<strong class="bold">suggested_constraints</strong>()
constraints_dict = constraints.body_dict["features"]
constraints_df = pd.<strong class="bold">json_normalize</strong>(constraints_dict)
constraints_df.head(7)</pre><p>这将为我们提供一个值的数据框架，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_07_17.jpg" alt="Figure 7.17 – Value of constraints_df&#13;&#10;" width="481" height="217"/></div><p class="figure-caption">图7.17–约束值_df</p><p>这里，我们有<a id="_idIndexMarker1542"/>一个包含建议约束的数据框架。我们可以看到，approved、sex、math、science、technology、random1和random2特性的Integral是它们的extruded _ type值。这意味着基准作业<a id="_idIndexMarker1543"/>检测到<a id="_idIndexMarker1544"/>使用的值来自<a id="_idTextAnchor783"/> <a id="_idTextAnchor784"/> <a id="_idTextAnchor785"/> <a id="_idTextAnchor786"/>中包含的基准CSV文件，是这些特性的整数值。稍后，我们将看到<a id="_idIndexMarker1545"/>我们基线中的这些建议约束值将如何用于检测<strong class="bold">模型监视器</strong>捕获的未来值是否有问题。</p><p>下一组步骤集中在调度一个监视作业，该作业检查约束冲突并生成统计报告:</p></li>
				<li>Define the generate_schedule_name() function, as shown in the following block of code. This function simply generates a random string for the name of the monitoring schedule. After that, use this function to generate the schedule name:<pre>import random
from string import ascii_uppercase
def <strong class="bold">generate_schedule_name</strong>():
    chars = random.ch<a id="_idTextAnchor787"/>oices(ascii_uppercase, k=5)
    output = 'schedule-' + ''.join(chars)
    return output
     
schedule_name = <strong class="bold">generate_schedule<a id="_idTextAnchor788"/>_name</strong>()</pre><p>这应该<a id="_idIndexMarker1546"/>生成一个格式<a id="_idIndexMarker1547"/>类似于‘schedule-KYTXY’的字符串。</p></li>
				<li>指定<a id="_idIndexMarker1548"/> S3目标报表路径，存储在s3_report_path变量:<pre>s3_report_path = f'{base}/report-path'</pre></li>
				<li>使用baseline_st <a id="_idTextAnchor789"/> atistics()函数加载<a id="_idIndexMarker1549"/>基线统计数据，并将其存储在baseline_stati <a id="_idTextAnchor790"/> stics变量中。将建议的约束值加载到约束变量中:<pre>baseline_statistics = default_monitor.<strong class="bold">baseline_statistics</strong>() constraints = default_monitor.<strong class="bold">suggested_constraints</strong>()</pre></li>
				<li>Prepare the cron_expression variable value:<pre>from sagemaker.model_monitor import CronExpressionGenerator
cron_expression = <strong class="bold">CronExpressionGenerator.hourly</strong>()
cron_expression</pre><p>我们应该得到一个输出equa <a id="_idTextAnchor791"/> l或者类似于' cron(0 *？* * *)'.在这里，我们计划使用这个值来配置我们稍后将调度的监视作业，以便我们可以每小时执行一次它的调度监视作业。</p></li>
				<li>Load the Predictor object by specifying the endpoint name from the <em class="italic">Deploying an endpoint from a model and enabling data capture with SageMaker Model Monitor</em> recipe:<pre>%store -r <strong class="bold">endpoint_name</strong>
from sagemaker import Predictor
predictor = <strong class="bold">Predictor</strong>(endpoint_name=<strong class="bold">endpoint_name</strong>)</pre><p>注意，这个<a id="_idIndexMarker1550"/>端点已经存在。我们在这里所做的全部<a id="_idIndexMarker1551"/>是使用端点名称将预测器对象附加到端点。</p></li>
				<li>Use the %store magic <a id="_idIndexMarker1553"/>to load the variable value for csv_input:<pre>%store -r <strong class="bold">csv_input</strong>
csv_input</pre><p>这应该给我们一个类似于“1，92，83，86，96，67”的值。</p></li>
				<li>使用上一步中的csv_input变量和预测器对象的predict()函数执行测试预测:<pre>from sagemaker.deserializers import JSONDeserializer from sagemaker.serializers import CSVSerializer predictor.serializer = CSVSerializer() predictor.deserializer = JSONDeserializer() predictor.<strong class="bold">predict</strong>(<strong class="bold">csv_input</strong>)</pre></li>
				<li>Inspect the constraints variable using the __dict__ attribute:<pre>constraints.<strong class="bold">__dict__</strong></pre><p>这将为我们提供一个嵌套的值字典，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_07_18.jpg" alt="Figure 7.18 – Suggested constraints stored inside the constraints variable&#13;&#10;" width="407" height="433"/></div><p class="figure-caption">图7.18–存储在约束变量中的建议约束</p><p>这里，我们有由<a id="_idIndexMarker1556"/>基线作业生成的<a id="_idIndexMarker1554"/>建议约束<a id="_idIndexMarker1555"/>。我们可以看到，要更改某个特性或字段的推断类型值，我们必须遍历<a id="_idIndexMarker1557"/>值的嵌套结构，我们将在下一步中看到。</p></li>
				<li>Next, we will override the inferred_type value from the suggested constraints using the following lines of code. Note that we need to use the save() function, similar to what is shown in the following block of code, to make sure this constraints configuration change is applied:<pre>constraints.body_dict['features'][0]['inferred_type'] = <strong class="bold">'Fractional'</strong>
constraints.<strong class="bold">save</strong>()</pre><p>这应该<a id="_idIndexMarker1558"/>返回一个类似于‘S3://&lt;S3 bucket name&gt;/chapter 07/model-monitor/baseline-results/constraints . JSON’的值。</p></li>
				<li>Use the create_monitoring_schedule() function:<pre>default_monitor.<strong class="bold">create_monitoring_schedule</strong>(
    monitor_schedule_name=schedule_name,
    endpo<a id="_idTextAnchor792"/><a id="_idTextAnchor793"/>int_input=predictor.endpoint,
    output_s3_uri=s3_report_path,
    statistics=<strong class="bold">baseline_statistics</strong>,
    constraints=<strong class="bold">constraints</strong>,
    schedule_cron_expression=<strong class="bold">cron_expression</strong>,
    enable_cloudwatch_metrics=True,
)</pre><p>这里，当调用create_monitoring_schedule()函数时，我们将在前面的步骤中准备的变量值(例如，baseline_statistics、constraints和cron_expression)作为参数值<a id="_idIndexMarker1560"/>传递给<a id="_idIndexMarker1559"/>。</p></li>
				<li>使用sleep()函数等待几分钟，此时正在创建监控计划<a id="_idIndexMarker1561"/>:<pre>from time import sleep <strong class="bold">sleep</strong>(300)</pre></li>
				<li>Define the perform_good_input() and perform_bad_input() functions:<pre>def <strong class="bold">perform_good_input</strong>():
    predictor.<strong class="bold">predict</strong>(csv_input)
    print("good input")
     
def <strong class="bold">perform_bad_input</strong>():
    csv_bad_input = '1,92,-83.3,86,-96,67'
    predictor.<strong class="bold">predict</strong>(csv_bad_input)
    print("bad input")</pre><p>在前面的<a id="_idIndexMarker1562"/>代码块中，我们可以<a id="_idIndexMarker1563"/>看到perform_bad_input()函数中使用的有效负载包含一个针对科学特性的负的<a id="_idIndexMarker1564"/>浮点值。我们预计稍后会看到该特性的违规报告，因为在<a id="_idIndexMarker1565"/>我们的约束配置中，我们已经指定端点接受的科学特性值应该是非负整数值。</p><p class="callout-heading">注意</p><p class="callout">逗号分隔值(“1，92，-83.3，86，-96，67”)映射到性别、数学、科学、技术、随机1和随机2要素。</p></li>
				<li>Next, get the latest constraint violations and monitoring statistics that were collected by <strong class="bold">Model Monitor</strong> using the latest_monitoring_constraint_violations() and latest_monitoring_statistics() functions, respectively:<pre>dm = default_monitor
gcv = dm.<strong class="bold">latest_monitoring_constraint_violations</strong>
lms = dm.<strong class="bold">latest_monitoring_statistics</strong>
monitoring_violations = gcv()
monitoring_statistics = lms()</pre><p>请注意，此时，monitoring_violations和monitoring_statistics的值将为None。这是因为它们只有在<a id="_idIndexMarker1566"/>用于收集监控违规和统计数据的预定处理任务已经<a id="_idIndexMarker1567"/>执行并完成后才会有值，这将在大约一个小时后发生。</p></li>
				<li>Wait until we <a id="_idIndexMarker1568"/>have data from <strong class="bold">Model Monitor</strong> using <a id="_idIndexMarker1569"/>the following block of code:<pre>%%time
from time import sleep
<strong class="bold">violations = monitoring_violations</strong>
while <strong class="bold">not</strong> <strong class="bold">violations</strong>:
    print("No executions yet. [Sleep - 5-min]")
    sleep(300)
    <strong class="bold">perform_good_input</strong>()
    <strong class="bold">perform_bad_input</strong>()
    try:
        <strong class="bold">violations</strong> = gcv()
    except:
        pass
    
print("Executions found!")</pre><p>这里，我们一直循环，直到使用latest _ monitoring _ constraint _ violations()函数得到一个违规报告。我们还在循环中调用perform_good_input()和perform_bad_input()函数，以便在执行计划的监视作业时有数据可以分析。</p><p class="callout-heading">重要说明</p><p class="callout">完成这一步大约需要一个小时。请随意阅读本食谱的<em class="italic">工作原理……</em>部分，甚至在等待的时候开始下一章！</p></li>
				<li>此时，<a id="_idIndexMarker1571"/>代码的前一个<a id="_idIndexMarker1570"/>块已经运行完毕，违例变量的值不再是None: <pre>violations = gcv()</pre></li>
				<li>使用<strong class="bold"> AWS CLI </strong> : <pre>!aws s3 cp {<strong class="bold">violations.file_s3_uri</strong>} tmp/<strong class="bold">violations.json</strong></pre>将<a id="_idIndexMarker1572"/>生成的关于约束<a id="_idIndexMarker1573"/>违反的报告从S3桶复制到tmp目录</li>
				<li>Inspect the constraint violations report:<pre>!cat tmp/<strong class="bold">violations.json</strong></pre><p>这应该会在字典中生成一个摘要报告，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_07_19.jpg" alt="Figure 7.19 – Violations report&#13;&#10;" width="721" height="143"/></div><p class="figure-caption">图7.19–违规报告</p><p>在这里，我们可以看到由<strong class="bold">模型监视器</strong>生成的违规报告。它检测到作为有效负载传递给<a id="_idIndexMarker1574"/>端点的科学字段值中的一个问题。在这种情况下，预期的数据类型应该是整数。我们使用perform_bad_input()函数传递了一个浮点值。</p></li>
				<li>Inspect the statistics report using the latest_monitoring_statistics() function. Note that the lms() function points to the latest_monitoring_statistics() function of the DefaultModelMonitor object:<pre>monitoring_statistics = lms()
monitoring_statistics.__dict__</pre><p>这将产生一个嵌套的值结构，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_07_20.jpg" alt="Figure 7.20 – Latest monitoring statistics&#13;&#10;" width="618" height="176"/></div><p class="figure-caption">图7.20–最新监控统计数据</p><p>在这里，我们可以<a id="_idIndexMarker1575"/>看到由<strong class="bold">模型监视器</strong>捕获的数据的监控统计的一个修剪版本<a id="_idIndexMarker1576"/>。使用这些<a id="_idIndexMarker1577"/>汇总统计数据中的值，我们将对已经捕获的请求-响应对中的值有一个更好的了解。</p></li>
				<li>Finally, let's delete the monitor<a id="_idTextAnchor794"/>ing schedule and the endpoint:<pre>default_monitor.<strong class="bold">delete_monitoring_schedule</strong>()
predictor.<strong class="bold">delete_endpoint</strong>()</pre><p>不要忘记这一步，因为您将为终端运行的时间付费。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-324"><a id="_idTextAnchor795"/>工作原理……</h2>
			<p>在一个模型被部署到产品中之后，会发生很多事情。发送到我们的推理端点的数据有可能包含数据质量问题，类似于我们在这个配方中使用perform_bad_input()函数模拟的情况。在<em class="italic">如何做… </em>部分，我们使用<strong class="bold"> SageMaker模型监控器</strong>对模型和数据进行连续监控，以检测这些类型的数据质量问题。以下是我们为实现这一目标而执行的步骤:</p>
			<ol>
				<li value="1">我们在<em class="italic">中启用了数据捕获，从模型部署一个端点，并使用SageMaker Model Monitor </em>方法启用数据捕获，以便在调用机器学习模型时收集请求和响应对。</li>
				<li>在这个配方中，我们使用一个基线作业生成了一个建议的基线，作为指标<a id="_idIndexMarker1579"/>和建议约束的参考点<a id="_idIndexMarker1578"/>。当<a id="_idIndexMarker1580"/>未来未发现的数据中存在数据质量问题时，这些约束是用于检测违规的规则。我们可以把约束看作边界，让我们知道用于调用我们的模型的<a id="_idIndexMarker1581"/>数据是否仍然在边界内。</li>
				<li>我们修改了建议的约束配置，以便<strong class="bold"> SageMaker模型监视器</strong>不会报告误报。</li>
				<li>我们配置了一个<a id="_idIndexMarker1582"/>监控计划，每小时运行一次处理作业。这个处理<a id="_idIndexMarker1583"/>作业利用捕获的数据、基线统计数据和约束配置来生成统计数据<a id="_idIndexMarker1584"/>和违规报告。注意，我们通过在调用create_monitoring_schedule()函数时指定enable_cloudwatch_metrics=True，将这个监控计划配置为在每个处理作业执行后自动向<strong class="bold"> Amazon CloudWatch </strong>发出指标。</li>
			</ol>
			<p>可选地，我们可以创建一个警报来检测在<strong class="bold"> Amazon CloudWatch </strong>中收集的特定指标是否低于特定的<a id="_idIndexMarker1586"/>阈值。然后，该警报可被配置为触发<strong class="bold">AWSλ</strong>功能，该功能将执行<a id="_idTextAnchor796"/> n自动操作，例如更新或重新训练生产中使用的模型。我们还可以使用这些警报来通知团队的特定成员检查和调试生产系统中任何检测到的问题。</p>
			<h2 id="_idParaDest-325">还有更多…</h2>
			<p><a id="_idIndexMarker1587"/>规则违反是如何运作的？规则违规从一组规则和约束开始，这些规则和约束是在使用create_monitoring_schedule()调度监视作业时配置的。我们可以指定不同类型的约束，其中一种涉及数据类型约束，如下图所示:</p>
			<div><div><img src="img/B16850_07_21.jpg" alt="Figure 7.21 – Data type check violation&#13;&#10;" width="870" height="411"/>
				</div>
			</div>
			<p class="figure-caption">图7.21–数据类型检查违规</p>
			<p>这里，我们有该配方中涉及的不同特征的预期<a id="_idIndexMarker1588"/>数据类型。这意味着，如果特征值的数据类型与约束配置中指定的数据类型不匹配，<strong class="bold">模型监视器</strong>将在调度作业执行完毕后，在违规报告中进行标记。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">我们可以使用<strong class="bold"> SageMaker模型监控器</strong>监控其他类型的违规行为。其中包括完整性检查、基线漂移检查、缺失列检查、额外列检查和分类值检查违规检查类型。有关这个主题的更多信息，请随时查看<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-violations.html">https://docs . AWS . Amazon . com/sage maker/latest/DG/model-monitor-interpreting-violations . html</a>。</p>
			<h2 id="_idParaDest-326"><a id="_idTextAnchor798"/>参见</h2>
			<p>如果您正在寻找在真实数据集上使用<strong class="bold"> SageMaker Model Monitor </strong>的<a id="_idIndexMarker1589"/>示例和更复杂的示例，请随意查看AWS/Amazon-sage maker-examples GitHub资源库中的一些笔记本:</p>
			<ul>
				<li>使用<strong class="bold"> SageMaker模型监视器检测模型质量漂移</strong>:<a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.ipynb">https://github . com/AWS/Amazon-SageMaker-examples/blob/master/SageMaker _ Model _ Monitor/Model _ quality/Model _ quality _ churn _ SDK . ipynb</a></li>
				<li>使用偏差监视器和可解释性<a id="_idIndexMarker1590"/>监视器检测偏差漂移和特征属性漂移:<a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.ipynb">https://github . com/AWS/Amazon-sage maker-examples/blob/master/sage maker _ Model _ Monitor/Fairness _ and _ explability/sage maker-Model-Monitor-Fairness-and-explability . ipynb</a></li>
			</ul>
			<p>此时，我们应该对使用<strong class="bold"> SageMaker Model Monitor </strong>可以做什么有一个很好的想法。有关这个主题的更多信息，请随时查看此链接:<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html">https://docs . AWS . Amazon . com/sage maker/latest/DG/model-monitor . html</a>。</p>
		</div>
	</div>
</body></html>