<html><head/><body>





<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}</style>
<div><div><h1 id="_idParaDest-376"><em class="italic"> <a id="_idTextAnchor866"/>第九章</em>:管理机器学习工作流程和部署</h1>
			<p>在前面的章节中，我们关注的是SageMaker相对简单的机器学习模型部署；也就是说，使用deploy()函数将单个模型部署到推理端点。在简单的实验和部署中，这将达到目的。然而，当处理涉及更复杂设置的需求时，我们需要有更多的锦囊妙计。</p>
			<p>在本章中，我们将使用一组相对更复杂的部署解决方案来实现实时终端部署和自动化工作流。如下图所示，本章有三个主要关注领域——面向<strong class="bold">拥抱脸</strong>模型的深度学习模型部署、<strong class="bold">多模型端点</strong>部署以及ML工作流:</p>
			<div><div><img src="img/B16850_09_01.jpg" alt="Figure 9.1 – How the recipes in this chapter are divided &#13;&#10;" width="918" height="407"/>
				</div>
			</div>
			<p class="figure-caption">图9.1-本章中的配方是如何划分的</p>
			<p>第一个重点领域涉及在SageMaker中微调和部署最先进的NLP模型。我们将使用<strong class="bold">拥抱面部变形金刚</strong>微调<strong class="bold"> PyTorch </strong>中的<strong class="bold">变形金刚</strong>模型。早在2017年，<strong class="bold">变形金刚</strong>就席卷了世界，因为其架构和方法允许对大量数据进行训练。这使得这些模型的性能明显优于rnn和CNN。第二个重点领域涉及在单个端点内部署多个模型时的一些相关变化。其中包括执行<strong class="bold">多模型端点</strong>部署的不同方式，以及设置<strong class="bold"> A/B测试</strong>来帮助我们在更新模型之前确定哪个模型在生产中具有更好的性能。本章的第三个重点领域涉及使用<strong class="bold">步骤功能</strong>和<strong class="bold"> SageMaker管道</strong>来构建工作流，帮助编排和自动化机器学习过程和任务。借助这些工作流管理解决方案，我们将能够自动化和协调数据准备、培训、评估和部署等任务，而无需担心服务器管理。</p>
			<p>也就是说，我们将在本章中介绍以下食谱:</p>
			<ul>
				<li>与<strong class="bold">拥抱脸</strong>模特一起工作</li>
				<li>准备<strong class="bold">多模型端点</strong>部署的先决条件</li>
				<li>通过<strong class="bold">多模型端点</strong>托管多个模型</li>
				<li>在具有生产变体的多个型号上设置<strong class="bold"> A/B测试</strong></li>
				<li>准备<strong class="bold">步骤功能</strong>执行角色</li>
				<li>使用<strong class="bold"> AWS步骤功能</strong>和<strong class="bold">数据科学SDK </strong>管理ML工作流</li>
				<li>使用<strong class="bold"> SageMaker管道</strong>管理ML工作流程</li>
			</ul>
			<p>一旦我们完成了本章中的配方，我们将对执行模型部署和自动化机器学习管道时可用的一些相关和有用的解决方案有更好的理解。</p>
			<h1 id="_idParaDest-377"><a id="_idTextAnchor867"/>技术要求</h1>
			<p>要执行本章中的配方，请确保您具备以下条件:</p>
			<ul>
				<li>一个亚马逊S3桶。</li>
				<li>管理<strong class="bold">亚马逊SageMaker </strong>和<strong class="bold">亚马逊S3 </strong>资源的权限，如果你使用的是带有自定义URL的<strong class="bold"> AWS IAM </strong>用户。如果您使用的是root帐户，那么您应该能够继续本章中的食谱。但是，建议您以AWS IAM用户的身份登录，而不是在大多数情况下使用root帐户。要了解更多信息，请随意查看以下指南:<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">https://docs . AWS . Amazon . com/IAM/latest/user guide/best-practices . html</a>。</li>
			</ul>
			<p>由于本章中的食谱涉及到一些代码，我们已经在本书的GitHub资源库中提供了笔记本:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/tree/master/Chapter09">https://GitHub . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/tree/master/chapter 09</a>。</p>
			<p>在开始本章的每一个食谱之前，确保my-experiments/chapter09目录已经准备好。如果还没有创建，请现在就创建，因为这有助于在我们学习本书中的每一个食谱时保持事物的有序。</p>
			<p>请点击以下链接查看动作视频中的相关代码:</p>
			<p><a href="https://bit.ly/3yViSEY">https://bit.ly/3yViSEY</a></p>
			<h1 id="_idParaDest-378"><a id="_idTextAnchor868"/>与拥抱脸模特一起工作</h1>
			<p><strong class="bold">抱脸</strong> <strong class="bold">变形金刚</strong>库汇集了<a id="_idIndexMarker1841"/>多个预先训练好的变形金刚模型<a id="_idIndexMarker1842"/>来解决文本分类、文本生成、信息抽取等相关NLP任务。这些型号包括<strong class="bold">伯特</strong>、<strong class="bold">罗伯塔</strong>、<strong class="bold"> GPT </strong>、<strong class="bold"> GPT-2 </strong>和<a id="_idIndexMarker1843"/>其他<a id="_idIndexMarker1844"/>最先进的变压器型号。使用预先训练好的模型<a id="_idIndexMarker1845"/>有什么好处？有了预训练模型<a id="_idIndexMarker1846"/>和<strong class="bold">转移学习</strong>，我们可以在更短的时间内得出准确的模型。这是因为我们可以从模型中的一组好的权重开始，这些模型已经被训练来解决一组类似的问题。</p>
			<p>在这个菜谱中，我们<a id="_idIndexMarker1847"/>将从预训练的<strong class="bold"> DistilBERT </strong>模型开始，并使用来自<strong class="bold"> SageMaker Python SDK </strong>的HuggingFace估计器类，以及一个定制的Python脚本文件，来微调我们的<strong class="bold"> DistilBERT </strong>模型。我们将使用来自第8章<em class="italic">的<em class="italic">生成用于文本分类问题的合成数据集</em>的合成文本数据，使用内置算法</em>解决NLP、图像分类和时间序列预测问题，以微调<strong class="bold"> DistilBERT </strong>模型，使其更适合我们的数据。除此之外，我们将演示如何使用PyTorchModel类来部署微调后的模型。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">如果你<a id="_idIndexMarker1848"/>想知道<strong class="bold">蒸馏伯特</strong>是什么，它是“伯特<strong class="bold">的蒸馏版本”几年前，来自Transformers</strong>(<strong class="bold">BERT</strong>)框架的<strong class="bold">双向编码器表示在情感分析、句子分类、语义角色标注和其他相关NLP任务中取得了最先进的成果<a id="_idIndexMarker1849"/>。通过使用<strong class="bold">知识蒸馏</strong>,<strong class="bold">拥抱脸</strong>的研究人员能够准备一个更小更快的模型，称为<strong class="bold">蒸馏瓶</strong>，而不会受到巨大的性能打击。关于这个话题的更多<a id="_idIndexMarker1850"/>信息，请随意查看<a href="https://huggingface.co/transformers/model_doc/distilbert.html">https://hugging face . co/transformers/model _ doc/distil Bert . html</a>。</strong></p>
			<p>我们将使用这个模型来解决一个文本分类问题，类似于我们在<em class="italic">培训中使用<strong class="bold"> BlazingText </strong>模型和部署<a href="B16850_08_Final_ASB_ePub.xhtml#_idTextAnchor814"> <em class="italic">第8章</em></a><em class="italic">的一个BlazingText模型</em>配方，使用内置的Alg <a id="_idTextAnchor869"/>算法</em>解决NLP、图像分类和时间序列预测问题。</p>
			<h2 id="_idParaDest-379">准备就绪</h2>
			<p>对于这个食谱，你需要一个运行<strong class="bold"> Python 3(数据科学)<a id="_idTextAnchor871"/> </strong>内核的<strong class="bold"> SageMaker Studio </strong>笔记本。</p>
			<h2 id="_idParaDest-380">如何<a id="_idTextAnchor872"/> <a id="_idTextAnchor873"/>去做…</h2>
			<p>该配方中的第一组步骤<a id="_idIndexMarker1851"/>着重于准备培训工作的先决条件。让我们开始吧:</p>
			<ol>
				<li>Create a new notebook using the <strong class="bold">Python 3 (Data Science)</strong> kernel inside the my-experiments/chapter09 directory and rename it to the name of this recipe (Working with Hugging Face models): <div><img src="img/B16850_09_02.jpg" alt="Figure 9.2 – Creating a new notebook&#13;&#10;" width="453" height="222"/></div><p class="figure-caption">图9.2–创建新笔记本</p><p>在<em class="italic">图9.2 </em>中，我们可以看到如何从<strong class="bold">文件</strong>菜单创建一个新的<strong class="bold">笔记本</strong>。当提示使用内核时，选择Python 3(数据科学)。</p></li>
				<li>如果脚本目录尚不存在，使用mkdir命令创建该目录:<pre>!mkdir -p <strong class="bold">scripts</strong></pre></li>
				<li>准备路径变量<a id="_idIndexMarker1852"/>，使其指向存储entry_point脚本文件以及一些必备文件的位置:<pre>g = "raw.githubusercontent.com" p = "PacktPublishing" a = "Machine-Learning-with-Amazon-SageMaker-Cookbook" mc = "master/Chapter09" <strong class="bold">path</strong> = f"https://{g}/{p}/{a}/{mc}/scripts"</pre></li>
				<li>使用wget: <pre>!wget -P scripts {path}/<strong class="bold">setup.py</strong> !wget -P scripts {path}/<strong class="bold">train.py</strong> !wget -P scripts {path}/<strong class="bold">inference.py</strong> !wget -P scripts {path}/<strong class="bold">requirements.txt</strong></pre>将setup.py、train.py、inference.py和requirements.txt文件下载到脚本目录</li>
				<li>Locate the scripts directory in the <strong class="bold">File Browser</strong>:<div><img src="img/B16850_09_03.jpg" alt="Figure 9.3 – Downloaded files inside the scripts directory&#13;&#10;" width="552" height="152"/></div><p class="figure-caption">图9.3–脚本目录中下载的文件</p><p>在这里，我们可以看到脚本目录，其中<a id="_idIndexMarker1853"/>包含requirements.txt、setup.py、train.py和inference.py文件。</p></li>
				<li>Inspect the train.py file inside the scripts directory:<div><img src="img/B16850_09_04.jpg" alt="Figure 9.4 – train.py&#13;&#10;" width="718" height="485"/></div><p class="figure-caption">图9.4–train . py</p><p>这里，我们有一个名为train.py的entry_point脚本文件。它包含处理参数、加载训练和验证数据、标记和处理数据、加载预训练的DistilBert模型、使用处理的训练和验证数据微调模型以及保存模型的Python代码。</p><p class="callout-heading">注意</p><p class="callout">这个菜谱中train.py文件的entry_point脚本文件的结构、流程和目标应该类似于我们在<em class="italic">准备entrypoint PyTorch培训脚本</em>第3章<a href="B16850_03_Final_ASB_ePub.xhtml#_idTextAnchor114"><em class="italic"/></a>、<em class="italic">使用机器学习和深度学习框架与Amazon SageMaker </em>中的内容。当然，这些脚本文件之间的一些主要差异包括在训练步骤中用于训练模型的库和数据。</p></li>
				<li>Quickly inspect<a id="_idIndexMarker1854"/> the inference.py file inside the scripts directory:<div><img src="img/B16850_09_05.jpg" alt="Figure 9.5 – The inference.py file&#13;&#10;" width="737" height="554"/></div><p class="figure-caption">图9.5–推论. py文件</p><p>这里，我们有一个名为inference.py的entry_point脚本文件，它包含四个名为model_fn、predict_fn、input_fn和output_fn的函数。</p></li>
				<li>Next, inspect the requirements.txt file as well:<p>该文件包含单行–变压器==4.4.2。请注意，requirements.txt文件需要位于脚本目录中，以便在运行entry_point脚本文件之前，requirements.txt文件中的包会自动安装。</p></li>
				<li>回到笔记本，使用mkdir命令创建<a id="_idIndexMarker1855"/>tmp目录，如果它还不存在:<pre>!mkdir -p <strong class="bold">tmp</strong></pre></li>
				<li>准备path变量，使其指向存储训练和验证数据集的位置:<pre>g = "raw.githubusercontent.com" p = "PacktPublishing" a = "Machine-Learning-with-Amazon-SageMaker-Cookbook" mc = "master/Chapter09" <strong class="bold">path</strong> = f"https://{g}/{p}/{a}/{mc}/files"</pre></li>
				<li>Use the wget command to download the files containing the training and validation data from this book's GitHub repository to the tmp directory:<pre>!wget -P tmp {path}/<strong class="bold">synthetic.train.txt</strong>
!wget -P tmp {path}/<strong class="bold">synthetic.validation.txt</strong></pre><p>这些文件应该包含标签和文本对，类似于下面的代码块所示:</p><pre><strong class="bold">__label__negative</strong>  Donut  this  is  bad  not  impressive  this  is  bad  spaghetti  chicken  soup 
<strong class="bold">__label__positive</strong>  Spaghetti  Chicken  Soup  tastes  good  donut  this  is  good  this  is  good  this  is  good  tastes  good</pre></li>
				<li>指定将存储数据的S3时段名称和前缀。确保将<insert s3="" bucket="" here="">的值替换为我们在<em class="italic">准备亚马逊S3桶和线性回归实验的训练数据集</em>配方<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第1章</em> </a> <em class="italic">中创建的桶的名称，使用亚马逊SageMaker </em> : <pre>s3_bucket = "<strong class="bold">&lt;insert s3 bucket here&gt;"</strong> prefix = "chapter09"</pre></insert></li>
				<li>初始化变量，使<a id="_idIndexMarker1856"/>指向训练和验证数据应该存储在<strong class="bold">亚马逊S3 </strong> : <pre><strong class="bold">s3_train_data</strong> = 's3://{}/{}/input/{}'.format(     s3_bucket,      prefix,      "<strong class="bold">synthetic.train.txt</strong>" ) <strong class="bold">s3_validation_data</strong> = 's3://{}/{}/input/{}'.format(     s3_bucket,      prefix,      "<strong class="bold">synthetic.validation.txt</strong>" )</pre>中的位置</li>
				<li>使用<strong class="bold"> AWS CLI </strong>上传包含训练和验证数据的TXT文件:<pre>!aws s3 cp tmp/<strong class="bold">synthetic.train.txt</strong> {<strong class="bold">s3_train_data</strong>} !aws s3 cp tmp/<strong class="bold">synthetic.validation.txt</strong> {<strong class="bold">s3_validation_data</strong>}</pre></li>
				<li>Prepare and load the role ARN using the get_execution_role() function from the <strong class="bold">SageMaker Python SDK</strong>:<pre>import sagemaker
role = sagemaker.get_execution_role()</pre><p>现在我们已经准备好了先决条件，我们可以专注于培训工作了。</p></li>
				<li>初始化HuggingFace估计器对象。这里，我们将为model_name值指定distilbert-base-uncased:<pre>from sagemaker.huggingface import HuggingFace hyperparameters = {     'epochs': 1,     'train_batch_size': 32,     'model_name':'<strong class="bold">distilbert-base-uncased</strong>' } estimator = <strong class="bold">HuggingFace</strong>(     entry_point='<strong class="bold">train.py</strong>',     source_dir='./<strong class="bold">scripts</strong>',     instance_type='ml.p3.2xlarge',     instance_count=1,     role=role,     transformers_version='4.4',     pytorch_version='1.6',     py_version='py36',     hyperparameters=hyperparameters )</pre></li>
				<li>准备data_channels字典，它包含指向存储在<strong class="bold">亚马逊S3 </strong> : <pre>from sagemaker.inputs import TrainingInput      train_data = TrainingInput(s3_train_data) validation_data = TrainingInput(s3_validation_data)      <strong class="bold">data_channels</strong> = {     'train': train_data,      'valid': validation_data }</pre>中的训练和验证数据集文件的训练输入对象</li>
				<li>Use the fit() function<a id="_idIndexMarker1858"/> to start the training job:<pre>%%time
estimator.<strong class="bold">fit</strong>(<strong class="bold">data_channels</strong>)</pre><p>这将产生一组日志，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_09_06.jpg" alt="Figure 9.6 – Training job logs&#13;&#10;" width="637" height="325"/></div><p class="figure-caption">图9.6–培训工作日志</p><p>这里，我们有调用fit()函数后生成的日志。</p><p class="callout-heading">注意</p><p class="callout">这大约需要7到10分钟才能完成。在等待的时候，请随意喝杯咖啡或茶！</p><p>最后一组步骤集中在部署<a id="_idIndexMarker1859"/>模型和测试推理端点上:</p></li>
				<li>接下来，初始化PyTorchModel对象，并将inference.py指定为entry_point参数的值:<pre>from sagemaker.pytorch.model import PyTorchModel <strong class="bold">model_data</strong> = <strong class="bold">estimator.model_data</strong>      model = <strong class="bold">PyTorchModel</strong>(     model_data=<strong class="bold">model_data</strong>,      role=role,      source_dir="scripts",     entry_point='<strong class="bold">inference.py</strong>',      framework_version='1.6.0',     py_version="py3" )</pre></li>
				<li>Deploy the model using the deploy() function:<pre>%%time
predictor = model.<strong class="bold">deploy</strong>(
    instance_type='ml.m5.xlarge', 
    initial_instance_count=1
)</pre><p class="callout-heading">注意</p><p class="callout">完成此步骤需要7到10分钟。在等待的时候，你可以随便吃点东西！</p></li>
				<li>更新预测器的串行化器和去串行化器:<pre>from sagemaker.serializers import JSONSerializer from sagemaker.deserializers import JSONDeserializer predictor.serializer = JSONSerializer() predictor.deserializer = JSONDeserializer()</pre></li>
				<li>Use the predict() function<a id="_idIndexMarker1860"/> to test a NEGATIVE scenario:<pre>test_data = {
    "text": "<strong class="bold">This tastes bad. I hate this place.</strong>"
}
predictor.<strong class="bold">predict</strong>(test_data)</pre><p>这将返回一个负的字符串值。</p></li>
				<li>Use the predict() function again to test a POSITIVE scenario:<pre>test_data = {
    "text": "<strong class="bold">Very delicious. I would recommend this to my friends</strong>"
}
predictor.<strong class="bold">predict</strong>(test_data)</pre><p>这将返回一个正的字符串值。</p></li>
				<li>Delete the endpoint afterward using the delete_endpoint() function:<pre>predictor.<strong class="bold">delete_endpoint</strong>()</pre><p>不要忘记这一步，因为您将为终端运行的时间付费。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的<a id="_idTextAnchor874"/>！</p>
			<h2 id="_idParaDest-381"><a id="_idTextAnchor875"/>工作原理……</h2>
			<p>在这个菜谱中，我们使用来自<strong class="bold"> SageMaker Python SDK </strong>的HuggingFace estimator <a id="_idIndexMarker1861"/>类来微调我们的<strong class="bold"> DistilBERT </strong>模型，以解决文本分类<a id="_idIndexMarker1862"/>问题。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">请注意，我们不仅限于在这里使用<strong class="bold"> DistilBERT </strong>。我们可以利用<a id="_idIndexMarker1864"/>在这个<a id="_idIndexMarker1865"/>配方中使用的同样的<a id="_idIndexMarker1863"/>方法和解决方案来微调和部署模型，例如<strong class="bold">伯特</strong>、<strong class="bold">罗伯塔</strong>、<strong class="bold"> GPT-2 </strong>，以及这里的其他基于变形金刚的NLP模型:<a href="https://huggingface.co/transformers/pretrained_models.html">https://huggingface.co/transformers/pretrained_models.html</a>。</p>
			<p>在处理HuggingFace模型部署时，需要注意的是，编写本文时还不支持Hugging Face估计器的deploy()函数。这意味着我们必须执行一个变通办法，使用来自<strong class="bold"> SageMaker Python SDK </strong>的PyTorchModel类，以及一个定制的entry_point脚本，来帮助我们将模型部署到推理端点。我们总是可以退回到使用亚马逊SageMaker和SageMaker Python SDK的其他现有功能，以及我们的定制技能。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">请随意查看<a href="https://aws.amazon.com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-amazon-sagemaker/">https://AWS . Amazon . com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-Amazon-sage maker/</a>了解更多关于这个主题的信息。</p>
			<p>当使用来自<strong class="bold"> SageMaker Python SDK </strong>的框架估算器时，例如TensorFlow、HuggingFace和PyTorch估算器类，我们需要确保在训练和部署步骤开始之前准备好以下文件和脚本:训练entry_point脚本文件、推理entry_point脚本文件和其他文件，例如requirements.txt文件，它们有助于在执行entry_point脚本文件之前安装必要的库。在training entry_point脚本文件中，我们使用以下代码行来微调和保存<strong class="bold"> DistilBERT </strong>模型:</p>
			<pre>trainer = <strong class="bold">Trainer</strong>(model=model,...)
eval_result = trainer.<strong class="bold">evaluate</strong>(...)
trainer.<strong class="bold">save_model</strong>(model_dir)</pre>
			<p>一旦训练作业完成运行，模型<a id="_idIndexMarker1868"/>工件被上传到model.tar.gz文件中的S3桶，然后在部署推理端点时被下载到推理容器。在推理entry_point脚本文件中，我们分别使用automodelforsequenceclassification . from _ pre trained()和AutoTokenizer.from_pretrained()函数加载了模型和标记器。</p>
			<p>请随意查看<em class="italic">使用亚马逊SageMaker本地模式</em>培训和部署PyTorch模型<a href="B16850_03_Final_ASB_ePub.xhtml#_idTextAnchor114"> <em class="italic">第三章</em> </a>、<em class="italic">使用机器学习和深度学习框架使用亚马逊SageMaker </em>，了解如何准备自定义entry_point脚本的更多信息。</p>
			<h2 id="_idParaDest-382"><a id="_idTextAnchor876"/>还有更多……</h2>
			<p>我们只是触及了SageMaker Python SDK 的HuggingFace estimator类的皮毛。由于模型被微调，我们正在处理相对较大的ML实例，我们可能需要使用不同的解决方案来降低成本和加快训练时间。</p>
			<p>使用SageMaker时显著降低成本的方法之一是在训练机器<a id="_idIndexMarker1869"/>学习模型时使用<strong class="bold">点实例</strong>。有了<strong class="bold"> Spot实例</strong>，考虑到Spot实例的中断，与按需实例相比，我们可以降低大约70%到90%的成本。有了SageMaker，我们可以利用其<strong class="bold">管理的现场培训</strong>功能，这允许我们利用现场实例<a id="_idIndexMarker1870"/>而不必担心细节。当然，需要做一些调整才能让它工作:</p>
			<ul>
				<li>我们必须在train entry_point脚本文件中添加对在中断期间使用检查点进行保存和恢复的支持。</li>
				<li>我们必须配置估计器，以便它可以使用<strong class="bold">管理的现场训练</strong>(例如，train_use_spot_instances=True)。</li>
			</ul>
			<p>我们还可以通过<strong class="bold">数据并行</strong>和<strong class="bold">模型并行</strong>利用分布式训练。利用<strong class="bold">数据并行</strong>，训练集被分成<a id="_idIndexMarker1871"/>小批量。然后，这些小批量用于在几个GPU实例中训练模型。这有助于减少训练时间，尤其是当我们处理较大的数据集时。另一方面，我们可以使用<strong class="bold">模型并行性</strong>在多个GPU和实例之间自动拆分大型深度学习模型<a id="_idIndexMarker1872"/>。我们不会在本书中深入讨论这些细节，所以请随意查看https://sage maker-examples . readthe docs . io/en/latest/training/distributed _ training/index . html。</p>
			<h2 id="_idParaDest-383"><a id="_idTextAnchor877"/>亦见</h2>
			<p>如果你正在寻找在真实数据集和更复杂的例子上使用SageMaker Python SDK 中的HuggingFace估计器的例子<a id="_idIndexMarker1874"/>，请在这里随意查看一些专注于这个主题的笔记本:<a href="https://huggingface.co/transformers/sagemaker.html">https://huggingface.co/transformers/sagemaker.html</a>。</p>
			<h1 id="_idParaDest-384"><a id="_idTextAnchor878"/>准备多模型端点部署的先决条件</h1>
			<p>在这个菜谱中，我们将准备一些多模型端点部署的<a id="_idIndexMarker1875"/>先决条件，包括预训练模型文件和预训练模型文件将被上传到的S3路径。这些先决条件将用于<em class="italic">托管具有多模型端点的多个模型</em>和<em class="italic">设置具有生产变体</em>配方的多个模型的A/B测试。</p>
			<h2 id="_idParaDest-385">准备就绪</h2>
			<p>为了这个食谱，你需要一台运行<strong class="bold"> Python 3(数据科学)</strong>内核的<strong class="bold"> SageMaker Studio </strong>笔记本。</p>
			<h2 id="_idParaDest-386"><a id="_idTextAnchor880"/>怎么做……</h2>
			<p>这个菜谱中的步骤主要是从本书的GitHub库中下载预先训练好的模型文件，并将它们上传到S3桶中。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter09目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为这个配方的名称(准备多模型端点部署的先决条件)。</li>
				<li>准备path变量，使其指向预先训练好的模型文件的存储位置:<pre><strong class="bold">path</strong> = "https://github.com/PacktPublishing/" + \     "Machine-Learning-with-Amazon-SageMaker-Cookbook/raw/master/" + \     "Chapter09/files/"</pre></li>
				<li>Use the wget command to download the pre-trained model files to the tmp directory:<pre><strong class="bold">pretrained_model_a</strong> = path + "<strong class="bold">model.a.tar.gz</strong>"
<strong class="bold">pretrained_model_b</strong> = path + "<strong class="bold">model.b.tar.gz</strong>"
!wget -O tmp/<strong class="bold">model.a.tar.gz</strong> {<strong class="bold">pretrained_model_a</strong>}
!wget -O tmp/<strong class="bold">model.b.tar.gz</strong> {<strong class="bold">pretrained_model_b</strong>}</pre><p class="callout-heading">注意</p><p class="callout">如果你想知道<a id="_idIndexMarker1876"/>我们从哪里得到这些预训练的模型文件，我们只是重用了我们在<a href="B16850_05_Final_ASB_ePub.xhtml#_idTextAnchor267"> <em class="italic">第5章</em> </a>、<em class="italic">有效管理机器学习实验</em>中训练的<strong class="bold"> XGBoost </strong>模型中的两个。我们只是决定在这个菜谱中下载这些模型，这样我们就不用再训练这些模型了。</p></li>
				<li>指定S3存储桶的名称<a id="_idIndexMarker1877"/>和存储数据的前缀。确保将&lt; insert s3 bucket name here &gt;的值替换为我们在<em class="italic">准备亚马逊s3 bucket和线性回归实验的训练数据集</em>第1章  <em class="italic">的<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020">配方，使用亚马逊SageMaker </a></em>开始机器学习:<pre>s3_bucket = "<strong class="bold">&lt;insert s3 bucket name here&gt;"</strong> prefix = "chapter09"</pre>中创建的bucket的名称</li>
				<li>将预先训练好的模型文件上传到<strong class="bold">亚马逊S3 </strong> : <pre>m_a = "files/<strong class="bold">model.a.tar.gz</strong>" m_b = "files/<strong class="bold">model.b.tar.gz</strong>" a = f"s3://{s3_bucket}/{prefix}/{m_a}" b = f"s3://{s3_bucket}/{prefix}/{m_b}" !aws s3 cp tmp/<strong class="bold">model.a.tar.gz</strong> {a} !aws s3 cp tmp/<strong class="bold">model.b.tar.gz</strong> {b}</pre></li>
				<li>使用%store magic保存model_a_s3_path和model_b_s3_path的变量值:<pre>model_a_s3_path = a model_b_s3_path = b %store <strong class="bold">model_a_s3_path</strong> %store <strong class="bold">model_b_s3_path</strong></pre></li>
				<li>Use the %store magic to save the variable values for s3_bucket and prefix:<pre>%store <strong class="bold">s3_bucket</strong>
%store <strong class="bold">prefix</strong></pre><p>我们将在随后的食谱中使用这些存储的变量值。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-387"><a id="_idTextAnchor881"/>工作原理……</h2>
			<p>在这个配方中，我们准备了<a id="_idIndexMarker1878"/>多模型端点的先决条件。这包括模型文件，以及文件在S3中的存储路径。当使用多模型端点时，请注意，我们需要指定将在推理端点中使用的模型工件和容器图像。</p>
			<p>也就是说，我们只是从这本书的GitHub库中下载了预先训练好的模型，然后将这些model.tar.gz文件上传到S3桶中。由于这些预先训练的模型工件是提前准备的，我们也知道它们是如何准备的，以及哪些<a id="_idIndexMarker1879"/>内置算法和容器图像(例如，<strong class="bold"> XGBoost </strong>)被用于训练模型。在接下来的菜谱中，我们将使用sagemaker.image_uris.retrieve()函数来获取<strong class="bold"> XGBoost </strong>的容器图像URI。这将帮助我们完成多模型端点部署的先决条件。</p>
			<h1 id="_idParaDest-388"><a id="_idTextAnchor882"/>通过多模型端点托管多个模型</h1>
			<p>在上一个菜谱中，我们为多模型端点部署准备了一些先决条件；即预训练模型文件和预训练模型文件将被上传到S3的路径。</p>
			<p>在这个菜谱中，我们将使用SageMaker的多模型端点支持在单个端点中部署多个模型。有了<strong class="bold">多模型端点</strong>，我们可以降低成本，因为我们可以在一个端点内托管多个模型，而不是每个模型都有一个专用端点。这种方法在试运行或测试环境中也能很好地工作，在这些环境中，偶尔的冷启动延迟对于不常使用的模型来说是可以容忍的。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">如果你想知道我们从哪里得到这些预训练的模型，我们只是重用了我们在<a href="B16850_05_Final_ASB_ePub.xhtml#_idTextAnchor267"> <em class="italic">第5章</em> </a>、<em class="italic">有效管理机器学习实验</em>中训练的<strong class="bold"> XGBoost </strong>模型中的两个。这些模型只接受a和b要素的数值，并返回预测的标注值。预测的标签值将是0.0和1.0之间的数字；如果预测值大于指定的阈值，例如0.8，我们可以简单地将结果值映射到1。</p>
			<h2 id="_idParaDest-389">正在准备中</h2>
			<p>以下是该配方的先决条件:</p>
			<ul>
				<li>该方法上接<em class="italic">准备多模型端点部署的先决条件</em>方法。</li>
				<li>你将需要一台运行<strong class="bold"> Python 3(数据科学)</strong>内核的<strong class="bold"> SageMaker Studio </strong>笔记本。</li>
			</ul>
			<h2 id="_idParaDest-390"><a id="_idTextAnchor884"/>怎么做……</h2>
			<p>该方法中的第一组步骤主要是为多模型端点部署准备一些先决条件和参数值。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter09目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为这个recipe的名称(托管具有多模型端点的多个模型)。</li>
				<li>使用%store magic加载model_a_s3_path和model_b_s3_path的变量值:<pre>%store -r <strong class="bold">model_a_s3_path</strong> %store -r <strong class="bold">model_b_s3_path</strong></pre></li>
				<li>使用%store magic为s3_bucket和prefix加载变量值:<pre>%store -r <strong class="bold">s3_bucket</strong> %store -r <strong class="bold">prefix</strong></pre></li>
				<li>从<strong class="bold"> SageMaker Python SDK </strong> : <pre>import sagemaker from sagemaker import get_execution_role session = sagemaker.Session() role = get_execution_role()</pre>中导入并准备一些<a id="_idIndexMarker1882"/>先决条件，比如会话和角色</li>
				<li>Use the retrieve() function to get the ECR image URI of the <strong class="bold">XGBoost</strong> built-in algorithm container image:<pre>from sagemaker.image_uris import retrieve
image_uri = <strong class="bold">retrieve</strong>(
    "<strong class="bold">xgboost</strong>", 
    region="us-east-1", 
    version="0.90-2"
)
image_uri</pre><p class="callout-heading">小费</p><p class="callout">如果您在另一个区域运营，请随意更改区域值。</p></li>
				<li>Prepare the models_path variable where the model data for the multi-model endpoint will be stored:<pre><strong class="bold">models_path</strong> = f"s3://{s3_bucket}/model-artifacts/"</pre><p>既然先决条件已经准备好，我们将把<a id="_idIndexMarker1883"/>集中在初始化多数据模型对象上，并继续进行部署<strong class="bold">多模型端点</strong>所需的其他步骤。</p></li>
				<li>初始化多数据模型对象:<pre>from sagemaker.multidatamodel import MultiDataModel multi_model = <strong class="bold">MultiDataModel</strong>(     name="chapter09-multi",     model_data_prefix=<strong class="bold">models_path</strong>,      image_uri=image_uri,     role=role )</pre></li>
				<li>使用add_model()函数将模型数据从原始S3位置传输并存储到models_path变量:<pre>multi_model.<strong class="bold">add_model</strong>(model_a_s3_path) multi_model.<strong class="bold">add_model</strong>(model_b_s3_path)</pre>中指定的位置</li>
				<li>Use the deploy() function to start the multi-model endpoint deployment:<pre>%%time
<strong class="bold">endpoint_name</strong> = "chapter09-mma"
multi_model.<strong class="bold">deploy</strong>(
    initial_instance_count=1, 
    instance_type='ml.t2.medium', 
    endpoint_name=<strong class="bold">endpoint_name</strong>
)</pre><p class="callout-heading">注意</p><p class="callout">完成此步骤大约需要7到15分钟。在等待的时候，请随意喝杯咖啡或茶！</p></li>
				<li>初始化预测器对象<a id="_idIndexMarker1884"/>并更新其序列化器和反序列化器:<pre>from sagemaker.predictor import Predictor from sagemaker.serializers import CSVSerializer from sagemaker.deserializers import JSONDeserializer      predictor = Predictor(     endpoint_name=endpoint_name )      predictor.serializer = CSVSerializer() predictor.deserializer = JSONDeserializer()</pre></li>
				<li>Store the model identifiers inside the a and b variables:<pre><strong class="bold">a</strong>, <strong class="bold">b</strong> = list(<strong class="bold">multi_model.list_models()</strong>)</pre><p>这将分别为a和b变量提供chapter09/files/model.a.tar.gz和chapter09/files/model.b.tar.gz。</p></li>
				<li>Use the predict() function and specify which model to use by passing a as the value for the target_model parameter:<pre>predictor.<strong class="bold">predict</strong>(data="10,-5", <strong class="bold">target_model=a</strong>)</pre><p>这将返回一个类似于[0.895996630191803]的值。</p></li>
				<li>Similarly, use the predict() function and specify which model to use by passing b as the value for the target_model parameter:<pre>predictor.<strong class="bold">predict</strong>(data="10,-5", <strong class="bold">target_model=b</strong>)</pre><p>这将返回一个类似于[0.8308258652687073]的值。</p></li>
				<li>Finally, delete the endpoint using the delete_endpoint() function:<pre>predictor.<strong class="bold">delete_endpoint</strong>()</pre><p>不要忘记<a id="_idIndexMarker1885"/>这一步，因为您将为终端运行的时间付费。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-391"><a id="_idTextAnchor885"/>工作原理……</h2>
			<p>在这个菜谱中，我们使用了来自<strong class="bold"> SageMaker Python SDK </strong>的MultiDataModel类来部署多模型端点。对于多模型端点，我们的模型文件存储在一个S3桶中。当端点被调用时，这些将被加载并用于推理:</p>
			<div><div><img src="img/B16850_09_07.jpg" alt="Figure 9.7 – Multi-model endpoint&#13;&#10;" width="813" height="355"/>
				</div>
			</div>
			<p class="figure-caption">图9.7–多模型端点</p>
			<p>在上图中，我们<a id="_idIndexMarker1886"/>可以看到，当在推理端点上执行调用请求时，模型被动态加载。当一个模型还没有被加载到ML实例中的容器内存中时，这个模型从S3桶中下载并被加载到内存中。这意味着后续调用会更快，因为模型已经被加载到内存中。有关更多信息，请随时查看<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html">https://docs . AWS . Amazon . com/sage maker/latest/DG/multi-model-endpoints . html</a>。</p>
			<h1 id="_idParaDest-392"><a id="_idTextAnchor886"/>在具有生产变型的多个模型上设置A/B测试</h1>
			<p>在处理生产<a id="_idIndexMarker1888"/>部署时，请注意可能会同时部署和测试多个<a id="_idIndexMarker1889"/>型号。这有助于数据科学家和机器学习工程师在处理这些模型以前没有见过的数据时，比较模型的性能。在生产中管理和测试多个模型的标准方法之一是通过在推理端点中使用<strong class="bold"> A/B测试</strong>。什么是<strong class="bold"> A/B测试</strong>？它<a id="_idIndexMarker1890"/>是一个实验，包括从部署的模型列表中随机选择一个模型来执行预测。它有助于在完全替换已部署的模型之前，识别生产中性能更好(或最好)的模型。</p>
			<p>在这个菜谱中，我们将使用SageMaker的多模型端点支持，在单个端点内部署两个预训练的<strong class="bold"> XGBoost </strong>模型。我们将配置和设置此端点，以允许<strong class="bold"> A/B测试已经部署在此端点中的预训练模型的</strong>。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">如果你想知道我们从哪里得到这些预训练的模型，我们只是重用了我们在<a href="B16850_05_Final_ASB_ePub.xhtml#_idTextAnchor267"> <em class="italic">第5章</em> </a>、<em class="italic">有效管理机器学习实验</em>中训练的<strong class="bold"> XGBoost </strong>模型中的两个。这些模型只接受a和b要素的数值，并返回预测的标注值。预测的标签值将是0.0和1.0之间的数字；如果预测值大于指定的阈值，例如0.8，我们可以简单地将结果值映射到1。</p>
			<p>一旦这个<strong class="bold"> A/B测试</strong>设置被配置和部署，流量应该在两个模型之间随机分配。</p>
			<h2 id="_idParaDest-393">准备就绪</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>该方法上接<em class="italic">准备多模型端点部署的先决条件</em>方法。</li>
				<li>你需要一台运行Python 3(数据科学)内核的<strong class="bold"> SageMaker Studio </strong>笔记本。</li>
			</ul>
			<h2 id="_idParaDest-394"><a id="_idTextAnchor888"/>怎么做……</h2>
			<p>该配方<a id="_idIndexMarker1891"/>中的步骤主要是设置<a id="_idIndexMarker1892"/>进行A/B测试。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter09目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为该配方的名称(在具有生产变量的多个模型上设置A/B测试)。</li>
				<li>使用%store magic加载model_a_s3_path和model_b_s3_path的变量值:<pre>%store -r <strong class="bold">model_a_s3_path</strong> %store -r <strong class="bold">model_b_s3_path</strong></pre></li>
				<li>使用%store magic为s3_bucket和prefix加载变量值:<pre>%store -r <strong class="bold">s3_bucket</strong> %store -r <strong class="bold">prefix</strong></pre></li>
				<li>从<strong class="bold">SageMaker Python SDK</strong>:<pre>import sagemaker from sagemaker import get_execution_role session = sagemaker.Session() role = get_execution_role()</pre>中导入并准备一些先决条件，如会话、角色等</li>
				<li>Use the retrieve() function to get the ECR image URI of the <strong class="bold">XGBoost</strong> built-in algorithm container image:<pre>from sagemaker.image_uris import retrieve
image_uri = <strong class="bold">retrieve</strong>(
    "<strong class="bold">xgboost</strong>", 
    region="us-east-1", 
    version="0.90-2"
)
image_uri</pre><p>这应该<a id="_idIndexMarker1893"/>给我们一个等于<a id="_idIndexMarker1894"/>或类似于683313688378 . dkr . ECR . us-east-1 . Amazon AWS . com/sage maker-xgboost:0.90-2-CPU-py3 for image _ uri的值。</p></li>
				<li>为容器1和容器2变量准备字典值:<pre><strong class="bold">image_uri_a</strong> = image_uri <strong class="bold">image_uri_b</strong> = image_uri <strong class="bold">container1</strong> = {      'Image': <strong class="bold">image_uri_a</strong>,     'ContainerHostname': 'containerA',     'ModelDataUrl': <strong class="bold">model_a_s3_path</strong> } <strong class="bold">container2</strong> = {      'Image': <strong class="bold">image_uri_b</strong>,     'ContainerHostname': 'containerB',     'ModelDataUrl': <strong class="bold">model_b_s3_path</strong> }</pre></li>
				<li>为SageMaker服务<pre>import boto3 <strong class="bold">sm_client</strong> = boto3.Session().client('<strong class="bold">sagemaker</strong>')</pre>准备<a id="_idIndexMarker1895"/>低级boto3客户端<a id="_idIndexMarker1896"/></li>
				<li>准备模型名称a、模型名称b、端点配置名称和端点名称的变量值:<pre><strong class="bold">model_name_a</strong> = "ab-model-a" <strong class="bold">model_name_b</strong> = "ab-model-b" <strong class="bold">endpoint_config_name</strong> = 'ab-endpoint-config' <strong class="bold">endpoint_name</strong> = 'ab-endpoint'</pre></li>
				<li>可选地，使用delete_model()函数删除任何现有的模型，以确保下一步成功且没有问题:<pre>try:     sm_client.<strong class="bold">delete_model</strong>(ModelName=model_name_a)     sm_client.<strong class="bold">delete_model</strong>(ModelName=model_name_b) except:     pass</pre></li>
				<li>Use the create_model() function to create the two models in SageMaker. For each of these<a id="_idIndexMarker1897"/> models, we specify the model's name, role, and the container<a id="_idIndexMarker1898"/> image URI when calling the create_model() function:<pre>response = sm_client.<strong class="bold">create_model</strong>(
    ModelName        = <strong class="bold">model_name_a</strong>,
    ExecutionRoleArn = role,
    Containers       = [container1])
print(response)
response = sm_client.<strong class="bold">create_model</strong>(
    ModelName        = <strong class="bold">model_name_b</strong>,
    ExecutionRoleArn = role,
    Containers       = [container2])
print(response)</pre><p>这将产生一组日志，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_09_08.jpg" alt="Figure 9.8 – Response values after using create_model()&#13;&#10;" width="1247" height="177"/></div><p class="figure-caption">图9.8–使用create_model()后的响应值</p><p>在这里，我们可以看到我们的create_model()调用已经成功，因为HTTPStatusCode值返回了200。</p></li>
				<li>为上一步中创建的每个模型准备相应的<a id="_idIndexMarker1899"/>生产变型。这里，我们还将为每个模型预期接收的流量部分指定一个50/50的分割:<pre>from sagemaker.session import production_variant variant1 = <strong class="bold">production_variant</strong>(     model_name=model_name_a,     instance_type="ml.t2.medium",     initial_instance_count=1,     variant_name='<strong class="bold">VariantA</strong>',     initial_weight=0.5 )                               variant2 = <strong class="bold">production_variant</strong>(     model_name=model_name_b,     instance_type="ml.t2.medium",     initial_instance_count=1,     variant_name='<strong class="bold">VariantB</strong>',     initial_weight=0.5 )</pre></li>
				<li>Use the endpoint_from_production_variants() function<a id="_idIndexMarker1900"/> to start the<a id="_idIndexMarker1901"/> deployment:<pre>session.<strong class="bold">endpoint_from_production_variants</strong>(
    name=endpoint_name,
    production_variants=[variant1, variant2]
)</pre><p class="callout-heading">注意</p><p class="callout">这大约需要10分钟才能完成。请随意喝杯咖啡或茶！</p></li>
				<li>Prepare the boto3 client for SageMaker Runtime:<pre>runtime_sm_client = boto3.client(<strong class="bold">'sagemaker-runtime</strong>')</pre><p class="callout-heading">注意</p><p class="callout">boto3.client('sagemaker ')和boto 3 . client(' sage maker-runtime ')有什么区别？<strong class="bold"> SageMaker运行时</strong>客户端只关注使用invoke_endpoint()函数调用SageMaker推理端点。另一方面，<strong class="bold"> SageMaker </strong>客户端提供了一整套功能，这些功能映射到可以用SageMaker服务执行的API动作。这包括create_auto_ml_job()、create_training_job()、create_endpoint()和create_transform_job()函数，以及此列表中的所有函数:<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html">https://boto 3 . Amazon AWS . com/v1/documentation/API/latest/reference/services/sage maker . html</a>。</p></li>
				<li>Test the A/B testing<a id="_idIndexMarker1903"/> setup by using the invoke_endpoint() function without<a id="_idIndexMarker1904"/> specifying the target variant:<pre>from time import sleep
<strong class="bold">body</strong> = "10,-5"
def <strong class="bold">test_ab_testing_setup</strong>():
    response = runtime_sm_client.<strong class="bold">invoke_endpoint</strong>(
        EndpointName=endpoint_name,
        ContentType='text/csv',
        Body=body
    )
    variant = response['<strong class="bold">InvokedProductionVariant</strong>']
    b = response['Body'].read()
    prediction = b.decode("utf-8")
    print(variant + " - "+ prediction)
    
for _ in range(0,10):
    <strong class="bold">test_ab_testing_setup</strong>()
    sleep(1)</pre><p>这应该会产生类似于以下屏幕截图所示的日志消息:</p><div><img src="img/B16850_09_09.jpg" alt="Figure 9.9 – Verifying the A/B testing setup of the inference endpoint&#13;&#10;" width="635" height="178"/></div><p class="figure-caption">图9.9–验证推理端点的A/B测试设置</p><p>在这里，我们可以看到我们的<strong class="bold"> A/B测试</strong>设置工作<a id="_idIndexMarker1905"/>很好。调用invoke_endpoint()函数<a id="_idIndexMarker1906"/>时，有时会调用VariantA其他时候，会调用VariantB。</p><p class="callout-heading">注意</p><p class="callout">同时，不要担心这些预测值意味着什么；我们这里的目标是用<strong class="bold"> A/B测试</strong>设置从已部署模型列表中触发一个随机模型。</p></li>
				<li>Finally, delete the endpoint by using the delete_endpoint() function:<pre>sm_client.<strong class="bold">delete_endpoint</strong>(
    EndpointName=<strong class="bold">endpoint_name</strong>
)</pre><p>不要忘记这一步，因为您将为终端运行的时间付费。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-395"><a id="_idTextAnchor889"/>工作原理……</h2>
			<p>在这个方法中，我们设置了一个支持模型A/B测试的多模型端点<a id="_idIndexMarker1907"/>。这里，我们配置了<a id="_idIndexMarker1908"/>我们的推理端点，将50%的流量传递给第一个模型，将另外50%的流量传递给第二个模型。流量分布是在我们准备生产变量时配置的，如以下代码块所示:</p>
			<pre>variant1 = <strong class="bold">production_variant</strong>(
    model_name=model_name_a,
    variant_name='<strong class="bold">VariantA</strong>',
    initial_weight=<strong class="bold">0.5</strong>,
    ...
)                              
variant2 = <strong class="bold">production_variant</strong>(
    model_name=model_name_b,
    variant_name='<strong class="bold">VariantB</strong>',
    initial_weight=<strong class="bold">0.5</strong>,
    ...
)</pre>
			<p>如果您想知道我们是否可以改变流量分配，使第一个模型接收大约80%的流量，而第二个模型接收大约20%的流量，那么答案将是<em class="italic">是的</em>。对于生产变量A和B，只需将initial_weight值分别更新为0.8和0.2即可。</p>
			<p>如果您也想知道我们是否可以对不同型号系列的型号进行A/B测试，那么答案<a id="_idIndexMarker1909"/>也是<em class="italic">是的</em>。我们只需要在使用这些模型<a id="_idIndexMarker1910"/>准备生产变体之前注册模型，如以下代码行所示:</p>
			<pre>sm_client.<strong class="bold">create_model</strong>(Containers=[<strong class="bold">container1</strong>], ...) 
sm_client.<strong class="bold">create_model</strong>(Containers=[<strong class="bold">container2</strong>], ...)</pre>
			<p>我们所需要做的就是根据预训练模型的模型系列来指定不同的容器图像。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">您可能还想知道为什么create_model()函数中的Containers参数接受列表而不是单个字符串值。这是因为我们可以建立一个包含线性容器序列的推理管道来处理单个端点调用请求。要了解更多信息，请随时查看<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html">https://docs . AWS . Amazon . com/sage maker/latest/DG/inference-pipelines . html</a>。</p>
			<h2 id="_idParaDest-396">还有更多…</h2>
			<p>即使有了A/B测试配置和设置，我们也可以直接调用特定的变体。我们可以通过使用invoke_endpoint()函数并指定我们想要调用的目标变量的名称作为target variant参数的值来实现这一点。以下是执行此操作的示例代码块:</p>
			<pre>response = runtime_sm_client.<strong class="bold">invoke_endpoint</strong>(
    EndpointName=endpoint_name,
    ContentType='text/csv',
    <strong class="bold">TargetVariant</strong>=<strong class="bold">'VariantB'</strong>,
    Body=body
)</pre>
			<p>也就是说，我们可以通过以下一系列步骤来评估每个变体的性能<a id="_idIndexMarker1912"/>:</p>
			<ol>
				<li value="1">当使用invoke_endpoint()函数直接调用每个变量时，使用来自测试数据集的数据作为有效负载。这应该给我们两组不同的预测值，因为我们在这个配方中使用了两个变量。</li>
				<li>使用来自测试数据集的已知目标值和来自端点调用的预测值，我们可以评估每个部署模型的性能，并计算回归模型的<strong class="bold"> RMSE </strong>、<strong class="bold"> MSE </strong>和<strong class="bold"> MAE </strong>，以及分类器模型的<strong class="bold"> AUC </strong>、<strong class="bold">精确度</strong>、<strong class="bold">精确度</strong>和<strong class="bold">召回</strong>。</li>
				<li>一旦我们计算了每个模型的度量值，我们就可以确定哪个模型“更好”</li>
			</ol>
			<p>之后，我们可以为我们部署的每个变体更新流量分布的配置。我们可以通过在SageMaker boto3客户端中使用update _ endpoint _ weights _ and _ capacities()函数来执行这一配置更改。我们<a id="_idIndexMarker1913"/>不会在这本书里深入探究细节，所以请随意查看<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html">https://docs . AWS . Amazon . com/sage maker/latest/DG/model-a b-testing . html</a>了解更多信息。</p>
			<h1 id="_idParaDest-397"><a id="_idTextAnchor891"/>准备步骤功能执行角色</h1>
			<p>在这个菜谱中，我们将创建一个IAM执行<a id="_idIndexMarker1914"/>角色，它将允许我们创建和执行<strong class="bold"> AWS步骤功能</strong>工作流。首先，我们将创建一个具有步骤功能的执行角色，作为AWS服务可信实体类型。然后，我们将向这个角色添加一个<strong class="bold">内联策略</strong>，并为这个执行角色分配必要的权限。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">什么是IAM角色？IAM角色<a id="_idIndexMarker1915"/>是一个IAM身份，用于委托对实体和资源的访问。该角色可由资源承担，以获得执行特定任务所需的权限。在我们的例子中，我们将创建一个具有创建和执行步骤功能工作流权限的角色。该角色将用于<em class="italic">使用AWS步骤功能和数据科学SDK </em>方法管理ML工作流。如需更多信息，请随时查看<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_terms-and-concepts.html">https://docs . AWS . Amazon . com/IAM/latest/user guide/id _ roles _ terms-and-concepts . html</a>。</p>
			<h2 id="_idParaDest-398">准备就绪</h2>
			<p>对于这个菜谱，您将需要创建和管理<strong class="bold"> AWS IAM </strong>角色、策略和其他资源的权限。</p>
			<h2 id="_idParaDest-399"><a id="_idTextAnchor893"/>怎么做……</h2>
			<p>这个方法中的步骤主要是使用AWS控制台准备执行角色。让我们开始吧:</p>
			<ol>
				<li value="1">Navigate to the IAM console using the search bar, similar to what is shown in the following screenshot:<div><img src="img/B16850_09_10.jpg" alt="Figure 9.10 – Navigating to the IAM console&#13;&#10;" width="565" height="301"/></div><p class="figure-caption">图9.10–导航到IAM控制台</p><p>正如我们所看到的，在搜索栏中使用iam作为关键字应该允许我们轻松地搜索IAM <a id="_idIndexMarker1917"/>服务，并直接跳转到IAM控制台。</p></li>
				<li>In the navigation pane, locate and click <strong class="bold">Roles</strong> under <strong class="bold">Access management</strong>:<div><img src="img/B16850_09_11.jpg" alt="Figure 9.11 – Navigating to the Roles page&#13;&#10;" width="287" height="398"/></div><p class="figure-caption">图9.11–导航到角色页面</p><p>正如我们所看到的，我们可以在<strong class="bold">访问管理</strong>下的<strong class="bold">用户</strong>和<strong class="bold">策略</strong>之间找到<strong class="bold">角色</strong>页面的链接。</p></li>
				<li>Click the <strong class="bold">Create role</strong> button, as shown in the following screenshot:<div><img src="img/B16850_09_12.jpg" alt="Figure 9.12 – Create role button&#13;&#10;" width="627" height="160"/></div><p class="figure-caption">图9.12–创建角色按钮</p><p>我们应该看到<strong class="bold"> Create role </strong>按钮，类似于前面的截图，位于页面顶部，导航窗格附近。</p></li>
				<li>Choose <strong class="bold">AWS service</strong> under <strong class="bold">Select type of trusted entity</strong>:<div><img src="img/B16850_09_13.jpg" alt="Figure 9.13 – Choosing the AWS service trusted entity type&#13;&#10;" width="1461" height="623"/></div><p class="figure-caption">图9.13–选择AWS服务可信实体类型</p><p>这里，我们从可信实体类型列表<a id="_idIndexMarker1918"/>中选择了<strong class="bold"> AWS服务</strong>。</p></li>
				<li>Under <strong class="bold">Choose a use case</strong>, select <strong class="bold">Step Functions</strong>:<div><img src="img/B16850_09_14.jpg" alt="Figure 9.14 – Choosing a use case&#13;&#10;" width="791" height="412"/></div><p class="figure-caption">图9.14–选择一个用例</p><p>如我们所见，我们选择了<strong class="bold">步进功能</strong>(右下角)。因为服务是按字母顺序排序的，所以应该相对容易找到。</p></li>
				<li>Click the <strong class="bold">Next: Permissions</strong> button:<div><img src="img/B16850_09_15.jpg" alt="Figure 9.15 – Locating the Next: Permissions button&#13;&#10;" width="585" height="133"/></div><p class="figure-caption">图9.15–定位下一个:权限按钮</p><p>请注意，我们可能需要将<a id="_idIndexMarker1919"/>向下滚动到页面底部，才能看到前面截图中显示的<strong class="bold"> Next: Permissions </strong>按钮。</p></li>
				<li>Click the <strong class="bold">Next: Tags</strong> button at the bottom of the page, as shown in the following screenshot:<div><img src="img/B16850_09_16.jpg" alt="Figure 9.16 – Locating the Next: Tags button (bottom right)&#13;&#10;" width="1464" height="798"/></div><p class="figure-caption">图9.16–定位下一个:标签按钮(右下方)</p><p>在这里，我们可以看到一个附加的权限策略。请注意，默认附加的权限策略不足以创建和执行<strong class="bold">步骤功能</strong>工作流。在本菜谱的后面，我们将为该角色附加一个自定义内联策略，这将帮助我们执行<em class="italic">使用AWS步骤函数和Data Science SDK </em>管理ML工作流中所需的步骤。</p></li>
				<li>在<strong class="bold">添加标签(可选)</strong>页面上，点击<strong class="bold">下一步:查看</strong>按钮。</li>
				<li>On the <strong class="bold">Create Role — Review</strong> page, specify the <strong class="bold">Role name</strong> value (for example, sf-execution-role). Click the <strong class="bold">Create role</strong> button afterward:<div><img src="img/B16850_09_17.jpg" alt="Figure 9.17 – Review page&#13;&#10;" width="1250" height="979"/></div><p class="figure-caption">图9.17–审查页面</p><p>正如我们所看到的，我们可以在这个页面上<a id="_idIndexMarker1920"/>指定角色名称和描述。</p></li>
				<li>A success notification will appear, similar to what is shown in the following screenshot. Click the link (for example, <strong class="bold">sf-execution-role</strong> in this case) to view and modify the details and configure the role:<div><img src="img/B16850_09_18.jpg" alt="Figure 9.18 – Role successfully created success notification&#13;&#10;" width="608" height="150"/></div><p class="figure-caption">图9.18-角色成功创建成功通知</p><p>或者，通过使用角色名称搜索角色来导航到特定角色页面。</p><p>接下来的一组步骤集中在为我们在这个菜谱的前半部分创建的角色添加一个带有额外权限的内联策略。</p></li>
				<li>在<code/>里面</li></ol></div><p class="figure-caption">图9.19–定位添加内嵌策略按钮</p><p>在这里，我们可以看到<strong class="bold">添加内嵌策略按钮<a id="_idIndexMarker1921"/>位于<strong class="bold">权限</strong>选项卡的右上角。</strong></p>
				<li>Navigate to the <strong class="bold">JSON</strong> tab, as shown in the following screenshot:<div><img src="img/B16850_09_20.jpg" alt="Figure 9.20 – Create policy JSON tab&#13;&#10;" width="1643" height="653"/></div><p class="figure-caption">图9.20–创建策略JSON选项卡</p><p>在这里，我们可以看到，我们可以直接编辑JSON策略，而不必使用<strong class="bold">可视化编辑器</strong>选项卡。</p></li>
				<li>Open a new browser tab. Navigate to the <strong class="bold">Machine-Learning-with-Amazon-SageMaker-Cookbook</strong> GitHub repository and copy the JSON value from the <strong class="bold">05 – Preparing the Step Functions Execution Role.ipynb</strong> notebook:<div><img src="img/B16850_09_21.jpg" alt="Figure 9.21 – JSON policy from this book's GitHub repository&#13;&#10;" width="1593" height="1003"/></div><p class="figure-caption">图9.21–本书GitHub资源库中的JSON策略</p><p>您可以决定从呈现的<strong class="bold">05-准备步骤函数执行Role.ipynb </strong>笔记本中复制JSON <a id="_idIndexMarker1922"/>策略，如前面的截图所示，或者使用Chapter09目录中的files/role.json文件中的策略JSON。</p><p class="callout-heading">小费</p><p class="callout">你可以在这里找到JSON策略:<a href="https://github.com/PacktPublishing/Machine-Learning-with-Amazon-SageMaker-Cookbook/tree/master/Chapter09">https://github . com/packt publishing/Machine-Learning-with-Amazon-sage maker-Cookbook/tree/master/chapter 09</a>。请注意，在将此策略用于生产环境之前，需要用更安全的配置对其进行审查和更新。</p></li>
				<li>Navigate back to the AWS console browser tab. Paste the JSON value we copied in the previous step into the text area shown in the following screenshot:<div><img src="img/B16850_09_22.jpg" alt="Figure 9.22 – Create policy JSON tab with the JSON policy value in the text area&#13;&#10;" width="1637" height="827"/></div><p class="figure-caption">图9.22–使用文本区域中的JSON策略值创建策略JSON选项卡</p><p>在这里，我们可以看到，当在<strong class="bold">可视化编辑器</strong>上使用该选项时，我们可以指定某个<a id="_idIndexMarker1923"/>级别的粒度。在文本区域中更新JSON策略值后，单击<strong class="bold"> Review policy </strong>按钮。</p></li>
				<li>在<strong class="bold">查看策略</strong>页面上，指定策略的名称(例如，sf-policy)。之后点击<strong class="bold">创建策略</strong>按钮。</li>
				<li>复制<strong class="bold">角色ARN </strong>值，如下截图所示:</li>
			
			<div><div><img src="img/B16850_09_23.jpg" alt="Figure 9.23 – Copying the role ARN from the Summary page&#13;&#10;" width="1397" height="837"/>
				</div>
			</div>
			<p class="figure-caption">图9.23–从摘要页面复制角色ARN</p>
			<p>请随意将该值复制到文本文件中。它的格式应该类似于arn:AWS:iam::01234567890:role/SF-execution-role。我们将在<em class="italic">使用AWS步骤函数和Data Science SDK </em>方法管理ML工作流中使用该ARN值。</p>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-400"><a id="_idTextAnchor894"/>工作原理……</h2>
			<p>在这个配方中，我们准备了一个<strong class="bold"> IAM角色</strong>，它将在我们初始化下一个配方中的工作流对象时使用。如果没有正确配置该角色，我们将无法使用<em class="italic">使用AWS步骤功能管理ML工作流中的<strong class="bold">步骤功能数据科学SDK </strong>和数据科学SDK </em>方法创建和执行<strong class="bold">步骤功能</strong>工作流。</p>
			<p>一旦我们创建了IAM角色，我们就创建并附加了一个内嵌策略，该策略允许承担角色的实体创建、执行和管理步骤功能工作流。什么是<strong class="bold">内联策略</strong>呢？内嵌策略<a id="_idIndexMarker1925"/>是与角色、用户或组相关联的策略，在防止策略的权限意外分配给另一个身份时非常有用。有关该主题的更多信息，请在此处查看托管策略和内联策略之间的差异<a id="_idIndexMarker1926"/>:<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html">https://docs . AWS . Amazon . com/IAM/latest/user guide/access _ policies _ managed-vs-inline . html</a>。</p>
			<h1 id="_idParaDest-401"><a id="_idTextAnchor895"/>使用AWS Step函数和Data Science SDK管理ML工作流</h1>
			<p><strong class="bold"> AWS步骤功能</strong>是一个无服务器的<a id="_idIndexMarker1927"/>编排服务，帮助使用多个AWS服务集成和排序任务。有了这项服务，我们只需专注于配置工作流，减少管理分布式复杂应用程序的运营开销。</p>
			<p>在这个菜谱中，我们将使用<strong class="bold">数据科学SDK </strong>来创建和管理<a id="_idIndexMarker1928"/>自动化ML工作流<a id="_idIndexMarker1929"/>和<strong class="bold"> AWS步骤函数</strong>。我们将在<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第一章</em> </a>、<em class="italic">使用亚马逊SageMaker </em>开始机器学习的<a id="_idIndexMarker1931"/>的基础上构建<a id="_idIndexMarker1930"/>，在那里我们训练并部署了一个<strong class="bold">线性学习器</strong>模型来解决一个回归问题。一旦我们完成了这个配方中的步骤，我们将能够使用<strong class="bold">步骤功能</strong>状态机执行端到端的自动化工作流程，而无需在Jupyter笔记本中手动运行脚本。</p>
			<h2 id="_idParaDest-402">准备就绪</h2>
			<p>以下是这个食谱的先决条件:</p>
			<ul>
				<li>你需要一台运行<strong class="bold"> Python 3(数据科学)</strong>内核的<strong class="bold"> SageMaker Studio </strong>笔记本。</li>
				<li>确保与<strong class="bold"> SageMaker Studio </strong>关联的执行角色拥有使用<strong class="bold"> AWS步骤功能</strong>资源的必要权限。您可能需要将AWSStepFunctionsFullAccess策略附加到上述执行角色。</li>
			</ul>
			<h2 id="_idParaDest-403"><a id="_idTextAnchor897"/>怎么做……</h2>
			<p>该配方<a id="_idIndexMarker1933"/>中的第一组<a id="_idIndexMarker1932"/>步骤集中于为<strong class="bold">步骤功能</strong>工作流程<a id="_idIndexMarker1935"/>准备好先决条件<a id="_idIndexMarker1934"/>。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter09目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为该配方的名称(使用AWS Step函数和数据科学SDK管理ML工作流)。</li>
				<li>如果tmp目录尚不存在，使用mkdir命令创建该目录:<pre>!mkdir -p <strong class="bold">tmp</strong></pre></li>
				<li>准备path变量，使其指向将在该配方中使用的CSV文件的位置:<pre>g = "raw.githubusercontent.com" p = "PacktPublishing" a = "Machine-Learning-with-Amazon-SageMaker-Cookbook" mc = "master/Chapter01" <strong class="bold">path</strong> = f"https://{g}/{p}/{a}/{mc}/files"</pre></li>
				<li>Use the wget command to download the CSV file from this book's GitHub repository to the tmp directory:<pre>fname = "<strong class="bold">management_experience_and_salary.csv</strong>"
!wget -P tmp {path}/{fname}</pre><p>注意，这是我们在第一章 、<em class="italic">使用亚马逊SageMaker </em>的机器学习入门中使用的同一个CSV文件。</p></li>
				<li>使用pandas的read_csv()函数<a id="_idIndexMarker1936"/>到<a id="_idIndexMarker1937"/>将csv文件<a id="_idIndexMarker1939"/>的内容<a id="_idIndexMarker1938"/>加载到数据帧:<pre>import pandas as pd filename = f"tmp/{fname}" <strong class="bold">df_all_data</strong> = pd.read_csv(filename)</pre></li>
				<li>使用sklearn: <pre>from sklearn.model_selection import train_test_split dad = <strong class="bold">df_all_data</strong> X = dad['<strong class="bold">management_experience_months</strong>'].values  y = dad[<strong class="bold">'monthly_salary</strong>'].values <strong class="bold">X_train</strong>, <strong class="bold">X_test</strong>, <strong class="bold">y_train</strong>, <strong class="bold">y_test</strong> = <strong class="bold">train_test_split</strong>(     X, y,      test_size=0.3, random_state=0 )</pre>中的train_test_split()函数执行训练测试分割</li>
				<li>准备包含训练数据的数据帧。注意，第一列包含目标变量值(例如，monthly_salary): <pre>import pandas as pd <strong class="bold">df_training_data</strong> = pd.DataFrame({      '<strong class="bold">monthly_salary</strong>': y_train,      '<strong class="bold">management_experience_months</strong>': X_train })</pre></li>
				<li>使用to_csv()函数<a id="_idIndexMarker1940"/>将df_training_data数据帧<a id="_idIndexMarker1943"/>的内容<a id="_idIndexMarker1942"/>存储到<pre>df_training_data.<strong class="bold">to_csv</strong>(     'tmp/<strong class="bold">training_data.csv</strong>',      header=False, index=False )</pre>CSV文件中</li>
				<li>指定将存储数据的S3时段名称和前缀。确保将<insert s3="" bucket="" name="" here="">的值替换为我们在<em class="italic">准备亚马逊S3桶和线性回归实验的训练数据集</em>配方<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020"> <em class="italic">第1章</em> </a> <em class="italic">中创建的桶的名称，使用亚马逊SageMaker </em> : <pre>s3_bucket = '<strong class="bold">&lt;insert s3 bucket name here&gt;</strong>' prefix = 'chapter09'</pre></insert></li>
				<li>使用<strong class="bold"> AWS CLI </strong>将tmp目录下的training_data.csv文件上传到S3 bucket: <pre>tn = "<strong class="bold">training_data.csv</strong>" source = f"tmp/{tn}" dest = f"s3://{s3_bucket}/{prefix}/input/{tn}" !aws s3 cp {source} {dest}</pre></li>
				<li>从<strong class="bold">SageMaker Python SDK</strong>:<pre>import sagemaker  import boto3 from sagemaker import get_execution_role  role = get_execution_role() session = sagemaker.Session() region_name = boto3.Session().region_name</pre>中导入并准备一些先决条件，如会话、角色等</li>
				<li>准备<a id="_idIndexMarker1944"/>训练_ S3 _输入_位置和训练_ S3 _输出_位置的变量值:<pre><strong class="bold">training_s3_input_location</strong> = f"s3://{s3_bucket}/{prefix}/input/training_data.csv"  <strong class="bold">training_s3_output_location</strong> = f"s3://{s3_bucket}/{prefix}/output/"</pre></li>
				<li>准备<a id="_idIndexMarker1945"/>训练输入对象<a id="_idIndexMarker1946"/>用于训练<a id="_idIndexMarker1947"/>数据:<pre>from sagemaker.inputs import TrainingInput train = <strong class="bold">TrainingInput</strong>(     training_s3_input_location,      content_type="text/csv" )</pre></li>
				<li>Use the retrieve() function to get the container<a id="_idIndexMarker1948"/> image URI for <strong class="bold">linear learner</strong>:<pre>from sagemaker.image_uris import <strong class="bold">retrieve</strong> 
container = <strong class="bold">retrieve</strong>(
    "<strong class="bold">linear-learner</strong>", 
    region_name, "1"
)
container</pre><p>容器变量的值应该等于或类似于382416733822 . dkr . ECR . us-east-1 . Amazon AWS . com/linear-learner:1。</p><p>该配方中的下一组<a id="_idIndexMarker1949"/>步骤<a id="_idIndexMarker1950"/>集中于<a id="_idIndexMarker1951"/>准备和执行<a id="_idIndexMarker1952"/>步骤功能<strong class="bold">工作流程:</strong></p></li>
				<li>初始化评估器对象:<pre>estimator = sagemaker.estimator.<strong class="bold">Estimator</strong>(     container,     role,      instance_count=1,      instance_type='ml.m5.xlarge',     output_path=training_s3_output_location,     sagemaker_session=session )</pre></li>
				<li>使用set_hyperparameters()函数配置超参数值:<pre>estimator.<strong class="bold">set_hyperparameters</strong>(     predictor_type='regressor',      mini_batch_size=4 )</pre></li>
				<li>使用pip安装<strong class="bold"> AWS Step函数Data Science SDK </strong> : <pre>!<strong class="bold">pip</strong> -q install --upgrade <strong class="bold">stepfunctions</strong></pre></li>
				<li>Set the variable<a id="_idIndexMarker1953"/> value of execution_role to the ARN<a id="_idIndexMarker1954"/> of the IAM role ARN we prepared in the <em class="italic">Preparing the Step Functions execution role</em> recipe:<pre>execution_role = '<strong class="bold">&lt;insert role arn here&gt;</strong>'</pre><p>execution_role变量值的格式应该类似于arn:AWS:iam::01234567890:role/SF-execution-role。</p><p class="callout-heading">重要说明</p><p class="callout">在继续下一组步骤之前，确保与<strong class="bold"> SageMaker Studio </strong>关联的执行角色拥有使用和创建<strong class="bold"> AWS步骤功能</strong>资源的必要权限。您可以将AWSStepFunctionsFullAccess策略附加到所述执行角色。</p></li>
				<li>初始化<a id="_idIndexMarker1955"/>execution input对象:<pre>from stepfunctions.inputs import ExecutionInput execution_input = <strong class="bold">ExecutionInput</strong>(     schema={          'ModelName': str,         'EndpointName': str,         'JobName': str     } )      ei = execution_input</pre></li>
				<li>初始化<a id="_idIndexMarker1956"/>的<a id="_idIndexMarker1957"/>训练步骤对象:<pre>from stepfunctions.steps import <strong class="bold">TrainingStep</strong> training_step = <strong class="bold">TrainingStep</strong>(     'Training Step',      estimator=estimator,     data={         'train': train     },     job_name=ei['<strong class="bold">JobName</strong>'] )</pre></li>
				<li>初始化<a id="_idIndexMarker1958"/>的<a id="_idIndexMarker1959"/>模型步骤对象:<pre>from stepfunctions.steps import <strong class="bold">ModelStep</strong> model_step = <strong class="bold">ModelStep</strong>(     'Model Step',     model=training_step.get_expected_model(),     model_name=ei['ModelName']   )</pre></li>
				<li>接下来，初始化<a id="_idIndexMarker1960"/>EndpointConfigStep对象:<pre>from stepfunctions.steps import <strong class="bold">EndpointConfigStep</strong> endpoint_config_step = EndpointConfigStep(     "Create Endpoint Configuration",     endpoint_config_name=ei['ModelName'],     model_name=ei['ModelName'],     initial_instance_count=1,     instance_type='ml.m5.xlarge' )</pre></li>
				<li>Initialize<a id="_idIndexMarker1961"/> the<a id="_idIndexMarker1962"/> EndpointStep object:<pre>from stepfunctions.steps import EndpointStep
endpoint_step = <strong class="bold">EndpointStep</strong>(
    "Deploy Endpoint",
    endpoint_name=ei['EndpointName'],
    endpoint_config_name=ei['ModelName']
)</pre><p class="callout-heading">注意</p><p class="callout">如果您想知道TrainingStep、ModelStep、EndpointConfigStep和EndpointStep的用途，请不要担心，我们将在<em class="italic">其工作原理……</em>部分讨论这些内容。</p></li>
				<li>初始化链对象。这个<a id="_idIndexMarker1963"/>将用于连接<a id="_idIndexMarker1964"/>我们<a id="_idIndexMarker1965"/>在前一组步骤<pre>from stepfunctions.steps import Chain workflow_definition = <strong class="bold">Chain</strong>([     <strong class="bold">training_step</strong>,     <strong class="bold">model_step</strong>,     <strong class="bold">endpoint_config_step</strong>,     <strong class="bold">endpoint_step</strong> ])</pre>中准备的TrainingStep、ModelStep、EndpointConfigStep和EndpointStep对象</li>
				<li>定义generate_random_string()函数:<pre>import uuid      def <strong class="bold">generate_random_string</strong>():     return uuid.uuid4().hex      <strong class="bold">grs</strong> = generate_random_string</pre></li>
				<li>初始化<a id="_idIndexMarker1966"/>工作流对象:<pre>from stepfunctions.workflow import Workflow workflow = <strong class="bold">Workflow</strong>(     name='{}-{}'.format('Workflow', grs()),     definition=workflow_definition,     role=execution_role,     execution_input=execution_input )</pre></li>
				<li>Create<a id="_idIndexMarker1967"/> the workflow<a id="_idIndexMarker1968"/> using<a id="_idIndexMarker1969"/> the create() function:<pre>workflow.<strong class="bold">create</strong>()</pre><p class="callout-heading">重要说明</p><p class="callout">如果在调用create()函数时遇到AccessDeniedException，请确保与<strong class="bold"> SageMaker Studio </strong>关联的执行角色拥有创建<strong class="bold"> AWS步骤函数</strong>资源的必要权限。您可以将AWSStepFunctionsFullAccess策略附加到所述执行角色来解决此问题。</p></li>
				<li>Use the execute() function to execute the workflow:<pre>execution = <strong class="bold">workflow.execute</strong>(
    inputs={
        '<strong class="bold">JobName</strong>': 'll-{}'.format(grs()),
        '<strong class="bold">ModelName</strong>': 'll-{}'.format(grs()),
        '<strong class="bold">EndpointName</strong>': 'll-{}'.format(grs())
    }
)</pre><p class="callout-heading">小费</p><p class="callout">要检查和调试执行工作流的配置，可以运行print(workflow . definition . to _ JSON(pretty = True))。</p></li>
				<li>Navigate back to the Studio<a id="_idIndexMarker1970"/> notebook and use<a id="_idIndexMarker1971"/> the list_events() function<a id="_idIndexMarker1972"/> to get more<a id="_idIndexMarker1973"/> details on the execution:<pre>import pandas as pd
events = execution.<strong class="bold">list_events</strong>()
pd.<strong class="bold">json_normalize</strong>(events)</pre><p>这将为我们提供一个值的数据框架，类似于下面的屏幕截图所示:</p></li>
			</ol>
			<div><div><img src="img/B16850_09_24.jpg" alt="Figure 9.24 – Execution event details&#13;&#10;" width="927" height="203"/>
				</div>
			</div>
			<p class="figure-caption">图9.24–执行事件详细信息</p>
			<p>在这里，我们对步骤函数工作流中每个步骤的进度有了更好的了解。此时，我们需要做的就是等待工作流的执行完成。如果我们需要再次执行这个工作流，我们需要做的就是使用Workflow.attach()和execute()函数将它附加到一个现有的状态机。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">不要忘记删除在这个配方中创建的推理端点，因为工作流会自动训练和部署模型。</p>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-404"><a id="_idTextAnchor898"/>它是如何工作的……</h2>
			<p>自动化机器学习工作流允许数据科学和MLOps团队显著加快训练和部署机器学习模型的过程。在这个菜谱中，我们使用了<strong class="bold"> Data Science SDK </strong>来使用Python代码自动生成一个Step Functions工作流状态机。通过这种方法，可以很容易地将现有的使用<strong class="bold"> SageMaker Python SDK </strong>的<a id="_idIndexMarker1974"/>笔记本转换为使用<strong class="bold">步骤函数</strong>和<strong class="bold">数据科学SDK </strong>的自动化工作流<a id="_idIndexMarker1976"/>。在<strong class="bold"> AWS步骤函数Data Science SDK </strong>中有几个类映射到机器学习工作流中的相应步骤或任务:</p>
			<ul>
				<li>TrainingStep:这侧重于执行一个训练作业来构建一个机器学习模型。</li>
				<li>ModelStep:这主要是在SageMaker中创建和注册一个模型。</li>
				<li>TransformStep:这主要是执行一个SageMaker <strong class="bold">批处理转换</strong>作业，它使用一个经过训练的模型来获得推理，而不需要一个实时的推理端点。</li>
				<li>EndpointConfigStep:这侧重于创建端点配置。</li>
				<li>EndpointStep:这主要是创建或更新一个推理端点。</li>
				<li>TuningStep:这主要是执行一个<strong class="bold">自动模型调整</strong>任务。</li>
				<li>处理步骤:这主要是执行一个<strong class="bold"> SageMaker处理</strong>任务。</li>
			</ul>
			<p>如果我们将<a id="_idIndexMarker1978"/>导航到Step Functions控制台，我们将看到状态机执行的可视化工作流图，类似于下图所示。在这里，我们可以看到我们已经自动执行了本书前面章节中手动运行的步骤:</p>
			<div><div><img src="img/B16850_09_25.jpg" alt="Figure 9.25 – Step Functions visual workflow&#13;&#10;" width="493" height="427"/>
				</div>
			</div>
			<p class="figure-caption">图9.25–步骤功能可视化工作流程</p>
			<p>在图9.25中，我们可以看到所有的步骤都已成功完成。如果您想知道我们是否可以使用不同的AWS服务以及<a id="_idIndexMarker1979"/>条件分支逻辑来设计更复杂的步骤函数工作流，那么答案<a id="_idIndexMarker1980"/>将是<em class="italic">是</em>。请注意，我们还可以在工作流中创建执行的并行分支，以及在出现运行时错误时处理错误情况。我们不会在本书中深入<a id="_idIndexMarker1983"/>使用<strong class="bold">步骤函数</strong>的细节，所以可以随意查看<a href="https://docs.aws.amazon.com/step-functions/latest/dg/how-step-functions-works.html">https://docs . AWS . Amazon . com/Step-Functions/latest/DG/how-Step-Functions-works . html</a>以了解更多信息。</p>
			<h2 id="_idParaDest-405"><a id="_idTextAnchor899"/>参见</h2>
			<p>如果您正在寻找在真实数据集<a id="_idIndexMarker1984"/>上使用<strong class="bold">步骤函数</strong>和<strong class="bold">数据科学SDK </strong>的示例以及更复杂的示例，请在此随意查看一些关注此主题的示例:<a href="https://sagemaker-examples.readthedocs.io/en/latest/step-functions-data-science-sdk/index.html">https://sagemaker-examples . readthedocs . io/en/latest/Step-Functions-Data-Science-SDK/index . html</a>。</p>
			<h1 id="_idParaDest-406"><a id="_idTextAnchor900"/>使用SageMaker管道管理ML工作流程</h1>
			<p><strong class="bold"> SageMaker Pipelines </strong>是一个专门构建的CI/CD <a id="_idIndexMarker1985"/>和编排<a id="_idIndexMarker1986"/>服务，有助于自动化、管理和重用<a id="_idIndexMarker1987"/>机器学习工作流。它与SageMaker的不同特性和功能紧密集成，这使得数据科学家和机器学习工程师可以轻松地使用它来满足SageMaker服务的<strong class="bold"> MLOps </strong>需求。</p>
			<p>在本菜谱中，我们将使用<strong class="bold"> SageMaker Pipelines </strong>来创建和管理自动化的ML工作流程。我们将使用一个简化的示例，该示例包括一个处理步骤的顺序工作流，随后是一个培训步骤。处理步骤利用<strong class="bold"> SageMaker处理</strong>来执行训练-测试分割，而训练步骤集中于使用由处理步骤准备的训练数据来训练<strong class="bold">线性学习器</strong>模型。一旦我们完成了这个配方中的步骤，我们将能够使用<strong class="bold"> SageMaker Pipelines </strong>执行端到端的自动化管道，而无需在Jupyter笔记本中手动运行脚本。</p>
			<h2 id="_idParaDest-407">准备就绪</h2>
			<p>对于这个食谱，你需要一个运行Python 3(数据科学)内核的笔记本。</p>
			<h2 id="_idParaDest-408"><a id="_idTextAnchor902"/>怎么做……</h2>
			<p>这个配方主要是使用<strong class="bold"> SageMaker管道</strong>创建和执行一个基本的工作流程。让我们开始吧:</p>
			<ol>
				<li value="1">在my-experiments/chapter09目录中使用Python 3(数据科学)内核创建一个新的笔记本，并将其重命名为该配方的名称(使用SageMaker管道管理ML工作流)。</li>
				<li>如果tmp目录尚不存在，使用mkdir命令创建该目录:<pre>!mkdir -p <strong class="bold">tmp</strong></pre></li>
				<li>准备路径变量<a id="_idIndexMarker1988"/>，使其指向本配方中使用的CSV文件的位置:<pre>g = "raw.githubusercontent.com" p = "PacktPublishing" a = "Machine-Learning-with-Amazon-SageMaker-Cookbook" mc = "master/Chapter01" <strong class="bold">path</strong> = f"https://{g}/{p}/{a}/{mc}/files"</pre></li>
				<li>使用wget命令将CSV文件下载到tmp目录:<pre>csv = "<strong class="bold">management_experience_and_salary.csv</strong>" !wget -P <strong class="bold">tmp</strong> {path}/{csv}</pre></li>
				<li>指定S3存储桶的名称<a id="_idIndexMarker1989"/>和存储数据的前缀。确保将&lt; insert s3 bucket name here &gt;的值替换为我们在第一章  <em class="italic">的<em class="italic">准备亚马逊s3 bucket和线性回归实验的训练数据集</em>中创建的bucket的名称<a href="B16850_01_Final_ASB_ePub.xhtml#_idTextAnchor020">:<pre>s3_bucket = '<strong class="bold">&lt;insert s3 bucket name here&gt;</strong>' prefix = 'chapter09' <strong class="bold">input_data_uri</strong> = f"s3://{s3_bucket}/{prefix}/input/{csv}"</pre></a></em></li>
				<li>使用<strong class="bold"> AWS CLI </strong>将CSV文件从tmp目录上传到S3桶:<pre>!aws s3 cp tmp/{csv} {<strong class="bold">input_data_uri</strong>}</pre></li>
				<li>准备与处理实例类型、培训实例类型、输入数据的S3位置的工作流参数值对应的ParameterString对象:<pre>from sagemaker.workflow.parameters import (     ParameterInteger,     ParameterString, ) <strong class="bold">processing_instance_type</strong> = <strong class="bold">ParameterString</strong>(     name="<strong class="bold">ProcessingInstanceType</strong>",      default_value="ml.m5.xlarge" ) <strong class="bold">training_instance_type</strong> = <strong class="bold">ParameterString</strong>(     name="<strong class="bold">TrainingInstanceType</strong>",      default_value="ml.m5.xlarge" ) <strong class="bold">input_data</strong> = <strong class="bold">ParameterString</strong>(     name="<strong class="bold">InputData</strong>",     default_value=input_data_uri, )</pre></li>
				<li>从<strong class="bold">SageMaker Python SDK</strong>:<pre>from sagemaker import get_execution_role  <strong class="bold">role</strong> = get_execution_role()</pre>中导入并准备<a id="_idIndexMarker1990"/>一些先决条件，如<a id="_idIndexMarker1991"/>角色</li>
				<li>准备path变量，使它指向preprocessing.py脚本文件在本书的GitHub存储库中的位置:<pre>g = "raw.githubusercontent.com" p = "PacktPublishing" a = "Machine-Learning-with-Amazon-SageMaker-Cookbook" mc = "master/Chapter09" <strong class="bold">path</strong> = f"https://{g}/{p}/{a}/{mc}/scripts"</pre></li>
				<li>Download the preprocessing.py script file from this book's GitHub repository to the tmp directory:<pre>!wget -P tmp {path}/<strong class="bold">preprocessing.p</strong>y</pre><p>这应该<a id="_idIndexMarker1992"/>在tmp目录中下载一个文件，类似于下面截图中显示的<a id="_idIndexMarker1993"/>。我们可以使用<strong class="bold">文件浏览器</strong>检查tmp/preprocessing.py的内容:</p><div><img src="img/B16850_09_26.jpg" alt="Figure 9.26 – preprocessing.py&#13;&#10;" width="510" height="304"/></div><p class="figure-caption">图9.26-预处理. py</p><p>preprocessing.py脚本文件侧重于执行训练-测试分割和准备训练数据CSV文件，以便为训练作业做好准备。</p></li>
				<li>初始化SKLearnProcessor对象:<pre>from sagemaker.sklearn.processing import SKLearnProcessor      framework_version = "0.23-1" sklearn_processor = <strong class="bold">SKLearnProcessor</strong>(     framework_version=framework_version,     instance_type=processing_instance_type,     instance_count=1,     role=role, )</pre></li>
				<li>初始化<a id="_idIndexMarker1994"/>的<a id="_idIndexMarker1995"/>处理步骤对象:<pre>from sagemaker.processing import ProcessingInput, ProcessingOutput from sagemaker.workflow.steps import ProcessingStep      <strong class="bold">step_process</strong> = <strong class="bold">ProcessingStep</strong>(     name="ProcessingStep",     processor=sklearn_processor,     inputs=[         ProcessingInput(             source=input_data,              destination="/opt/ml/processing/input"         ),     ],     outputs=[         ProcessingOutput(             output_name="output",              source="/opt/ml/processing/output"         ),     ],     code="tmp/<strong class="bold">preprocessing.py</strong>", )</pre></li>
				<li>从<strong class="bold">SageMaker Python SDK</strong>:<pre>import sagemaker  import boto3      <strong class="bold">session</strong> = sagemaker.Session() <strong class="bold">region_name</strong> = boto3.Session().region_name</pre>中导入<a id="_idIndexMarker1996"/>并准备一些<a id="_idIndexMarker1997"/>先决条件，如session和region_name</li>
				<li>初始化评估对象，并使用set_hyperparameters()函数指定超参数:<pre>from sagemaker.image_uris import retrieve  model_path = f"s3://{s3_bucket}/{prefix}/model" container = <strong class="bold">retrieve</strong>(     "linear-learner",      region_name, "1" ) <strong class="bold">estimator</strong> = sagemaker.estimator.<strong class="bold">Estimator</strong>(     container,     role,      instance_count=1,      instance_type='ml.m5.xlarge',     output_path=model_path,     sagemaker_session=session ) estimator.<strong class="bold">set_hyperparameters</strong>(     predictor_type='regressor',      mini_batch_size=4 )</pre></li>
				<li>初始化<a id="_idIndexMarker1998"/>的<a id="_idIndexMarker1999"/>训练步骤对象:<pre>from sagemaker.inputs import TrainingInput from sagemaker.workflow.steps import TrainingStep <strong class="bold">s3_input_data</strong> = step_process.properties.ProcessingOutputConfig.Outputs["output"].S3Output.S3Uri <strong class="bold">step_train</strong> = <strong class="bold">TrainingStep</strong>(     name="TrainStep",     estimator=estimator,     inputs={         "train": TrainingInput(             s3_data=s3_input_data,             content_type="text/csv",         )     }, )</pre></li>
				<li>初始化<a id="_idIndexMarker2000"/>管道对象:<pre>from sagemaker.workflow.pipeline import Pipeline <strong class="bold">pipeline</strong> = <strong class="bold">Pipeline</strong>(     name="Pipeline",     <strong class="bold">parameters</strong>=[         processing_instance_type,         training_instance_type,         input_data,     ],     <strong class="bold">steps</strong>=[<strong class="bold">step_process</strong>, <strong class="bold">step_train</strong>], )</pre></li>
				<li>使用upsert()函数<a id="_idIndexMarker2001"/>将我们在前面步骤中准备的管道定义<a id="_idIndexMarker2002"/>提交给<strong class="bold"> SageMaker管道</strong>服务。如果管道还不存在，这将创建一个管道:<pre>pipeline.<strong class="bold">upsert</strong>(role_arn=role)</pre></li>
				<li>Start the pipeline's execution using the start() function:<pre>execution = pipeline.<strong class="bold">start</strong>()</pre><p class="callout-heading">注意</p><p class="callout">请注意，start()函数不会等待管道完成执行。您可能会惊讶地发现，运行前面一行代码只需要一秒钟或更少的时间就可以完成！在幕后，管道仍在运行，完成整个过程大约需要8到15分钟。</p></li>
				<li>Use the describe() function to inspect the pipeline's execution: <pre>execution.<strong class="bold">describe</strong>()</pre><p>这将为我们提供一个嵌套的值字典，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_09_27.jpg" alt="Figure 9.27 – Results of execution.describe()&#13;&#10;" width="1214" height="449"/></div><p class="figure-caption">图9.27–执行的结果</p><p>在这里，我们可以看到管道的执行状态仍然是“正在执行”。</p></li>
				<li>Call the wait() function<a id="_idIndexMarker2003"/> to wait for the execution<a id="_idIndexMarker2004"/> to complete:<pre>execution.<strong class="bold">wait</strong>()</pre><p class="callout-heading">注意</p><p class="callout">完成此步骤大约需要8到15分钟。在等待的时候，请随意喝杯咖啡或茶！</p><p>接下来的几个步骤主要是检查我们在前面的步骤中创建的管道:</p></li>
				<li>Use the list_steps() function to inspect the progress of the steps in our execution workflow:<pre>execution.<strong class="bold">list_steps</strong>()</pre><p>这应该会给我们一个字典列表，类似于下面的截图所示:</p><div><img src="img/B16850_09_28.jpg" alt="Figure 9.28 – Results of execution.list_steps()&#13;&#10;" width="1333" height="263"/></div><p class="figure-caption">图9.28–执行结果. list_steps()</p><p>从<em class="italic">图9.28 </em>中可以看到，加工步骤和训练步骤已经成功。</p></li>
				<li>Use LineageTableVisualizer to see<a id="_idIndexMarker2005"/> the input and output<a id="_idIndexMarker2006"/> artifacts that are connected to the execution steps in the workflow:<pre>import time
from sagemaker.lineage.visualizer import LineageTableVisualizer
session = sagemaker.session.Session()
viz = <strong class="bold">LineageTableVisualizer</strong>(session)
ess = reversed(execution.list_steps())
    
for execution_step in ess:
    print(execution_step)
    display(viz.show(
        pipeline_execution_step=execution_step
    ))
    time.sleep(3)</pre><p>这将为我们提供字典和值表，类似于下面的屏幕截图所示:</p><div><img src="img/B16850_09_29.jpg" alt="Figure 9.29 – Using LineageTableVisualizer&#13;&#10;" width="1104" height="588"/></div><p class="figure-caption">图9.29–使用LineageTableVisualizer</p><p>在这里，我们可以看到<a id="_idIndexMarker2007"/>与工作流中的执行步骤相关联的工件和资源<a id="_idIndexMarker2008"/>。</p></li>
				<li>Navigate to the <strong class="bold">Components and registries</strong> tab and locate the pipeline we just created in this recipe:<div><img src="img/B16850_09_30.jpg" alt="Figure 9.30 – Components and registries&#13;&#10;" width="337" height="425"/></div><p class="figure-caption">图9.30-组件和注册表</p><p>为了找到我们在这个配方中创建的管道，使用<strong class="bold">管道</strong>下拉列表列出所有的管道资源。双击映射到管道的行，类似于前面的屏幕截图所示。</p></li>
				<li>Double-click the row corresponding to the execution we triggered in this recipe using pipeline.start():<div><img src="img/B16850_09_31.jpg" alt="Figure 9.31 – Pipeline execution&#13;&#10;" width="1142" height="189"/></div><p class="figure-caption">图9.31–管道执行</p><p>在这里，我们可以看到<a id="_idIndexMarker2009"/>我们的管道执行<a id="_idIndexMarker2010"/>已经成功，执行完成大约需要8分半钟。</p></li>
				<li>We should see a graph of the execution, similar to what is shown in the following screenshot. Click the <strong class="bold">TrainStep</strong> node:<div><img src="img/B16850_09_32.jpg" alt="Figure 9.32 – Pipeline graph&#13;&#10;" width="1351" height="798"/></div><p class="figure-caption">图9.32–管道图</p><p>点击<strong class="bold"> TrainStep </strong>节点，我们会看到以下详细信息:</p><div><img src="img/B16850_09_33.jpg" alt="Figure 9.33 – TrainStep details&#13;&#10;" width="1298" height="716"/></div><p class="figure-caption">图9.33–train step细节</p><p>这里，我们有<a id="_idIndexMarker2011"/>训练作业<a id="_idIndexMarker2012"/>信息、细节和结果，包括train:object_loss:final、train:mse、train:progress、train:throughput、train:absolute_loss和train:objective_loss的值。</p><p class="callout-heading">小费</p><p class="callout">还可以使用pprint(pipeline.describe())来获取更多详细信息。</p></li>
				<li>Back in the notebook, use the delete() function to delete the pipeline:<pre>pipeline.<strong class="bold">delete</strong>()</pre><p>此时，管道应该被删除；但是，不应该删除创建的其他资源(例如，模型)。</p></li>
			</ol>
			<p>现在，让我们看看这是如何工作的！</p>
			<h2 id="_idParaDest-409"><a id="_idTextAnchor903"/>工作原理……</h2>
			<p>在这个菜谱中，我们使用<strong class="bold"> SageMaker Python SDK </strong>中的不同类创建并执行了一个管道。与<strong class="bold"> AWS步骤函数Data Science SDK </strong>类似，<strong class="bold"> SageMaker Python SDK </strong>中有几个类映射到机器学习工作流中的相应步骤或任务:</p>
			<ul>
				<li>ProcessingStep:这集中在诸如自动化数据处理、特征工程、数据清理和模型评估等任务上。</li>
				<li>TrainingStep:这侧重于模型训练和微调任务。</li>
				<li>CreateModelStep:这着重于从一个训练步骤的输出中创建一个SageMaker模型。</li>
				<li>TransformStep:这关注于<a id="_idIndexMarker2013"/>使用现有的SageMaker模型<a id="_idIndexMarker2014"/>在测试数据集上执行批量转换。</li>
				<li>RegisterModelStep:这着重于创建一个模型包，它封装了推理所需的工件和模型属性。</li>
				<li>ConditionStep:这允许在管道中支持条件执行。</li>
			</ul>
			<p>对于一个更复杂的例子，我们可能决定创建一个新项目，并使用SageMaker提供的模板(例如，<strong class="bold">MLOps template for model building，training，and deployment </strong>)。在这里，我们将创建和使用一个相对更复杂的管道版本，它涉及到条件表达式、模型注册、自动化模型评估，甚至还有一个手动批准步骤:</p>
			<div><div><img src="img/B16850_09_34.jpg" alt="Figure 9.34 – Pipeline graph from the project template&#13;&#10;" width="1086" height="787"/>
				</div>
			</div>
			<p class="figure-caption">图9.34-项目模板中的管道图</p>
			<p>在本书中，我们不会深入探讨使用<strong class="bold"> SageMaker管道</strong>的本质细节<a id="_idIndexMarker2016"/>，所以请随意<a id="_idIndexMarker2017"/>查看下面的链接以获得关于该主题的更多信息:<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines.html">https://docs . AWS . Amazon . com/SageMaker/latest/DG/Pipelines . html</a>。</p>
			<h2 id="_idParaDest-410"><a id="_idTextAnchor904"/>亦见</h2>
			<p>如果您正在寻找在真实数据集上使用<strong class="bold"> SageMaker Pipelines </strong>的示例和更复杂的示例，请在这里随意查看一些关注该主题的笔记本:<a href="https://github.com/aws/amazon-sagemaker-examples/tree/master/sagemaker-pipelines/tabular">https://github . com/AWS/Amazon-sage maker-examples/tree/master/sage maker-Pipelines/tabular</a>。</p>
		</div>
	
</body></html>