<title>Chapter 3: Deep Learning Containers</title>

# 3

# 深度学习容器

在 [*第二章*](B18638_02.xhtml#_idTextAnchor041) 、*深度学习 AMIs* 中，我们使用 **AWS 深度学习 AMIs** ( **DLAMIs** )在 EC2 实例内部建立一个环境，在那里我们可以训练和评估深度学习模型。在这一章中，我们将仔细研究一下 **AWS 深度学习容器** ( **DLCs** )，它们可以跨多个环境和服务一致地运行。除此之外，我们还将讨论 DLAMIs 和 DLC 之间的异同。

本章中的实践解决方案着重于我们可以使用 DLCs 的不同方式来解决在云中处理**机器学习** ( **ML** )需求时的几个棘手问题。例如，像 **Docker** 这样的容器技术允许我们充分利用正在运行的 EC2 实例，因为我们将能够在容器中运行不同类型的应用程序，而不必担心它们的依赖关系是否会冲突。除此之外，在尝试管理和降低成本时，我们将有更多的选项和解决方案可用。首先，如果我们使用 **AWS Lambda** (一种无服务器计算服务，允许我们运行自定义后端代码)的容器映像支持来在无服务器功能内部署我们的深度学习模型，我们将能够显著降低与全天候运行推理端点相关的基础设施成本。同时，对于无服务器函数，我们需要担心的只是函数内部的定制代码，因为 AWS 会负责运行该函数的基础设施。

在前一章的*了解 AWS 定价如何适用于 EC2 实例*一节中讨论的场景中，我们能够使用`m6i.large`实例将运行 24/7 推理端点的成本降低到大约每月*69.12 美元*。值得注意的是，即使这个推断端点没有接收到任何流量，这个值或多或少会保持不变。换句话说，我们可能每月支付*69.12 美元*来购买一项未充分利用或未使用的资源。如果我们要建立一个与生产环境配置相同的转移环境，该成本将会翻倍，并且几乎可以肯定转移环境资源将会严重利用不足。此时，您可能会想，*我们有可能进一步降低成本吗？好消息是这是可能的，只要我们能够使用正确的工具、服务和框架来设计一个更好的架构。*

我们将通过在 DLC 内训练一个 **PyTorch** 模型来开始本章的实践部分。这个模型将被上传到一个定制的容器映像中，该映像将被用来创建一个 **AWS Lambda** 函数。之后，我们将创建一个 **API 网关** HTTP API，它接受一个 HTTP 请求，并用一个包含输入请求数据的事件触发 AWS Lambda 函数。然后，AWS Lambda 函数将加载我们为执行 ML 预测而训练的模型。

在本章中，我们将讨论以下主题:

*   AWS 深度学习容器入门
*   基本先决条件
*   使用 AWS 深度学习容器来训练 ML 模型
*   具有 Lambda 容器映像支持的无服务器 ML 部署

在研究本章的动手解决方案时，我们将讨论几个*无服务器*服务，如 AWS Lambda 和 Amazon API Gateway，它们允许我们运行应用程序，而不必自己管理基础设施。同时，使用这些资源的成本会根据这些资源的使用情况自动调整。在典型的设置中，我们可能有一个 24/7 运行的 EC2 实例，我们将为运行的资源付费，而不管它是否被使用。有了 AWS Lambda，我们只需要在函数代码运行时付费。如果它每个月只运行几秒钟，那么我们这个月的费用可能接近于零！

记住这几点，让我们从 AWS DLCs 如何工作的快速介绍开始本章。

# 技术要求

开始之前，我们必须准备好以下内容:

*   网络浏览器(最好是 Chrome 或 Firefox)
*   访问本书前两章中使用的 AWS 帐户
*   访问您在*创建您的 Cloud9 环境*和*增加 Cloud9 存储*章节 [*第 1 章*](B18638_01.xhtml#_idTextAnchor017) 、*AWS 上的 ML 工程介绍*中准备的 Cloud9 环境

本书的 GitHub 资源库 https://GitHub . com/packt publishing/Machine-Learning-Engineering-on-AWS 提供了 Jupyter 笔记本、源代码和其他用于每章的文件。

重要说明

建议您在运行本书中的示例时，使用具有有限权限的 IAM 用户，而不是 root 帐户。我们将在 [*第 9 章*](B18638_09.xhtml#_idTextAnchor187) 、*安全、治理和遵从性策略*中详细讨论这一点以及其他安全最佳实践。如果您刚刚开始使用 AWS，您可以同时继续使用 root 帐户。

# AWS 深度学习容器入门

容器允许开发人员、工程师和系统管理员在一致的隔离环境中运行进程、脚本和应用程序。这种一致性是有保证的，因为这些容器是从容器映像启动的，类似于 EC2 实例从**亚马逊机器映像** ( **AMIs** )启动的方式。

值得注意的是，我们可以在一个实例中同时运行不同的独立容器。这使得工程团队能够充分利用现有实例的计算能力，运行不同类型的流程和工作负载，如下图所示:

![Figure 3.1 – Running multiple containers inside a single EC2 instance

](img/B18638_03_001.jpg)

图 3.1–在一个 EC2 实例中运行多个容器

最受欢迎的集装箱管理解决方案之一是 Docker。它是一个开源容器化平台，允许开发者和工程师轻松地构建、运行和管理容器。它涉及到一个 **Dockerfile** 的使用，这个是一个包含如何构建容器映像的说明的文本文档。然后，这些容器映像被管理并存储在容器注册表中，以便以后可以使用。

注意

Docker 图像用于创建容器。Docker 图像就像 ZIP 文件，它打包了运行应用程序所需的一切。当 Docker 容器从容器映像运行时(使用`docker run`命令)，容器就像一个虚拟机，其环境与运行容器的服务器隔离开来。

现在我们对容器和容器映像的工作原理有了更好的了解，让我们继续讨论什么是 DLC，以及如何使用它们来加速 ML 模型的训练和部署。使用 AWS DLCs 的一个主要好处是，大多数相关的 ML 包、框架和库已经安装在容器映像中。这意味着 ML 工程师和数据科学家不再需要担心安装和配置 ML 框架、库和包。这允许他们继续准备用于训练和部署他们的深度学习模型的定制脚本。

由于 DLC 映像仅仅是预构建的容器映像，因此这些可以用于任何可以使用容器和容器映像的 AWS 服务。这些 AWS 服务包括**亚马逊 EC2** 、**亚马逊弹性容器服务** ( **ECS** )、**亚马逊弹性 Kubernetes 服务(EKS)** 、**亚马逊 SageMaker** 、 **AWS CodeBuild** 、 **AWS Lambda** 、等等。

记住这些，让我们继续使用 AWS 深度学习容器来训练和部署深度学习模型！

# 必要的先决条件

在本节中，我们将确保在继续培训步骤之前，满足以下先决条件:

1.  我们将准备一个 Cloud9 环境，并确保它已经设置好，这样我们就可以训练模型并构建定制的容器映像。
2.  我们将准备一个训练数据集，用于训练深度学习模型。

## 准备 Cloud9 环境

在本章的第一部分，我们将在 EC2 实例中运行我们的深度学习容器，类似于下图所示:

![Figure 3.2 – Running a Deep Learning Container inside an EC2 instance

](img/B18638_03_002.jpg)

图 3.2–在 EC2 实例中运行深度学习容器

这个容器将作为使用脚本训练 ML 模型的环境，该脚本利用了 **PyTorch** 框架。即使 PyTorch 没有安装在 EC2 实例中，训练脚本仍然可以成功运行，因为它将在预先安装了 PyTorch 的容器环境中执行。

注意

如果你想知道 PyTorch 是什么，它是可用的最流行的开源 ML 框架之一。你可以去 https://pytorch.org/了解更多信息。

在下一组步骤中，我们将确保我们的 Cloud9 环境已经准备就绪:

1.  在搜索栏中输入`cloud9`。从结果列表中选择 **Cloud9** :

![Figure 3.3 – Navigating to the Cloud9 console

](img/B18638_03_003.jpg)

图 3.3–导航至 Cloud9 控制台

在这里，我们可以看到该区域当前被设置为`us-west-2`。确保您将此更改为您在第 1 章 、*AWS 上的 ML 工程简介*中创建 Cloud9 实例的位置。

1.  在 [*第一章*](B18638_01.xhtml#_idTextAnchor017) 、*AWS 上的 ML 工程介绍*的*创建你的 Cloud9 环境*部分打开你创建的 Cloud9 环境，点击 [*第一章*](B18638_01.xhtml#_idTextAnchor017) 、*AWS 上的 ML 工程介绍*中创建 Cloud9 环境的`us-west-2`。

注意

如果您跳过了第一章，请确保在继续之前完成该章的*创建您的 Cloud9 环境*和*增加 Cloud9 存储*部分。

1.  在 Cloud9 环境的终端，运行以下`bash`命令创建`ch03`目录:

    ```
    mkdir -p ch03
    ```

    ```
    cd ch03
    ```

我们将使用这个目录作为本章的当前工作目录。

现在我们已经准备好了 Cloud9 环境，让我们继续下载训练数据集，以便我们可以训练我们的深度学习模型。

## 下载样本数据集

我们将在本章中使用的训练数据集与我们在 [*第 2 章*](B18638_02.xhtml#_idTextAnchor041) 、*深度学习 AMIs* 中使用的数据集相同。它有两列对应于连续的 *x* 和 *y* 变量。在本章的后面，我们还将使用这个数据集生成一个回归模型。回归模型预期接受输入的 *x* 值，并返回预测的 *y* 值。

在下一组步骤中，我们将把训练数据集下载到我们的 Cloud9 环境中:

1.  运行以下命令创建`data`目录:

    ```
    mkdir -p data
    ```

2.  接下来，让我们使用`wget`命令:

    ```
    wget https://bit.ly/3h1KBx2 -O data/training_data.csv
    ```

    下载训练数据 CSV 文件
3.  使用`head`命令检查我们的训练数据是什么样子:

    ```
    head data/training_data.csv
    ```

这将为我们提供多行 *(x，y)对*，类似于下面的截图所示:

![Figure 3.4 – The first few rows of the training_data.csv file

](img/B18638_03_004.jpg)

图 3.4–training _ data . CSV 文件的前几行

因为我们是在`ch03`目录中开始这一节的，所以需要注意的是`training_data.csv`文件应该在`ch03/data`目录中。

既然我们已经准备好了先决条件，我们可以继续进行培训步骤。

# 使用 AWS 深度学习容器训练一个 ML 模型

在这个点上，你可能想知道是什么让深度学习模型不同于其他 ML 模型。深度学习模型是相互连接的节点网络，它们相互通信，类似于人脑中神经元网络的通信方式。这些模型利用了网络中的多个层，类似于下图所示。更多的层和每层更多的神经元使深度学习模型能够处理和学习复杂的非线性模式和关系:

![Figure 3.5 – Deep learning model

](img/B18638_03_005.jpg)

图 3.5–深度学习模型

深度学习在**自然语言处理** ( **NLP** )、**计算机视觉**、**欺诈检测**中有几个实用应用。除此之外，这里还有一些其他的应用和示例:

*   **生成对抗网络** ( **甘斯**):这些可以用来从原始数据集生成真实的例子，类似于我们在*使用深度学习模型生成合成数据集 [*第 1 章*](B18638_01.xhtml#_idTextAnchor017) 、*AWS 上的 ML 工程简介*中的*部分。**
*   **深度强化学习**:这个利用深度神经网络和强化学习技术来解决机器人和游戏等行业的复杂问题。

在过去的几年里，深度学习模型的培训和部署已经通过深度学习框架得到了极大的简化，如 **PyTorch** 、 **TensorFlow** 和 **MXNet** 。AWS DLCs 通过提供已经预装了运行这些 ML 框架所需的一切的容器映像，进一步加快了速度。

注意

可以在这里查看可用 DLC 图片列表:[https://github . com/AWS/deep-learning-containers/blob/master/available _ images . MD](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)。注意，这些容器映像是按照(1)已安装的 ML 框架( **PyTorch** 、 **TensorFlow** 或 **MXNet** )，(2)作业类型(*培训*或*推理*)，以及(3)已安装的 Python 版本来分类的。

在下一组步骤中，我们将使用已优化的 DLC 图像来训练 PyTorch 模型:

1.  让我们通过运行以下命令下载`train.py`文件:

    ```
    wget https://bit.ly/3KcsG3v -O train.py
    ```

在我们继续之前，让我们从`File`树中打开`train.py`文件，检查它的内容:

![Figure 3.6 – Opening the train.py file from the File tree

](img/B18638_03_006.jpg)

图 3.6–从文件树中打开 train.py 文件

我们应该会看到一个脚本，它利用存储在`data`目录中的训练数据来训练一个深度学习模型。训练步骤完成后，该模型保存在`model`目录中:

![Figure 3.7 – The main() function of the train.py script file

](img/B18638_03_007.jpg)

图 3.7–train . py 脚本文件的 main()函数

在这里，我们可以看到我们的`train.py`脚本的`main()`函数执行以下操作:

*   (1)使用`prepare_model()`功能定义模型
*   (2)使用`load_data()`功能加载训练数据
*   (3)使用`fit()`方法执行训练步骤
*   (4)使用`torch.save()`方法保存模型工件

如果`train.py`作为脚本直接执行，前面截图中的最后一段代码只是运行`main()`函数。

注意

在这里可以找到完整的`train.py`脚本:[https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter 03/train . py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/train.py)。

1.  接下来，使用`mkdir`命令:

    ```
    mkdir -p model
    ```

    创建`model`目录

稍后，我们将看到模型输出保存在这个目录中。

1.  通过运行以下命令安装实用程序:

    ```
    sudo apt install tree
    ```

2.  让我们使用刚刚安装的`tree`实用程序:

    ```
    tree
    ```

这将产生一个树状结构，类似于下面的截图:

![Figure 3.8 – Results after using the tree command

](img/B18638_03_008.jpg)

图 3.8–使用树命令后的结果

需要注意的是，`train.py`脚本位于`ch03`目录中，这也是`data`和`model`目录所在的位置。

1.  使用`wget`命令:

    ```
    wget https://bit.ly/3Iz7zaV -O train.sh
    ```

    下载`train.sh`文件

如果我们检查`train.sh`文件的内容，我们应该看到以下几行:

```
aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com

TRAINING_IMAGE=763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:1.8.1-cpu-py36-ubuntu18.04

docker run -it -v `pwd`:/env -w /env $TRAINING_IMAGE python train.py
```

`train.sh`脚本首先向**亚马逊弹性容器注册中心**(一个完全托管的 Docker 容器注册中心，我们可以在那里存储我们的容器映像)认证，以便我们可以成功下载训练容器映像。这个容器镜像已经预装了 *PyTorch 1.8.1* 和 *Python 3.6* 。

重要说明

`train.sh`脚本中的代码假设我们将在 *Oregon* ( `us-west-2`)地区的 EC2 实例(运行 Cloud9 环境的地方)中运行训练实验。确保用适当的地区代码替换`us-west-2`。有关这个主题的更多信息，请随时查看 https://docs . AWS . Amazon . com/AWS C2/latest/user guide/using-regions-avail ability-zones . XHTML。

`docker run`命令首先下载指定的容器映像，并使用该映像创建一个正在运行的容器进程。之后，在运行`docker run`命令时，使用`-v`标志将当前工作目录(`ch03`)挂载到容器后，当前工作目录的内容被“复制”到容器中。然后，我们使用`-w`标志将工作目录设置为我们的文件在容器中的挂载位置(`/env`)。一旦所有步骤都完成了，就在运行容器的环境中执行`train.py`脚本。

注意

查看[https://docs.docker.com/engine/reference/run/](https://docs.docker.com/engine/reference/run/)了解更多关于如何使用`docker run`命令的信息。

1.  现在我们对执行`train.sh`文件时会发生什么有了一个更好的想法，让我们使用下面的命令运行它:

    ```
    chmod +x train.sh
    ```

    ```
    ./train.sh
    ```

这将产生一组日志，如下所示:

![Figure 3.9 – Logs generated while running the train.sh script

](img/B18638_03_009.jpg)

图 3.9–运行 train.sh 脚本时生成的日志

这里，`train.sh`脚本运行一个容器，该容器调用`train.py` (Python)脚本来训练深度学习模型。在前面的屏幕截图中，我们可以看到由`train.py`脚本生成的日志，因为它迭代地更新神经网络的权重，以提高输出模型的质量(也就是说，减少每次迭代的损失，以便我们可以最小化错误)。值得注意的是，这个`train.py`脚本利用 **PyTorch** 使用提供的数据来准备和训练一个样本深度学习模型。

这就是为什么我们使用已经预装了 *PyTorch 1.8.1* 和 *Python 3.6* 的深度学习容器映像的原因。

注意

完成此步骤可能需要 5 到 10 分钟。在等待的时候，请随意喝杯咖啡或茶！

1.  在训练脚本完成运行后，让我们使用`tree`命令:

    ```
    tree
    ```

    检查`model`目录是否包含一个`model.pth`文件

这应该产生一个树状结构，如下所示:

![Figure 3.10 – Verifying whether the model was saved successfully

](img/B18638_03_010.jpg)

图 3.10–验证模型是否保存成功

这个`model.pth`文件包含我们使用`train.py`脚本训练的序列化模型。该文件是在模型训练步骤完成后使用`torch.save()`方法创建的。请随意查看[https://py torch . org/tutorials/beginner/saving _ loading _ models . XHTML](https://pytorch.org/tutorials/beginner/saving_loading_models.xhtml)了解更多信息。

注意

生成的`model.pth`文件允许我们使用模型的参数进行预测(从文件中加载模型之后)。例如，如果我们的模型使用诸如 *ax^2 + bxy + cy^2 = 0* 的等式，则 *a* 、 *b* 和 *c* 值就是模型参数。有了这个，如果我们有了 *x* (也就是自变量)，就可以很容易的计算出 *y* 的值。也就是说，我们可以说确定 *a* 、 *b* 和 *c* 是训练阶段的任务，而确定给定 *x* (以及给定 *a* 、 *b* 和 *c* )的 *y* 是推理阶段的任务。通过加载`model.pth`文件，我们可以继续进行推理阶段，并在给定输入值 *x* 的情况下计算 *y* 的预测值。

那不是很容易吗？完成培训步骤后，我们将继续下一部分的部署步骤。

# 支持 Lambda 容器映像的无服务器 ML 部署

现在我们有了`model.pth`文件，我们该怎么处理它？答案很简单:我们将使用一个 **AWS Lambda** 函数和一个**Amazon API Gateway**HTTP API 在一个无服务器 API 中部署这个模型，如下图中的所示:

![Figure 3.11 – Serverless ML deployment with an API Gateway and AWS Lambda

](img/B18638_03_011.jpg)

图 3.11–带有 API 网关和 AWS Lambda 的无服务器 ML 部署

正如我们所看到的，HTTP API 应该能够接受来自“客户端”的 *GET* 请求，比如移动应用和其他与最终用户交互的 web 服务器。这些请求然后作为输入事件数据传递给 AWS Lambda 函数。然后，Lambda 函数从`model.pth`文件中加载模型，并使用输入事件数据中的 *x* 值计算预测的 *y* 值。

## 构建自定义容器图像

我们的 AWS Lambda 函数代码需要利用 **PyTorch** 函数和实用程序来加载模型。为了让这个设置正常工作，我们将从现有的 DLC 映像构建一个定制的容器映像，该映像针对 **PyTorch** 推理需求进行了优化。这个自定义容器映像将用于我们的 AWS Lambda 函数代码将通过 AWS Lambda 的容器映像支持运行的环境。

注意

有关 AWS Lambda 的容器图像支持的更多信息，请查看 https://AWS . Amazon . com/blogs/AWS/new-for-AWS-Lambda-container-image-support/。

值得注意的是，有多种 DLC 图像可供我们选择。这些图像根据它们的作业类型(*训练与推理*)、安装的框架( *PyTorch 与 TensorFlow 与 MXNet 与其他选项*)以及安装的 Python 版本( *3.8 与 3.7 与 3.6 与其他选项*)进行分类。由于我们计划使用一个容器来加载 **PyTorch** 模型并用于执行预测，因此在构建自定义 Docker 映像时，我们将选择一个为推理而优化的 **PyTorch** DLC *作为基础映像。*

以下步骤着重于从现有 DLC 映像构建自定义容器映像:

1.  通过在终端中运行`pwd`命令，确保您位于`ch03`目录中。
2.  接下来，运行以下命令来下载`dlclambda.zip`并在`ch03`目录中提取其内容:

    ```
    wget https://bit.ly/3pt5mGN -O dlclambda.zip
    ```

    ```
    unzip dlclambda.zip
    ```

这个 ZIP 文件包含构建定制容器映像所需的文件和脚本。

1.  使用`tree`命令查看`ch03`目录的样子:

    ```
    tree
    ```

这将产生一个树状结构，如下所示:

![Figure 3.12 – Results after running the tree command

](img/B18638_03_012.jpg)

图 3.12–运行 tree 命令后的结果

这里，从`dlclambda.zip`文件中提取了几个新文件:

*   `Dockerfile`
*   `app/app.py`
*   `build.sh`
*   `download-rie.sh`
*   `invoke.sh`
*   `run.sh`

我们将在本章的步骤中详细讨论每个文件。

1.  在文件树中，找到并打开位于`ch03/app`目录下的`app.py`文件:

![Figure 3.13 – app.py Lambda handler implementation

](img/B18638_03_013.jpg)

图 3.13–app . py Lambda 处理程序实现

该文件包含 AWS Lambda 处理程序实现代码，它(1)加载模型，(2)从事件数据中提取输入的 *x* 值，(3)使用模型计算预测的 *y* 值，以及(4)以字符串形式返回输出的 *y* 值。

在本章末尾的*完成和测试无服务器 API 设置*部分，我们将设置一个 HTTP API，通过 URL 查询字符串(例如，`https://<URL>/predict?x=42`)接受`x`的值。一旦请求进来，Lambda 将调用一个包含代码的处理函数来处理进来的请求。它将加载深度学习模型，并使用它来预测使用 *x* 的值的`y`的值。

注意

在这里可以找到完整的`app/app.py`文件:[https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter 03/app/app . py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/app/app.p)。

1.  使用`cp`命令:

    ```
    cp model/model.pth app/model/model.pth
    ```

    将`model.pth`文件从`model`目录复制到`app/model`目录

重要说明

确保您只从可信来源加载 ML 模型。在`app/app.py`内部，我们使用`torch.load()`加载模型，攻击者可以利用包含恶意有效负载的模型来利用该模型。攻击者可以很容易地准备一个模型(带有恶意的有效负载)，当加载该模型时，攻击者可以访问运行 ML 脚本的服务器或资源(例如，通过**反向外壳**)。关于这个主题的更多信息，你可以查看作者关于如何黑客攻击和保护 ML 环境和系统的演讲:[https://speaker deck . com/ARV slat/pycon-APAC-2022-hacking-and-securing-machine-learning-environments-and-systems？slide=8](https://speakerdeck.com/arvslat/pycon-apac-2022-hacking-and-securing-machine-learning-environments-and-systems?slide=8) 。

1.  接下来，让使用`chmod`命令:

    ```
    chmod +x *.sh
    ```

    使`build.sh`、`download-rie.sh`、`invoke.sh`和`run.sh`脚本文件可执行
2.  在运行`build.sh`命令之前，让我们使用`cat`命令:

    ```
    cat build.sh
    ```

    来检查脚本的内容

这将产生一行代码，类似于下面的代码块:

```
docker build -t dlclambda .
```

`docker build`命令使用当前目录下 Docker 文件中指定的指令构建 Docker 容器映像。*这是什么意思？*这意味着我们正在使用目录中的相关文件构建一个容器映像，并且我们也在使用 Dockerfile 文件中的指令来安装必要的包。这个过程类似于准备容器的 *DNA* ，它可以用来创建新的容器，其环境配置有所需的工具和软件包。

因为我们将`dlclambda`作为参数传递给了`-t`标志，所以在构建过程完成后，我们的定制容器图像将拥有`dlclambda:latest`名称和标签。注意，我们可以用一个特定的版本号(例如，`dlclambda:3`)替换最新的标签，但是现在我们将坚持使用`latest`标签。

注意

有关和`docker build`命令的更多信息，请查看 https://docs . docker . com/engine/reference/command line/build/。

1.  我们还必须检查 Dockerfile 文件的内容。当我们使用这个 Dockerfile 文件构建容器映像时会发生什么？
    1.  以下 DLC 图像用作构建两个阶段的基础图像:`https://763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:1.8.1-cpu-py36-ubuntu18.04`。值得注意的是，这个 Dockerfile 利用了**多阶段构建**到来确保最终的容器不包含来自先前构建阶段的未使用的工件和文件。
    2.  接下来，安装 **Lambda 运行时接口客户端**。这允许任何定制容器映像与 AWS Lambda 兼容使用。
    3.  创建了`/function`目录。然后将`app/`目录(在 Cloud9 环境的`ch03`目录中)的内容复制到容器中的`/function`目录。
    4.  `ENTRYPOINT`设置为`/opt/conda/bin/python -m awslambdaric`。`CMD`然后被设置为`app.handler`。`ENTRYPOINT`和`CMD`指令定义当容器开始运行时执行哪个命令。

注意

单个 Dockerfile 文件中的一个`FROM`指令。这些`FROM`指令中的每一个都对应于一个新的构建阶段，在该阶段可以复制来自先前阶段的工件和文件。对于多阶段构建，最后一个构建阶段会生成最终映像(理想情况下，它不包括前面构建阶段中未使用的文件)。

预期的最终输出将是一个可用于启动容器的容器图像，如下所示:

![Figure 3.14 – Lambda Runtime Interface Client

](img/B18638_03_014.jpg)

图 3.14–Lambda 运行时接口客户端

如果这个容器在没有任何附加参数的情况下启动，将执行以下命令:

```
/opt/conda/bin/python -m awslambdaric app.handler
```

这将运行我们的`app.py`文件的`handler()`函数来处理 AWS Lambda 事件。这个`handler()`函数然后将使用我们在*中使用 AWS 深度学习容器训练的深度学习模型来训练 ML 模型*部分以进行预测。

注意

你可以在这里找到 docker file:[https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter 03/docker file](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/Dockerfile)。

在运行`build.sh`脚本之前，确保用适当的地区代码替换 docker 文件中的所有`us-west-2`实例。

1.  现在，让我们运行`build.sh`脚本:

    ```
    ./build.sh
    ```

2.  最后，我们需要使用`docker images`命令:

    ```
    docker images | grep dlclambda
    ```

    检查定制容器映像的大小是否超过 10 GB

我们应该看到`dlclambda`的容器图像尺寸是`4.61GB`。重要的是要注意，对 Lambda 函数使用容器映像时有 10 GB 的限制。如果我们希望在 AWS Lambda 中使用自定义容器图像，那么它的图像大小需要低于 10 GB。

至此，我们的定制容器映像已经准备好了。下一步是在使用容器映像创建 AWS Lambda 函数之前在本地测试它。

## 测试容器图像

我们可以使用 **Lambda 运行时接口仿真器**在本地测试容器映像。这个将帮助我们检查我们的容器映像在稍后部署到 AWS Lambda 时是否能正常运行。

在接下来的几个步骤中，我们将下载并使用 Lambda 运行时接口仿真器来检查我们的容器映像:

1.  使用`cat`命令检查`download-rie.sh` :

    ```
    cat download-rie.sh
    ```

    的内容

这将在终端中输出以下代码块:

```
mkdir -p ~/.aws-lambda-rie && curl -Lo ~/.aws-lambda-rie/aws-lambda-rie \

https://github.com/aws/aws-lambda-runtime-interface-emulator/releases/latest/download/aws-lambda-rie \

&& chmod +x ~/.aws-lambda-rie/aws-lambda-rie
```

`download-rie.sh`脚本简单地下载 Lambda 运行时接口仿真器二进制文件，并使用`chmod`命令使其可执行。

1.  接下来，运行`download-rie.sh`脚本:

    ```
    sudo ./download-rie.sh
    ```

2.  使用`cat`命令检查`run.sh` :

    ```
    cat run.sh
    ```

    的内容

我们应该看到一个带有几个参数值的`docker run`命令，类似于下面的代码块:

```
docker run -v ~/.aws-lambda-rie:/aws-lambda -p 9000:8080 --entrypoint /aws-lambda/aws-lambda-rie dlclambda:latest /opt/conda/bin/python -m awslambdaric app.handler
```

让我们快速检查一下传递给每个标志的参数值:

*   `-v` : `~/.aws-lambda-rie`是运行 Docker 容器外部的一个目录，将被挂载到`/aws-lambda`(在容器内部)。
*   `-p`:这将容器的端口`8080`绑定到实例的端口`9000`。
*   `--entrypoint`:这将覆盖容器启动时执行的默认`ENTRYPOINT`命令。
*   `[IMAGE]` : `dlclambda:latest.`
*   `[COMMAND]` `[ARG…]` : `/opt/conda/bin/python -m awslambdaric app.handler.`

该`docker run`命令覆盖默认的`ENTRYPOINT`命令，并使用T2，而不是使用`--entrypoint`标志。这将在`http://localhost:9000/2015-03-31/functions/function/invocations`启动一个本地端点。

注意

关于命令`docker run`的更多信息，请随时查看[https://docs.docker.com/engine/reference/commandline/run/](https://docs.docker.com/engine/reference/commandline/run/)。

1.  现在，让调用`run.sh`脚本:

    ```
    ./run.sh
    ```

2.  通过单击加号( **+** )按钮创建一个新的终端选项卡，如下面的屏幕截图所示:

![Figure 3.15 – Creating a new Terminal tab

](img/B18638_03_015.jpg)

图 3.15–创建新的终端标签

请注意，当我们打开一个**新终端**标签时，`run.sh`脚本应该保持运行。

1.  在`invoke.sh`脚本中:

    ```
    cd ch03
    ```

    ```
    cat invoke.sh
    ```

这应该向我们展示了`invoke.sh`脚本文件中的内容。它应该包含一个单行脚本，类似于下面的代码块:

```
curl -XPOST "http://localhost:9000/2015-03-31/functions/function/invocations" -d '{"queryStringParameters":{"x":42}}'
```

这个脚本简单地利用`curl`命令向本地端点发送一个包含`x`输入值的示例`POST`请求，这个请求之前由`run.sh`脚本启动。

1.  现在，让我们运行`invoke.sh`脚本:

    ```
    ./invoke.sh
    ```

这将产生一个接近`"42.4586"`的值。在`invoke.sh`脚本中随意更改输入`x`值，看看输出值是如何变化的。

1.  导航回到第一个选项卡，按下 *Ctrl* + *C* 停止运行`run.sh`脚本。

假设我们能够使用 **Lambda 运行时接口仿真器**成功调用定制容器映像中的`app.py` Lambda 函数处理程序，我们现在可以继续将容器映像推送到 Amazon ECR，并使用它来创建 AWS Lambda 函数。

## 将容器图像推送到 Amazon ECR

**亚马逊弹性容器注册** ( **ECR** )是一个容器注册服务，允许我们存储和管理 Docker 容器图像。在本节中，我们将创建一个 ECR 存储库，然后将我们的定制容器映像推送到这个 ECR 存储库中。

让我们从创建 ECR 存储库开始:

1.  在 Cloud9 环境的右上角，定位并点击**分享**按钮旁边的圆圈，如下图所示。从选项列表中选择**转到仪表板**:

![Figure 3.16 – Navigating to the Cloud9 console

](img/B18638_03_016.jpg)

图 3.16–导航至 Cloud9 控制台

这应该会打开 Cloud9 控制台，在这里我们可以找到所有创建的 Cloud9 环境。

1.  在搜索栏中输入`registry`。从结果列表中选择**弹性容器注册表**。
2.  找到并点击 ECR 控制台页面右上角的**创建存储库**按钮。
3.  在`dlclambda`上):

![Figure 3.17 – Creating an ECR repository

](img/B18638_03_017.jpg)

图 3.17–创建 ECR 存储库

可选地，您可以启用**标签不变性**，类似于前面的截图所示。这将有助于确保我们不会意外覆盖现有的容器图像标签。

1.  向下滚动到页面底部，然后单击**创建存储库**。
2.  我们应该会看到一个成功通知，以及 **View push commands** 按钮，类似于下面的截图:

![Figure 3.18 – View push commands

](img/B18638_03_018.jpg)

图 3.18–查看推送命令

点击**查看推送命令**按钮，打开< ECR 库名称>的**推送命令弹出窗口。**

1.  在*步骤 1* 下的灰色框中找到`bash`命令。通过单击下面屏幕截图中突出显示的框按钮，将命令复制到剪贴板:

![Figure 3.19 – Push commands

](img/B18638_03_019.jpg)

图 3.19–推送命令

这个命令将用于在我们的 Cloud9 环境中向 Amazon ECR 认证 Docker 客户机。这将允许我们将容器图像推送到 Amazon ECR。

1.  导航回到`bash`命令:

![Figure 3.20 – Running the client authentication command

](img/B18638_03_020.jpg)

图 3.20–运行客户端验证命令

我们应该会得到一条**登录成功**的消息。如果没有这一步，我们将无法从 Amazon ECR 推送和提取容器图像。

1.  导航回带有 ECR push 命令的浏览器选项卡，并复制*步骤 3* 下的命令，如下图所示:

![Figure 3.21 – Copying the docker tag command

](img/B18638_03_021.jpg)

图 3.21–复制 docker 标签命令

这一次，我们将从`docker tag`命令复制`docker tag`命令，该命令用于创建命名引用并将其映射到 Docker 图像。

注意

`docker tag`命令用于指定元数据(如名称和版本)并将其添加到容器映像中。容器映像存储库存储特定映像的不同版本，当使用`docker push`命令时，`docker tag`命令帮助存储库识别哪个版本的映像将被更新(或上传)。如需更多信息，请随时查看 https://docs.docker.com/engine/reference/commandline/tag/.

1.  回到包含 Cloud9 环境的浏览器选项卡，将复制的`docker tag`命令粘贴到终端窗口中。找到命令末尾的`latest`标记值，并替换为`1`:

    ```
    docker tag dlclambda:latest <ACCOUNT ID>.dkr.ecr.us-west-2.amazonaws.com/dlclambda:latest
    ```

在用`1`替换了`latest`标签后，该命令应该类似于下面的代码块:

```
docker tag dlclambda:latest <ACCOUNT ID>.dkr.ecr.us-west-2.amazonaws.com/dlclambda:1
```

确保`<ACCOUNT ID>`值被正确设置为您正在使用的 AWS 帐户的帐户 ID。您从`<ACCOUNT ID>`值中复制的`docker tag`命令设置正确。

1.  使用`docker images`命令快速检查我们的 Cloud9 环境中的容器映像:

    ```
    docker images
    ```

这将返回所有容器图像，包括`dlclambda`容器图像，如下面的屏幕截图所示:

![Figure 3.22 – Running the docker images command

](img/B18638_03_022.jpg)

图 3.22–运行 docker images 命令

值得注意的是，前面屏幕截图中显示的两个容器图像标签具有相同的图像 ID。这意味着它们指向同一个图像，即使它们有不同的名称和标签。

1.  使用`docker push`命令:

    ```
    docker push <ACCOUNT ID>.dkr.ecr.us-west-2.amazonaws.com/dlclambda:1
    ```

    将容器映像推送到 Amazon ECR 存储库

确保用您正在使用的 AWS 帐户的帐户 ID 替换`<ACCOUNT ID>`的值。在上一步运行`docker images`命令后，通过检查`.dkr.ecr.us-west-2.amazonaws.com/dlclambda`前的数值，可以得到`<ACCOUNT ID>`的值。

注意

注意，图像标签值是一个`1`(一)，而不是容器图像名称和冒号后的字母 *l* 。

1.  导航回包含 ECR 按钮命令的浏览器选项卡，点击**关闭**按钮。
2.  在**私有库**列表下找到并点击我们创建的 ECR 库的名称(即`dlclambda`):

![Figure 3.23 – Private repositories

](img/B18638_03_023.jpg)

图 3.23–私有存储库

这应该会将我们重定向到详细信息页面，在这里我们可以看到不同的图像标签，如下面的屏幕截图所示:

![Figure 3.24 – Repository details page

](img/B18638_03_024.jpg)

图 3.24–存储库详细信息页面

一旦我们的带有指定图像标签的容器图像反映在相应的 Amazon ECR 存储库详细信息页面中，我们就可以使用它来创建 AWS Lambda 函数，使用 Lambda 的容器图像支持。

既然我们的定制容器映像已经被推送到 **Amazon ECR** ，我们就可以准备和配置无服务器 API 设置了！

## 在自动气象站 Lambda 上运行最大似然预测

**AWS Lambda** 是一种无服务器计算服务，允许开发人员和工程师运行事件驱动的代码，而无需供应或管理基础设施。Lambda 函数可以被来自其他 AWS 服务的资源调用，例如作为 **API 网关**(一个用于配置和管理 API 的完全托管的服务)**亚马逊 S3** (一个对象存储服务，我们可以在那里上传和下载文件)**亚马逊 SQS** (一个完全托管的消息队列服务)，等等。这些函数在隔离的运行时环境中执行，这些运行时环境有定义的最大执行时间和最大内存限制，类似于下图所示:

![Figure 3.25 – AWS Lambda isolated runtime environment

](img/B18638_03_025.jpg)

图 3.25–AWS Lambda 隔离运行时环境

有两种方法部署 Lambda 函数代码及其依赖项:

*   使用容器映像作为部署包。
*   使用一个`.zip`文件作为部署包

当使用容器映像作为部署包时，自定义 Lambda 函数代码可以使用容器映像中安装和配置的内容。也就是说，如果我们要使用从 AWS DLC 构建的自定义容器映像，我们将能够在我们的函数代码中使用安装的 ML 框架(即 **PyTorch** ),并在 AWS Lambda 执行环境中运行 ML 预测。

现在我们对 AWS Lambda 的容器图像支持有了更好的理解，让我们继续创建我们的 AWS Lambda 函数:

1.  在搜索栏中输入`lambda`。从结果列表中选择 **Lambda** 导航至 AWS Lambda 控制台。
2.  找到并点击页面右上角的**创建功能**按钮。
3.  【T2 上】 ):

![Figure 3.26 – Using the container image support of AWS Lambda

](img/B18638_03_026.jpg)

图 3.26–使用 AWS Lambda 的容器图像支持

选择**容器映像**选项意味着我们将使用定制的容器映像作为部署包。这个部署包应该包含 Lambda 代码及其依赖项。

1.  在**容器图像 URI** 下，点击**浏览图像**按钮。这将打开一个弹出窗口，如下所示:

![Figure 3.27 – Selecting the container image

](img/B18638_03_027.jpg)

图 3.27–选择容器图像

在`dlclambda:1`下)。

1.  单击`dlclambda`容器图像将用于我们 Lambda 函数的部署包。
2.  在之后，点击**创建功能**。

注意

完成此步骤可能需要 3 到 5 分钟。在等待的时候，请随意喝杯咖啡或茶！

1.  导航到**配置>通用配置**选项卡，点击**编辑**:

![Figure 3.28 – Editing the general configuration

](img/B18638_03_028.jpg)

图 3.28–编辑常规配置

在这里，我们可以看到 AWS Lambda 函数被配置为默认的最大内存限制为 128 MB，超时为 3 秒。如果 Lambda 函数在执行过程中超过一个或多个配置的限制，则会引发错误。

1.  接下来，更新`10240` MB，因为我们期待我们的`1` min 和`0` seconds，因为推断步骤可能需要比默认值 3 秒更长的时间:

![Figure 3.29 – Modifying the memory and timeout settings

](img/B18638_03_029.jpg)

图 3.29–修改内存和超时设置

注意增加内存和超时限制会影响 Lambda 函数的计算能力和总运行时间，以及使用服务运行预测的总成本。现在，让我们专注于使用**内存**和**超时**的这些当前配置值让 **AWS Lambda** 功能工作。一旦我们可以运行初始设置，我们就可以使用不同的配置值组合来管理设置的性能和成本。

注意

我们可以使用 **AWS 计算优化器**来帮助 us 优化 AWS Lambda 函数的整体性能和成本。有关这个主题的更多信息，请查看[https://AWS . Amazon . com/blogs/compute/optimizing-AWS-lambda-cost-and-performance-using-AWS-compute-optimizer/](https://aws.amazon.com/blogs/compute/optimizing-aws-lambda-cost-and-performance-using-aws-compute-optimizer/)。

1.  之后点击**保存**按钮。我们应该看到一个类似于**更新函数<函数名>** 的通知。
2.  导航至**测试**选项卡。
3.  在`test`下):

![Figure 3.30 – Configuring the test event

](img/B18638_03_030.jpg)

图 3.30–配置测试事件

确保您在代码编辑器中指定了以下测试事件值，类似于前面的屏幕截图所示:

```
{

  "queryStringParameters": {

    "x": 42

  }

}
```

当执行测试时，这个测试事件值被传递给 AWS Lambda `handler()`函数的`event`(第一个)参数。

1.  点击**保存**。
2.  现在，让我们通过点击**测试**按钮来测试我们的设置:

![Figure 3.31 – Successful execution result

](img/B18638_03_031.jpg)

图 3.31–成功的执行结果

几秒钟后，我们应该看到执行结果成功，类似于我们在前面的截图中看到的。

1.  在`x`到`41`然后马上点击`41.481697`。

重要说明

在 AWS Lambda 函数的第一次调用过程中，可能需要几秒钟的时间来下载函数代码并准备好执行环境。这种现象通常被称为*冷启动*。当第二次被调用时(例如，在同一分钟内)， Lambda 功能立即运行，没有与冷启动相关的延迟。例如，Lambda 函数完成第一次调用可能需要大约 30 到 40 秒。在此之后，所有后续的请求都需要一秒或更短的时间。Lambda 函数完成其执行的速度明显更快，因为在第一次调用期间准备的执行环境被冻结，并在随后的调用中重用。如果 AWS Lambda 函数在一段时间后(例如，大约 10 到 30 分钟不活动)没有被调用，则执行环境被删除，并且需要在下次调用该函数时重新准备一个新的执行环境。有不同的方法来管理这一点，并确保 AWS Lambda 功能一致地执行，而不会受到冷启动的影响。其中一个策略是利用**提供的并发性**，这有助于确保可预测的函数启动时间。查看[https://AWS . Amazon . com/blogs/compute/operating-lambda-performance-optimization-part-1/](https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/)了解更多关于这个主题的信息。

我们的 AWS Lambda 函数已经准备好执行 ML 预测，我们可以继续创建触发 Lambda 函数的无服务器 HTTP API。

## 完成并测试无服务器 API 设置

我们创建的 AWS Lambda 函数需要由事件源触发。一个可能的事件源是被配置为接收 HTTP 请求的 API 网关 HTTP API。收到请求后，HTTP API 会将请求数据作为事件传递给 AWS Lambda 函数。Lambda 函数一旦接收到事件，就会使用深度学习模型进行推理，然后将预测的输出值返回给 HTTP API。之后，HTTP API 将向请求资源返回 HTTP 响应。

创建 API 网关 HTTP API 有不同的方法。在接下来的几个步骤中，我们将直接从 AWS Lambda 控制台创建这个 HTTP API:

1.  找到**功能概述**窗格，点击**添加触发器**:

![Figure 3.32 – Add trigger

](img/B18638_03_032.jpg)

图 3.32–添加触发器

**添加触发器**按钮应该在**功能概述**窗格的左侧，如前面的截图所示。

1.  使用以下触发器配置添加一个新 AWS Lambda 触发器:

![Figure 3.33 – Trigger configuration

](img/B18638_03_033.jpg)

图 3.33–触发器配置

这是我们的触发器配置:

*   **选择一个触发器** : **API 网关**
*   **创建新的 API 或使用现有的 API**:**创建 API**
*   **API 类型** : **HTTP API**
*   **安全** : **开启**

这将创建并配置一个 HTTP API，该 API 接受请求并将请求数据作为事件发送给 AWS Lambda 函数。

重要说明

请注意，一旦我们为生产使用配置了我们的设置，就需要保护这个配置。有关这个主题的更多信息，请查看[https://docs . AWS . Amazon . com/API gateway/latest/developer guide/security . XHTML](https://docs.aws.amazon.com/apigateway/latest/developerguide/security.xhtml)。

1.  一旦您完成了新触发器的配置，点击**添加**按钮。
2.  在**触发器**窗格下找到我们刚刚创建的 API 网关触发器。点击 **API 网关**链接(例如 **dlclambda-API** )，这将打开一个新的选项卡。在**开发**(在侧栏中)下，点击**集成**。在 **dlclambda-API** 路径下，点击**任意**。点击**管理集成**，然后点击**编辑**(位于**集成细节**窗格)。在**编辑集成**页面，将**有效载荷格式版本**(在**高级设置**下)的值更新为 **2.0** ，类似于*图 3.34* 中的值。之后点击**保存**。

![Figure 3.34 – Updating the Payload format version

](img/B18638_03_034.jpg)

图 3.34–更新有效载荷格式版本

在更新了 URL 中的`x`值之后，Lambda 函数将在执行测试推断时使用`0`作为默认的`x`值。

注意

如果在向 API 网关端点发送请求时没有指定`x`值，您可能希望触发一个异常。可以随意修改`app.py`的*行 44*:[https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter 03/app/app . py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/app/app.py)来改变这种行为。

1.  将`?x=42`追加到浏览器 URL 的末尾，类似于下面的 URL 字符串:

    ```
    https://<API ID>.execute-api.us-west-2.amazonaws.com/default/dlclambda?x=42
    ```

确保按下`42`作为输入`x`值:

![Figure 3.35 – Testing the API endpoint

](img/B18638_03_035.jpg)

图 3.35–测试 API 端点

这应该会返回一个接近于`42.4586`的值，如前面的截图所示。随意测试`x`的不同值，看看预测的 *y* 值如何变化。

重要说明

确保在完成配置和测试 API 设置后，删除 AWS Lambda 和 API 网关资源。

在这一点上，我们应该为自己感到骄傲，因为我们能够使用 **AWS Lambda** 和 **Amazon API Gateway** 在无服务器 API 中成功部署我们的深度学习模型！在 AWS Lambda 的容器映像支持发布之前，使用我们在本章中使用的相同技术栈来设置和维护无服务器 ML 推理 API 是很棘手的。现在我们已经有了这个初始设置，准备和配置类似的无服务器 ML 驱动的 API 应该更容易了。注意，我们还可以选择创建一个 Lambda 函数 URL 来为 Lambda 函数生成一个惟一的 URL 端点。

![Figure 3.36 – Cost of running the serverless API versus an API running inside an EC2 instance

](img/B18638_03_036.jpg)

图 3.36-运行无服务器 API 与在 EC2 实例中运行 API 的成本比较

在我们结束本章之前，让我们快速检查一下如果我们使用 **AWS Lambda** 和 **API Gateway** 作为 ML 推理端点，成本会是什么样子。如上图所示，运行这个无服务器 API 的预期成本取决于通过它的流量。这意味着，如果没有流量通过 API，成本将是最小的。一旦更多的流量通过这个 HTTP API 端点，成本也会逐渐增加。与右边的图表相比，无论是否有流量通过部署在 EC2 实例中的 HTTP API，预期成本都是相同的。

为您的 API 选择架构和设置取决于多种因素。我们不会详细讨论这个话题，所以请随意查看这里提供的资源:[https://aws.amazon.com/lambda/resources/](https://aws.amazon.com/lambda/resources/)。

# 总结

在这一章中，我们能够更仔细地了解 **AWS 深度学习容器** ( **DLCs** )。与 **AWS 深度学习 AMIs** ( **DLAMIs** )类似，AWS DLCs 已经安装了相关的 ML 框架、库和包。这大大加快了构建和部署深度学习模型的过程。同时，容器环境保证是一致的，因为它们是从预先构建的容器映像运行的。

DLAMIs 和 DLC 之间的一个关键区别是多个 AWS DLCs 可以在一个 EC2 实例中运行。这些容器也可以在其他支持容器的 AWS 服务中使用。这些服务包括 **AWS Lambda** 、**亚马逊 ECS** 、**亚马逊 EKS** 和**亚马逊 EC2** 等等。

在这一章中，我们能够使用 DLC 训练深度学习模型。然后，我们通过 Lambda 的容器映像支持将这个模型部署到 AWS Lambda 函数中。之后，我们测试了 Lambda 函数，看看它是否能够成功加载深度学习模型来执行预测。为了从 HTTP 端点触发这个 Lambda 函数，我们创建了一个 API 网关 HTTP API。

在下一章中，我们将关注**无服务器数据管理**，并使用各种服务来建立和配置数据仓库和数据湖。我们将使用以下 AWS 服务、功能和特性:**红移无服务器**、 **AWS 湖形成**、 **AWS 胶水**和**亚马逊雅典娜**。

# 延伸阅读

有关本章主题的更多信息，请随时查阅以下资源:

*   *什么是深度学习容器？*([https://docs . AWS . Amazon . com/deep-learning-containers/latest/dev guide/what-is-DLC . XHTML](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/what-is-dlc.xhtml))
*   *亚马逊 API 网关中的安全性*(https://docs . AWS . Amazon . com/API Gateway/latest/developer guide/Security . XHTML)
*   *AWS Lambda-容器图像支持的新功能*(https://AWS . Amazon . com/blogs/AWS/New-for-AWS-Lambda-Container-Image-Support/)
*   *使用 AWS Lambda 实现无服务器架构时要避免的问题*([https://AWS . Amazon . com/blogs/Architecture/missons-to-Avoid-When-Implementing-server less-Architecture-with-Lambda/)](https://aws.amazon.com/blogs/architecture/mistakes-to-avoid-when-implementing-serverless-architecture-with-lambda/)