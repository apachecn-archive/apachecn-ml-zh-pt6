<html><head/><body>









<title>Chapter 10: Machine Learning Pipelines with Kubeflow on Amazon EKS</title>







<div><div><h1 class="chapter-number" id="_idParaDest-201"><a id="_idTextAnchor215"/> <a id="_idTextAnchor216"/> 10</h1>

<h1 id="_idParaDest-202"><a id="_idTextAnchor217"/>亚马逊EKS上Kubeflow的机器学习管道</h1>

<p>在<a href="B18638_09.xhtml#_idTextAnchor187"> <em class="italic">第9章</em> </a>、<em class="italic">安全性、治理和遵从性策略</em>中，我们讨论了许多概念和解决方案，这些概念和解决方案关注于我们在处理<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)需求时需要担心的其他挑战和问题。到现在为止，你可能已经意识到ML从业者有很多责任和工作要做，要进行外部模型培训和部署！一旦一个模型被部署到产品中，我们就必须监控这个模型，并确保我们能够检测和管理各种各样的问题。除此之外，ML工程师可能需要构建ML管道来自动化ML生命周期中的不同步骤。为了确保我们在生产中可靠地部署ML模型，以及简化ML生命周期，我们最好学习并应用<strong class="bold">机器学习操作</strong> ( <strong class="bold"> MLOps </strong>)的不同原则。通过MLOps，我们将利用来自<strong class="bold">软件工程</strong>、<strong class="bold"> DevOps </strong>和<strong class="bold">数据工程</strong>的久经考验的工具和实践来生产 ML模型。其中包括利用各种自动化技术将手动执行的Jupyter笔记本转换为自动化的ML工作流程和管道。</p>

<p>在本章中，我们将在<strong class="bold"> Kubernetes </strong>和<strong class="bold"> Amazon Elastic Kubernetes服务</strong> ( <strong class="bold"> EKS </strong>)的基础上使用<strong class="bold"> Kubeflow </strong>构建并运行一个自动化的MLOps管道。如果您想知道这些是什么，不要担心，因为我们稍后将详细讨论这些工具、平台和服务！一旦我们对它们的工作原理有了更好的理解，我们将在构建更复杂的管道时，更深入地研究推荐的策略和最佳实践，以及保护和扩展我们的设置。</p>

<p>也就是说，在本章中，我们将讨论以下主题:</p>

<ul>

<li>深入库伯弗洛、库伯内特和EKS</li>

<li>准备必要的先决条件</li>

<li>在亚马逊EKS上设置Kubeflow</li>

<li>运行我们的第一条Kubeflow管道</li>

<li>使用Kubeflow Pipelines SDK构建ML工作流</li>

<li>清理</li>

<li>推荐的策略和最佳实践</li>

</ul>

<p>一旦我们读到本章的结尾，我们应该对使用本章所学的工具、平台和服务来构建复杂的ML管道更有信心。</p>

<h1 id="_idParaDest-203"><a id="_idTextAnchor218"/>技术要求</h1>

<p>开始之前，我们必须准备好以下内容:</p>

<ul>

<li>网络浏览器(最好是Chrome或Firefox)</li>

<li>访问在<em class="italic">创建您的Cloud9环境</em>和<em class="italic">增加Cloud9存储</em>部分准备的Cloud9环境<a href="B18638_01.xhtml#_idTextAnchor017"> <em class="italic">第1章</em> </a>、<em class="italic">AWS上的ML工程介绍</em></li>

</ul>

<p>Jupyter笔记本、源代码和每章使用的其他文件可从这个资源库获得:<a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS">https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS</a>。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">建议您在运行本书中的示例时，使用具有有限权限的IAM用户，而不是root帐户。如果您刚刚开始使用AWS，可以同时使用root帐户。</p>

<h1 id="_idParaDest-204">深入库伯弗洛、库伯内特斯和EKS</h1>

<p>在<a href="B18638_03.xhtml#_idTextAnchor060"> <em class="italic">第三章</em> </a>、<em class="italic">深度学习容器</em>中，我们了解到容器有助于保证应用运行环境的一致性。在上述章节的实践解决方案中，我们使用了两个容器——一个容器用于训练我们的深度学习模型，另一个容器用于部署模型。在较大的应用程序中，我们很可能会遇到运行各种应用程序、数据库和自动化脚本的多个容器的使用。管理这些容器并不容易，创建定制脚本来管理运行中容器的正常运行时间和伸缩是我们希望避免的开销。也就是说，建议你使用一个工具来帮助你专注于你需要完成的事情。可以帮助我们部署、扩展和管理容器化应用程序的可用工具之一是Kubernetes。这是一个开源容器<a id="_idIndexMarker1290"/>编排系统，为运行弹性分布式系统提供了一个框架。它在后台自动负责伸缩和故障转移工作——这意味着如果您的容器由于某种原因停止工作，Kubernetes会自动替换它。很酷吧？当然，这只是可用的炫酷功能之一。除此之外，Kubernetes还提供以下内容:</p>

<ul>

<li>自动化部署和回滚</li>

<li>秘密(凭证)管理</li>

<li>管理网络流量并将其分配给容器</li>

<li>存储编排</li>

<li>通过根据CPU和RAM需求相应地安装容器来充分利用服务器(节点)</li>

</ul>

<p>注意，这个列表并不详尽，在使用Kubernetes时还有更多可用的特性。使用Kubernetes时，我们必须很好地理解所使用的术语、概念和工具。在<em class="italic">图10.1 </em>中，我们可以看到一个<a id="_idIndexMarker1291"/> Kubernetes集群的示例:</p>

<div><div><img alt="Figure 10.1 – An example Kubernetes cluster&#10;&#10;" height="561" src="img/B18638_10_001.jpg" width="989"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.1–Kubernetes集群示例</p>

<p>让我们快速定义和描述<em class="italic">图10.1 </em>中的一些概念:</p>

<ul>

<li><strong class="bold">节点</strong>:这个<a id="_idIndexMarker1292"/>映射到包含正在运行的容器化应用程序的虚拟机或物理机(或EC2实例)。</li>

<li><strong class="bold">集群</strong>:这是一组<a id="_idIndexMarker1293"/>节点(或服务器)。</li>

<li><strong class="bold"> Pod </strong>:这个<a id="_idIndexMarker1294"/>是一组一个或多个应用程序容器，代表一个服务单元(在一个节点内运行)。</li>

<li><strong class="bold">控制平面</strong>:这个<a id="_idIndexMarker1295"/>管理工作节点(服务器)以及Kubernetes集群中的pod。</li>

<li>kubectl :这是<a id="_idIndexMarker1296"/>命令行工具，用于运行命令来管理Kubernetes资源。</li>

</ul>

<p>请注意，这是一个简化的列表，因为我们不会深入本章中的其他概念和术语。了解它们应该足以帮助我们完成本章的动手解决方案。</p>

<p>当在AWS上运行Kubernetes时，建议您使用托管服务，如<strong class="bold">亚马逊EKS </strong>，它<a id="_idIndexMarker1297"/>帮助我们在幕后管理许多事情——包括控制平面节点的可用性和可扩展性(这些节点专注于存储集群数据，确保应用可用性，以及集群中的其他重要流程和任务)。当使用亚马逊EKS时，我们不再需要担心控制平面实例的管理，因为AWS会自动扩展这些实例，并为我们替换任何不健康的实例。除此之外，亚马逊EKS帮助工程师在使用Kubernetes时无缝地与其他AWS服务和资源(例如，<strong class="bold"> AWS IAM </strong>、<strong class="bold"> AWS应用程序负载平衡器</strong>和<strong class="bold">亚马逊云观察</strong>)合作。</p>

<p class="callout-heading">注意</p>

<p class="callout">可以使用Kubernetes和亚马逊EKS来设置节点的自动缩放。这是使用<a id="_idIndexMarker1298"/>解决方案配置的，例如<strong class="bold"> Kubernetes集群自动缩放器</strong>。有关更多信息，请随时查看<a href="https://aws.github.io/aws-eks-best-practices/cluster-autoscaling/">https://AWS . github . io/AWS-eks-best-practices/cluster-auto scaling/</a>。</p>

<p>管理EKS集群的主要工具是<a id="_idIndexMarker1299"/>eks CTL命令行工具。使用这个工具，只需一个命令就可以轻松地创建、更新和删除EKS集群。一旦集群可用，我们就可以继续使用其他工具，如<a id="_idIndexMarker1300"/><strong class="bold">kubectl</strong>命令行工具来创建和管理集群中的Kubernetes资源。</p>

<p>由于Kubernetes的强大功能和潜力，许多其他工具都是在它的基础上构建的。其中包括<strong class="bold">kube flow</strong>——一个流行的开源ML平台，专注于帮助数据科学家和ML工程师在Kubernetes上编排和管理复杂的ML工作流。Kubeflow汇集了数据科学家和ML工程师已经熟悉的数据科学和ML工具的集合。其中包括以下内容:</p>

<ul>

<li><strong class="bold">JupyterHub</strong>——这是一个<a id="_idIndexMarker1302"/>中枢，帮助产生和管理多个Jupyter笔记本(数据科学家可以在这里运行ML实验的代码)。</li>

<li><strong class="bold"> Argo工作流</strong>–这个<a id="_idIndexMarker1303"/>是一个工作流引擎，自动化管道在其上运行。</li>

<li><strong class="bold">kna tive Serving</strong>—<a id="_idIndexMarker1304"/>支持快速部署无服务器容器(ML模型可以在其中运行)。</li>

<li><strong class="bold">Istio</strong>–这是一个<a id="_idIndexMarker1305"/>服务网格，提供了一种轻松管理网络配置和集群中部署的微服务之间的通信的方法。</li>

<li><strong class="bold">MinIO</strong>—<a id="_idIndexMarker1306"/>这是一个多云端对象存储解决方案，原生于Kubernetes。</li>

</ul>

<p>有了Kubeflow，ML从业者可以执行ML实验和部署，而不用担心基础设施。同时，自动化的ML工作流和管道可以使用Kubeflow中可用的各种工具<a id="_idIndexMarker1308"/>轻松部署和管理(如<strong class="bold"> Kubeflow管道</strong>和<strong class="bold"> Kubeflow管道SDK </strong>)。如果构建得当，这些管道可以帮助数据科学家和ML工程师通过ML过程不同步骤的自动化节省大量时间。同时，这些管道可以实现自动化的模型再训练，这将有助于确保使用最新的可用训练数据来更新部署的模型。</p>

<p>现在我们对将要使用的工具有了更好的了解，我们将继续准备在亚马逊EKS上使用Kubeflow运行ML管道的必要先决条件！</p>

<h1 id="_idParaDest-205"><a id="_idTextAnchor220"/>准备必要的先决条件</h1>

<p>在此<a id="_idIndexMarker1309"/>部分，我们将进行以下工作:</p>

<ul>

<li>为Cloud9环境的EC2实例准备IAM角色</li>

<li>将IAM角色附加到Cloud9环境的EC2实例</li>

<li>用必要的先决条件更新Cloud9环境</li>

</ul>

<p>让我们一个接一个地准备必要的先决条件。</p>

<h2 id="_idParaDest-206"><a id="_idTextAnchor221"/>为Cloud9环境的EC2实例准备IAM角色</h2>

<p>为了让我们从Cloud9环境的EC2实例内部安全地创建和管理<strong class="bold">亚马逊EKS </strong>和<strong class="bold"> AWS CloudFormation </strong>资源<a id="_idIndexMarker1311"/>，我们需要将IAM角色附加到EC2实例。在本节中，我们将准备此IAM角色，并为其配置创建和管理本章中其他资源所需的权限。</p>

<p class="callout-heading">注意</p>

<p class="callout">我们将在本章的<em class="italic">在亚马逊EKS </em>上设置kube flow部分更详细地讨论<strong class="bold">亚马逊EKS </strong>和<strong class="bold"> AWS CloudFormation </strong>。</p>

<p>在接下来的一组步骤中，我们<a id="_idIndexMarker1312"/>将导航到IAM控制台并创建一个IAM角色，该角色将在本章稍后部分附加到(Cloud9环境的)EC2实例:</p>

<ol>

<li>通过在搜索栏中键入<code>iam</code>导航到IAM控制台，然后从结果列表中单击<strong class="bold"> IAM </strong>，如<em class="italic">图10.2 </em>中突出显示的:</li>

</ol>

<div><div><img alt="Figure 10.2 – Navigating to the IAM console&#10;&#10;" height="502" src="img/B18638_10_002.jpg" width="890"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.2–导航至IAM控制台</p>

<p class="list-inset">在<em class="italic">图10.2 </em>中，我们<a id="_idIndexMarker1313"/>有一种导航到IAM控制台的方法。另一个选项是单击<strong class="bold">服务</strong>下拉菜单(在前面的屏幕截图中未显示)，并在<strong class="bold">安全、身份和合规性</strong>服务组下找到<strong class="bold"> IAM </strong>服务。</p>

<ol>

<li value="2">在左侧边栏中，找到并点击<strong class="bold">角色</strong>(在<strong class="bold">访问管理</strong>下)。</li>

<li>在页面的右上角，找到并点击<strong class="bold">创建角色</strong>按钮。</li>

<li>在<strong class="bold">选择可信实体</strong>页面(第1步，共3步)，选择<strong class="bold">可信实体类型</strong>下的<strong class="bold"> AWS服务</strong>，如图<em class="italic">图10.3 </em>所示:</li>

</ol>

<div><div><img alt="Figure 10.3 – The Select trusted entity page&#10;&#10;" height="602" src="img/B18638_10_003.jpg" width="816"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.3–选择受信任实体页面</p>

<p class="list-inset">这里，我们还<a id="_idIndexMarker1314"/>确保在<strong class="bold">用例&gt;通用用例</strong>下选择<strong class="bold"> EC2 </strong>选项。一旦我们检查了所选的选项，我们可以随后点击<strong class="bold">下一个</strong>按钮。</p>

<ol>

<li value="5">在<code>administrator</code>中进入过滤搜索框(如图10.4<em class="italic">中高亮显示的</em>，然后按<em class="italic">回车</em>键过滤结果列表。选中与<strong class="bold">管理员访问</strong>策略对应的复选框，向下滚动到页面底部，然后单击<strong class="bold">下一步</strong>按钮:</li>

</ol>

<div><div><img alt="Figure 10.4 – The Add permissions page&#10;&#10;" height="590" src="img/B18638_10_004.jpg" width="939"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.4–添加权限页面</p>

<p class="list-inset">确保<a id="_idIndexMarker1315"/>你不会意外地从过滤结果列表中选择不正确的权限，因为有相似名称的权限可用。<strong class="bold">管理员访问</strong>策略应该具有<strong class="bold">描述</strong>值<strong class="bold">提供对AWS服务和资源的完全访问</strong>。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">在本章中，<code>AdministratorAccess</code>策略的使用将帮助我们在设置时避免不同的权限相关问题。在您的工作环境中进行设置时，您应该使用一个定制策略，该策略只添加EC2实例运行应用程序所需的权限(仅此而已)。</p>

<ol>

<li value="6">在<code>kubeflow-on-eks</code>中的<strong class="bold">角色名称</strong>输入框中。向下滚动到页面底部，然后单击<strong class="bold">创建角色</strong>按钮。</li>

</ol>

<p>没那么容易吧！此时，我们应该有一个IAM角色可以附加到AWS资源，比如EC2实例。</p>

<h2 id="_idParaDest-207"><a id="_idTextAnchor222"/>将IAM角色附加到Cloud9环境的EC2实例</h2>

<p>既然我们已经准备好了IAM角色，现在我们可以继续将这个IAM角色附加到EC2实例。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">在本章中，我们将在<code>us-west-2</code>区域创建和管理我们的资源。在继续下一步之前，请确保您已经设置了正确的区域。</p>

<p>在下一组步骤中，我们将使用AWS管理控制台将IAM角色附加到运行Cloud9环境的EC2实例:</p>

<ol>

<li value="1">通过在搜索栏中键入<code>cloud9</code>，然后从结果列表中选择<strong class="bold"> Cloud9 </strong>，导航到Cloud9控制台:</li>

</ol>

<div><div><img alt="Figure 10.5 – Navigating to the Cloud9 console&#10;&#10;" height="511" src="img/B18638_10_005.jpg" width="828"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.5–导航至Cloud9控制台</p>

<p class="list-inset">在<em class="italic">图10.5 </em>中，我们有一种导航到Cloud9服务页面的方法。另一个选择是点击<strong class="bold">服务</strong>下拉菜单(在前面的截图中没有显示)并在<strong class="bold">开发者工具</strong>服务组中找到<strong class="bold"> Cloud9 </strong>服务。</p>

<ol>

<li value="2">定位并选择我们在<a href="B18638_01.xhtml#_idTextAnchor017"> <em class="italic">第一章</em> </a>、<em class="italic">AWS上ML工程介绍</em>中准备的Cloud9环境:</li>

</ol>

<div><div><img alt="Figure 10.6 – Locating the View details button&#10;&#10;" height="640" src="img/B18638_10_006.jpg" width="907"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.6–定位查看详细信息按钮</p>

<p class="list-inset">一旦<a id="_idIndexMarker1317"/>选择了Cloud9环境，点击位于页面右上方的<strong class="bold">查看详情</strong>按钮(如图<em class="italic">图10.6 </em>中突出显示的)。</p>

<p class="callout-heading">注意</p>

<p class="callout">您还可能决定从头创建一个新的Cloud9环境，并增加附加到运行该环境的EC2实例的卷的大小。如果是这种情况，请确保遵循<a href="B18638_01.xhtml#_idTextAnchor017"> <em class="italic">第1章</em> </a>、<em class="italic">AWS上的ML工程介绍</em>的<em class="italic">创建您的Cloud9环境</em>和<em class="italic">增加Cloud9存储</em>部分中指定的分步说明。</p>

<ol>

<li value="3">在<strong class="bold">环境细节</strong>下，定位并点击<strong class="bold">转到实例</strong>链接，如图<em class="italic">图10.7 </em>所示:</li>

</ol>

<div><div><img alt="Figure 10.7 – Locating and clicking on the Go To Instance button&#10;&#10;" height="395" src="img/B18638_10_007.jpg" width="832"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.7–定位并点击“转到实例”按钮</p>

<p class="list-inset">这应该会将您重定向到EC2控制台，在那里您应该会看到Cloud9环境正在运行的特定EC2实例。</p>

<ol>

<li value="4">勾选EC2实例对应的<a id="_idIndexMarker1318"/>复选框(从<code>aws-cloud9</code>开始)，然后打开<strong class="bold">动作</strong>下拉菜单，如图<em class="italic">图10.8 </em>所示:</li>

</ol>

<div><div><img alt="Figure 10.8 – Modifying the IAM role of the EC2 instance &#10;&#10;" height="459" src="img/B18638_10_008.jpg" width="1072"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.8–修改EC2实例的IAM角色</p>

<ol>

<li value="5">接下来，我们在<strong class="bold">安全</strong>下的选项列表中找到并点击<strong class="bold">修改IAM角色</strong>选项。这应该会将您重定向到一个页面，在该页面中您可以选择特定的IAM角色来附加到所选的EC2实例。</li>

<li>在IAM角色下拉菜单中(如<em class="italic">图10.9 </em>中突出显示的)，找到并选择我们在本章前面创建的IAM角色(即<code>kubeflow-on-eks</code> IAM角色):</li>

</ol>

<div><div><img alt="Figure 10.9 – Specifying kubeflow-on-eks as the IAM role&#10;&#10;" height="506" src="img/B18638_10_009.jpg" width="1047"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.9–将kubeflow-on-eks指定为IAM角色</p>

<p class="list-inset">一旦<a id="_idIndexMarker1319"/>将IAM角色下拉值更新为<code>kubeflow-on-eks</code>，您现在可以点击<strong class="bold">更新IAM角色</strong>按钮(如图<em class="italic">图10.9 </em>中突出显示的)。</p>

<ol>

<li value="7">通过在搜索栏中键入<code>cloud9</code>，然后从结果列表中选择<strong class="bold"> Cloud9 </strong>，导航回Cloud9控制台。</li>

<li>找到并点击与我们的Cloud9环境相关的<strong class="bold"> Open IDE </strong>按钮。这将打开一个类似于图10.10所示的Cloud9环境:</li>

</ol>

<div><div><img alt="Figure 10.10 – The Cloud9 environment&#10;&#10;" height="511" src="img/B18638_10_010.jpg" width="887"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.10–云9环境</p>

<p class="list-inset">在这里，我们<a id="_idIndexMarker1320"/>应该会看到一个熟悉的屏幕(因为我们已经在<a href="B18638_01.xhtml#_idTextAnchor017"> <em class="italic">第一章</em> </a>、<em class="italic">AWS上的ML工程简介</em>和<a href="B18638_03.xhtml#_idTextAnchor060"> <em class="italic">第三章</em> </a>、<em class="italic">深度学习容器</em>中使用过这个)。</p>

<p class="list-inset">在Cloud9环境的终端中(在屏幕下部的＄符号之后)，运行以下命令来禁用环境中的托管临时凭据:</p>

<pre class="list-inset1 source-code"><strong class="bold">ENV_ID=$C9_PID</strong>

<strong class="bold">aws cloud9 update-environment --managed-credentials-action DISABLE --environment-id $ENV_ID</strong></pre>

<ol>

<li value="9">同样，让我们删除<code>.aws</code>目录中的凭证文件，以确保临时凭证也不存在:<pre class="source-code"><strong class="bold">rm -vf /home/ubuntu/.aws/credentials</strong></pre></li>

<li>最后，让我们验证Cloud9环境正在使用我们在本章中准备的IAM角色(即<code>kubeflow-on-eks</code> IAM角色):<pre class="source-code"><strong class="bold">aws sts get-caller-identity</strong> --query Arn </pre></li>

</ol>

<p class="list-inset">这应该会产生类似如下的结果:</p>

<pre class="list-inset1 source-code">arn:aws:sts::1234567890:assumed-role/<strong class="bold">kubeflow-on-eks</strong>/i-abcdefgh12345</pre>

<p>一旦<a id="_idIndexMarker1321"/>验证了我们在Cloud9环境中使用了正确的IAM角色，我们就可以继续下一部分了。</p>

<p class="callout-heading">注意</p>

<p class="callout"><em class="italic">这里发生了什么？</em> IAM角色(附属于AWS资源)在每隔几小时到期的环境内生成并提供凭证。为了能够使用IAM角色，我们需要删除任何现有的凭证集(在Cloud9环境中),以便环境将使用IAM角色凭证。有关这个主题的更多信息，请随时查看<a href="https://docs.aws.amazon.com/cloud9/latest/user-guide/security-iam.xhtml">https://docs . AWS . Amazon . com/cloud 9/latest/user-guide/security-iam . XHTML</a>。</p>

<h2 id="_idParaDest-208"><a id="_idTextAnchor223"/>使用必要的先决条件更新Cloud9环境</h2>

<p>在创建我们的<a id="_idIndexMarker1322"/> EKS集群并在其上设置Kubeflow之前，我们需要下载并<a id="_idIndexMarker1323"/>安装一些先决条件<a id="_idIndexMarker1324"/>，包括<a id="_idIndexMarker1325"/>几个命令行工具，比如<strong class="bold"> kubectl </strong>、<strong class="bold"> eksctl </strong>和<strong class="bold"> kustomize </strong>。</p>

<p class="callout-heading">注意</p>

<p class="callout">我们将在本章的<em class="italic">在亚马逊EKS </em>部分讨论这些是如何工作的。</p>

<p>在下一组步骤中，我们将运行几个脚本，<a id="_idIndexMarker1326"/>将安装让<strong class="bold"> Kubernetes </strong>和<strong class="bold"> Kubeflow </strong>在我们的环境中运行所需的先决条件:</p>

<ol>

<li value="1">让我们首先使用<code>wget</code>命令(在Cloud9环境的终端中)下载包含各种安装脚本的<code>prerequisites.zip</code>文件。之后，我们将使用<code>unzip</code>命令提取我们刚刚下载的ZIP文件的内容:<pre class="source-code"><strong class="bold">wget</strong> -O <strong class="bold">prerequisites.zip</strong> https://bit.ly/3ByyDGV</pre> <pre class="source-code"><strong class="bold">unzip</strong> prerequisites.zip</pre></li>

</ol>

<p class="list-inset">这将从ZIP文件中提取以下文件:</p>

<ul>

<li><code>00_install_kubectl_aws_jq_and_more.sh</code>–这是一个运行所有其他脚本(前缀为<code>01</code>到<code>07</code>)来安装先决条件的脚本。</li>

<li><code>01_install_kubectl.sh</code>–这是一个安装kubectl命令行工具的脚本。</li>

<li><code>02_install_aws_cli_v2.sh</code>–这是一个<a id="_idIndexMarker1328"/>脚本，安装<strong class="bold"> AWS CLI </strong>的v2。</li>

<li><code>03_install_jq_and_more.sh</code>–这是一个安装并设置了<a id="_idIndexMarker1329"/>几个先决条件的脚本，比如<em class="italic"> jq </em>和<em class="italic"> yq </em>。</li>

<li><code>04_check_prerequisites.sh</code>–这是一个检查前几个先决条件是否已经成功安装的脚本。</li>

<li><code>05_additional_setup_instructions.sh</code>–这是一个设置Bash完成的脚本。</li>

<li><code>06_download_eksctl.sh</code>–这是<a id="_idIndexMarker1330"/>安装<strong class="bold"> eksctl </strong>命令行工具的脚本。</li>

<li><code>07_install_kustomize.sh</code>–这是一个<a id="_idIndexMarker1331"/>脚本，安装<strong class="bold"> kustomize </strong>的3.2.3版本。</li>

</ul>

<ol>

<li value="2">导航到<code>ch10_prerequisites</code>文件夹，运行<code>chmod</code>命令，使文件夹中的脚本可执行:<pre class="source-code">cd ch10_prerequisites</pre> <pre class="source-code"><strong class="bold">chmod +x *.sh</strong></pre></li>

<li>现在，运行以下命令开始安装和设置过程:<pre class="source-code"><strong class="bold">sudo ./00_install_kubectl_aws_jq_and_more.sh</strong></pre></li>

</ol>

<p class="list-inset">这将运行从<code>01_install_kubectl.sh</code>到<code>07_install_kustomize.sh</code>的<code>ch10_prerequisites</code>文件夹中的其他脚本。</p>

<p class="callout-heading">注意</p>

<p class="callout">一旦<code>00_install_kubectl_aws_jq_and_more.sh</code>脚本完成运行，几个<a id="_idIndexMarker1332"/>先决条件，如<strong class="bold"> AWS CLI v2 </strong>、<strong class="bold"> eksctl </strong>和<strong class="bold"> kustomize </strong>，应该已经可供我们使用<a id="_idIndexMarker1334"/>来准备Kubernetes集群(如果安装期间没有错误)。请确保在继续操作之前查看脚本生成的日志。</p>

<ol>

<li value="4">验证我们当前拥有的AWS CLI的<a id="_idIndexMarker1335"/>版本:<pre class="source-code"><strong class="bold">aws --version</strong></pre></li>

</ol>

<p class="list-inset">这应该会产生类似如下的结果:</p>

<pre class="list-inset1 source-code">aws-cli/<strong class="bold">2.7.20</strong> Python/3.9.11 Linux/5.4.0-1081-aws exe/x86_64.ubuntu.18 prompt/off</pre>

<ol>

<li value="5">接下来，让我们验证我们将使用的<code>kustomize</code>的版本:<pre class="source-code"><strong class="bold">kustomize version</strong></pre></li>

</ol>

<p class="list-inset">这应该会产生类似如下的结果:</p>

<pre class="list-inset1 source-code">Version: {Version:kustomize/<strong class="bold">v3.2.3</strong> GitCommit:f8412aa3d39f32151525aff97a351288f5a7470b BuildDate:2019-10-08T23:30:25Z GoOs:linux GoArch:amd64}</pre>

<ol>

<li value="6">我们也来验证一下<code>eksctl</code>的版本:<pre class="source-code"><strong class="bold">eksctl version</strong></pre></li>

</ol>

<p class="list-inset">这应该会产生类似如下的结果:</p>

<pre class="list-inset1 source-code"><strong class="bold">0.109.0</strong></pre>

<ol>

<li value="7">运行以下命令，以便安装脚本中的其他更改(如环境变量值)反映在我们当前的shell中:<pre class="source-code"><strong class="bold">. ~/.bash_completion</strong></pre> <pre class="source-code"><strong class="bold">. ~/.bash_profile</strong></pre> <pre class="source-code"><strong class="bold">. ~/.bashrc</strong></pre></li>

</ol>

<p class="list-inset">注意每行开头的波浪号(<code>~</code>)前有一个点(<code>.</code>)和一个空格。</p>

<ol>

<li value="8">使用AWS CLI时，运行下面的<a id="_idIndexMarker1336"/>命令块来设置一些环境变量并配置默认区域:<pre class="source-code">export <strong class="bold">AWS_REGION</strong>="us-west-2"</pre> <pre class="source-code">echo "export AWS_REGION=${<strong class="bold">AWS_REGION</strong>}" | tee -a ~/.bash_profile</pre> <pre class="source-code">aws configure set <strong class="bold">default.region</strong> ${AWS_REGION}</pre></li>

<li>最后，确认默认区域设置成功:<pre class="source-code">aws configure get <strong class="bold">default.region</strong></pre></li>

</ol>

<p class="list-inset">这应该产生一个值<code>us-west-2</code>(如果我们在俄勒冈州运行我们的Cloud9环境)。</p>

<p>既然已经安装、设置并验证了所有的先决条件，我们就可以继续创建一个EKS集群并在其上设置Kubeflow了！</p>

<h1 id="_idParaDest-209"><a id="_idTextAnchor224"/>在亚马逊EKS上设置Kubeflow</h1>

<p>准备好所有的先决条件后，我们现在可以继续<a id="_idIndexMarker1338"/>创建我们的EKS集群，然后在其上安装Kubeflow。在安装和设置过程中，我们将使用以下工具:</p>

<ul>

<li>用于创建和管理亚马逊EKS集群的CLI工具</li>

<li><strong class="bold">ku bectl</strong>—<a id="_idIndexMarker1340"/>用于创建、配置和删除Kubernetes资源的CLI工具</li>

<li><strong class="bold">AWS CLI</strong>–用于创建、配置和删除AWS资源的<a id="_idIndexMarker1341"/> CLI工具</li>

<li>用于管理Kubernetes对象配置的CLI工具</li>

</ul>

<p>本部分的实践部分包括以下一系列高级步骤:</p>

<ol>

<li value="1">准备包含EKS配置的<code>eks.yaml</code>文件(例如节点数量、所需容量和实例类型)</li>

<li>使用<code>eks.yaml</code>文件运行<code>eks create cluster</code>命令来创建亚马逊EKS集群</li>

<li>使用<strong class="bold"> kustomize </strong>和<strong class="bold"> kubectl </strong>在我们的集群内部安装Kubeflow</li>

</ol>

<p>记住这些，我们现在可以开始设置我们的EKS集群和Kubeflow:</p>

<ol>

<li value="1">继续我们在上一节中停止的地方，让我们在Cloud9环境的终端中运行以下命令:<pre class="source-code">cd <strong class="bold">~/environment</strong></pre> <pre class="source-code">mkdir <strong class="bold">ch10</strong></pre> <pre class="source-code">cd <strong class="bold">ch10</strong></pre></li>

</ol>

<p class="list-inset">这里，我们使用<code>mkdir</code>命令创建<code>ch10</code>目录。之后，我们将使用<code>cd</code>命令导航到该目录。</p>

<ol>

<li value="2">接下来，让我们使用<code>touch</code>命令创建一个空的<code>eks.yaml</code>文件:<pre class="source-code">touch <strong class="bold">eks.yaml</strong></pre></li>

<li>在<a id="_idIndexMarker1343"/>的<strong class="bold">文件树</strong>中，找到带有您的Cloud9环境名称的环境目录。右键单击该目录，打开类似于<em class="italic">图10.11 </em>所示的上下文菜单:</li>

</ol>

<div><div><img alt="Figure 10.11 – Refreshing the displayed directories and files&#10;&#10;" height="290" src="img/B18638_10_011.jpg" width="380"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.11–刷新显示的目录和文件</p>

<p class="list-inset">从<a id="_idIndexMarker1344"/>选项列表中选择<strong class="bold">刷新</strong>到<a id="_idIndexMarker1345"/>确保最新的更改已经反映在文件树中。</p>

<ol>

<li value="4">接下来，双击文件树中的<code>eks.yaml</code>文件(在<code>ch10</code>目录中),在<strong class="bold">编辑器</strong>窗格中打开该文件。在这个空白文件里面，指定以下YAML配置:<pre class="source-code">---</pre><pre class="source-code">apiVersion: eksctl.io/v1alpha5</pre><pre class="source-code">kind: ClusterConfig</pre><pre class="source-code">metadata:</pre><pre class="source-code">  name: <strong class="bold">kubeflow-eks-000</strong></pre><pre class="source-code">  region: <strong class="bold">us-west-2</strong></pre><pre class="source-code">  version: "1.21"</pre><pre class="source-code">availabilityZones: [<strong class="bold">"us-west-2a"</strong>, <strong class="bold">"us-west-2b"</strong>, <strong class="bold">"us-west-2c"</strong>, <strong class="bold">"us-west-2d"</strong>]</pre><pre class="source-code">managedNodeGroups:</pre><pre class="source-code">- name: nodegroup</pre><pre class="source-code">  desiredCapacity: <strong class="bold">5</strong></pre><pre class="source-code">  instanceType: <strong class="bold">m5.xlarge</strong></pre><pre class="source-code">  ssh:</pre><pre class="source-code">    enableSsm: true</pre></li>

</ol>

<p class="list-inset">确保通过按下<em class="italic"> Ctrl </em> + <em class="italic"> S </em>键来<a id="_idIndexMarker1346"/>保存您的更改(或者，在使用Mac设备时，按下<em class="italic"> Cmd </em> + <em class="italic"> S </em>)。此外，您可以使用<strong class="bold">文件</strong>菜单中的<strong class="bold">保存</strong>选项来保存您的更改。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">在继续之前，我们必须知道使用这个配置文件运行<code>eksctl create cluster</code>命令时将会创建的资源。在这里，我们指定希望我们的集群(名为<code>kubeflow-eks-000</code>)有五个(<code>5</code> ) <code>m5.xlarge</code>实例。在下一步中运行<code>eksctl create cluster</code>命令后，确保在集群创建后的一两个小时内删除集群，以管理成本。一旦您需要删除集群，请随意跳到本章末尾的<em class="italic">清理</em>部分。</p>

<ol>

<li value="5">在<a id="_idIndexMarker1347"/>为我们的集群创建真正的资源之前，让我们使用带有<code>--dry-run</code>选项的<code>eksctl create cluster</code>命令:<pre class="source-code"><strong class="bold">eksctl create cluster -f eks.yaml --dry-run</strong></pre></li>

</ol>

<p class="list-inset">这应该有助于我们在创建实际的资源集之前检查配置。</p>

<ol>

<li value="6">现在，让我们使用<code>eksctl create</code>命令:<pre class="source-code"><strong class="bold">eksctl create cluster -f eks.yaml</strong></pre>创建我们的集群</li>

</ol>

<p class="list-inset">这里，我们使用在上一步中准备的<code>eks.yaml</code>文件作为运行命令时的配置文件。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">如果您遇到一个类似于<code>eks.yaml</code>文件中的<code>version</code>字符串值的错误消息，该文件具有错误消息中指定的最低支持版本。一旦你更新了<code>eks.yaml</code>文件，你可以再次运行<code>eksctl create cluster</code>命令，检查问题是否已经解决。有关这个主题的更多信息，请随时查看<a href="https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.xhtml">https://docs . AWS . Amazon . com/eks/latest/user guide/kubernetes-versions . XHTML</a>。</p>

<p class="list-inset">运行<code>eksctl create cluster</code>命令大约需要15-30分钟才能完成<a id="_idIndexMarker1348"/>。它将使用<strong class="bold">云信息</strong>堆栈<a id="_idIndexMarker1349"/>来启动<a id="_idIndexMarker1350"/> AWS资源。如果您想知道什么是CloudFormation，它是一种让您在模板中定义基础架构的每个组件及其设置的服务。然后，CloudFormation读取该模板，以调配您的基础架构所需的资源:</p>

<div><div><img alt="Figure 10.12 – How EKS resources are created using eksctl&#10;&#10;" height="531" src="img/B18638_10_012.jpg" width="1053"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.12–如何使用eksctl创建EKS资源</p>

<p class="list-inset">在<em class="italic">图10.12 </em>中，我们可以看到<code>eksctl</code>命令利用<code>eks.yaml</code>文件来准备模板，这些模板将被云信息<a id="_idIndexMarker1351"/>服务用来提供资源。</p>

<p class="callout-heading">注意</p>

<p class="callout">注意<code>eksctl</code>也创建了CloudFormation之外的其他资源。这意味着用于准备EKS资源的云形成模板将<em class="italic">而不是</em>包含使用<code>eksctl</code>命令创建的所有资源。也就是说，在删除本节创建的资源时，最好使用<code>eksctl delete cluster</code>命令。一旦需要删除资源，请确保遵循本章<em class="italic">清理</em>一节中指定的说明。</p>

<ol>

<li value="7">让我们使用<code>kubectl get nodes</code>命令:<pre class="source-code"><strong class="bold">kubectl get nodes -o wide</strong></pre>快速<a id="_idIndexMarker1352"/>检查我们的设置</li>

</ol>

<p class="list-inset">这应该给我们五个节点，它们的<strong class="bold">状态</strong>值为<strong class="bold">就绪</strong>。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">如果您在部署EKS集群时遇到问题，请确保查看<a href="https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.xhtml">https://docs . AWS . Amazon . com/eks/latest/user guide/trouble shooting . XHTML</a>。</p>

<ol>

<li value="8">在继续之前，让我们确保<code>CLUSTER_NAME</code>和<code>CLUSTER_REGION</code>已经设置了适当的值:<pre class="source-code">CLUSTER_NAME=<strong class="bold">kubeflow-eks-000</strong></pre> <pre class="source-code">CLUSTER_REGION=<strong class="bold">us-west-2</strong></pre></li>

</ol>

<p class="list-inset">在这里，我们指定一个与在<code>eks.yaml</code>文件中指定的名称等价的<code>CLUSTER_NAME</code>值。注意，如果您需要试验另一组配置参数，您可以指定不同的集群名称(通过更新<code>CLUSTER_NAME</code>和<code>eks.yaml</code>文件)并在创建新集群时用<code>kubeflow-eks-001</code>替换<code>kubeflow-eks-000</code>(等等)。只需确保在创建新集群之前正确删除任何现有集群。</p>

<ol>

<li value="9">此外，让我们将IAM OIDC提供者与集群相关联:<pre class="source-code"><strong class="bold">eksctl utils associate-iam-oidc-provider --cluster $CLUSTER_NAME --approve -v4</strong></pre></li>

</ol>

<p class="list-inset">那么，什么是IAM OIDC提供商呢？嗯，它是一个IAM实体，用于在您的<a id="_idIndexMarker1353"/> AWS帐户和外部OpenID Connect兼容的<a id="_idIndexMarker1354"/>身份提供者之间建立信任。这意味着，我们可以使用IAM OIDC提供者来代替创建IAM用户，并授予这些身份使用我们的AWS帐户中的资源的权限。</p>

<p class="callout-heading">注意</p>

<p class="callout">有关这个主题的更多信息，请随时查看<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc.xhtml">https://docs . AWS . Amazon . com/IAM/latest/user guide/id _ roles _ providers _ create _ oidc . XHTML</a>。</p>

<ol>

<li value="10">让我们使用<code>aws eks update-kubeconfig</code>命令来配置<code>kubectl</code>，这样我们就可以连接到亚马逊EKS集群:<pre class="source-code"><strong class="bold">aws eks update-kubeconfig --name $CLUSTER_NAME --region ${AWS_REGION}</strong></pre></li>

<li>接下来，我们将克隆两个包含清单(包含Kubernetes对象规范的文件)的存储库，用于安装我们需要的内容:<pre class="source-code">export <strong class="bold">KUBEFLOW_VERSION=v1.5.1</strong></pre> <pre class="source-code">export <strong class="bold">AWS_VERSION=v1.5.1-aws-b1.0.0</strong></pre> <pre class="source-code">git clone <strong class="bold">https://github.com/awslabs/kubeflow-manifests.git</strong> &amp;&amp; cd <strong class="bold">kubeflow-manifests</strong></pre> <pre class="source-code">git checkout ${AWS_VERSION}</pre> <pre class="source-code">git clone --branch ${KUBEFLOW_VERSION} \</pre> <pre class="source-code"><strong class="bold">https://github.com/kubeflow/manifests.git</strong> upstream</pre></li>

<li>导航<a id="_idIndexMarker1355"/>到<code>deployments/vanilla</code>目录:<pre class="source-code"><strong class="bold">cd deployments/vanilla</strong></pre></li>

</ol>

<p class="list-inset">我们应该在这个目录中找到一个<code>kustomization.yaml</code>文件。有关这个主题的更多信息，请随时查看<a href="https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/">https://kubernetes . io/docs/tasks/manage-kubernetes-objects/kustomization/</a>。</p>

<ol>

<li value="13">一切准备就绪后，让我们运行这个单行命令来安装Kubeflow组件和服务:<pre class="source-code"><strong class="bold">while ! kustomize build . | kubectl apply -f -; do echo "Retrying"; sleep 30; done</strong></pre></li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">完成此步骤大约需要4-10分钟。如果输出日志似乎已经无限循环了超过20-30分钟，您可能需要在<code>eks.yaml</code>文件的<code>version</code>字符串值中尝试不同的值。我们可以使用哪些值？假设目前支持的版本有<code>1.20</code>、<code>1.21</code>、<code>1.22</code>、<code>1.23</code>(如<a href="https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.xhtml">https://docs . AWS . Amazon . com/eks/latest/user guide/kubernetes-versions . XHTML</a>所示)。我们应该尝试使用1.23版本吗？如果我们在<code>eks.yaml</code>文件中使用最新支持的Kubernetes版本<code>1.23</code>，我们可能会在安装Kubeflow时遇到问题。我们可能需要等待几个月来让Kubeflow支持跟上(如<a href="https://awslabs.github.io/kubeflow-manifests/docs/about/eks-compatibility/">https://aw slabs . github . io/kube flow-manifests/docs/about/eks-compatibility/</a>中所示)。也就是说，当使用<code>eksctl create cluster</code>命令时，我们可以尝试在<code>eks.yaml</code>文件中指定<code>1.20</code>、<code>1.21</code>或<code>1.22</code>(从支持的最低版本的<code>1.20</code>开始)。记住这些，下一步是使用<code>eksctl delete cluster</code>命令删除集群(请参见<em class="italic">清理</em>部分)，用所需的Kubernetes版本更新<code>eks.yaml</code>文件，然后重复本部分中从<code>eksctl create cluster</code>命令开始的步骤。</p>

<ol>

<li value="14">让我们使用以下命令快速地<a id="_idIndexMarker1357"/>检查创建的资源:<pre class="source-code">ns_array=(<strong class="bold">kubeflow</strong> <strong class="bold">kubeflow-user-example-com</strong> <strong class="bold">kserve</strong> <strong class="bold">cert-manager</strong> <strong class="bold">istio-system</strong> <strong class="bold">auth</strong> <strong class="bold">knative-eventing</strong> <strong class="bold">knative-serving</strong>)</pre> <pre class="source-code">for i in ${ns_array[@]}; do </pre> <pre class="source-code">  echo "[+] kubectl get pods -n $i"</pre> <pre class="source-code">  <strong class="bold">kubectl get pods -n $i</strong>; </pre> <pre class="source-code">  echo "---"</pre> <pre class="source-code">done</pre></li>

</ol>

<p class="list-inset">这里，我们<a id="_idIndexMarker1358"/>使用<code>kubectl get pods</code>命令来检查集群节点内部创建的资源。</p>

<ol>

<li value="15">现在，我们运行下面的命令，这样我们就可以通过Cloud9环境的端口<code>8080</code>访问Kubeflow仪表板:<pre class="source-code"><strong class="bold">kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80 --address=localhost</strong></pre></li>

<li>点击<strong class="bold">预览</strong>(位于页面顶部)打开类似于<em class="italic">图10.13 </em>所示的下拉菜单选项列表:</li>

</ol>

<div><div><img alt="Figure 10.13 – Preview Running Application&#10;&#10;" height="186" src="img/B18638_10_013.jpg" width="267"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.13–预览正在运行的应用程序</p>

<p class="list-inset">从下拉菜单选项列表中，选择<strong class="bold">预览正在运行的应用程序</strong>，打开屏幕底部终端窗格旁边的一个小窗口<a id="_idIndexMarker1359"/>。</p>

<p class="callout-heading">注意</p>

<p class="callout">我们能够直接从我们的Cloud9环境中预览该应用程序，因为该应用程序当前使用HTTP通过端口8080运行。关于这个主题的更多信息，请随时查看<a href="https://docs.aws.amazon.com/cloud9/latest/user-guide/app-preview.xhtml">https://docs . AWS . Amazon . com/cloud 9/latest/user-guide/app-preview . XHTML</a>。</p>

<ol>

<li value="17">点击<a id="_idIndexMarker1360"/>按钮，如图<em class="italic">图10.14 </em>中突出显示的，在单独的浏览器选项卡中打开预览窗口:</li>

</ol>

<div><div><img alt="Figure 10.14 – Previewing in a new window&#10;&#10;" height="470" src="img/B18638_10_014.jpg" width="1051"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.14–在新窗口中预览</p>

<p class="list-inset">在第二个浏览器选项卡中使用应用程序预览时，请确保不要关闭运行Cloud9环境的浏览器选项卡。</p>

<ol>

<li value="18">在<code>user@example.com</code>上指定以下<a id="_idIndexMarker1361"/>凭证</li>

<li><code>12341234</code></li>



</ol>

<p class="callout-heading">重要说明</p>

<p class="callout">不要与他人共享应用程序预览选项卡的URL。要更改默认密码，请随意查看以下链接:https://aw slabs . github . io/kube flow-manifests/docs/deployment/connect-kube flow-dashboard/</p>

<p class="list-inset">这个<a id="_idIndexMarker1362"/>应该会将您重定向到<strong class="bold"> Kubeflow中央仪表盘</strong>类似于<a id="_idIndexMarker1363"/>图10.15 中显示的内容:</p>

<div><div><img alt="Figure 10.15 – The Kubeflow central dashboard&#10;&#10;" height="871" src="img/B18638_10_015.jpg" width="1650"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.15–kube flow中央仪表盘</p>

<p class="list-inset">在<em class="italic">图10.15 </em>中，我们可以<a id="_idIndexMarker1364"/>看到<strong class="bold"> Kubeflow中央仪表盘</strong>——一个仪表盘界面，提供对我们创建和使用的组件和资源的直接<a id="_idIndexMarker1365"/>访问。使用侧边栏随意导航到该控制面板的不同部分。</p>

<p>终于，所有的设置工作都完成了！在下一部分中，我们将运行我们的第一个定制Kubeflow管道。在继续之前，请随意喝杯咖啡或茶。</p>

<h1 id="_idParaDest-210">运行我们的第一条Kubeflow管道</h1>

<p>在本节中，我们<a id="_idIndexMarker1366"/>将运行一个定制管道，该管道将下载一个样本表格数据集，并将其用作训练数据来构建我们的<strong class="bold">线性回归</strong>模型。由管道执行的<a id="_idIndexMarker1367"/>步骤和指令已在YAML文件中定义。一旦上传了这个YAML文件，我们就能够运行Kubeflow管道，该管道将运行以下步骤:</p>

<ol>

<li value="1"><strong class="bold">下载数据集</strong>:这里，我们将下载并使用一个只有20条记录的数据集(以及包含标题的行)。除此之外，我们将从一个没有任何缺失或无效值的干净版本开始:</li>

</ol>

<div><div><img alt="" height="644" src="img/B18638_10_016.jpg" width="881"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.16–表格数据集示例</p>

<p class="list-inset">在<em class="italic">图10.16 </em>中，我们可以看到我们的数据集有三列:</p>

<ul>

<li><code>last_name</code>–这是经理的姓氏。</li>

<li><code>management_experience_months</code>–这是经理管理团队成员的总月数。</li>

<li><code>monthly_salary</code>–这是经理目前的月薪(美元)。</li>

</ul>

<p class="list-inset">为了稍微简化一下，我们将使用一个只有几条记录的数据集——刚好足以生成一个简单的ML模型。除此之外，我们将从一个没有任何缺失或无效值的干净版本开始。</p>

<ol>

<li value="2"><code>monthly_salary</code>)第二列是预测值列(<code>management_experiment_months</code>)。同时，我们将执行<strong class="bold">训练-测试分割</strong>以便<a id="_idIndexMarker1370"/>我们可以使用数据集的70%来训练模型，剩余的30%用于评估它。</li>

<li><code>LinearRegression</code>对训练数据拟合线性模型的算法。</li>

<li><strong class="bold">评估模型</strong>:一旦训练步骤完成，我们将使用测试集对其进行评估。</li>

<li><code>monthly_salary</code>)给定一个输入值(<code>management_experiment_months</code>)。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">请注意，我们可以完全控制管道的行为。我们可以将管道看作是一系列步骤，其中每一步都可能生成一个输出，然后由另一步用作输入。</p>

<p>现在我们对我们的管道有了更好的了解，让我们继续运行我们的第一个管道:</p>

<ol>

<li value="1">让我们首先在另一个浏览器选项卡中打开以下链接:<a href="https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/main/chapter10/basic_pipeline.yaml">https://raw . githubusercontent . com/packt publishing/Machine-Learning-Engineering-on-AWS/main/chapter 10/basic _ pipeline . YAML</a>。</li>

<li>右键单击页面的任何部分，打开类似于<em class="italic">图10.17 </em>所示的上下文菜单:</li>

</ol>

<div><div><img alt="Figure 10.17 – Downloading the YAML file&#10;&#10;" height="755" src="img/B18638_10_017.jpg" width="1162"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.17–下载YAML文件</p>

<p class="list-inset">将文件另存为<code>basic_pipeline.yaml</code>，并将其下载到本地机器的<code>Downloads</code>文件夹(或类似文件夹)中。</p>

<ol>

<li value="3">回到显示<strong class="bold"> Kubeflow中央仪表盘</strong>的<a id="_idIndexMarker1374"/>浏览器标签，找到<a id="_idIndexMarker1375"/>并点击侧边栏中的<strong class="bold">管道</strong>。</li>

<li>接下来，点击<strong class="bold">上传管道</strong>按钮(在<strong class="bold">刷新</strong>按钮旁边)</li>

<li>在<code>basic_pipeline.yaml</code>文件下的<code>My first pipeline</code>中(从您的本地机器)使用提供的文件输入字段。最后，点击<strong class="bold">创建</strong>按钮(在<em class="italic">图10.18 </em>中高亮显示):</li>

</ol>

<div><div><img alt="Figure 10.18 – Uploading a pipeline (file)&#10;&#10;" height="661" src="img/B18638_10_018.jpg" width="812"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.18–上传管道(文件)</p>

<p class="list-inset">点击<strong class="bold">创建</strong>按钮上的<a id="_idIndexMarker1376"/>应该会创建管道并重定向到类似于<em class="italic">图10.19 </em>所示的管道页面:</p>

<div><div><img alt="Figure 10.19 – A graph of the first pipeline&#10;&#10;" height="645" src="img/B18638_10_019.jpg" width="804"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.19–第一条管道的图表</p>

<p class="list-inset">此时，我们的管道应该准备好了！下一步是创建一个实验并运行它。</p>

<p class="callout-heading">注意</p>

<p class="callout"><em class="italic">刚刚发生了什么？</em>上传YAML文件后，Kubeflow Pipelines将YAML文件转换为可通过管道运行执行的管道。</p>

<ol>

<li value="6">接下来，找到<a id="_idIndexMarker1377"/>并点击<strong class="bold">创建实验</strong>按钮(位于页面右上角)。如果您找不到<strong class="bold">创建实验</strong>按钮，请随意放大/缩小(并关闭任何可能出现的弹出窗口和覆盖图)。</li>

<li>在<strong class="bold">实验名称</strong>下指定<code>My first experiment</code>。然后点击<strong class="bold">下一个</strong>按钮。</li>

<li>在<strong class="bold">开始运行</strong>页面上，向下滚动到页面底部，然后点击<strong class="bold">开始</strong>按钮。</li>

<li>定位并点击我的第一条管线的<strong class="bold">管路，如图<em class="italic">图10.20 </em>中高亮显示:</strong></li>

</ol>

<div><div><img alt="Figure 10.20 – Navigating to the pipeline run&#10;&#10;" height="359" src="img/B18638_10_020.jpg" width="805"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.20-导航到管道运行</p>

<p class="list-inset">在这里，我们可以看到我们的管道已经开始运行。导航到特定管道运行页面后，您应该会看到一个相对较新或部分完成的<a id="_idIndexMarker1378"/>管道，类似于<em class="italic">图10.21 </em>中所示:</p>

<div><div><img alt="Figure 10.21 – Waiting for the pipeline to finish running&#10;&#10;" height="653" src="img/B18638_10_021.jpg" width="598"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.21–等待管道完成运行</p>

<p class="list-inset">这大约需要1-2分钟完成。您应该会在每个成功完成的步骤上看到一个复选标记。</p>

<ol>

<li value="10">当管道运行时，您可以单击任何步骤来检查相应的输入和输出工件、日志和其他细节:</li>

</ol>

<div><div><img alt="Figure 10.22 – Inspecting the artifacts&#10;&#10;" height="703" src="img/B18638_10_022.jpg" width="890"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.22–检查工件</p>

<p class="list-inset">在<em class="italic">图10.22 </em>中，我们<a id="_idIndexMarker1379"/>可以看到，点击<strong class="bold">过程数据</strong>步骤对应的方框后，我们可以查看和调试输入和输出工件。此外，我们应该通过导航到其他选项卡(<strong class="bold">可视化</strong>、<strong class="bold">细节</strong>、<strong class="bold">卷</strong>和<strong class="bold">日志</strong>)来找到关于当前步骤的其他细节。</p>

<p>祝贺您运行第一条管道！如果你想知道我们是如何准备这个管道的，我们只是使用了<strong class="bold"> Kubeflow管道SDK </strong>来定义管道的步骤，并生成包含所有指令和配置的YAML文件。在下一节中，我们将在构建定制ML管道时更深入地使用<strong class="bold"> Kubeflow Pipelines SDK </strong>。</p>

<h1 id="_idParaDest-211"><a id="_idTextAnchor226"/>使用Kubeflow Pipelines SDK构建ML工作流</h1>

<p>在此<a id="_idIndexMarker1380"/>部分，我们将使用<strong class="bold"> Kubeflow Pipelines SDK </strong>构建ML工作流。Kubeflow Pipelines SDK包含我们构建管道组件所需的内容，这些组件包含我们想要运行的定制代码。使用Kubeflow Pipelines SDK，我们可以定义映射到管道的管道组件的Python函数。</p>

<p>以下是我们在使用<a id="_idIndexMarker1381"/>kube flow Pipelines SDK构建<strong class="bold"> Python基于函数的组件</strong>时需要遵循的一些准则:</p>

<ul>

<li>定义的Python函数应该是独立的，不应该使用在函数定义之外声明的任何代码和变量<a id="_idIndexMarker1382"/>。这意味着<code>import pandas</code>也应该在函数内部实现。这里有一个导入应该如何实现的快速示例:<pre class="source-code">def process_data(...):</pre> <pre class="source-code">    <strong class="bold">import pandas as pd    </strong></pre> <pre class="source-code">    df_all_data = pd.read_csv(df_all_data_path)</pre> <pre class="source-code">    # and so on...</pre></li>

<li>在组件之间传递大量数据(或具有复杂数据类型的数据)时，数据必须作为文件传递。下面是一个简单的例子:<pre class="source-code">def evaluate_model(</pre><pre class="source-code">    <strong class="bold">model_path</strong>: <strong class="bold">InputPath(str)</strong>,</pre><pre class="source-code">    <strong class="bold">df_test_data_path</strong>: <strong class="bold">InputPath(str)</strong>):</pre><pre class="source-code">    </pre><pre class="source-code">    import pandas as pd</pre><pre class="source-code">    from joblib import load</pre><pre class="source-code">    </pre><pre class="source-code">    df_test_data = pd.read_csv(<strong class="bold">df_test_data_path</strong>)</pre><pre class="source-code">    model = load(<strong class="bold">model_path</strong>)</pre><pre class="source-code">    # and so on...</pre></li>

<li>使用<code>create_component_from_func()</code>函数(来自<code>kfp.components</code>)将定义的函数转换成管道组件。当调用<code>create_component_from_func()</code>函数时，可以在<code>packages_to_install</code>参数中指定一个包列表，类似于下面的代码块:<pre class="source-code">process_data_op = <strong class="bold">create_component_from_func</strong>(</pre> <pre class="source-code">    process_data, </pre> <pre class="source-code">    <strong class="bold">packages_to_install=['pandas', 'sklearn']</strong></pre> <pre class="source-code">)</pre></li>

</ul>

<p class="list-inset">然后，在执行该功能之前，将安装指定的软件包。</p>

<ul>

<li>或者，我们可以准备一个自定义容器映像，用于Python函数运行的环境。调用<code>create_component_from_func()</code>函数时，可以在<code>base_image</code>参数中指定自定义容器图像。</li>

</ul>

<p>也就是说，让我们开始使用<strong class="bold"> Kubeflow Pipelines SDK </strong>定义和配置我们的ML管道:</p>

<ol>

<li value="1">在<strong class="bold"> Kubeflow中央仪表盘</strong>的<a id="_idIndexMarker1384"/>侧边栏中找到并点击<strong class="bold">笔记本</strong>。</li>

<li>接下来，点击<strong class="bold">新建笔记本</strong>按钮。</li>

<li>为<strong class="bold">名称</strong>输入字段值指定<code>first-notebook</code>。</li>

<li>向下滚动到页面底部，然后单击<strong class="bold">启动</strong>按钮。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">等待笔记本变得可用。笔记本准备就绪大约需要1-2分钟。</p>

<ol>

<li value="5">笔记本可用后，点击<strong class="bold">连接</strong>按钮。</li>

<li>在<strong class="bold"> Jupyter Lab Launcher </strong>中，选择<strong class="bold"> Python 3 </strong>选项(在<strong class="bold">笔记本</strong>下)，如<em class="italic">图10.23 </em>中高亮显示的<a id="_idIndexMarker1385"/>:</li>

</ol>

<div><div><img alt="Figure 10.23 – Jupyter Lab Launcher&#10;&#10;" height="502" src="img/B18638_10_023.jpg" width="756"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.23–Jupyter实验室发射器</p>

<p class="list-inset">这应该会创建一个新的<strong class="bold"> Jupyter笔记本</strong>(在Kubernetes Pod内的一个容器中)，我们可以在其中运行Python代码。</p>

<p class="callout-heading">注意</p>

<p class="callout">我们将在我们发布的Jupyter笔记本中运行后续步骤中的代码块。</p>

<ol>

<li value="7">下面我们来执行一个<a id="_idIndexMarker1387"/>从<strong class="bold">kube flow Pipelines SDK</strong>:<pre class="source-code">import kfp</pre><pre class="source-code">from kfp import <strong class="bold">dsl</strong></pre><pre class="source-code">from kfp.components import <strong class="bold">InputPath</strong>, <strong class="bold">OutputPath</strong></pre><pre class="source-code">from kfp.components import <strong class="bold">create_component_from_func</strong></pre></li>

<li>对于管道中的第一步，我们定义了<code>download_dataset()</code>函数，该函数下载一个虚拟数据集并将其转换为CSV文件。这个CSV文件通过<code>df_all_data_path</code> <code>OutputPath</code>对象<pre class="source-code">def <strong class="bold">download_dataset</strong>(</pre><pre class="source-code">    <strong class="bold">df_all_data_path</strong>: OutputPath(str)):</pre><pre class="source-code">    </pre><pre class="source-code">    import pandas as pd</pre><pre class="source-code">    </pre><pre class="source-code">    url="https://bit.ly/3POP8CI"</pre><pre class="source-code">    </pre><pre class="source-code">    df_all_data = pd.read_csv(url)</pre><pre class="source-code">    print(df_all_data)</pre><pre class="source-code">    df_all_data.to_csv(</pre><pre class="source-code">        df_all_data_path, </pre><pre class="source-code">        header=True, </pre><pre class="source-code">        index=False)</pre>将<a id="_idIndexMarker1388"/>传递到下一步</li>

<li>对于管道中的第二步，我们定义了<code>process_data()</code>函数，其中我们从上一步中读取CSV数据，并应用训练-测试分割，这将产生一个训练集和一个测试集。然后可以将这些保存为CSV文件并通过<code>df_training_data_path</code>和<code>df_test_data_path</code> <code>OutputPath</code>对象传递给下一步，分别是:<pre class="source-code">def <strong class="bold">process_data</strong>(</pre><pre class="source-code">    <strong class="bold">df_all_data_path</strong>: InputPath(str), </pre><pre class="source-code">    <strong class="bold">df_training_data_path</strong>: OutputPath(str), </pre><pre class="source-code">    <strong class="bold">df_test_data_path</strong>: OutputPath(str)):</pre><pre class="source-code">    </pre><pre class="source-code">    import pandas as pd</pre><pre class="source-code">    from sklearn.model_selection import \</pre><pre class="source-code">        train_test_split</pre><pre class="source-code">    </pre><pre class="source-code">    df_all_data = pd.read_csv(df_all_data_path)</pre><pre class="source-code">    print(df_all_data)</pre><pre class="source-code">    </pre><pre class="source-code">    mem = 'management_experience_months'</pre><pre class="source-code">    ms = 'monthly_salary'</pre><pre class="source-code">    X = df_all_data[mem].values </pre><pre class="source-code">    y = df_all_data[ms].values</pre><pre class="source-code">    X_train, X_test, y_train, y_test = \</pre><pre class="source-code">        <strong class="bold">train_test_split</strong>(</pre><pre class="source-code">            X, y, test_size=0.3, random_state=0</pre><pre class="source-code">        )</pre><pre class="source-code">    </pre><pre class="source-code">    df_training_data = pd.DataFrame({ </pre><pre class="source-code">        'monthly_salary': y_train, </pre><pre class="source-code">        'management_experience_months': X_train</pre><pre class="source-code">    })</pre><pre class="source-code">        <strong class="bold">df_training_data_path</strong>, </pre><pre class="source-code">        header=True, index=False</pre><pre class="source-code">    )</pre><pre class="source-code">    df_test_data = pd.DataFrame({ </pre><pre class="source-code">        'monthly_salary': y_test, </pre><pre class="source-code">        'management_experience_months': X_test</pre><pre class="source-code">    })</pre></li>

<li>对于管道中的第三步<a id="_idIndexMarker1389"/>，我们定义了<code>train_model()</code>函数，其中我们使用上一步的训练数据来训练一个样本模型。然后，通过<code>model_path</code> <code>OutputPath</code>对象:<pre class="source-code">def <strong class="bold">train_model</strong>(</pre><pre class="source-code">    <strong class="bold">df_training_data_path</strong>: InputPath(str),</pre><pre class="source-code">    <strong class="bold">model_path</strong>: OutputPath(str)):</pre><pre class="source-code">    </pre><pre class="source-code">    import pandas as pd</pre><pre class="source-code">    from sklearn.linear_model import LinearRegression</pre><pre class="source-code">    from joblib import dump</pre><pre class="source-code">    </pre><pre class="source-code">    df_training_data = pd.read_csv(</pre><pre class="source-code">        <strong class="bold">df_training_data_path</strong></pre><pre class="source-code">    )</pre><pre class="source-code">    print(df_training_data)</pre><pre class="source-code">    </pre><pre class="source-code">    mem = 'management_experience_months'</pre><pre class="source-code">    X_train = df_training_data[mem].values</pre><pre class="source-code">    ms = 'monthly_salary'</pre><pre class="source-code">    y_train = df_training_data[ms].values</pre><pre class="source-code">    </pre><pre class="source-code">    model = <strong class="bold">LinearRegression</strong>().<strong class="bold">fit</strong>(</pre><pre class="source-code">        X_train.reshape(-1, 1), y_train</pre><pre class="source-code">    )</pre><pre class="source-code">    print(model)</pre><pre class="source-code">    dump(model, <strong class="bold">model_path</strong>)</pre></li>

<li>在第四步中，我们<a id="_idIndexMarker1390"/>定义<code>evaluate_model()</code>函数，其中我们使用来自第二步的测试数据来评估我们从上一步获得的训练模型:<pre class="source-code">def <strong class="bold">evaluate_model</strong>(</pre><pre class="source-code">    <strong class="bold">model_path</strong>: InputPath(str),</pre><pre class="source-code">    <strong class="bold">df_test_data_path</strong>: InputPath(str)):</pre><pre class="source-code">    </pre><pre class="source-code">    import pandas as pd</pre><pre class="source-code">    from joblib import load</pre><pre class="source-code">    </pre><pre class="source-code">    df_test_data = pd.read_csv(df_test_data_path)</pre><pre class="source-code">    mem = 'management_experience_months'</pre><pre class="source-code">    ms = 'monthly_salary'</pre><pre class="source-code">    X_test = df_test_data[mem].values</pre><pre class="source-code">    y_test = df_test_data[ms].values</pre><pre class="source-code">    </pre><pre class="source-code">    model = load(<strong class="bold">model_path</strong>)</pre><pre class="source-code">    print(model.score(X_test.reshape(-1, 1), y_test))</pre></li>

<li>对于流水线的最后一步<a id="_idIndexMarker1391"/>，我们定义了<code>perform_sample_prediction()</code>函数，其中我们使用第三步中训练好的模型来执行样本预测(使用样本输入值):<pre class="source-code">def <strong class="bold">perform_sample_prediction</strong>(</pre> <pre class="source-code">    <strong class="bold">model_path</strong>: InputPath(str)):</pre> <pre class="source-code">    from joblib import load</pre> <pre class="source-code">    </pre> <pre class="source-code">    model = load(<strong class="bold">model_path</strong>)</pre> <pre class="source-code">    print(model.predict([[42]])[0])</pre></li>

<li>然后，我们将<code>create_component_from_func()</code>函数用于我们准备创建组件的每个函数。在这里，我们指定在运行这些函数之前要安装的软件包:<pre class="source-code"><strong class="bold">download_dataset_op</strong> = create_component_from_func(</pre><pre class="source-code">    download_dataset, </pre><pre class="source-code">    <strong class="bold">packages_to_install=['pandas']</strong></pre><pre class="source-code">)</pre><pre class="source-code"><strong class="bold">process_data_op</strong> = create_component_from_func(</pre><pre class="source-code">    process_data, </pre><pre class="source-code">    <strong class="bold">packages_to_install=['pandas', 'sklearn']</strong></pre><pre class="source-code">)</pre><pre class="source-code"><strong class="bold">train_model_op</strong> = create_component_from_func(</pre><pre class="source-code">    train_model, </pre><pre class="source-code">    <strong class="bold">packages_to_install=[</strong></pre><pre class="source-code">        <strong class="bold">'pandas', 'sklearn', 'joblib'</strong></pre><pre class="source-code">    <strong class="bold">]</strong></pre><pre class="source-code">)</pre><pre class="source-code"><strong class="bold">evaluate_model_op</strong> = create_component_from_func(</pre><pre class="source-code">    evaluate_model, </pre><pre class="source-code">    <strong class="bold">packages_to_install=[</strong></pre><pre class="source-code">        <strong class="bold">'pandas', 'joblib', 'sklearn'</strong></pre><pre class="source-code">    <strong class="bold">]</strong></pre><pre class="source-code">)</pre><pre class="source-code"><strong class="bold">perform_sample_prediction_op</strong> = \</pre><pre class="source-code">    create_component_from_func(</pre><pre class="source-code">        perform_sample_prediction, </pre><pre class="source-code">        <strong class="bold">packages_to_install=['joblib', 'sklearn']</strong></pre><pre class="source-code">    )</pre></li>

<li>现在，让我们把<a id="_idIndexMarker1392"/>的所有东西放在一起，用<code>basic_pipeline()</code>函数定义管道:<pre class="source-code">@dsl.pipeline(</pre><pre class="source-code">    name='Basic pipeline',</pre><pre class="source-code">    description='Basic pipeline'</pre><pre class="source-code">)</pre><pre class="source-code">def <strong class="bold">basic_pipeline()</strong>:</pre><pre class="source-code">    DOWNLOAD_DATASET = download_dataset_op()</pre><pre class="source-code">    PROCESS_DATA = process_data_op(</pre><pre class="source-code">        DOWNLOAD_DATASET.<strong class="bold">output</strong></pre><pre class="source-code">    )</pre><pre class="source-code">    TRAIN_MODEL = train_model_op(</pre><pre class="source-code">        PROCESS_DATA.<strong class="bold">outputs['df_training_data']</strong></pre><pre class="source-code">    )</pre><pre class="source-code">    EVALUATE_MODEL = evaluate_model_op(</pre><pre class="source-code">        TRAIN_MODEL.outputs['model'], </pre><pre class="source-code">        PROCESS_DATA.<strong class="bold">outputs['df_test_data']</strong></pre><pre class="source-code">    )</pre><pre class="source-code">    PERFORM_SAMPLE_PREDICTION = \</pre><pre class="source-code">        perform_sample_prediction_op(</pre><pre class="source-code">            TRAIN_MODEL.<strong class="bold">outputs['model']</strong></pre><pre class="source-code">        )</pre><pre class="source-code">    PERFORM_SAMPLE_PREDICTION.after(EVALUATE_MODEL)</pre></li>

<li>最后，让我们使用下面的代码块<a id="_idIndexMarker1393"/>生成管道的YAML文件:<pre class="source-code">kfp.compiler.Compiler().<strong class="bold">compile</strong>(</pre> <pre class="source-code">    basic_pipeline, </pre> <pre class="source-code">    <strong class="bold">'basic_pipeline.yaml'</strong></pre> <pre class="source-code">)</pre></li>

</ol>

<p class="list-inset">此时，我们应该在文件浏览器中看到一个YAML文件。如果没有，请随意使用刷新按钮来更新显示的文件列表。</p>

<ol>

<li value="16">在文件浏览器中，右击生成的<code>basic_pipeline.yaml</code>文件，打开类似于<em class="italic">图10.24 </em>所示的上下文菜单:</li>

</ol>

<div><div><img alt="Figure 10.24 – Downloading the basic_pipeline.yaml file&#10;&#10;" height="439" src="img/B18638_10_024.jpg" width="737"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图10.24–下载basic_pipeline.yaml文件</p>

<p class="list-inset">从<a id="_idIndexMarker1394"/>右键菜单的选项列表中选择<strong class="bold">下载</strong>(如图<em class="italic">图10.24 </em>中高亮显示)。这会将YAML文件下载到本地机器的下载文件夹(或类似的文件夹)中。</p>

<ol>

<li value="17">下载完<code>basic_pipeline.yaml</code>文件后，导航到浏览器选项卡，在那里我们打开了<strong class="bold"> Kubeflow中央仪表盘</strong>。之后，通过点击侧边栏中的<strong class="bold">管道</strong>导航到<strong class="bold">管道</strong>页面(在<strong class="bold"> Kubeflow中央仪表盘</strong>中)。</li>

<li>接下来，单击我们在本节中生成的<code>basic_pipeline.yaml</code>文件来运行另一个管道。</li>

</ol>

<p class="callout-heading">重要说明</p>

<p class="callout">运行新管道时，请随意检查并遵循本章<em class="italic">运行我们的第一条Kubeflow管道</em>一节中指定的步骤。我们将把这个留给您作为练习！(生成的管道应该是相同的。)</p>

<p>这比预期的要容易，对吗？完成本章的动手解决方案后，我们应该恭喜自己！能够在EKS上正确地设置Kubeflow，并让定制的ML管道使用Kubeflow工作是一项成就。这应该让我们有信心使用我们现在使用的技术栈来构建更复杂的ML管道。</p>

<p>在下一节中，我们将快速清理并删除我们在本章中创建的资源。</p>

<h1 id="_idParaDest-212"><a id="_idTextAnchor227"/>清理</h1>

<p>现在我们已经完成了本章的动手解决方案，是时候清理并关闭我们不再使用的资源了。在这个时间点，我们有一个EKS集群在运行，其中有<code>5</code> x <code>m5.xlarge</code>个实例在运行。我们需要终止这些资源来控制成本。</p>

<p class="callout-heading">注意</p>

<p class="callout">如果我们(一个月内)不关掉它们，会花多少钱？最低(每月)运行EC2实例的成本约为700.80美元(<em class="italic"> 5个实例x 0.192美元x每月730小时</em>)，加上EKS集群的<em class="italic">73美元</em><code> </code>(<em class="italic">1个集群x每小时0.10美元x每月730小时</em>)，假设我们在俄勒冈州地区运行EKS集群(<code>us-west-2</code>)。请注意，除了本章中使用的其他资源之外，还会有与这些实例附带的EBS卷相关的其他额外成本。</p>

<p>在下一组步骤中，我们将卸载并删除Cloud9环境终端中的资源:</p>

<ol>

<li value="1">让我们导航回cloud 9 environment<strong class="bold">Terminal</strong>选项卡，在这里我们最后运行了下面的命令(<em class="italic">注意:不要运行下面的命令，因为我们只需要导航回运行这个命令的选项卡</em>:<pre class="source-code"><strong class="bold">kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80 --address=localhost</strong></pre></li>

</ol>

<p class="list-inset">我们应该在这个终端中为8080 日志找到几个<strong class="bold">处理连接。</strong></p>

<ol>

<li value="2">通过按下终端内的<em class="italic"> Ctrl </em> + <em class="italic"> C </em>(或者，当使用Mac设备时，<em class="italic"> Cmd </em> + <em class="italic"> C </em>)来停止该命令。</li>

<li>之后，让我们运行下面的命令，它利用<code>kubectl delete</code>删除资源:<pre class="source-code"><strong class="bold">cd ~/environment/ch10/kubeflow-manifests/</strong></pre> <pre class="source-code"><strong class="bold">cd deployments/vanilla/</strong></pre> <pre class="source-code"><strong class="bold">kustomize build . | kubectl delete -f -</strong></pre></li>

<li>让我们通过运行以下命令来删除<a id="_idIndexMarker1396"/>EKS集群:<pre class="source-code"><strong class="bold">eksctl delete cluster</strong> --region $CLUSTER_REGION --name $CLUSTER_NAME</pre></li>

</ol>

<p class="list-inset">运行命令前，确保<code>CLUSTER_REGION</code>和<code>CLUSTER_NAME</code>变量设置为适当的值。例如，如果您在俄勒冈地区运行Kubernetes集群，<code>CLUSTER_REGION</code>应该被设置为<code>us-west-2</code>，而<code>CLUSTER_NAME</code>应该被设置为<code>kubeflow-eks-000</code>(这类似于<code>eks.yaml</code>文件中指定的内容)</p>

<p class="callout-heading">重要说明</p>

<p class="callout">确保验证由<code>eksctl</code>命令创建的云形成堆栈已被完全删除。您可以通过导航到CloudFormation控制台并检查是否有状态为<strong class="bold"> DELETE_FAILED </strong>的堆栈来完成此操作。如果是这种情况，只需重新尝试删除这些堆栈，直到所有资源都被成功删除。</p>

<ol>

<li value="5">最后，分离附加到运行Cloud9环境的EC2实例的IAM角色。我们将把这个留给您作为练习！</li>

</ol>

<p>在继续下一部分之前，请确保检查所有删除操作是否都已成功。</p>

<h1 id="_idParaDest-213"><a id="_idTextAnchor228"/>推荐的策略和最佳实践</h1>

<p>在我们结束本章之前，我们将快速讨论一些在EKS上使用Kubeflow时推荐的策略和最佳实践。</p>

<p>让我们首先确定我们可以改进如何设计和实现我们的ML管道的方法。<em class="italic">我们可以对初始版本的管道进行哪些改进？下面是我们可以实施的一些可能的升级:</em></p>

<ul>

<li>通过允许管道的第一步接受数据集输入路径作为输入参数(而不是像现在这样硬编码)，使管道更具可重用性</li>

<li>使用管道组件时，构建和使用自定义容器映像，而不是使用<code>packages_to_install</code>参数</li>

<li>将模型工件保存到存储<a id="_idIndexMarker1398"/>服务中，比如<strong class="bold">亚马逊S3 </strong>(这将帮助我们确保即使Kubernetes集群被删除，我们也能够保留工件)</li>

<li>使用<code>ContainerOp</code>对象的<code>set_memory_limit()</code>和<code>set_cpu_limit()</code>向流水线中的特定步骤添加资源限制(如CPU和内存限制)</li>

<li>利用<strong class="bold">用于Kubeflow管道的SageMaker组件</strong>将一些<a id="_idIndexMarker1399"/>数据处理和培训工作转移到SageMaker</li>

</ul>

<p class="callout-heading">注意</p>

<p class="callout">如果您有兴趣在准备<strong class="bold"> Kubeflow管道组件</strong>时学习和应用最佳实践，请随时查看<a id="_idIndexMarker1400"/>https://www . kube flow . org/docs/components/Pipelines/SDK/best-practices/。</p>

<p>接下来，让我们讨论一些策略和解决方案，我们可以实施这些策略和解决方案来升级我们的EKS集群和Kubeflow设置:</p>

<ul>

<li>在亚马逊EKS集群上设置<a id="_idIndexMarker1401"/>以监控集群性能<strong class="bold">cloud watch Container Insights</strong></li>

<li>设置和<a id="_idIndexMarker1402"/>部署<strong class="bold"> Kubernetes Dashboard </strong>和/或<strong class="bold"> Rancher </strong>到<a id="_idIndexMarker1403"/>管理和控制亚马逊EKS集群资源</li>

<li>设置<a id="_idIndexMarker1404"/> up <strong class="bold"> Prometheus </strong>和<strong class="bold"> Grafana </strong>用于<a id="_idIndexMarker1405"/>监控<a id="_idIndexMarker1406"/>Kubernetes集群</li>

<li>访问<strong class="bold"> Kubeflow中央仪表盘</strong>时更改默认的<a id="_idIndexMarker1407"/>用户密码</li>

<li>部署Kubeflow时使用<strong class="bold"> AWS Cognito </strong>作为<a id="_idIndexMarker1408"/>身份提供者(用于Kubeflow用户认证)</li>

<li>使用<a id="_idIndexMarker1409"/> Amazon <strong class="bold">关系数据库服务</strong> ( <strong class="bold"> RDS </strong>)和Amazon <strong class="bold">简单存储服务</strong> ( <strong class="bold"> S3 </strong>)部署Kubeflow，用于<a id="_idIndexMarker1410"/>存储元数据和管道工件</li>

<li>通过<a id="_idIndexMarker1411"/>和<strong class="bold">应用负载平衡器</strong>公开和访问Kubeflow</li>

<li>使用<strong class="bold">亚马逊弹性文件系统</strong> ( <strong class="bold"> EFS </strong>)和<a id="_idIndexMarker1412"/> Kubeflow进行持久存储</li>

<li>减少附属于运行Cloud9环境的EC2实例的IAM角色的权限(到最小的特权集)</li>

<li>审核和升级所使用的每个资源的安全配置</li>

<li>设置<a id="_idIndexMarker1413"/> EKS集群的自动缩放(例如，使用<strong class="bold">集群自动缩放器</strong></li>

<li>为了管理运行EKS集群的长期成本，我们可以利用<strong class="bold">成本节约计划</strong>，其中<a id="_idIndexMarker1414"/>包括在做出长期承诺(例如，1年或3年的承诺)后降低运行资源的总体成本</li>

</ul>

<p>还有更多的我们可以添加到这个列表，但这些应该做了！请务必查看并检查<a href="B18638_09.xhtml#_idTextAnchor187"> <em class="italic">第9章</em> </a>、<em class="italic">安全、治理和合规性策略</em>中分享的建议解决方案和策略。</p>

<h1 id="_idParaDest-214"><a id="_idTextAnchor229"/>总结</h1>

<p>在本章中，我们使用<strong class="bold"> Kubeflow </strong>、<strong class="bold"> Kubernetes </strong>和<strong class="bold">亚马逊EKS </strong>来设置和配置我们的容器化ML环境。设置好环境后，我们使用<strong class="bold"> Kubeflow Pipelines SDK </strong>准备并运行一个定制的ML管道。在完成所有需要动手的工作之后，我们继续清理我们创建的资源。在结束本章之前，我们讨论了相关的最佳实践和策略，以使用我们在本章实践部分使用的技术堆栈来保护、扩展和管理ML管道。</p>

<p>在下一章中，我们将使用<strong class="bold">sage maker Pipelines</strong>—<strong class="bold">Amazon sage maker的</strong>专用解决方案来构建和设置一个ML管道，以使用相关的MLOps实践来自动化ML工作流。</p>

<h1 id="_idParaDest-215"><a id="_idTextAnchor230"/>延伸阅读</h1>

<p>有关本章主题的更多信息，请随时查阅以下资源:</p>

<ul>

<li><em class="italic"> Kubernetes概念</em>(<a href="https://kubernetes.io/docs/concepts/">https://kubernetes.io/docs/concepts/</a>)</li>

<li><em class="italic">亚马逊EKS入门</em>(<a href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started.xhtml">https://docs . AWS . Amazon . com/eks/latest/user guide/Getting-started . XHTML</a>)</li>

<li><em class="italic">eks CTL——亚马逊EKS</em>(<a href="https://eksctl.io/">https://eksctl.io/</a>)的官方CLI</li>

<li><em class="italic">亚马逊EKS故障排除</em>(<a href="https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.xhtml">https://docs . AWS . Amazon . com/eks/latest/user guide/trouble shooting . XHTML</a>)</li>

<li><em class="italic">kube flow on AWS–Deployment</em>(<a href="https://awslabs.github.io/kubeflow-manifests/docs/deployment/">https://aw slabs . github . io/kube flow-manifests/docs/Deployment/</a>)</li>

<li><em class="italic">kube flow on AWS Security</em>(<a href="https://awslabs.github.io/kubeflow-manifests/docs/about/security/">https://aw slabs . github . io/kube flow-manifests/docs/about/Security/</a>)</li>

</ul>

</div>

</div>



</body></html>