<title>Chapter 1: Introduction to ML Engineering on AWS</title>

# 1

# AWS 上的 ML 工程简介

我们大多数人通过在我们的笔记本电脑或家用电脑上使用样本数据集训练我们的第一个 ML 模型，开始了我们的**机器学习** ( **ML** )之旅。事情有些简单，直到我们需要处理更大的数据集，并在云中运行我们的 ML 实验。一旦我们需要将训练好的模型部署到生产级推理端点或 web 服务器上，这也变得更具挑战性。在设计和构建 ML 系统时，有许多事情需要考虑，这些只是数据科学家和 ML 工程师在处理现实需求时面临的一些挑战。也就是说，当在云中执行 ML 实验和部署时，我们必须使用正确的平台和正确的工具集。

在这一点上，你可能想知道为什么我们在运行我们的工作负载时还要使用云平台。*难道我们不能自己搭建这个平台*？也许你会认为建立和运营自己的数据中心是一件相对容易的事情。过去，不同的团队和公司曾尝试在其数据中心和本地硬件中建立基础架构。随着时间的推移，这些公司开始将其工作负载迁移到云，因为他们意识到管理和运营数据中心是多么困难和昂贵。一个很好的例子是网飞团队，他们将资源迁移到 AWS 云。迁移到云使他们能够更好地扩展，并显著提高服务可用性。

**亚马逊网络服务** ( **AWS** )平台提供了很多服务和功能，可供世界各地的专业人士和公司用来管理云中不同类型的工作负载。在过去的几年中，AWS 已经宣布并发布了大量的服务、功能和特性，它们也可以用于生产级 ML 实验和部署。这是由于全球迁移到云的 ML 工作负载的增加。当我们阅读本书的每一章时，我们将会更好地理解如何使用不同的服务来解决生产 ML 模型时的挑战。

下图显示了本章的实践之旅:

![Figure 1.1 – Hands-on journey for this chapter

](img/B18638_01_001.jpg)

图 1.1–本章的实践之旅

在这一介绍性的章节中，我们将着重于在 AWS 上构建 ML 模型时尝试不同的选项。如上图所示，我们将使用各种 **AutoML** 服务和解决方案来构建 ML 模型，这些模型可以帮助我们根据可用信息预测酒店预订是否会被取消。我们将从建立一个**云 9** 环境开始，这将帮助我们通过浏览器中的**集成开发环境** ( **IDE** )运行我们的代码。在这个环境中，我们将使用一个名为**条件生成对抗网络**的**深度学习**模型来生成一个现实的合成数据集。我们将使用 **AWS CLI** 将这个数据集上传到**亚马逊 S3** 。在 Cloud9 环境中，我们还将安装 **AutoGluon** 并运行 **AutoML** 实验，以使用合成数据集训练并生成多个模型。最后，我们将使用 **SageMaker Canvas** 和 **SageMaker Autopilot** 在 S3 使用上传的数据集运行 AutoML 实验。如果你想知道这些奇特的术语是什么，请继续阅读，我们将在本章中逐一揭开它们的神秘面纱。

在本章中，我们将讨论以下主题:

*   对 ML 工程师的期望是什么？
*   ML 工程师如何充分利用 AWS
*   基本先决条件
*   准备数据集
*   带自动旋转的 AutoML
*   SageMaker 和 SageMaker Canvas 入门
*   使用 SageMaker Canvas 的无代码机器学习
*   带 SageMaker 自动驾驶仪的 AutoML

除了使用关键的 ML 服务、库和工具来执行 AutoML 实验，这一介绍性章节将帮助我们更好地理解与本书后续章节相关的几个 ML 和 ML 工程概念。考虑到这一点，我们开始吧！

# 技术要求

在我们开始之前，我们必须有一个 AWS 帐户。如果您还没有 AWS 帐户，只需在这里创建一个帐户:[https://aws.amazon.com/free/](https://aws.amazon.com/free/)。一旦账户准备好，你就可以继续下一步了。

每一章的 Jupyter 笔记本、源代码和其他文件都可以在本书的 GitHub 资源库中找到:[https://GitHub . com/packt publishing/Machine-Learning-Engineering-on-AWS](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS)。

# 对 ML 工程师的期望是什么？

ML 工程涉及使用 ML 和**软件工程**概念和技术来设计、构建和管理生产级 ML 系统，以及流水线。在致力于构建 ML 驱动的应用程序的团队中， **ML 工程师**通常被期望构建和操作用于训练和部署模型的 ML 基础设施。在某些情况下，数据科学家可能还需要处理与基础设施相关的需求，特别是在组织中 ML 工程师和数据科学家的角色和职责没有明确划分的情况下。

在设计和构建 ML 系统和平台时，ML 工程师应该考虑几件事情。这些将包括部署的 ML 模型的*质量*，以及所使用的 ML 基础设施的*安全性*、*可伸缩性*、*可演进性*、*稳定性*和*总成本*。在这本书里，我们将讨论不同的策略和最佳实践来实现一个 ML 工程师的不同目标。

ML 工程师还应该能够使用各种解决方案设计和构建自动化 ML 工作流程。部署的模型会随着时间而退化，而**模型再培训**对于确保部署的 ML 模型的质量变得至关重要。拥有自动化的 ML 管道有助于实现自动化的模型再训练和部署。

重要说明

如果你很想了解更多关于如何在 AWS 上构建定制 ML 管道的知识，那么你应该看看这本书的最后一节:*设计和构建端到端 MLOps 管道*。您应该会找到几个章节专门讨论在 AWS 上部署复杂的 ML 管道！

# ML 工程师如何充分利用 AWS

AWS 平台中有许多服务和功能可供 ML 工程师选择。已经熟悉使用虚拟机的专业人员可以轻松地启动 **EC2** 实例，并在这些虚拟专用服务器内使用深度学习框架运行 ML 实验。诸如 **AWS Glue** 、 **Amazon EMR** 和 **AWS Athena** 等服务可以被 ML 工程师和数据工程师用于不同的数据管理和处理需求。一旦需要将 ML 模型部署到专用的推理端点中，就可以使用多种选项:

![Figure 1.2 – AWS machine learning stack

](img/B18638_01_002.jpg)

图 1.2–AWS 机器学习堆栈

如上图所示，数据科学家、开发人员和 ML 工程师可以利用 **AWS 机器学习堆栈**中的多种服务和功能。归入**人工智能服务**的服务很容易被最少 ML 经验的开发者使用。要使用这里列出的服务，我们需要的只是一些处理数据的经验，以及使用 SDK 和 API 所需的软件开发技能。如果我们想快速构建具有语言翻译、文本到语音和产品推荐等功能的 ML 驱动的应用程序，那么我们可以使用 AI Services bucket 下的服务轻松实现。在中间，我们有 **ML 服务**和它们的功能，帮助解决数据科学家和 ML 工程师的更多定制 ML 需求。要使用这里列出的服务和功能，需要对 ML 流程有一个扎实的理解。最后一层， **ML 框架和基础设施**，提供了最高级别的灵活性和可定制性，因为这包括了更高级用例所需的 ML 基础设施和框架支持。

那么，ML 工程师如何充分利用 AWS 机器学习堆栈呢？随着 ML 工程师对 AWS 平台中可用的服务、功能和工具越来越熟悉，他们设计、构建和管理 ML 系统的能力也在提高。他们可能会从人工智能服务开始，在 AWS 上快速构建人工智能驱动的应用程序。随着时间的推移，这些 ML 工程师将利用来自较低两层的不同的服务、能力和基础设施，因为他们在处理中级 ML 工程需求时变得更加自如。

# 必要的先决条件

在本节中，我们将准备以下内容:

*   云 9 环境
*   S3 桶
*   将使用深度学习模型生成的合成数据集

让我们开始吧。

## 创建云 9 环境

在虚拟专用服务器中执行 ML 实验时，更方便的选择之一是使用 AWS Cloud9 服务。AWS Cloud9 允许开发人员、数据科学家和 ML 工程师使用浏览器在开发环境中管理和运行代码。代码存储在 EC2 实例中并在其中执行，这提供了一个与大多数开发人员相似的环境。

重要说明

运行本书中的示例时，建议使用具有有限权限的**身份和访问管理** ( **IAM** )用户，而不是 root 帐户。我们将在第 9 章 *、安全、治理和遵从策略*中详细讨论这一点以及其他安全最佳实践。如果您刚刚开始使用 AWS，您可以同时继续使用 root 帐户。

按照以下步骤创建一个 Cloud9 环境，我们将在其中生成合成数据集并运行**autoglon AutoML**实验:

1.  在搜索栏中输入`cloud9`。从结果列表中选择 **Cloud9** :

![Figure 1.3 – Navigating to the Cloud9 console

](img/B18638_01_003.jpg)

图 1.3–导航至 Cloud9 控制台

这里我们可以看到该区域目前设置为`us-west-2`。请确保将它更改为您希望创建资源的位置。

1.  接下来，点击**创建环境**。
2.  在`mle-on-aws`下点击**下一步**。
3.  在**环境类型**下，选择**为环境创建新的 EC2 实例(直接访问)**。为**实例类型**选择 **m5.large** ，然后为**平台**选择 **Ubuntu Server (18.04 LTS)** :

![Figure 1.4 – Configuring the Cloud9 environment settings

](img/B18638_01_004.jpg)

图 1.4–配置 Cloud9 环境设置

在这里，我们可以看到实例类型还有其他选项。同时，我们将坚持使用 **m5.large** ，因为它应该足以运行本章中的动手解决方案。

1.  对于**节约成本设置**选项，从下拉选项列表中选择**四小时后**。这意味着运行 Cloud9 环境的服务器将在 4 小时不活动后自动关闭。
2.  在`vpc-abcdefg (default)`下。对于`subnet-abcdefg | Default in us-west-2a`。

重要说明

建议您使用默认的 VPC，因为网络配置很简单。这将帮助您避免问题，尤其是如果您刚刚开始使用 VPCs。如果您在启动 Cloud9 实例时遇到任何与 VPC 相关的问题，您可能需要检查所选子网是否已通过 VPC 控制台中的路由表配置配置了互联网访问。您可以尝试使用另一个子网或完全使用新的 VPC 来启动该实例。如果你计划创建一个新的 VPC，导航到[https://go.aws/3sRSigt](https://go.aws/3sRSigt)并创建一个带有单一公共子网的 **VPC。如果这些选项都不起作用，您可以尝试在另一个地区启动 Cloud9 实例。我们将在 [*第 9 章*](B18638_09.xhtml#_idTextAnchor187) *、安全、治理和合规性策略*中详细讨论**虚拟私有云** ( **VPC** )网络。**

1.  点击**下一步**。
2.  在查看页面上，点击**创建环境**。这会将您重定向到 Cloud9 环境，加载该环境需要一分钟左右的时间。下面的截图显示了云 9 **IDE** 。在这里，我们可以编写代码，运行脚本和命令，以处理本书中的一些动手解决方案:

![Figure 1.5 – AWS Cloud9 interface

](img/B18638_01_005.jpg)

图 1.5–AWS cloud 9 界面

使用这个 IDE 相当简单，因为它看起来非常类似于代码编辑器，例如 **Visual Studio 代码**和 **Sublime 文本**。如前面的截图所示，我们可以在顶部找到**菜单栏**(**A**)。在左侧可以找到**文件树**(**B**)。**编辑器**覆盖了屏幕中间的主要部分( **C** )。最后，我们可以在底部找到**端子**(**D**)。

重要说明

如果这是你第一次使用 AWS Cloud9，这里有一个来自 AWS 的 4 分钟介绍视频，可以帮助你入门:[https://www.youtube.com/watch?v=JDHZOGMMkj8](https://www.youtube.com/watch?v=JDHZOGMMkj8)。

现在我们已经准备好了 Cloud9 环境，是时候为它配置一个更大的存储空间了。

## 增加 Cloud9 的存储量

当创建一个 Cloud9 实例时，附加的卷只有 10GB 的磁盘空间。假设我们将在这个实例中运行 ML 实验时安装不同的库和框架，我们将需要超过 10GB 的磁盘空间。我们将使用`boto3`库以编程方式调整卷的大小。

重要说明

如果这是您第一次使用`boto3`库，那么它就是用于 Python 的 **AWS SDK，它为我们提供了一种以编程方式管理 AWS 帐户中不同 AWS 资源的方法。它是一个服务级别的 SDK，帮助我们列出、创建、更新和删除 AWS 资源，如 EC2 实例、S3 存储桶和 EBS 卷。**

按照以下步骤下载并运行一些脚本，将卷磁盘空间从 10GB 增加到 120GB:

1.  在我们的 Cloud9 环境的终端中(就在屏幕底部的`$`符号之后)，运行下面的 bash 命令:

    ```
    wget -O resize_and_reboot.py https://bit.ly/3ea96tW
    ```

这将下载位于[https://bit.ly/3ea96tW](https://bit.ly/3ea96tW)的脚本文件。这里，我们简单地使用了一个 URL shortener，它将缩短的链接映射到[https://raw . githubusercontent . com/packt publishing/Machine-Learning-Engineering-on-AWS/main/chapter 01/resize _ and _ reboot . py](https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/main/chapter01/resize_and_reboot.py)。

重要说明

注意，当使用`wget`命令时，我们使用大的`O`标志，而不是小的`o`或零(`0`)。

1.  我们刚刚下载的文件里面的是什么？在运行脚本之前，让我们快速检查一下文件。双击文件树(位于屏幕左侧)中的`resize_and_reboot.py`文件，在编辑器窗格中打开 Python 脚本文件。如下面的截图所示，`resize_and_reboot.py`脚本有三个主要部分。第一个代码块着重于导入运行脚本所需的先决条件。第二个代码块关注于使用`boto3`库调整所选 EC2 实例的大小。它使用`describe_volumes()`方法获取当前实例的卷 ID，然后使用`modify_volume()`方法将卷大小更新为 120GB。最后一部分包含一行代码，它只是重启 EC2 实例。这行代码使用`os.system()`方法运行`sudo reboot` shell 命令:

![Figure 1.6 – The resize_and_reboot.py script file

](img/B18638_01_006.jpg)

图 1.6–resize _ and _ reboot . py 脚本文件

你可以在本书的 GitHub 资源库中找到`resize_and_reboot.py`脚本文件:[https://GitHub . com/packt publishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter 01/resize _ and _ reboot . py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter01/resize_and_reboot.py)。注意，为了让这个脚本工作，必须设置环境变量`EC2_INSTANCE_ID`来选择正确的目标实例。我们将在运行`resize_and_reboot.py`脚本之前设置这个环境变量。

1.  接下来，在终端中运行下面的命令:

    ```
    python3 -m pip install --user --upgrade boto3
    ```

这将使用`pip`升级`boto3`的版本。

重要说明

如果这是你第一次使用`pip`，那就是 Python 的包安装程序。使用命令行安装不同的包和库非常方便。

你可以使用`python3 -m pip show boto3`来检查你正在使用的版本。本书假设您使用的是版本`1.20.26`或更高版本。

1.  剩余的语句关注于从实例元数据服务获取 Cloud9 环境的`instance_id`,并将该值存储在`EC2_INSTANCE_ID`变量中。让我们在终端中运行下面的:

    ```
    TARGET_METADATA_URL=http://169.254.169.254/latest/meta-data/instance-id
    ```

    ```
    export EC2_INSTANCE_ID=$(curl -s $TARGET_METADATA_URL)
    ```

    ```
    echo $EC2_INSTANCE_ID
    ```

这应该给我们一个 EC2 实例 ID，其格式类似于`i-01234567890abcdef`。

1.  现在我们已经为`EC2_INSTANCE_ID`环境变量设置了适当的值，我们可以运行下面的命令:

    ```
    python3 resize_and_reboot.py
    ```

这将使用`wget`命令运行我们之前下载的 Python 脚本。使用`boto3`执行卷大小调整操作后，脚本将重启实例。当 Cloud9 环境的 EC2 实例重新启动时，您应该会在页面的顶部看到一个**重新连接…** 通知。

重要说明

实例重启后，可以随意运行`lsblk`命令。这应该有助于验证 Cloud9 环境实例的卷大小已经调整到 120GB。

既然我们已经成功地将卷的大小调整到 120GB，我们应该能够处理下一组解决方案，而不必担心我们的 Cloud9 环境中的磁盘空间问题。

## 安装 Python 先决条件

按照以下步骤在 Cloud9 环境中安装和更新几个 Python 包:

1.  在我们的 Cloud9 环境的终端中(就在屏幕底部的`$`标志之后)，运行以下命令来更新`pip`、`setuptools`和`wheel` :

    ```
    python3 -m pip install -U pip
    ```

    、

    ```
    python3 -m pip install -U setuptools wheel
    ```

升级这些版本将有助于我们确保其他安装步骤顺利进行。本书假设你使用的是以下版本或更高版本:`pip`–`21.3.1`、`setuptools`–`59.6.0`、`wheel`–`0.37.1`。

重要说明

要检查版本，您可以使用终端中的`python3 -m pip show <package>`命令。只需用包的名称替换`<package>`。这方面的一个例子是`python3 -m pip show wheel`。如果您想安装软件包的特定版本，您可以使用`python3 -m pip install -U <package>==<version>`。比如要安装`wheel`版本`0.37.1`，可以运行`python3 -m pip install -U wheel==0.37.1`。

1.  接下来，通过运行以下命令安装`ipython`。IPython 提供了许多方便的实用程序，帮助专业人员交互式地使用 Python。我们将在稍后的*执行您的第一个 AutoGluon AutoML 实验*部分:

    ```
    python3 -m pip install ipython
    ```

    中看到使用 IPython 是多么容易

本书假设您使用的是`ipython`–`7.16.2`或更高版本。

1.  现在，让我们安装`ctgan`。CTGAN 允许我们利用**生成对抗网络** ( **GAN** )深度学习模型来生成合成数据集。在我们安装了 Python 先决条件:

    ```
    python3 -m pip install ctgan==0.5.0
    ```

    之后，我们将在*使用深度学习模型生成合成数据集*一节中对此进行讨论

本书假设你用的是`ctgan`–`0.5.0`。

重要说明

完成此步骤可能需要大约 5 到 10 分钟。一边等，一边说 CTGAN 是什么。 **CTGAN** 是一个开放的源库，它使用深度学习来学习现有数据集的属性，并生成一个新的数据集，其列、值和属性与原始数据集相似。要了解更多信息，请随意查看它的 GitHub 页面:https://github.com/sdv-dev/CTGAN。

1.  最后，通过运行以下命令安装`pandas_profiling`。这使得我们可以轻松地为我们的数据集生成一个概要报告，这将有助于我们的**探索性数据分析** ( **EDA** )工作。在生成合成数据集

    ```
    python3 -m pip install pandas_profiling
    ```

    之后，我们将在*探索性数据分析*部分看到这一点

这本书假设你正在使用`pandas_profiling`–`3.1.0`或更高版本。

现在我们已经完成了 Python 先决条件的安装，我们可以开始使用深度学习模型生成一个真实的合成数据集了！

# 准备数据集

在这一章中，我们将构建多个 ML 模型，这些模型将*根据可用信息*预测酒店预订是否会被取消。酒店取消会给酒店业主和经理带来很多问题，所以尝试预测哪些预订会被取消是我们 ML 技能的一个很好的应用。

在我们开始 ML 实验之前，我们需要一个可以在训练 ML 模型时使用的数据集。我们将从*努诺·安东尼奥*、*安娜·德·阿尔梅达*和*路易斯·努内斯*生成一个类似于*酒店预订需求*数据集的真实合成数据集。

合成数据集总共有 21 列。以下是一些栏目:

*   `is_cancelled`:表示酒店预订是否取消
*   `lead_time` : [ *到达日期*–[*预订日期*
*   `adr`:平均日费率
*   `adults`:成年人数量
*   `days_in_waiting_list`:预订在得到确认之前在等候名单上停留的天数
*   `assigned_room_type`:分配的房间类型
*   `total_of_special_requests`:客户提出特殊要求的总数

我们不会详细讨论每个字段，但这应该有助于我们了解哪些数据可供我们使用。有关更多信息，您可以在 https://www.kaggle.com/jessemostipak/hotel-booking-demand 和 https://www . science direct . com/science/article/pii/s 2352340918315191 找到该数据集的原始版本。

## 使用深度学习模型生成合成数据集

ML 的一个很酷的应用是让**深度学习**模型“吸收”现有数据集的属性，并生成一个具有类似字段和属性集的新数据集。我们将使用预训练的**生成对抗网络** ( **甘**)模型来生成合成数据集。

重要说明

**生成式建模**涉及从输入数据集的值中学习模式，然后用于生成一个具有相似值集的新数据集。当涉及到生成建模时，GANs 很受欢迎。例如，研究论文专注于如何使用 GANs 来生成“deepfakes”，即从源数据集生成逼真的人类图像。

生成和使用合成数据集有很多好处，包括:

*   生成比用于训练模型的原始数据集大得多的数据集的能力
*   匿名化原始数据集中任何敏感信息的能力
*   能够在数据生成后获得更清晰的数据集版本

也就是说，让我们通过在我们的 Cloud9 环境的终端中运行以下命令来开始生成合成数据集(就在屏幕底部的`$`符号之后):

1.  从我们在*安装 Python 先决条件*一节中停止的地方继续，运行以下命令在当前工作目录中创建一个名为`tmp`的空目录:

    ```
    mkdir -p tmp
    ```

注意，这不同于`/tmp`目录。

1.  接下来，让我们使用`wget`命令:

    ```
    wget -O utils.py https://bit.ly/3CN4owx
    ```

    下载`utils.py`文件

`utils.py`文件包含`block()`函数，它将帮助我们读取脚本生成的日志并对其进行故障排除。

1.  运行以下命令，将预构建的 GAN 模型下载到 Cloud9 环境中:

    ```
    wget -O hotel_bookings.gan.pkl https://bit.ly/3CHNQFT
    ```

在这里，我们有一个序列化的 pickle 文件，其中包含深度学习模型的属性。

重要说明

有多种保存和加载 ML 模型的方法。其中一个选择是使用 **Pickle** 模块来序列化一个 Python 对象并将其存储在一个文件中。这个文件稍后可以被加载并反序列化回一个具有类似属性集的 Python 对象。

1.  使用`touch`命令:

    ```
    touch data_generator.py
    ```

    创建一个空的`data_generator.py`脚本文件

重要说明

在继续之前，确保`data_generator.py`、`hotel_bookings.gan.pkl`和`utils.py`文件在同一目录下，以便合成数据发生器脚本工作。

1.  双击文件树中的`data_generator.py`文件(位于 Cloud9 环境的左侧)以在编辑器窗格中打开空的 Python 脚本文件。
2.  添加以下代码行以导入运行脚本所需的先决条件:

    ```
    from ctgan import CTGANSynthesizer
    ```

    ```
    from pandas_profiling import ProfileReport
    ```

    ```
    from utils import block, debug
    ```

3.  接下来，我们添加下面几行代码来加载预先训练好的 GAN 模型:

    ```
    with block('LOAD CTGAN'):
    ```

    ```
        pkl = './hotel_bookings.gan.pkl'
    ```

    ```
        gan = CTGANSynthesizer.load(pkl)
    ```

    ```
        print(gan.__dict__)
    ```

4.  在终端中运行以下命令(就在屏幕底部的`$`符号之后)来测试脚本中的初始代码块是否按预期工作:

    ```
    python3 data_generator.py
    ```

这将为我们提供一组日志，类似于下面的屏幕截图所示:

![Figure 1.7 – GAN model successfully loaded by the script

](img/B18638_01_007.jpg)

图 1.7–脚本成功加载 GAN 模型

在这里，我们可以看到预训练 GAN 模型使用`CTGANSynthesizer.load()`方法成功加载。在这里，我们还可以看到`block`(来自我们之前下载的`utils.py`文件)做了什么来提高我们日志的可读性。它只是帮助标记代码块执行的开始和结束，以便我们可以轻松地调试我们的脚本。

1.  让我们回到编辑器窗格(我们正在编辑`data_generator.py`)并添加下面几行代码:

    ```
    with block('GENERATE SYNTHETIC DATA'):
    ```

    ```
        synthetic_data = gan.sample(10000)
    ```

    ```
        print(synthetic_data)
    ```

当我们稍后运行脚本时，这些代码行将生成`10000`记录，并将它们存储在`synthetic_data`变量中。

1.  接下来，让我们添加下面的代码块，它将把生成的数据保存到`tmp`目录下的一个 CSV 文件中:

    ```
    with block('SAVE TO CSV'):
    ```

    ```
        target_location = "tmp/bookings.all.csv"
    ```

    ```
        print(target_location)
    ```

    ```
        synthetic_data.to_csv(
    ```

    ```
            target_location, 
    ```

    ```
            index=False
    ```

    ```
        )
    ```

2.  最后，让我们添加下面几行代码来完成脚本:

    ```
    with block('GENERATE PROFILE REPORT'):
    ```

    ```
        profile = ProfileReport(synthetic_data)
    ```

    ```
        target_location = "tmp/profile-report.xhtml"
    ```

    ```
        profile.to_file(target_location)
    ```

这段代码将分析合成数据集，并生成一个分析报告来帮助我们分析数据集的属性。

重要说明

你可以在这里找到`data_generator.py`文件的副本:[https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter 01/data _ generator . py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter01/data_generator.py)。

1.  一切准备就绪后，让我们在终端中运行以下命令(就在屏幕底部的`$`符号之后):

    ```
    python3 data_generator.py
    ```

脚本完成大约需要一分钟左右的时间。运行该脚本应该会给我们一组日志，类似于下面的屏幕截图所示:

![Figure 1.8 – Logs generated by data_generator.py

](img/B18638_01_008.jpg)

图 1.8-由 data_generator.py 生成的日志

正如我们可以看到的，运行`data_generator.py`脚本会生成多个日志块，这应该会让我们在脚本运行时容易读取和调试发生的事情。除了加载 CTGAN 模型，脚本还将使用深度学习模型(`tmp`目录(`tmp/bookings.all.csv` ) ( `pandas_profiling` ( **C** )生成合成数据集。

那不是很容易吗？在进入下一节之前，可以随意使用文件树(位于 Cloud9 环境的左侧)来检查存储在`tmp`目录中的生成文件。

## 探索性数据分析

此时，我们应该有一个包含`10000`行的合成数据集。您可能想知道我们的数据是什么样的。我们的数据集包含无效值吗？我们需要担心丢失记录吗？我们必须对我们的数据集有一个很好的理解，因为在我们做任何模型训练工作之前，我们可能需要首先清理和处理数据。EDA 是在数据集可用于训练 ML 模型之前分析数据集的关键步骤。有不同的方法来分析数据集和生成报告——使用`pandas_profiling`是执行 EDA 的一种更快的方法。

也就是说，让我们检查由`pandas_profiling` Python 库生成的报告。右击文件树(位于 Cloud9 环境的左侧)中的`tmp/profile-report.xhtml`，然后从选项列表中选择**预览**。我们应该会找到类似如下的报告:

![Figure 1.9 – Generated report

](img/B18638_01_009.jpg)

图 1.9-生成的报告

报告有多个部分:**概述**、**变量**、**交互**、**相关性**、**缺失值**和**样本**。在**概述**部分，我们可以找到数据集统计和变量类型的快速总结。这包括变量的数量、记录(观察)的数量、缺失单元格的数量、重复行的数量以及其他相关的统计数据。在**变量**部分，我们可以找到数据集中每个变量(列)的统计数据和值的分布。在**交互**和**相关性**部分，我们可以看到关于数据集中变量潜在关系的不同模式和观察结果。在**缺少值**部分，我们可以看到是否有需要处理的带有缺少值的列。最后，在**示例**部分，我们可以看到数据集的前 10 行和后 10 行。

在进入下一部分之前，请随意通读报告。

## 训练-测试分割

现在我们已经完成了表演 EDA，接下来我们做什么？假设我们的数据是干净的，并准备好进行模型训练，我们是否只是使用生成的所有 10，000 条记录来训练和构建我们的 ML 模型？在我们训练二元分类器模型之前，我们必须将数据集分成训练集和测试集:

![Figure 1.10 – Train-test split

](img/B18638_01_010.jpg)

图 1.10–列车测试分离

如我们所见，**训练集**是用于在训练阶段建立模型并更新其参数。然后**测试集**用于评估模型的最终版本，其数据之前未见过。这里没有显示的是**验证集**，其用于评估模型，以在模型训练阶段微调**超参数**。在实践中，将数据集划分为训练集、验证集和测试集的比率通常在 **60:20:20** 左右，其中训练集获得大多数记录。在本章中，我们不再需要将训练集进一步划分为更小的训练集和验证集，因为 AutoML 工具和服务会自动为我们完成这项工作。

重要说明

在继续本节的动手解决方案之前，我们必须了解什么是超参数和参数。`y = m * x`，其中`m`为参数，`x`为单一预测变量，`y`为目标变量。例如，如果我们要测试取消(`y`)和收入(`x`)之间的关系，那么`m`就是定义这种关系的参数。如果`m`为正值，取消订单会随着收入的增加而增加。如果是负数，取消的数量会随着收入的增加而减少。另一方面，**超参数**是在模型训练前调整的可配置值。这些变量影响我们选择的 ML 模型如何“模拟”这种关系。每个 ML 模型都有自己的超参数集，这取决于所使用的算法。一旦我们在 [*第二章*](B18638_02.xhtml#_idTextAnchor041) 、*深度学习 AMIs* 和 [*第三章*](B18638_03.xhtml#_idTextAnchor060) 、*深度学习容器*中再看几个例子，这些概念就更有意义了。

现在，让我们创建一个脚本来帮助我们执行训练测试分割:

1.  在我们的 Cloud9 环境的终端中(就在屏幕底部的`$`符号之后)，运行下面的命令来创建一个名为`train_test_split.py`的空文件:

    ```
    touch train_test_split.py
    ```

2.  使用文件树(位于 Cloud9 环境的左侧)，双击`train_test_split.py`文件，在编辑器窗格中打开该文件。
3.  在编辑器窗格中，添加以下代码行以导入运行脚本的先决条件:

    ```
    import pandas as pd
    ```

    ```
    from utils import block, debug
    ```

    ```
    from sklearn.model_selection import train_test_split
    ```

4.  添加以下代码块，该代码块将读取 CSV 文件的内容并将其存储在`DataFrame` :

    ```
    with block('LOAD CSV'):
    ```

    ```
        generated_df = pd.read_csv('tmp/bookings.all.csv')
    ```

    中
5.  接下来，让我们使用 scikit-learn 中的`train_test_split()`函数将我们生成的数据集分成训练集和测试集:

    ```
    with block('TRAIN-TEST SPLIT'):
    ```

    ```
        train_df, test_df = train_test_split(
    ```

    ```
            generated_df, 
    ```

    ```
            test_size=0.3, 
    ```

    ```
            random_state=0
    ```

    ```
        )
    ```

    ```
        print(train_df)
    ```

    ```
        print(test_df)
    ```

6.  最后，添加以下代码行，将训练集和测试集保存到`tmp`目录中各自的 CSV 文件中:

    ```
    with block('SAVE TO CSVs'):
    ```

    ```
        train_df.to_csv('tmp/bookings.train.csv', 
    ```

    ```
                        index=False)
    ```

    ```
        test_df.to_csv('tmp/bookings.test.csv', 
    ```

    ```
                       index=False)
    ```

重要说明

你可以在这里找到`train_test_split.py`文件的副本:[https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter 01/train _ test _ split . py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter01/train_test_split.py)。

1.  现在我们已经完成了脚本文件，让我们在终端中运行下面的命令(就在屏幕底部的`$`符号之后):

    ```
    python3 train_test_split.py
    ```

这将生成一组日志，类似于下面的屏幕截图所示:

![Figure 1.11 – Train-test split logs

](img/B18638_01_011.jpg)

图 1.11–列车测试分割日志

在这里，我们可以看到我们的训练数据集包含 7000 条记录，而测试集包含 3000 条记录。

有了这个，我们可以上传我们的数据集到亚马逊 S3。

## 上传数据集到亚马逊 S3

亚马逊 S3 是 AWS 的对象存储服务，我们可以在这里存储不同类型的文件，比如数据集 CSV 文件和输出工件。当使用 AWS 的不同服务时，需要注意的是，这些服务有时需要将输入数据和文件首先存储在 S3 存储桶中，或者存储在使用另一个服务创建的资源中。

将数据集上传到 S3 应该很容易。继续我们在*列车测试分割*部分停止的地方，我们将在终端运行以下命令:

1.  在终端中运行以下命令。这里，我们将创建一个新的 S3 存储桶，其中包含我们将在本章中使用的数据。确保将`<INSERT BUCKET NAME HERE>`的值替换为一个在所有 AWS 用户中全局唯一的存储段名称:

    ```
    BUCKET_NAME="<INSERT BUCKET NAME HERE>"
    ```

    ```
    aws s3 mb s3://$BUCKET_NAME
    ```

有关 S3 桶命名规则的更多信息，请随时查看[https://docs . AWS . Amazon . com/Amazon S3/latest/user guide/bucket naming grules . XHTML](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.xhtml)。

1.  既然已经创建了 S3 存储桶，让使用**AWS CLI**:

    ```
    S3=s3://$BUCKET_NAME/datasets/bookings
    ```

    ```
    TRAIN=bookings.train.csv
    ```

    ```
    TEST=bookings.test.csv
    ```

    ```
    aws s3 cp tmp/bookings.train.csv $S3/$TRAIN
    ```

    ```
    aws s3 cp tmp/bookings.test.csv $S3/$TEST
    ```

    上传训练和测试数据集

现在一切都准备好了，我们可以开始激动人心的部分了！是时候我们使用各种解决方案和服务进行多种自动实验了。

# 带自动旋转的 AutoML

之前，我们讨论了什么是**超参数**。当训练和调整 ML 模型时，重要的是我们要知道 ML 模型的性能取决于算法、训练数据和训练模型时使用的超参数配置。其他输入配置参数也可能会影响模型的性能，但是我们现在只关注这三个参数。团队不是训练单个模型，而是使用各种超参数配置构建多个模型。超参数配置的变化和调整会影响模型的性能——有些会导致更好的性能，而有些会导致更差的性能。尝试超参数配置的所有可能组合需要时间，尤其是在模型调整过程不是自动化的情况下。

在过去的几年里，一些库、框架和服务已经允许团队最大限度地利用自动化机器学习来自动化 ML 过程的不同部分。最初，AutoML 工具专注于自动化**超参数优化** ( **HPO** )过程，以获得超参数值的最佳组合。在运行训练作业时，我们不需要花费数小时(甚至数天)手动尝试不同的超参数组合，我们只需要配置、运行并等待这个自动化程序来帮助我们找到最佳的超参数值集。多年来，专注于自动化超参数优化的几个工具和库可供 ML 从业者使用。过了一段时间，ML 工作流的其他方面和过程被自动化并包含在 AutoML 管道中。

有几个工具和服务可用于 AutoML，其中最受欢迎的选项是**autoglon**。有了 **AutoGluon** ，我们可以使用不同的算法训练多个模型，并且只用几行代码就可以对它们进行评估:

![Figure 1.12 – AutoGluon leaderboard – models trained using a variety of algorithms

](img/B18638_01_012.jpg)

图 1.12–自动登录排行榜–使用各种算法训练的模型

与前面截图中的类似，我们也可以使用排行榜来比较生成的模型。在本章中，我们将对表格数据集使用 AutoGluon。但是，需要注意的是，AutoGluon 还支持对文本和图像数据执行 AutoML 任务。

## 设置和安装自动旋翼

在使用自动旋翼之前，我们需要安装它。完成安装过程大约需要一分钟时间:

1.  在安装 AutoGluon 之前，在终端中运行以下命令来安装和更新先决条件:

    ```
    python3 -m pip install -U "mxnet<2.0.0"
    ```

    ```
    python3 -m pip install numpy
    ```

    ```
    python3 -m pip install cython
    ```

    ```
    python3 -m pip install pyOpenSSL --upgrade
    ```

本书假设你使用的是以下版本或更高版本:`mxnet`–`1.9.0`、`numpy`–`1.19.5`、`cython`–`0.29.26`。

1.  接下来，运行以下命令来安装`autogluon` :

    ```
    python3 -m pip install autogluon
    ```

本书假设你正在使用`autogluon`版本`0.3.1`或更高版本。

重要说明

完成此步骤可能需要大约 5 到 10 分钟。请随意喝杯咖啡或茶！

在我们的 Cloud9 环境中安装了 AutoGluon 之后，让我们继续进行我们的第一个 AutoGluon AutoML 实验。

## 进行你的第一次自动旋转实验

如果你用过`fit()`和`predict()`。请遵循以下步骤:

1.  首先，在终端中运行以下命令:

    ```
    ipython
    ```

这将打开**IPython****Read-Eval-Print-Loop**(**REPL**)/interactive shell。我们将像使用 **Python shell** 一样使用它。

1.  在控制台内，键入(或复制)以下代码块。确保在输入右括号

    ```
    from autogluon.tabular import (
    ```

    ```
        TabularDataset,
    ```

    ```
        TabularPredictor
    ```

    ```
    )
    ```

    后按*回车*
2.  现在，让我们通过运行下面的语句将保存在`bookings.train.csv`和`bookings.test.csv`文件中的合成数据分别加载到`train_data`和`test_data`变量中:

    ```
    train_loc = 'tmp/bookings.train.csv'
    ```

    ```
    test_loc = 'tmp/bookings.test.csv'
    ```

    ```
    train_data = TabularDataset(train_loc)
    ```

    ```
    test_data = TabularDataset(test_loc)
    ```

由于自动生成的父类`TabularDataset`是一个熊猫数据帧，我们可以在`train_data`和`test_data`上使用不同的方法，例如`head()`、`describe()`、`memory_usage()`等等。

1.  接下来，运行下面几行代码:

    ```
    label = 'is_cancelled'
    ```

    ```
    save_path = 'tmp'
    ```

    ```
    tp = TabularPredictor(label=label, path=save_path)
    ```

    ```
    predictor = tp.fit(train_data)
    ```

这里，我们将`is_cancelled`指定为 AutoML 任务的目标变量，将`tmp`目录指定为存储生成模型的位置。这段代码将使用我们提供的训练数据，使用不同的算法来训练多个模型。AutoGluon 将自动检测到我们正在处理一个二元分类问题，并使用各种 ML 算法生成多个二元分类器模型。

重要说明

在`tmp/models`目录中，我们应该找到`CatBoost`、`ExtraTreesEntr`和`ExtraTreesGini`，以及对应于 AutoML 任务中使用的算法的其他目录。每个目录都包含一个包含序列化模型的`model.pkl`文件。为什么我们有多个模型？在幕后，AutoGluon 使用各种算法以及超参数值的不同组合运行大量训练实验，以产生“最佳”模型。“最佳”模型是使用特定的评估标准选择的，该评估标准有助于确定哪个模型比其他模型表现得更好。例如，如果使用的评估指标是*准确度*，那么准确度分数为 90%的模型(每 10 次尝试得到 9 个正确答案)比准确度分数为 80%的模型(每 10 次尝试得到 8 个正确答案)更“好”。也就是说，一旦生成并评估了模型，AutoGluon 只需选择具有最高评估度量值的模型(例如， *accuracy* )并将其标记为“最佳模型”

1.  现在我们已经准备好了“最佳模型”，接下来我们做什么？下一步是我们使用测试数据集来评估“最佳模型”。也就是说，让我们通过移除目标标签

    ```
    y_test = test_data[label]
    ```

    ```
    test_data_no_label = test_data.drop(columns=[label])
    ```

    来准备用于推断的测试数据集
2.  一切准备就绪后，让我们使用`predict()`方法来预测作为有效负载提供的测试数据集的`is_cancelled`列值:

    ```
    y_pred = predictor.predict(test_data_no_label)
    ```

3.  现在我们已经有了实际的 *y* 值(`y_test`)和预测的 *y* 值(`y_pred`)，让我们使用`evaluate_predictions()`方法快速检查训练好的模型的性能:

    ```
    predictor.evaluate_predictions(
    ```

    ```
        y_true=y_test, 
    ```

    ```
        y_pred=y_pred, 
    ```

    ```
        auxiliary_metrics=True
    ```

    ```
    )
    ```

前面的代码块应该产生类似于下面的性能指标值:

```
{'accuracy': 0.691...,

 'balanced_accuracy': 0.502...,

 'mcc': 0.0158...,

 'f1': 0.0512...,

 'precision': 0.347...,

 'recall': 0.0276...}
```

在这一步中，我们使用各种公式来比较目标列的实际值和预测值，这些公式用于比较这些值之间的接近程度。这里，训练模型的目标是在看不见的数据上尽可能“犯最少的错误”。更好的模型通常在性能指标上有更好的得分，如**准确性**、**马修斯相关系数** ( **MCC** )、**F1-得分**。我们不会在这里详细讨论模型性能指标是如何工作的。如需更多信息，请随时查看 https://bit.ly/3zn2crv。

1.  现在我们已经完成了快速实验，让我们退出 **IPython** shell:

    ```
    exit()
    ```

使用自动旋转，我们可以做更多的事情，但这应该有助于我们理解使用自动旋转进行自动实验是多么容易。我们还可以使用其他方法，比如`leaderboard()`、`get_model_best()`和`feature_importance()`，所以请随时查看[https://auto.gluon.ai/stable/index.xhtml](https://auto.gluon.ai/stable/index.xhtml)了解更多信息。

# sage maker 和 SageMaker Studio 入门

在 AWS 上执行 ML 和 ML 工程时，专业人员应该考虑使用 **Amazon SageMaker** 的一个或多个功能和特性。如果这是你第一次了解 SageMaker，它是一个完全管理的 ML 服务，有助于显著加快准备、培训、评估和部署 ML 模型的过程。

如果您想知道这些功能是什么，请查看*ML 工程师如何充分利用 AWS* 部分的*图 1.2* 中 **ML 服务**下标记的一些功能。在本书的不同章节中，我们将讨论 SageMaker 的几个功能。与此同时，我们将从 SageMaker Studio 开始，因为在我们处理 SageMaker Canvas 和 SageMaker Autopilot 示例之前，我们需要首先设置它。

## 加入 SageMaker 工作室

**SageMaker Studio** 为 ML 从业者提供一个功能丰富的 IDE。SageMaker Studio 的一个伟大之处是它与 SageMaker 的其他功能紧密集成，这允许我们通过使用界面来管理不同的 SageMaker 资源。

为了更好地了解它的外观和工作原理，让我们继续设置和配置 SageMaker Studio:

1.  在 AWS 控制台的搜索栏中，输入`sagemaker studio`。在**功能**下选择 **SageMaker 工作室**。
2.  选择**标准设置**，如下截图所示:

![Figure 1.13 – Setup SageMaker Domain

](img/B18638_01_013.jpg)

图 1.13–设置 SageMaker 域

正如我们所见，**标准设置**应该给我们更多的配置选项来调整**快速设置**。在点击**配置**按钮之前，确保您使用的是 S3 桶以及训练和测试数据集所在的同一区域。

1.  在**认证**下，选择 **AWS 身份和访问管理(IAM)** 。对于**权限**下的默认执行角色，选择**新建角色**。选择**任意一个 S3 斗**。然后，点击**创建角色**。
2.  在`us-west-2a`下)，类似于下面的截图所示:

![Figure 1.14 – Network and Storage Section

](img/B18638_01_014.jpg)

图 1.14–网络和存储部分

在这里，我们还通过选择**仅公共互联网**将 SageMaker 域配置为使用默认的 SageMaker 互联网访问。在**加密密钥**下，我们通过选择**无自定义加密**保持不变。查看配置，然后点击**下一步**。

重要说明

请注意，对于生产环境，需要进一步检查和升级最后几个步骤中指定的安全配置。与此同时，这应该可以解决问题，因为我们正在处理一个样本数据集。我们将在第 9 章 *、安全、治理和遵从策略*中详细讨论如何保护环境。

1.  在**工作室设置**下，保持一切不变，点击**下一步**。
2.  同样，在**通用设置** | **RStudio 工作台**下，点击**提交**。

一旦完成这些步骤，您应该会看到**准备 SageMaker 域**加载消息。完成此步骤大约需要 3 到 5 分钟。一旦完成，您应该会看到一个通知，声明**sage maker 域准备就绪**。

## 将用户添加到现有的 SageMaker 域

现在我们的 **SageMaker 域**已经准备好了，让我们创建一个用户。创建用户非常简单。那么，让我们开始吧:

1.  在 **SageMaker 域/控制面板**页面，点击**添加用户**。
2.  在**名称**下指定用户的名称。在**默认执行角色**下，选择您在上一步中创建的执行角色。点击**下一个**。
3.  在**工作室设置** | **SageMaker 项目和 JumpStart** 下，点击**下一步。**
4.  在 **RStudio 设置** | **Rstudio 工作台**下，点击**提交。**

这应该可以暂时解决问题。在 [*第 9 章*](B18638_09.xhtml#_idTextAnchor187) *“安全、治理和合规性策略*中，我们将回顾如何改进此处的配置以提高我们环境的安全性。

# 使用 SageMaker Canvas 的无代码机器学习

在之前，我们继续使用更加全面的 SageMaker 功能集来执行 ML 实验和部署，让我们从使用 **SageMaker Canvas** 构建一个模型开始。SageMaker Canvas 的一大优点是，构建模型并使用它们进行预测不需要任何编码工作。当然， **SageMaker Autopilot** 会有更强大、更灵活的功能，但 SageMaker Canvas 应该能帮助业务分析师、数据科学家和初级 ML 工程师理解 ML 流程，并立即开始构建模型。

由于我们的数据集已经上传到 S3 桶，我们可以开始构建和训练我们的第一个 SageMaker 画布模型:

1.  在 **SageMaker 域/控制面板**页面，找到我们刚刚创建的用户所在的行，点击**启动应用**。从下拉菜单的可用选项列表中选择**画布**，如下图所示:

![Figure 1.15 – Launching SageMaker Canvas

](img/B18638_01_015.jpg)

图 1.15–启动 SageMaker 画布

正如我们所见，我们可以从 **SageMaker 域/控制面板**页面启动 SageMaker Canvas。我们也可以在这里启动 SageMaker Studio，我们将在本章的后面进行介绍。

1.  点击**新型号**:

![Figure 1.16 – The SageMaker Canvas Models page

](img/B18638_01_016.jpg)

图 1.16–sage maker 画布模型页面

这里，我们有 SageMaker Canvas **Models** 页面，它应该列出我们已经训练过的模型。由于我们尚未进行任何培训，我们应该会看到**您尚未创建任何模型**消息。

1.  在中输入`first-model`并点击**创建**。
2.  当您看到**入门**向导窗口时，点击**跳过介绍**。
3.  点击 S3 桶`Amazon S3/<S3 BUCKET>/datasets/bookings`文件夹中的`booking.train.csv`和`booking.test.csv`文件。

![Figure 1.17 – Choose files to import

](img/B18638_01_017.jpg)

图 1.17–选择要导入的文件

选择需要的 CSV 文件，如前面截图所示，点击**导入数据**。

重要说明

请注意，如果您的帐户中有大量 S3 存储桶，您可能很难找到我们在*将数据集上传到 S3* 部分创建的 S3 存储桶。请随意使用位于右手边的搜索框(带有**搜索亚马逊 S3** 占位符)，就在列出不同 S3 桶和资源的表格上方。

1.  一旦文件被导入，点击包含`bookings.train.csv`的行的单选按钮。点击**选择数据集**。
2.  在**目标列**字段的下拉选项列表中的`is_cancelled`。
3.  接下来，点击**预览模型**(在**快速构建**按钮下)，如下图所示:

![Figure 1.18 – The Build tab

](img/B18638_01_018.jpg)

图 1.18–构建选项卡

几分钟后，我们应该会得到大约 70%的估计准确率。请注意，在这一步中，您可能会得到一组不同的数字。

1.  点击**快速构建**，等待模型准备就绪。

重要说明

此步骤可能需要 15 分钟才能完成。在等待的同时，我们来快速讨论一下**快速构建**和**标准构建**的区别。快速构建使用较少的记录进行训练，通常持续大约 2 到 15 分钟，而标准构建持续更长时间，通常大约 2 到 4 小时。需要注意的是，使用快速构建训练的模型不能与 SageMaker Studio 中的其他数据科学家或 ML 工程师共享。另一方面，使用标准构建训练的模型可以在构建完成后共享。

1.  一旦结果可用，您可以通过点击以下截图中突出显示的选项卡来打开**评分**选项卡:

![Figure 1.19 – The Analyze tab

](img/B18638_01_019.jpg)

图 1.19–分析选项卡

我们应该会看到一个快速图表，显示用于分析模型的记录数量，以及模型做出的正确预测和错误预测的数量。

重要说明

至此，我们已经构建了一个 ML 模型，可以用来预测预订是否会被取消。由于本例中的准确率只有 70%左右，我们期望该模型每 10 次尝试能得到大约 7 个正确答案。在 [*第十一章*](B18638_11.xhtml#_idTextAnchor231) *、带有 SageMaker 流水线的机器学习流水线*中，我们将训练这个模型的改进版本，准确率在 88%左右。

1.  一旦我们检查完**分析**选项卡中的不同数字和图表，我们可以点击**预测**按钮继续。
2.  点击`bookings.test.csv`并点击**生成预测**。
3.  一旦的**状态**列值设置为**就绪**，将悬停在该行的**状态**列上，点击 3 个点(悬停在该行上后会出现)，然后从选项列表中选择**预览**:

![Figure 1.20 – Batch prediction results

](img/B18638_01_020.jpg)

图 1.20–批量预测结果

我们应该会看到一个值表，类似于前面截图中显示的内容。在第一列中，我们应该有测试数据集每一行的`is_cancelled`字段的预测值。在第二列中，我们应该找到预测正确的概率。

重要说明

注意，我们也可以通过点击**预测目标值**下的**单次预测**后提供的界面进行单次预测。

1.  最后，让我们注销我们的会话。点击左侧工具条中的**账户**图标，选择**注销**选项。

重要说明

确保在使用 SageMaker Canvas 后总是注销当前会话，以避免任何意外费用。更多信息请访问[https://docs . AWS . Amazon . com/sage maker/latest/DG/canvas-log-out . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-log-out.xhtml)。

那不是很容易吗？既然我们对如何使用 SageMaker Canvas 有了一个很好的想法，让我们使用 SageMaker Autopilot 运行一个 AutoML 实验。

# 带 SageMaker 自动驾驶仪的 AutoML

**SageMaker Autopilot** 让 ML 从业者不用写一行代码就能构建高质量的 ML 模型。当然，使用 **SageMaker Python SDK** 以编程方式配置、运行和管理 SageMaker 自动驾驶实验是可能的，但是我们将专注于使用 SageMaker Studio 接口来运行 AutoML 实验。在开始配置我们的第一个自动驾驶实验之前，让我们看看幕后发生了什么:

![Figure 1.21 – AutoML with SageMaker Autopilot

](img/B18638_01_021.jpg)

图 1.21–带 SageMaker 自动驾驶仪的 AutoML

在前面的图中，我们可以看到运行 AutoML 实验时 SageMaker 自动驾驶仪执行的不同步骤。它从**数据预处理**步骤开始，并继续进行**生成候选模型**(流水线和算法对)步骤。然后，它继续执行**特征工程**和**模型调整**步骤，这将从不同的模型族、超参数值和模型性能度量值中产生多个训练模型。自动驾驶作业将生成的具有最佳性能指标值的模型标记为“最佳模型”。接下来，生成两个报告:**可解释性报告**和**洞察力报告**。最后，模型被部署到一个推理端点。

让我们更深入地了解一下每一步都发生了什么:

*   **数据预处理**:自动清理数据，自动输入缺失值。
*   **候选定义生成**:生成多个“候选定义”(由一个数据处理作业和一个训练作业组成)，这些定义都将在数据集上使用。
*   **特征工程**:这里，数据转换被应用于执行自动化特征工程。
*   **模型调整**:SageMaker 的**自动模型调整**(超参数调整)功能用于使用各种超参数配置值生成多个模型，以找到“最佳模型”
*   **可解释性报告生成**:使用 **SageMaker Clarify** 提供的工具生成模型可解释性报告，该报告利用 SHAP 值来帮助解释所生成模型的行为(SageMaker 的另一个功能集中在 AI **公平性**和**可解释性**)。我们将在稍后的第 9 章[](B18638_09.xhtml#_idTextAnchor187)*、*安全、治理和法规遵从性策略*中更深入地探讨这个主题。*
**   **Insights 报告生成**:生成了 Insights 报告，其中包含了标量指标等数据见解，有助于我们更好地理解数据集。*   **模型部署**:将最佳模型部署到专用的推理端点。这里，目标度量的值用于确定在模型调整步骤期间训练的所有模型中哪一个是最佳模型。*

 *重要说明

如果您想知道 AutoML 解决方案是否会完全“取代”数据科学家，那么对您的问题的快速回答将是“不会”或“不会很快”ML 流程的某些特定领域需要数据科学家掌握领域知识。AutoML 解决方案有助于为数据科学家和 ML 实践者提供一个良好的起点。例如，白盒 AutoML 解决方案(如 SageMaker Autopilot)可以生成脚本和笔记本，数据科学家和 ML 从业者可以修改这些脚本和笔记本，以产生定制和复杂的数据处理、实验和部署流程和管道。

现在我们对自动驾驶实验中发生的事情有了更好的了解，让我们运行我们的第一个自动驾驶实验:

1.  在**控制面板**页面，点击**启动应用**下拉菜单，从下拉选项列表中选择**工作室**，如下图所示:

![Figure 1.22 – Opening SageMaker Studio

](img/B18638_01_022.jpg)

图 1.22–打开 SageMaker 工作室

请注意，如果您是第一次打开 **SageMaker Studio** 可能需要大约 5 分钟来加载。

重要说明

AWS 会定期发布 SageMaker Studio 的更新和升级。为了确保您使用的是最新版本，请确保关闭并更新 SageMaker Studio 和 Studio 应用程序。更多信息请访问[https://docs . AWS . Amazon . com/sage maker/latest/DG/studio-tasks-update . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tasks-update.xhtml)。

1.  打开**文件**菜单，点击**新建**子菜单下的**实验**:

![Figure 1.23 – Using the File menu to create a new experiment

](img/B18638_01_023.jpg)

图 1.23–使用文件菜单创建新实验

这里，我们在**新**子菜单下有多个选项。我们将在本书中探讨其他选项。

在下一组步骤中，我们将配置自动驾驶仪实验，类似于下面的截图所示:

![Figure 1.24 – Configuring the Autopilot experiment

](img/B18638_01_024.jpg)

图 1.24–配置自动驾驶仪实验

在这里，我们可以看到在运行自动驾驶实验之前可用的不同配置选项。请注意，实际的自动驾驶仪实验设置表单只有一列，而不是两列。

1.  指定`first-automl-job`)。
2.  在`bookings.train.csv`下，我们通过点击**浏览**上传。
3.  在**目标**下拉菜单中，选择**被取消**。点击**下一步:训练方法**。
4.  其他一切保持不变，然后点击**下一个** : **部署和高级设置**。
5.  确保**自动展开**？配置设置为是。

重要说明

您可以选择将**自动部署**配置设置为**否**，这样自动驾驶作业就不会创建推理端点。如果您已经将此设置为 **Yes** ，确保您删除了不使用的推理端点。

1.  在**高级设置** ( **可选** ) **>运行时间**下，将**最大候选值**设置为 **20** (或者，将**最大试验运行时间分钟数**和**最大作业运行时间分钟数**设置为 **20** )。点击**下一步:审核并创建**。

重要说明

设置`20`的值意味着 Autopilot 将只训练和考虑 20 个候选模型来完成这项自动驾驶工作。当然，我们可以将其设置为一个更高的数字，这将增加找到具有更高评估指标分数的候选人的机会(例如，一个表现更好的模型)。然而，这将意味着自动驾驶需要更长的时间来运行，因为我们将运行更多的培训工作。因为我们只是在测试这个功能，所以我们应该同时设置好`20`。

1.  查看我们在前面步骤中设置的所有配置参数，并点击**创建实验**。当询问您是否要自动部署最佳型号时，点击**确认**。AutoML 作业启动后，我们应该会看到类似于以下内容的加载屏幕:

![Figure 1.25 – Waiting for the AutoML job to complete

](img/B18638_01_025.jpg)

图 1.25–等待 AutoML 作业完成

在这里，我们可以看到自动驾驶作业包括以下步骤:

1.  **预处理**
2.  **候选人定义生成**
3.  **特征工程**
4.  **模型调整**
5.  **生成可说明性报告**
6.  **生成的洞察报告**
7.  **部署模型**

如果我们已经将**自动部署**配置设置为**是，**最佳模型会自动部署到一个全天候运行的推理端点中。

重要说明

完成此步骤可能需要大约 30 分钟到 1 小时。请随意喝杯咖啡或茶！

大约一个小时后，我们应该会看到一个试验列表，以及由多个培训工作生成的几个模型，如下面的屏幕截图所示:

![Figure 1.26 – Autopilot job results

](img/B18638_01_026.jpg)

图 1.26-自动驾驶仪工作结果

我们还应该看到页面右上方有两个按钮:**打开候选生成笔记本**和**打开数据探索笔记本**。由于这两个笔记本是在过程的早期生成的，我们可能会在实验开始后大约 10 到 15 分钟看到按钮出现。

1.  点击**打开候选生成笔记本**和**打开数据探索笔记本**按钮，打开 SageMaker 自动驾驶仪生成的笔记本；

![Figure 1.27 – The Data Exploration Report (left) and the Candidate Definition Notebook (right)

](img/B18638_01_027.jpg)

图 1.27–数据探索报告(左)和候选定义笔记本(右)

在这里，我们可以看到左侧的**数据探索报告**和右侧的**候选定义笔记本**。**数据探索报告**帮助数据科学家和 ML 工程师识别给定数据集中的问题。它包含一个列分析报告，显示缺失值的百分比，以及一些计数统计和描述性统计。另一方面，**候选定义笔记本**包含建议的 ML 算法，以及规定的超参数范围。除此之外，它还包含训练步骤开始前的推荐预处理步骤。

这些生成的笔记本的伟大之处在于，我们可以根据需要修改这些笔记本的某些部分。这使得 SageMaker Autopilot 易于初学者使用，同时仍然允许中级用户定制 AutoML 过程的某些部分。

重要说明

如果你想了解更多关于 SageMaker Autopilot 的信息，包括 AutoML 实验生成的输出工件，可以查看《用亚马逊 SageMaker Cookbook 学习机器》一书*的 [*第 6 章*](B18638_06.xhtml#_idTextAnchor132) 、 *SageMaker 培训和调试解决方案*。您应该可以在那里找到一些方法，这些方法侧重于使用 **SageMaker Python SDK** 以编程方式运行和管理自动驾驶实验。*

1.  导航回到包含自动驾驶作业结果的选项卡。右键单击带有**最佳型号**标签的行，并从上下文菜单的选项中选择**在型号详情中打开**。这将打开一个类似于以下屏幕截图所示的页面:

![Figure 1.28 – The model details page

](img/B18638_01_028.jpg)

图 1.28–模型详细信息页面

在这里，我们可以看到 **reserved_room_type、lead_time 和 adr** 是影响酒店预订被取消几率的最重要特征。

注意

请注意，您可能会得到与本部分不同的结果。

我们还应该在车型详情页面上看到以下信息:

*   问题类型
*   使用的算法
*   输入和输出工件的位置
*   模型度量值
*   用于训练模型的超参数值

重要说明

确保删除运行 SageMaker Autopilot 实验后创建的推断端点。要找到正在运行的推理端点，只需导航到[https://us-west-2.console.aws.amazon.com/sagemaker/home?region=us-west-2#/endpoints](https://us-west-2.console.aws.amazon.com/sagemaker/home?region=us-west-2#/endpoints) 并手动删除未使用的资源。注意，所提供的链接假设推断端点已经在**俄勒冈州** ( **us-west-2** )地区创建。我们现在将跳过使用推断端点执行样本预测。我们将在 [*第 7 章*](B18638_07.xhtml#_idTextAnchor151) 、 *SageMaker 部署解决方案*中讨论这一点以及部署策略。

此时，我们应该很好地掌握了如何使用几个 AutoML 解决方案，如**autoglon**、 **SageMaker Canvas** 和 **SageMaker Autopilot** 。正如我们在本节的动手解决方案中看到的，当使用 SageMaker Autopilot 来影响寻找最佳模型的过程时，我们有大量的选项。如果我们更喜欢选项更少的简单 UI，那么我们可能会使用 SageMaker Canvas。如果我们更愿意通过代码来开发和设计 ML 解决方案，那么我们也可以考虑使用 AutoGluon。

# 摘要

在这一章中，我们使用 AWS 上的各种服务、功能和工具进行了多次 AutoML 实验。这包括在 Cloud9 环境中使用 AutoGluon 以及 SageMaker Canvas 和 SageMaker Autopilot 来运行 AutoML 实验。本章介绍的解决方案也帮助我们更好地理解了基本的 ML 和 ML 工程概念。我们能够看到 ML 过程中的一些步骤，如 EDA、训练-测试分离、模型训练、评估和预测。

在下一章中，我们将重点关注 **AWS 深度学习 AMIs** 如何帮助加速 ML 实验过程。我们还将进一步了解 AWS 定价如何适用于 EC2 实例，以便我们能够更好地管理在云中运行 ML 工作负载的总成本。

# 延伸阅读

有关本章涵盖的主题的更多信息，请查阅以下资源:

*   *自动引导:文本、图像和表格数据的自动引导*([https://auto.gluon.ai/stable/index.xhtml](https://auto.gluon.ai/stable/index.xhtml))
*   *用亚马逊 sage maker auto pilot*(https://docs . AWS . Amazon . com/sage maker/latest/DG/auto pilot-Automate-model-development . XHTML)实现模型开发自动化
*   SageMaker 帆布定价(https://aws.amazon.com/sagemaker/canvas/pricing/)
*   *用亚马逊 SageMaker Cookbook* 进行机器学习，作者约书亚·李北·拉特([https://www . Amazon . com/Machine-Learning-Amazon-sage maker-Cookbook/DP/1800567030/](https://www.amazon.com/Machine-Learning-Amazon-SageMaker-Cookbook/dp/1800567030/))*