<html><head/><body>





<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style>
<div><div><h1 id="_idParaDest-85"><em class="italic"> <a id="_idTextAnchor086"/>第七章</em>:带TPOT的神经网络分类器</h1>
			<p>在这一章中，你将学习如何以自动化的方式构建你的深度学习分类器——通过使用TPOT库。假设你知道人工神经网络的基础知识，那么像<em class="italic">神经元</em>、<em class="italic">层</em>、<em class="italic">激活函数</em>和<em class="italic">学习速率</em>这样的术语应该听起来很熟悉。如果你不知道如何简单解释这些术语，请重温<a href="B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073"> <em class="italic">第六章</em> </a>，<em class="italic">深度学习入门:神经网络速成班</em>。</p>
			<p>通过本章，您将了解到基于神经网络构建一个简单的分类器是多么容易，以及如何调整神经网络，使其更好地满足您的需求和训练数据。</p>
			<p>本章将涵盖以下主题:</p>
			<ul>
				<li>探索数据集</li>
				<li>探索训练神经网络分类器的选择</li>
				<li>训练神经网络分类器</li>
			</ul>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor087"/>技术要求</h1>
			<p>深度学习和神经网络不需要任何事先的实践经验。然而，一些基本概念和术语的知识是必须的。如果你对这个主题完全陌生，请重温第6章 ，<em class="italic">深度学习入门:神经网络速成班</em>。</p>
			<p>你可以在这里下载本章的源代码和数据集:<a href="https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter07">https://github . com/packt publishing/Machine-Learning-Automation-with-TPOT/tree/main/chapter 07</a>。</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor088"/>探索数据集</h1>
			<p>没有理由疯狂使用数据集。仅仅因为我们可以用TPOT训练神经网络模型，并不意味着我们应该花50多页来探索和转换不必要的复杂数据集。</p>
			<p>因此，您将在整个章节中使用scikit-learn内置数据集——乳腺癌数据集。这个数据集不必从网上下载，因为它内置了scikit-learn。让我们从<a id="_idIndexMarker420"/>加载并探索它开始:</p>
			<ol>
				<li>首先，您需要加载几个库。我们正在导入NumPy、pandas、Matplotlib和Seaborn，以便于数据分析和可视化。此外，我们从<code>sklearn.datasets</code>模块中导入了<code>load_breast_cancer</code>函数。这是将加载到数据集中的函数。最后，从Matplotlib中导入了<code>rcParams</code>模块，使得默认样式看起来更容易一些:<pre>import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from sklearn.datasets import load_breast_cancer from matplotlib import rcParams rcParams['figure.figsize'] = (14, 7) rcParams['axes.spines.top'] = False rcParams['axes.spines.right'] = False</pre></li>
				<li>You can now use the <code>load_breast_cancer</code> function to load in the dataset. The function returns a dictionary, so we can use the <code>keys()</code> method to print the keys:<pre>data = load_breast_cancer()
data.keys()</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_1.jpg" alt="Figure 7.1 – Dictionary keys of the Breast cancer dataset&#13;&#10;" width="1446" height="35"/></div><p class="figure-caption">图7.1-乳腺癌数据集的字典关键字</p></li>
				<li>You can now <a id="_idIndexMarker421"/>use this dictionary to extract attributes of interest. What is essential for now are the <code>data</code> and <code>target</code> keys. You can store their values to separate variables and then construct a data frame object from them. Working with raw values is possible, but a pandas data frame data structure will allow easier data manipulation, transformation, and exploration. <p>以下是将它们转换为熊猫数据框的方法:</p><pre>features = data.data
target = data.target
df =\
pd.DataFrame(data=features,columns=data.feature_names)
df['target'] = target
df.sample(8)</pre><p>结果如下表所示:</p><div><img src="img/B16954_07_2.jpg" alt="Figure 7.2 – Sample of eights rows from the Breast cancer dataset&#13;&#10;" width="1586" height="600"/></div><p class="figure-caption">图7.2-乳腺癌数据集的八行样本</p></li>
				<li>The first thing you <a id="_idIndexMarker422"/>always want to do, analysis-wise, is to check for missing data. Pandas has an <code>isnull()</code> method built in, which returns Booleans for every value in the dataset. You can then call the <code>sum()</code> method on top of these results to get the count of missing values per column:<pre>df.isnull().sum()</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_3.jpg" alt="Figure 7.3 – Missing value count per column&#13;&#10;" width="476" height="984"/></div><p class="figure-caption">图7.3–每列缺失值计数</p><p>如您所见，没有丢失值。</p></li>
				<li>The next thing to do in the <a id="_idIndexMarker423"/>exploratory phase is to get familiar with your dataset. Data visualization techniques can provide an excellent way of doing so.<p>例如，您可以声明一个名为<code>make_count_chart()</code>的函数，它接受任何分类属性并可视化其分布。下面是这个函数的代码:</p><pre>def make_count_chart(column, title, ylabel, xlabel, y_offset=0.12, x_offset=700):
    ax = df[column].value_counts().plot(kind='bar', fontsize=13, color='#4f4f4f')
    ax.set_title(title, size=20, pad=30)
    ax.set_ylabel(ylabel, fontsize=14)
    ax.set_xlabel(xlabel, fontsize=14)
                  
    for i in ax.patches:
        ax.text(i.get_x() + x_offset, i.get_height()\
 + y_offset, f'{str(round(i.get_height(), 2))}',\
 fontsize=15)
    return ax</pre><p>您现在可以使用下面的代码片段<a id="_idIndexMarker424"/>来可视化目标变量，以找出有多少实例是良性的，有多少是恶性的:</p><pre>make_count_chart(
    column='target',
    title=\
'Number of malignant (1) vs benign (0) cases',
    ylabel='Malignant? (0 = No, 1 = Yes)',
    xlabel='Count',
    y_offset=10,
    x_offset=0.22
)</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_4.jpg" alt="Figure 7.4 – Number of malignant and benign cases&#13;&#10;" width="1650" height="929"/></div><p class="figure-caption">图7.4–恶性和良性病例的数量</p><p>如你所见，恶性案件的数量相当可观，所以各个阶层并不完全平衡。类别不平衡会导致高度精确但不可用的模型。想象一下，你正在对一个罕见的事件进行分类。在每10，000次交易中，只有一次被归类为异常。显然，机器学习模型没有太多机会了解是什么使异常与其他异常如此不同。</p><p>此外，总是预测交易是正常的导致99.99%准确的模型。最先进的精确度，当然，但是这个模型是不可用的。</p><p>有许多处理不平衡数据集的技术，但是它们超出了本书的范围。</p></li>
				<li>Next stop – correlation analysis. The aim of this step is to take a glimpse at which feature(s) have the biggest effect on the target variables. In other words, we want to establish how correlated a change in direction in a feature is with the target class. Visualizing an entire correlation matrix on a dataset of 30+ columns isn't the best idea because it would require a figure too large to fit comfortably on a single page. Instead, we can calculate the correlation of the feature with the target variable.<p>下面是如何为<code>mean area</code>特性实现这一点——通过从NumPy调用<code>corrcoeff()</code>方法:</p><pre>np.corrcoef(df['mean area'], df['target'])[1][0]</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_5.jpg" alt="Figure 7.5 – Correlation coefficient between a single feature and the target variable&#13;&#10;" width="302" height="30"/></div><pre>corr_with_target = []
for col in df.columns[:-1]:
    corr = np.corrcoef(df[col], df['target'])[1][0]
    corr_with_target.append({'Column': col, 'Correlation': corr})
    
corr_df = pd.DataFrame(corr_with_target)
corr_df = \
corr_df.sort_values(by='Correlation', ascending=False)</pre><p>请注意循环开始处的<code>[:-1]</code>。由于目标变量是最后一列，我们可以使用前面提到的切片技术从相关性计算中排除目标变量。目标<a id="_idIndexMarker427"/>变量和非目标变量之间的相关系数将是1，这对我们来说不是特别有用。</p><p>现在，您可以使用以下代码制作一个与目标变量相关的水平条形图:</p><pre>plt.figure(figsize=(10, 14))
plt.barh(corr_df['Column'], corr_df['Correlation'], color='#4f4f4f')
plt.title('Feature correlation with the target variable', fontsize=20)
plt.xlabel('Feature', fontsize=14)
plt.ylabel('Correlation', fontsize=14)
plt.show()</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_6.jpg" alt="Figure 7.6 – Feature correlation with the target variable&#13;&#10;" width="934" height="1072"/></div><p class="figure-caption">图7.6–特征与目标变量的相关性</p><p>正如您所看到的，大多数特征与目标变量有很高的负相关性。负相关意味着一个变量随着另一个变量的减少而增加。在我们的例子中，特征数量的减少导致目标变量的增加。</p></li>
				<li>You could also <a id="_idIndexMarker428"/>visualize the distribution of every numeric column with respect to the target variable value. To be more precise, this means two separate histograms are drawn on a single chart, and each histogram shows the distribution only for the respective target value's subset. <p>例如，这意味着对于每个变量，一个直方图将显示恶性实例的分布，另一个直方图将显示良性实例的分布。</p><p>您将看到的代码片段声明了一个<code>draw_histogram()</code>函数，该函数遍历数据集中的每一列，针对目标变量中的不同类制作一个直方图，并将该直方图附加到一个图形中。</p><p>一旦附加了所有直方图，就向用户显示该图。用户还必须指定他们想要多少行和多少列，这在设计可视化时提供了一点额外的自由。</p><p>下面是绘制直方图网格的代码片段:</p><pre>def draw_histogram(data, columns, n_rows, n_cols):
    fig = plt.figure(figsize=(12, 18))
    for i, var_name in enumerate(columns):
        ax = fig.add_subplot(n_rows, n_cols, i + 1)
        sns.histplot(data=data, x=var_name, hue='target')
        ax.set_title(f'Distribution of {var_name}')
    fig.tight_layout()
    plt.show()
draw_histogram(df, df.columns[:-1], 9, 4)</pre><p>这将是一个非常大的数据可视化，包含9行和4列。最后一行只有2个直方图，因为总共有30个连续变量。</p><p>结果如下图所示:</p></li>
			</ol>
			<div><div><img src="img/B16954_07_7.jpg" alt="Figure 7.7 – Histogram for every continuous variable&#13;&#10;" width="980" height="1300"/>
				</div>
			</div>
			<p class="figure-caption">图7.7-每个连续变量的直方图</p>
			<p>正如你所看到的，大部分时间都有一个<a id="_idIndexMarker430"/>明显的分离，所以我们的模型在类之间进行适当的分离应该不会有太大的困难。</p>
			<p>这就是我们对探索性数据分析的全部内容。我们鼓励您做更多的工作，尤其是在定制和更复杂的数据集上。下一节将向您介绍用于训练自动神经网络分类器的选项。</p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor089"/>探索训练神经网络分类器的选项</h1>
			<p>用TPOT训练神经网络模型时，你有很多<a id="_idIndexMarker431"/>选择。对于TPOT来说，整个神经网络故事仍然是新的和实验性的，需要比常规的scikit-learn估计器多一点的人工工作。</p>
			<p>默认情况下，TPOT不会使用神经网络模型，除非你明确指定它必须使用。这种规范是通过选择一个适当的配置字典来完成的，该字典包括一个或多个神经网络估计器(您也可以手动编写)。</p>
			<p>更方便的选择是从<code>tpot/config/classifier_nn.py</code>文件中导入配置字典。该文件包含两个PyTorch分类器配置，如下图所示:</p>
			<div><div><img src="img/B16954_07_8.jpg" alt="Figure 7.8 – TPOT PyTorch classifier configurations&#13;&#10;" width="716" height="517"/>
				</div>
			</div>
			<p class="figure-caption">图7.8-TPOT py torch分级机配置</p>
			<p>从上图中，你<a id="_idIndexMarker432"/>可以看到TPOT目前可以处理两种不同类型的基于深度学习库的分类器:</p>
			<ul>
				<li>逻辑回归:如<code>tpot.builtins.PytorchLRClassifier</code>所示</li>
				<li>多层感知器:如图<code>tpot.builtins.PytorchMLPClassifier</code></li>
			</ul>
			<p>您可以导入此文件或手动编写配置。此外，您还可以指定自己的配置字典，它会以某种方式修改现有的字典。例如，您可以使用此代码来使用基于PyTorch的逻辑回归估计器:</p>
			<pre>tpot_config = {
    'tpot.nn.PytorchLRClassifier': {
        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.]
    }
}</pre>
			<p>当我们开始实现神经网络分类器时，自定义配置将在本章后面讨论。</p>
			<p>您应该记住，用TPOT训练神经网络分类器是一项昂贵的任务，通常比scikit-learn估计器花费更多的时间来训练。根据经验，使用<a id="_idIndexMarker433"/>神经网络，训练时间会慢几个数量级。这是因为神经网络架构可能有数百万个可训练和可调整的参数，而为所有这些参数找到正确的值需要时间。</p>
			<p>记住这一点，你应该总是首先考虑更简单的选项，因为TPOT极有可能在默认的scikit-learn估计器上给你一个优秀的执行管道。</p>
			<p>下一节将从上一节停止的地方继续训练神经网络分类器，并向您展示如何使用不同的训练配置来训练您的模型。</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor090"/>训练一个神经网络分类器</h1>
			<p>到目前为止，我们已经加载了数据集，并进行了基本的探索性数据分析。<a id="_idIndexMarker434"/>一章的这一节将重点介绍通过不同配置的培训模型:</p>
			<ol>
				<li value="1">Before we can move on to model training, we need to split our dataset into training and testing subsets. Doing so will allow us to have a sample of the data never seen by the model, and which can later be used for evaluation.<p>以下代码片段将以75:25的比例分割数据:</p><pre>from sklearn.model_selection import train_test_split
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test =train_test_split(\
X, y, test_size=0.25, random_state=42)</pre><p>接下来我们可以开始训练了。</p></li>
				<li>As always, let's start simply by training a baseline model. This will serve as a minimum viable performance that the neural network classifier has to outperform.<p>最简单的二进制分类算法是逻辑回归。下面的代码片段<a id="_idIndexMarker435"/>从scikit-learn导入它，还有一些评估指标，比如混淆矩阵和准确度分数。此外，该代码片段实例化该模型，对其进行定型，对维持集进行预测，并打印混淆矩阵和准确性分数。</p><p>代码片段如下:</p><pre>from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)
lr_preds = lr_model.predict(X_test)
print(confusion_matrix(y_test, lr_preds))
print()
print(accuracy_score(y_test, lr_preds))</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_9.jpg" alt="Figure 7.9 – Confusion matrix and accuracy of the baseline model&#13;&#10;" width="301" height="139"/></div><p class="figure-caption">图7.9–混淆矩阵和基线模型的准确性</p><p>我们现在知道基线模型是96.5%准确，产生4个假阳性和1个假阴性。接下来，我们将使用TPOT训练一个自动神经网络分类器，看看结果如何比较。</p></li>
				<li>As mentioned before, training a <a id="_idIndexMarker436"/>neural network classifier with TPOT is a heavy task. For that reason, you might be better off switching to a free GPU Cloud environment, such as <em class="italic">Google Colab</em>. <p>这将确保更快的培训时间，而且你不会融化你的电脑。在那里，您可以使用下面的代码片段来训练基于PyTorch的逻辑回归模型:</p><pre>from tpot import TPOTClassifier
classifier_lr = TPOTClassifier(
    config_dict='TPOT NN',
    template='PytorchLRClassifier',
    generations=2,
    random_state=42,
    verbosity=3
)
classifier_lr.fit(X_train, y_train)</pre><p>这将训练两代人的模型。在培训过程中，您会看到各种输出，如下所示:</p><div><img src="img/B16954_07_10.jpg" alt="Figure 7.10 – TPOT neural network training process&#13;&#10;" width="1045" height="88"/></div><pre>classifier_lr.fitted_pipeline_</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_12.jpg" alt="Figure 7.12 – TPOT PyTorch logistic regression best pipeline&#13;&#10;" width="1185" height="210"/></div><pre>from sklearn.metrics import confusion_matrix,\
 accuracy_score
tpot_lr_preds = classifier_lr.predict(X_test)
print(confusion_matrix(y_test, tpot_lr_preds))
print()
print(accuracy_score(y_test, tpot_lr_preds))</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_13.jpg" alt="Figure 7.13 – Confusion matrix and accuracy score of a PyTorch logistic regression model&#13;&#10;" width="314" height="135"/></div><p class="figure-caption">图7.13-py torch逻辑回归模型的混淆矩阵和准确度得分</p><p>如你所见，两代人不足以产生比基线更好的模型。让我们看看使用多层感知器模型是否有帮助。</p></li>
				<li>We're still in the Google Colab environment, as training on your own PC is significantly <a id="_idIndexMarker439"/>slower (depending on your configuration). The idea now is to use the multi-layer perceptron model instead of logistic regression and see how the change in the model could affect performance.<p>首先，您必须更改<code>TPOTClassifier</code>的<code>template</code>参数，如下所示:</p><pre>classifier_mlp = TPOTClassifier(
    config_dict='TPOT NN',
    template='PytorchMLPClassifier',
    generations=2,
    random_state=42,
    verbosity=3
)</pre><p>如你所见，我们现在使用的是<code>PytorchMLPClassifier</code>而不是<code>PytorchLRClassifier</code>。要开始优化过程，只需用训练数据调用<code>fit()</code>方法:</p><pre>classifier_mlp.fit(X_train, y_train)</pre><p>与逻辑回归算法一样，在优化过程中您也会看到进度条:</p><div><img src="img/B16954_07_14.jpg" alt="Figure 7.14 – TPOT multi-layer perceptron training process&#13;&#10;" width="1072" height="90"/></div><pre>classifier_mlp.fitted_pipeline_</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_16.jpg" alt="Figure 7.16 – TPOT PyTorch multi-layer perceptron best pipeline&#13;&#10;" width="1231" height="204"/></div><pre>from sklearn.metrics import confusion_matrix,\
 accuracy_score
tpot_mlp_preds = classifier_mlp.predict(X_test)
print(confusion_matrix(y_test, tpot_mlp_preds))
print()
print(accuracy_score(y_test, tpot_mlp_preds))</pre><p>结果如下图所示:</p><div><img src="img/B16954_07_17.jpg" alt="Figure 7.17 – Confusion matrix and accuracy score of a PyTorch multi-layer perceptron model&#13;&#10;" width="317" height="144"/></div><p class="figure-caption">图7.17-py torch多层感知器模型的混淆矩阵和准确度分数</p><p>正如你所看到的，两代人仍然不足以产生一个好于基线的模型，但MLP模型优于逻辑回归模型。现在，让我们看看使用定制的训练配置是否可以将精确度推得更高。</p></li>
				<li>Finally, let's see <a id="_idIndexMarker442"/>how you can specify possible hyperparameter values for either logistic regression or multi-layer perceptron models. All you have to do is specify a custom configuration dictionary, which holds the hyperparameters you want to test for (such as learning rate, batch size, and number of epochs), and assign values to those hyperparameters in the form of a list.<p>这里有一个例子:</p><pre>custom_config = {
    'tpot.builtins.PytorchMLPClassifier': {
        'learning_rate': [1e-1, 0.5, 1.],
        'batch_size': [16, 32],
        'num_epochs': [10, 15],
    }
}</pre><p>你现在可以在训练模型时使用这个<code>custom_config</code>字典。以下是基于多层感知器模型的示例训练片段:</p><pre>classifier_custom = TPOTClassifier(
    config_dict=custom_config,
    template='PytorchMLPClassifier',
    generations=2,
    random_state=42,
    verbosity=3
)
classifier_custom.fit(X_train, y_train)</pre><p>正如您<a id="_idIndexMarker443"/>所见，只有<code>config_dict</code>参数发生了变化。培训过程开始后，您会在笔记本中看到一个与此类似的进度条:</p></li>
			</ol>
			<div><div><img src="img/B16954_07_18.jpg" alt="Figure 7.18 – TPOT custom tuning with neural networks&#13;&#10;" width="522" height="52"/>
				</div>
			</div>
			<p class="figure-caption">图7.18–使用神经网络的TPOT定制调整</p>
			<p>培训过程完成后，您应该会在笔记本中看到以下内容:</p>
			<div><div><img src="img/B16954_07_19.jpg" alt="Figure 7.19 – TPOT multi-layer perceptron classifier with custom hyperparameters&#13;&#10;" width="1650" height="1149"/>
				</div>
			</div>
			<p class="figure-caption">图7.19–带有自定义超参数的TPOT多层感知器分类器</p>
			<p>这就是全部的内容！为了验证这一点，您可以通过执行以下命令来检查最适合的管道:</p>
			<pre>classifier_custom.fitted_pipeline_</pre>
			<p>结果如下图所示:</p>
			<div><div><img src="img/B16954_07_20.jpg" alt="Figure 7.20 – TPOT best-fitted pipeline for a model with custom hyperparameters&#13;&#10;" width="603" height="108"/>
				</div>
			</div>
			<p class="figure-caption">图7.20–带有自定义超参数的模型的TPOT最佳拟合管道</p>
			<p>正如您所看到的，所有的超参数值都在指定的范围内，这表明定制模型训练成功。</p>
			<p>这就结束了本节的模型培训部分和本节的总体内容。接下来的是对我们到目前为止所学的所有内容的简要总结，以及对接下来章节的所有内容的简要介绍。</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor091"/>总结</h1>
			<p>这一章在实际操作的例子和演示方面相当深入。希望你已经学会了如何用TPOT训练自动分类管道，以及在这个过程中你可以调整什么。</p>
			<p>你现在应该能够用TPOT训练任何类型的自动机器学习模型，无论我们谈论的是回归、分类、标准分类器还是神经网络分类器。有好消息，因为这是最后一章TPOT的例子。</p>
			<p>在接下来的章节中，<a href="B16954_08_Final_SK_ePub.xhtml#_idTextAnchor093"> <em class="italic">第8章</em> </a>，<em class="italic"> TPOT模型部署</em>，您将学习如何将您的模型的预测功能包装在一个REST API中，然后在本地和云环境中测试和部署。您还将学习如何在部署后与API进行通信。</p>
			<p>最后，在前面的章节中，<a href="B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102"> <em class="italic">第9章</em> </a>，<em class="italic">在生产中使用部署的TPOT模型</em>，您将学习如何使用部署的API开发一些有用的东西。更准确地说，您将学习如何通过对部署的API进行REST调用来在笔记本环境中进行预测，并且您将学习如何开发一个简单的GUI应用程序，使您的模型可以呈现给最终用户。</p>
			<p>和往常一样，你可以更深入地研究TPOT，但是现在，你已经远远领先于大多数人，你已经准备好让机器学习变得有用了。那里见！</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor092"/>问题</h1>
			<ol>
				<li value="1">关于神经网络，TPOT有哪两种算法？</li>
				<li>神经网络分类器的训练速度大约比默认的scikit-learn慢多少倍？</li>
				<li>列出并简要解释使用TPOT和神经网络训练模型时可用的不同超参数。</li>
				<li>使用TPOT训练自定义神经网络模型时，可以指定自定义的超参数值范围吗？如果有，如何实现？</li>
				<li>在模型完成训练后，如何找到最合适的管道？</li>
				<li>使用TPOT训练神经网络模型时，使用Google Colab等GPU运行时有什么优势？</li>
				<li>描述为什么多层感知器模型中的单个神经元可以被认为是逻辑回归。</li>
			</ol>
		</div>
	</div>
</body></html>