<html><head/><body>


	
		<title>B16783_03_Final_SB_epub</title>
		
	
	
		<div><h1 id="_idParaDest-56"><a id="_idTextAnchor066"/> <em class="italic">第三章</em>:你的数据科学工作台</h1>
			<p>在本章中，您将在创建本地环境的背景下学习MLflow，以便您可以使用MLflow提供的不同功能在本地开发您的机器学习项目。这一章的重点是机器学习工程，机器学习工程师最重要的角色之一是建立一个环境，让模型开发者和实践者能够高效工作。我们还将演示一个实际操作的例子，说明我们如何使用工作台来完成特定的任务。</p>
			<p>具体来说，我们将在本章中探讨以下主题:</p>
			<ul>
				<li>了解数据科学工作台的价值</li>
				<li>创建您自己的数据科学工作台</li>
				<li>使用工作台进行库存预测</li>
			</ul>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor067"/>技术要求</h1>
			<p>对于本章，您将需要以下先决条件:</p>
			<ul>
				<li>The latest version of Docker installed on your machine. If you don’t already have it installed, please follow the instructions at <a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a>.<p>安装了最新版本的Docker Compose。如果你还没有安装，请按照https://docs.docker.com/compose/install/.的说明进行操作</p></li>
				<li>在命令行访问Git，按照本<strong class="bold">统一资源定位符</strong>(<strong class="bold">URL</strong>):<a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">https://Git-SCM . com/book/en/v2/Getting-Started-Installing-Git</a>中的描述进行安装。</li>
				<li>访问<code>bash</code>终端(Linux或Windows)。</li>
				<li>访问浏览器。</li>
				<li>Python 3.5以上版本已安装。</li>
				<li>MLflow安装在本地，如第1章<em class="italic">介绍MLflow </em>中所述。</li>
			</ul>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor068"/> <a id="_idTextAnchor069"/>了解数据科学工作台的价值</h1>
			<p>数据科学工作台是一个标准化组织的机器学习工具和实践的环境，允许快速加入和开发模型和分析。一个关键的机器学习工程功能是用工具支持数据科学从业者，这些工具增强并加速他们的日常活动。</p>
			<p>在数据科学团队中，快速测试多种方法和技术的能力至关重要。每天都有新的库和开源工具产生。为了测试一个新类型的模型，一个项目通常需要十几个库。这些大量的库，如果没有正确整理，可能会导致模型中的错误或不兼容。</p>
			<p>数据是数据科学工作流程的<a id="_idIndexMarker105"/>中心。拥有可用于开发和评估模型的干净数据集至关重要。有了大量的大型数据集，就需要专门的大数据工具来处理这些数据。数据可以以多种格式和速度出现，用于分析或实验，并且可以以多种格式和<a id="_idIndexMarker106"/>介质获得。可以通过文件、云端，或者<strong class="bold">具象状态转移</strong> ( <strong class="bold"> REST </strong> ) <strong class="bold">应用编程接口</strong>(<strong class="bold">API</strong>)获得。</p>
			<p>数据科学在很大程度上是一门合作的手艺；在团队成员之间共享模型和过程是工作流的一部分。不可避免地，活动中出现的一个痛点是从业者之间模型开发工作的交叉再现性。数据科学家A共享了一个模型的训练脚本，该模型假设库的版本为2.6，但是数据科学家B使用的是2.8版本的环境。在某些情况下，跟踪和修复问题可能需要几个小时。如果这个问题发生在生产环境中，它会给公司带来极大的损失。</p>
			<p>例如，当迭代一个模型时，每次运行都包含多个参数，可以调整这些参数来改进它。如果我们不以结构化的方式存储实验的细节，那么维护哪个参数产生了特定的性能指标(例如准确性)的可追溯性可能会有问题。如果我们只在模型开发阶段保留最新的设置，那么回到产生更好模型的特定一批设置可能是不可能的。</p>
			<p>当将原型代码翻译到生产环境时，快速迭代的需求可能会导致许多挫折，在生产环境中，它可以以可靠的方式执行。例如，如果您正在Windows机器上开发一个新的交易模型，可以轻松访问<strong class="bold">图形处理单元</strong>(<strong class="bold">GPU</strong>)进行推理，那么您的<a id="_idIndexMarker108"/>工程团队成员可能会决定重用现有的Linux基础设施，而不访问GPU。这会导致这样一种情况，即您的生产算法最终需要5个小时，而本地运行只需要30秒，这会影响项目的最终结果。</p>
			<p>很明显，如果与环境和工具相关的问题没有提前解决，数据科学部门将面临系统性技术难题的风险。总而言之，我们可以列出本节所述的以下要点:</p>
			<ul>
				<li>再现性摩擦</li>
				<li>处理大量不同数据集的复杂性</li>
				<li>实验设置管理不善</li>
				<li>在本地和生产环境之间漂移</li>
			</ul>
			<p>数据科学工作台通过创建一个结构化的环境来解决本节中描述的痛点，在这个环境中，机器学习从业者可以可靠地开发和部署他们的模型，减少摩擦。一个无摩擦的环境将允许高成本的模型开发时间集中于开发和迭代模型，而不是解决工具和数据技术问题。</p>
			<p>在深入研究了为机器学习团队构建数据科学工作台的动机之后，我们接下来将根据已知的难点开始设计数据科学工作台。</p>
			<h1 id="_idParaDest-59">创建您自己的数据科学工作b <a id="_idTextAnchor070"/> <a id="_idTextAnchor071"/> ench</h1>
			<p>为了解决<a id="_idIndexMarker109"/>在数据科学中开发模型的常见摩擦，如前一节所述，我们需要为数据科学家和从业者提供一个标准化的环境，在其中他们可以开发和管理他们的工作。数据科学工作台应该允许您快速启动项目，并且具有一组启动工具和框架的环境的可用性允许数据科学家快速启动项目。</p>
			<p>数据科学家和机器学习实践者处于工作台的中心:他们应该有一个可靠的平台，允许他们开发并为组织增加价值，他们的模型触手可及。</p>
			<p>下图描述了数据科学工作台的核心功能:</p>
			<div><div><img src="img/B16783_03_001.jpg" alt="Figure 3.1 – Core features of a data science workbench &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.1—数据科学工作台的核心功能</p>
			<p>为了思考我们的数据科学工作台的<a id="_idIndexMarker110"/>设计，基于<em class="italic">图3.1 </em>中的图表，我们需要我们的数据科学工作台具有以下核心特性:</p>
			<ul>
				<li><strong class="bold">依赖性管理</strong>:将依赖性管理构建到您的本地环境中有助于处理可再现性问题，并防止不同环境之间的库冲突。这通常是通过使用Docker之类的环境管理器或者在编程语言中提供环境管理框架来实现的。MLflow通过支持基于Docker或Conda的环境来实现这一点。</li>
				<li><strong class="bold">数据管理</strong>:如果您必须处理庞大的数据集，在本地环境中管理数据可能会非常复杂和令人畏惧。对如何在本地项目中处理数据有一个标准化的定义，可以让其他人在您的项目中自由协作，并理解可用的结构。</li>
				<li><strong class="bold">模型管理</strong>:组织并正确存储<a id="_idIndexMarker111"/>不同的模型提供了一个简单的结构，能够同时处理许多想法，并保留那些有潜力的想法。MLflow通过模型格式抽象和管理模型的<strong class="bold">模型注册</strong>组件帮助支持这一点。</li>
				<li><strong class="bold">部署</strong>:拥有一个与生产环境相一致的开发环境，模型将在那里被服务，这需要在本地环境中仔细考虑。生产环境需要准备好从模型开发人员那里接收模型，尽可能减少摩擦。只有正确设计本地环境，这种平稳的部署工作流才有可能实现。</li>
				<li><strong class="bold">Experimentation Management</strong>: Tweaking parameters is the most common thing that a machine learning practitioner does. Being able to keep abreast of the different versions and specific parameters can quickly become cumbersome for the model developer.<p class="callout-heading">重要说明</p><p class="callout">在本节中，我们将使用MLflow从零开始实现数据科学工作台的基础，主要支持本地开发。云提供商提供了几个非常固执己见且功能丰富的选项，如<strong class="bold">亚马逊网络服务</strong> ( <strong class="bold"> AWS </strong>)、Sagemaker、Google AI和<strong class="bold"> Azure机器学习</strong> ( <strong class="bold"> Azure ML </strong>)。</p></li>
			</ul>
			<p>机器学习工程团队在他们服务的团队将使用的用例和技术方面有自由。</p>
			<p>以下步骤展示了使用数据科学工作台进行开发的良好工作流程<a id="_idIndexMarker114"/>:</p>
			<ul>
				<li>模型开发人员通过安装程序或者通过克隆存储库来安装company workbench包。</li>
				<li>模型开发人员运行一个命令来启动一个项目。</li>
				<li>模型开发人员根据配置或提示选择一组选项。</li>
				<li>The basic scaffolding is produced with specific folders for the following items:<p>a) <code>Data</code>:这将包含您当前项目的所有数据资产</p><p>b) <code>Notebooks</code>:保存所有的迭代开发笔记本，包括产生模型所需的所有步骤</p><p>c) <code>Model</code>:包含二进制模型或者模型引用的文件夹，可能是二进制格式</p><p>d) <code>Source Code</code>:存储代码的结构化代码组件和可重用库的文件夹</p><p>e) <code>Output</code>:一个文件夹，用于存放项目的任何特定输出，例如，可视化、报告或预测</p></li>
				<li>创建一个项目文件夹，其中包含包、依赖项管理和工具的组织标准。</li>
				<li>模型开发人员可以在组织级别使用支持的工具自由地迭代和创建模型。</li>
			</ul>
			<p>由于机器学习最佳实践的标准化和高效采用，建立数据科学工作台为组织中机器学习的加速和民主化提供了工具。</p>
			<p>在本章中，我们将从行业范围内使用的合理组件开始我们的工作台实现。</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor072"/>构建我们的工作台</h2>
			<p>我们将在开发环境的架构中拥有<a id="_idIndexMarker115"/>以下组件:</p>
			<ul>
				<li><strong class="bold">Docker/Docker Compose</strong>:Docker<a id="_idIndexMarker116"/>将用于处理架构的每一个主要组件依赖关系，Docker Compose将用作不同软件块容器之间的<a id="_idIndexMarker117"/>协调器。将工作台架构的每个组件都放在Docker中的好处是，两个元素的库不会互相冲突。</li>
				<li><strong class="bold"> JupyterLab </strong>:在机器学习的背景下开发数据科学代码和分析的<a id="_idIndexMarker118"/>实际环境。</li>
				<li><strong class="bold"> MLflow </strong> : MLflow是<a id="_idIndexMarker119"/>工作台的基石，为实验跟踪、模型管理、注册和部署接口提供设施。</li>
				<li><strong class="bold"> PostgreSQL数据库</strong>:<a id="_idIndexMarker120"/>PostgreSQL数据库是这个阶段架构的一部分，作为后端元数据的MLflow的存储层。其他关系数据库可以用作元数据的MLflow后端，但是我们将使用PostgreSQL。</li>
			</ul>
			<p>我们的数据科学工作台<a id="_idIndexMarker121"/>设计如下图所示:</p>
			<div><div><img src="img/image0021.jpg" alt="Figure 3.2 – Our data science workbench design &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.2–我们的数据科学工作台设计</p>
			<p><em class="italic">图3.2 </em>展示了支持我们的数据科学工作台的建议组件的布局。</p>
			<p>一旦环境启动并运行，从业者通常的工作流程是在Jupyter中开发他们的代码，并在MLflow的支持下运行他们的实验。该环境将自动路由到配置到正确后端的正确MLflow安装，如图<em class="italic">图3.2 </em>所示。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">正如本章所定义的，我们的数据科学工作台是一个完整的本地环境。随着本书的进展，我们将介绍基于云的环境，并将我们的工作台链接到共享资源。</p>
			<p>下面的GitHub文件夹中提供了一个项目布局示例:</p>
			<p>https://github . com/packt publishing/Machine-Learning-Engineering-with-ml flow/tree/master/chapter 03/grad flow</p>
			<p>您可以在这里看到以文件表示的工作台的一般布局:</p>
			<pre>├── Makefile
├── README.md
├── data
├── docker
├── docker-compose.yml
├── docs
├── notebooks
├── requirements.txt
├── setup.py
├── src
├── tests
└── tox.ini</pre>
			<p>此文件夹结构的主要<a id="_idIndexMarker123"/>元素如下:</p>
			<ul>
				<li>这允许控制你的工作台。通过发出命令，您可以要求您的工作台设置一个新的环境笔记本，以不同的格式启动MLflow。</li>
				<li><code>README.md</code>:一个文件，包含了你的项目以及如何运行它的示例描述。</li>
				<li><code>data</code>文件夹:一个文件夹，我们在其中存储开发过程中使用的数据集，并在本地运行时挂载数据库的数据目录。</li>
				<li><code>docker</code>:一个文件夹，包含我们的环境所包含的不同子系统的Docker映像。</li>
				<li><code>docker-compose.yml</code>:一个文件，包含我们的工作台环境中不同服务的编排——即:Jupyter Notebooks、MLflow和PostgreSQL to back MLflow。</li>
				<li><code>docs</code>:包含我们想要为项目持久化的相关项目文档。</li>
				<li><code>notebooks</code>:包含笔记本信息的文件夹。</li>
				<li><code>requirements.txt</code>:向项目添加库的需求文件。</li>
				<li><code>src</code>:包含项目源代码的文件夹，将在项目的后续阶段进行更新。</li>
				<li><code>tests</code>:包含项目代码端到端测试的文件夹。</li>
				<li><code>tox.ini</code>:控制单元测试执行的模板文件。</li>
			</ul>
			<p>基于我们刚刚构建的框架，我们现在将继续使用我们自己的开发环境来解决股票预测问题。</p>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor073"/>使用工作台进行库存预测</h1>
			<p>在本节中，我们将逐步使用<a id="_idIndexMarker124"/>工作台来建立一个新项目。按照说明一步一步地启动您的环境，并将工作台用于股票预测项目。</p>
			<p class="callout-heading">重要说明</p>
			<p class="callout">将<em class="italic">技术要求</em>一节中列出的所有包/库正确安装在您的本地机器上，以使您能够遵循，这一点非常重要。</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor074"/>启动您的环境</h2>
			<p>接下来，我们将继续<a id="_idIndexMarker125"/>探索您自己的开发环境，基于本节中显示的开发环境。请执行以下步骤:</p>
			<ol>
				<li>复制https://github . com/packt publishing/Machine-Learning-Engineering-with-ml flow/tree/master/chapter 03/grad flow中的项目内容。</li>
				<li>通过运行以下命令启动您的本地环境:<pre>make</pre></li>
				<li>Inspect the created environments, like this: <pre>$ docker ps </pre><p>下面的屏幕截图展示了三个Docker图像:第一个用于Jupyter，第二个用于MLflow，第三个用于PostgreSQL数据库。状态应显示<code>Up x minutes</code>:</p></li>
			</ol>
			<div><div><img src="img/image0031.jpg" alt="Figure 3.3 – Running Docker images &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.3–运行Docker图像</p>
			<p>您的工作台使用的<a id="_idIndexMarker126"/>常用端口如下:Jupyter服务于端口<code>8888</code>，MLflow服务于端口<code>5000</code>，PostgreSQL服务于端口<code>5432</code>。</p>
			<p>如果有任何容器失败，您可能需要检查端口是否被不同的服务使用。如果是这种情况，您需要关闭所有其他服务。</p>
			<p>检查您在<a href="http://localhost:8888"> http://localhost:8888 </a>的Jupyter笔记本环境，如下图所示:</p>
			<div><div><img src="img/image0041.jpg" alt="Figure 3.4 – Running Jupyter environment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.4–运行Jupyter环境</p>
			<p>您的<a id="_idIndexMarker127"/>应该有一个可用的环境，允许您在指定的文件夹中创建新的<code>notebooks</code>文件。</p>
			<p>检查位于http://localhost:5000的MLflow环境，如下图所示:</p>
			<div><div><img src="img/image0051.jpg" alt="Figure 3.5 – Running MLflow environment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.5–运行MLflow环境</p>
			<p><em class="italic">图3.5 </em>显示了<a id="_idIndexMarker128"/>您在MLflow中的实验跟踪器环境，您将使用它来可视化您在MLflow中运行的实验。</p>
			<p>通过运行<code>/notebooks/mlflow_sample.ipynb</code>中可用的<code>notebook</code>文件，在MLflow中运行一个示例实验，如下图所示:</p>
			<div><div><img src="img/image0061.jpg" alt="Figure 3.6 – Excerpt of mlflow_sample code&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.6–ml flow _ sample代码摘录</p>
			<p><em class="italic">图3.6 </em>中的代码导入MLflow并在第二行使用<code>mlflow.set_experiment(‘mlflow_experiment’)</code>手动创建一个虚拟实验。</p>
			<p><code>with mlflow.start_run()</code>线负责启动和拆除MLflow中的实验。</p>
			<p>在接下来的三行中，我们使用<code>mlflow.log_param</code>函数记录了几个字符串类型的测试参数。为了记录数值，我们将使用<code>mlflow.log_metric</code>功能。</p>
			<p>最后，我们<a id="_idIndexMarker129"/>还使用<code>mlflow.log_artifact(“mlflow_example.ipynb”)</code>函数记录执行该函数的整个文件，以确保模型和产生它的代码的可追溯性。</p>
			<p>检查示例运行，以确认环境工作正常。您应该返回到位于http://localhost:5000的MLflow <strong class="bold">用户界面</strong> ( <strong class="bold"> UI </strong>)并检查新实验是否已创建，如下面的屏幕截图所示:</p>
			<div><div><img src="img/image0071.jpg" alt="Figure 3.7 – MLflow test experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.7–毫升流量测试实验</p>
			<p><em class="italic">图3.7 </em>显示了我们在具体实验中使用的附加参数，以及在<strong class="bold">指标</strong>列中可见的名为<code>i</code>的具体指标。</p>
			<p>接下来，您应该点击创建的实验，以访问到目前为止我们已经执行的运行的细节。下面的截图说明了这一点:</p>
			<div><div><img src="img/image0081.jpg" alt="Figure 3.8 – MLflow experiment details&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.8–ml flow实验细节</p>
			<p>除了指标的细节，您还可以访问特定时间点的<code>mlflow_example</code>笔记本文件。</p>
			<p>在这个阶段，您的环境按照预期运行和工作。接下来，我们会用自己的算法更新它；我们会用我们在<a href="B16783_02_Final_SB_epub.xhtml#_idTextAnchor030"> <em class="italic">第二章</em></a><em class="italic">你的机器学习项目</em>中创建的那个。</p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor075"/>用你自己的算法更新</h2>
			<p>我们来更新一下我们在<a href="B16783_02_Final_SB_epub.xhtml#_idTextAnchor030"> <em class="italic">第二章</em> </a>、<em class="italic"> ML问题取景</em>中创建的<a id="_idIndexMarker131"/>笔记本文件，并将其添加到您本地工作台上的笔记本文件夹中。以下是代码摘录:</p>
			<pre>import mlflow
class RandomPredictor(mlflow.pyfunc.PythonModel):
  def __init__(self):
    pass
  def predict(self, context, model_input):
    return model_input.apply(lambda column: random.randint(0,1))</pre>
			<p>在<code>notebooks/stockpred_randomizer.ipynb</code>文件的<code>notebook</code>文件夹下，您可以在我们最近创建的data science workbench中集成前面的代码摘录。我们将如下进行:</p>
			<ol>
				<li value="1">We will first import all the dependencies needed and run the first cell of the notebook, as follows:<div><img src="img/image0091.jpg" alt="Figure 3.9 – MLflow experiment details&#13;&#10;"/></div><p class="figure-caption">图3.9–ml flow实验细节</p></li>
				<li>Let’s declare and execute the class outlined in <em class="italic">Figure 3.9</em>, represented in the second cell of the notebook, as follows: <div><img src="img/image010.jpg" alt="Figure 3.10 – Notebook cell with the RandomPredictor class declaration&#13;&#10;"/></div><p class="figure-caption">图3.10–带有RandomPredictor类声明的笔记本单元格</p></li>
				<li>We can <a id="_idIndexMarker132"/>now save our model in the MLflow infrastructure so that we can test the loading of the model. <code>model_path</code> holds the folder name where the model will be saved. You need to instantiate the model in an <code>r</code> variable and use <code>mlflow.pyfunc.save_model</code> to save the model locally, as illustrated in the following code snippet:<div><img src="img/image011.jpg" alt="Figure 3.11 – Notebook demonstrating saving the model&#13;&#10;"/></div><p class="figure-caption">图3.11–演示保存模型的笔记本</p><p>您可以在笔记本环境的左窗格中看到，在您的文件旁边创建了一个新文件夹来存储您的模型。该文件夹将存储Conda环境和模型的酸洗/二进制化Python函数，如下图所示:</p><div><img src="img/image012.jpg" alt="Figure 3.12 – Notebook demonstrating the saved model folder&#13;&#10;"/></div><p class="figure-caption">图3.12–演示保存的模型文件夹的笔记本</p></li>
				<li>接下来，我们<a id="_idIndexMarker133"/>可以加载并使用模型来检查保存的模型是否可用，如下所示:</li>
			</ol>
			<div><div><img src="img/image013.jpg" alt="Figure 3.13 – Notebook demonstrating the saved model folder&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.13–演示保存的模型文件夹的笔记本</p>
			<p><em class="italic">图3.14 </em>展示了随机输入<code>loaded_model</code>的创建，以预测输入向量。我们将运行名为<code>stockpred_experiment_days_up</code>的实验，将每个模型的市场上涨天数记录为一个指标，如下所示:</p>
			<div><div><img src="img/image014.jpg" alt="Figure 3.14 – Notebook cell demonstrating use of the loaded model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.14–演示加载模型使用的笔记本单元</p>
			<p>要检查实验的最后一次运行，您可以查看http://localhost:5000并检查新实验是否已创建，如下面的屏幕截图所示:</p>
			<div><div><img src="img/image015.jpg" alt="Figure 3.15 – Initial UI of MLflow for our stockpred experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.15–我们库存实验的MLflow初始用户界面</p>
			<p>现在，您可以比较我们算法的多次运行，并查看<strong class="bold">天数</strong>指标的差异，如下图所示。您可以相应地选择深入研究<a id="_idIndexMarker135"/>您想了解更多细节的跑步:</p>
			<div><div><img src="img/image016.jpg" alt="Figure 3.16 – Logged details of the artifacts saved&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图3.16–保存的工件的记录细节</p>
			<p>在<em class="italic">图3.16 </em>中，您可以清楚地看到我们运行的日志细节——即工件模型和<strong class="bold">天数</strong>指标。</p>
			<p>为了正确地拆除环境，您必须在同一个文件夹中运行以下命令:</p>
			<pre>make down</pre>
			<h1 id="_idParaDest-64"><a id="_idTextAnchor077"/>总结</h1>
			<p>在这一章中，我们介绍了数据科学工作台的概念，并探讨了采用这一工具作为加速我们机器学习工程实践的方法背后的一些动机。</p>
			<p>我们设计了一个数据科学工作台，根据我们的需求使用MLflow和相邻技术。我们详细介绍了使用MLflow设置开发环境的步骤，并举例说明了如何在现有代码中使用它。在后面的部分中，我们探索了工作台，并在其中添加了我们在上一章中开发的股票交易算法。</p>
			<p>在下一章中，我们将使用本章中开发的工作台，通过实验来改进我们的MLflow模型。</p>
			<h1 id="_idParaDest-65"><a id="_idTextAnchor078"/>延伸阅读</h1>
			<p>为了加深您的知识，您可以参考以下链接中的文档:</p>
			<ul>
				<li>库克卡特文档页面:<a href="https://cookiecutter.readthedocs.io/en/1.7.2/">https://cookiecutter.readthedocs.io/en/1.7.2/</a></li>
				<li>饼干模具参考信息:<a href="https://drivendata.github.io/cookiecutter-data-science/">https://drivendata.github.io/cookiecutter-data-science/</a></li>
				<li>数据科学工作台背后的动机:<a href="https://dzone.com/articles/what-is-a-data-science-workbench-and-why-do-data-s#">https://dzone . com/articles/what-is-a-data-science-work bench-and-why-do-data-s #</a></li>
			</ul>
		</div>
	

</body></html>