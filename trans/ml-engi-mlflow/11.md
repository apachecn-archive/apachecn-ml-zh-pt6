

# *第八章*:用 MLflow 训练模型

在本章中，您将了解如何使用 MLflow 创建生产就绪型训练工作。在更大的范围内，我们将重点关注如何从我们在前面章节中看到的笔记本环境中的训练工作转移到创建训练工作的标准化格式和蓝图。

具体来说，我们将了解本章的以下部分:

*   使用 MLflow 创建您的训练项目
*   实施训练工作
*   评估模型
*   在模型注册中心部署模型
*   为您的训练工作创建 Docker 图像

是时候添加 pyStock **机器学习** ( **ML** )平台训练基础设施，将在 [*第 3 章*](B16783_03_Final_SB_epub.xhtml#_idTextAnchor066)*中开发的工作台中创建的**概念验证**模型带到生产环境*。

在本章中，您将开发一个定期运行或由数据集到达触发时运行的训练项目。训练项目的主要输出是一个新的模型，它作为输出生成，并以不同的细节在模型注册中心注册。

以下是训练工作流程的概述:

![Figure 8.1 – Training workflow
](img/image0014.jpg)

图 8.1–训练工作流程

*图 8.1* 在较高层次上描述了一般流程，通过该流程，训练数据集到达，训练作业开始。训练作业生成一个模型，该模型最终被评估并部署到模型注册中心。上游系统现在能够使用新部署的模型部署推理**应用编程接口**(**API**)或批处理作业。

# 技术要求

对于本章，您将需要以下先决条件:

*   最新版本的 Docker 安装在您的机器上。如果您还没有安装，请按照[https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)上的说明进行操作。
*   安装了最新版本的 Docker Compose 请按照[https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/)上的说明操作。
*   在命令行访问 Git，按照[https://Git-SCM . com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)所述进行安装。
*   访问 Bash 终端(Linux 或 Windows)。
*   访问浏览器。
*   Python 3.5 以上版本已安装。
*   按照 MLflow 中的 [*第 4 章*](B16783_04_Final_SB_epub.xhtml#_idTextAnchor081) 、*实验管理中的描述，在本地安装您的 ML 库的最新版本*

# 使用 MLflow 创建您的训练项目

你从一位基于XG boost 模型的数据科学家那里收到一份规格说明，准备从**概念验证**进入生产阶段。

我们可以查看最初的 Jupyter 笔记本，数据科学家最初从其中注册了模型，这是开始创建 ML 工程管道的起点。在笔记本电脑上完成最初的原型制作和训练后，他们就可以开始生产了。

一些公司直接自己生产笔记本电脑，这肯定是可能的，但由于以下原因，这变得不可能:

*   笔记本很难版本化。
*   很难对代码进行单元测试。
*   对于长时间运行的测试是不可靠的。

通过这三个不同的阶段，我们确保了训练数据生成过程的可再现性以及该过程不同步骤的可见性和清晰分离。

我们首先将 MLflow 项目组织成步骤，并为管道的每个组件创建占位符，如下所示:

1.  在你的本地机器上创建一个新文件夹，命名为`pystock-training`。添加`MLProject`文件，如下:

    ```
    name: pystock_training conda_env: conda.yaml entry_points:   main:     data_file: path     command: "python main.py"   train_model:     command: "python train_model.py"   evaluate_model:     command: "python evaluate_model.py "   register_model:     command: "python register_model.py"
    ```

2.  在`conda.yaml`文件:

    ```
    name: pystock-training channels:   - defaults dependencies:   - python=3.8   - numpy   - scipy   - pandas   - cloudpickle   - pip:     - git+git://github.com/mlflow/mlflow     - sklearn     - pandas_datareader     - great-expectations==0.13.15     - pandas-profiling     - xgboost
    ```

    后增加的
3.  你现在可以添加一个样本文件到文件夹中，以确保项目的基本结构是工作的，如下:

    ```
    import mlflow import click import os def _run(entrypoint, parameters={}, source_version=None, use_cache=True):     print("Launching new run for entrypoint=%s and parameters=%s" % (entrypoint, parameters))     submitted_run = mlflow.run(".", entrypoint, parameters=parameters)     return mlflow.tracking.MlflowClient().get_run(submitted_run.run_id) @click.command() def workflow():     with mlflow.start_run(run_name ="pystock-training") as active_run:         mlflow.set_tag("mlflow.runName", "pystock-training")         _run("train_model")         _run("evaluate_model")                 _run("register_model")          if __name__=="__main__":     workflow()
    ```

4.  Test the basic structure by running the following command:

    ```
    mlflow run.
    ```

    这个命令将基于由您的`conda.yaml`文件创建的环境构建您的项目，并运行您刚刚创建的基本项目。它应该会出错，因为我们需要添加丢失的文件。

在这个阶段，我们有了将在本章中构建的数据管道的 MLflow 项目的基本模块。接下来，您将填写 Python 文件来训练数据。

# 实施训练工作

我们将使用前一章中产生的训练数据。这里假设一个独立的作业填充特定文件夹中的数据管道。在本书的 GitHub 资源库中，可以查看 https://GitHub . com/packt publishing/Machine-Learning-Engineering-with-ml flow/blob/master/chapter 08/psy stock-training/data/training/data . CSV 中的数据。

我们现在将创建一个`train_model.py`文件，它将负责加载训练数据以适应并生成一个模型。测试预测将被生成并保存在环境中，以便工作流的其他步骤可以使用这些数据来评估模型。

本节中生成的文件可从以下链接获得:

https://github . com/packt publishing/Machine-Learning-Engineering-with-ml flow/blob/master/chapter 08/psy stock-training/train _ model . py[:](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Mlflow/blob/master/chapter_8/psytock-training/train_model.py  )

1.  我们将从导入相关的包开始。在这种情况下，我们将需要`pandas`来处理数据，`xgboost`来运行训练算法，并且——显然——需要 m `lflow`来跟踪和记录数据运行。下面是你需要做的代码:

    ```
    import pandas as pd import mlflow import xgboost as xgb import mlflow.xgboost from sklearn.model_selection import train_test_split
    ```

2.  接下来，您应该添加一个函数来执行从`sklearn`到`train_test_split`的数据分割。我们为测试和训练数据分别选择了 33/67%的分割。我们指定`random_state`参数，以便使过程可重复，如下:

    ```
    def train_test_split_pandas(pandas_df,t_size=0.33,r_state=42):     X=pandas_df.iloc[:,:-1]     Y=pandas_df.iloc[:,-1]     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=t_size, random_state=r_state)     return X_train, X_test, y_train, y_test
    ```

3.  此函数返回训练和测试数据集以及每个数据集的目标。我们依靠`xgboost`矩阵`xgb.Dmatrix`数据格式来有效地加载训练和测试数据，并提供给`xgboost.train`方法。代码如下面的代码片段所示:

    ```
    if __name__ == "__main__":     THRESHOLD = 0.5     mlflow.xgboost.autolog()     with mlflow.start_run(run_name="train_model") as run:         mlflow.set_tag("mlflow.runName", "train_model")         pandas_df=pd.read_csv("data/training/data.csv")         pandas_df.reset_index(inplace=True)         X_train, X_test, y_train, y_test = train_test_split_pandas(pandas_df)         train_data = xgb.DMatrix(X_train, label=y_train)         test_data =  xgb.DMatrix(X_test)         model = xgb.train(dtrain=train_data,params={})        
    ```

4.  我们也利用这一时刻，用`model.predict`方法产生测试预测。执行一些数据转换来离散股票上涨或下跌的概率，并将其转换为`0`(不上涨)或`1`(上涨)，如下:

    ```
            y_probas=model.predict(test_data)          y_preds = [1 if  y_proba > THRESHOLD else 0\. for y_proba in y_probas]
    ```

5.  作为最后一个步骤，我们将保持对`result`变量的测试预测。我们删除索引，以便在运行`result.to_csv`命令时，保存的`pandas`数据帧不包含索引，如下:

    ```
            test_prediction_results = pd.DataFrame(data={'y_pred':y_preds,'y_test':y_test})         result = test_prediction_results.reset_index(drop=True)                  result.to_csv("data/predictions/test_predictions.csv")    
    ```

6.  您可以通过运行以下命令来查看您的 MLflow **用户界面** ( **UI** )以查看记录的指标:

    ```
     mlflow ui
    ```

您应该能够查看您的 MLflow UI，可在下面的屏幕截图中查看，您可以在其中看到持久模型和刚刚训练的模型的不同模型信息:

![Figure 8.2 – Training model
](img/image0025.jpg)

图 8.2–训练模型

在这个阶段，我们将我们的模型保存并持久化在我们的 MLflow 安装的工件上。接下来，我们将向我们的工作流添加一个新的步骤，以生成刚刚生成的模型的指标。

# 评估模型

我们现在将继续为我们的模型收集评估指标，以添加到模型的元数据中。

我们将处理`evaluate_model.py`文件。您可以通过在一个空文件中工作或转到 https://github . com/packt publishing/Machine-Learning-Engineering-with-ml flow/blob/master/chapter 08/psy stock-training/evaluate _ model . py 来继续操作。操作如下:

1.  Import the relevant packages—`pandas` and `mlflow—f`or reading and running the steps, respectively. We will rely on importing a selection of model-evaluation metrics available in `sklearn` for classification algorithms, as follows:

    ```
    import pandas as pd
    import mlflow
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import  \
        classification_report, \
        confusion_matrix, \
        accuracy_score, \
        auc, \
        average_precision_score, \
        balanced_accuracy_score, \
        f1_score, \
        fbeta_score, \
        hamming_loss, \
        jaccard_score, \
        log_loss, \
        matthews_corrcoef, \
        precision_score, \
        recall_score, \
        zero_one_loss
    ```

    在这个阶段，我们已经导入了下一部分需要提取的指标所需的所有函数。

2.  Next, you should add a `classification_metrics` function to generate metrics based on a `df` parameter. The assumption is that the DataFrame has two columns: `y_pred`, which is the target predicted by the training model, and `y_test`, which is the target present on the training data file. Here is the code you will need:

    ```
    def classification_metrics(df:None):
        metrics={}
        metrics["accuracy_score"]=accuracy_score(df["y_pred"], df["y_test"]  )
        metrics["average_precision_score"]=average_precision_score( df["y_pred"], df["y_test"]  )
        metrics["f1_score"]=f1_score( df["y_pred"], df["y_test"]  )
        metrics["jaccard_score"]=jaccard_score( df["y_pred"], df["y_test"]  )
        metrics["log_loss"]=log_loss( df["y_pred"], df["y_test"]  )
        metrics["matthews_corrcoef"]=matthews_corrcoef( df["y_pred"], df["y_test"]  )
        metrics["precision_score"]=precision_score( df["y_pred"], df["y_test"]  )
        metrics["recall_score"]=recall_score( df["y_pred"], df["y_test"] )
        metrics["zero_one_loss"]=zero_one_loss( df["y_pred"], df["y_test"]  )
        return metrics
    ```

    前面的函数根据预测值和测试预测生成一个`metrics`字典。

3.  在创建了这个生成指标的函数之后，我们需要使用`start_run`，由此我们基本上读取预测测试文件并运行指标。我们在`mlflow.log_metrics`方法中发布所有的度量，同时记录多个度量的字典。代码如下面的代码片段所示:

    ```
    if __name__ == "__main__":     with mlflow.start_run(run_name="evaluate_model") as run:         mlflow.set_tag("mlflow.runName", "evaluate_model")         df=pd.read_csv("data/predictions/test_predictions.csv")         metrics = classification_metrics(df)         mlflow.log_metrics(metrics)    
    ```

4.  我们可以再次查看 MLflow UI，在这里我们可以看到不同的指标刚刚被保存下来。您可以在这里查看输出:

![Figure 8.3 – Training model metrics persisted
](img/image0035.jpg)

图 8.3–持续的训练模型指标

在这个阶段，我们有一个训练工作的模型评估，为模型实现者/部署者提供度量和信息。我们现在将转移到训练过程的最后一步，即在 MLflow 模型注册表中注册模型，以便它可以部署到生产中。

# 在模型注册中心部署模型

接下来，您应该添加`register_model.py`函数在模型注册表中注册模型。

这就像用模型的**统一资源标识符** ( **URI** )和模型名称执行`mlflow.register_model`方法一样简单。基本上，如果模型不存在，它将被创建。如果它已经在注册表中，将会添加一个新版本，允许部署工具查看模型并跟踪训练工作和指标。它还允许决定是否将模型投入生产。您需要的代码如下面的代码片段所示:

```
import mlflow
if __name__ == "__main__":

    with mlflow.start_run(run_name="register_model") as run:
        mlflow.set_tag("mlflow.runName", "register_model")
        model_uri = "runs:/{}/sklearn-model".format(run.info.run_id)
        result = mlflow.register_model(model_uri, "training-model-psystock")

```

在下面的屏幕截图中，显示了注册的模型，我们可以根据我们的工作流更改状态并进入试运行或生产状态:

![Figure 8.4 – Registered model
](img/image0045.jpg)

图 8.4-注册模型

注册了我们的模型后，我们现在将继续准备我们训练工作的 Docker 映像，该映像可以在公共云环境或 Kubernetes 集群中使用。

# 为您的训练工作创建 Docker 图像

在许多环境中，Docker 映像是模型开发人员向更专业的系统基础设施团队交付训练工作时最关键的交付物。该项目包含在存储库的以下文件夹中:https://github . com/packt publishing/Machine-Learning-Engineering-with-ml flow/tree/master/chapter 08/psy stock-training-docker。在接下来的步骤中，我们将为生成的代码生成一个随时可以部署的 Docker 映像:

1.  你需要在项目的根文件夹下设置一个 Docker 文件，如下面的代码片段所示:

    ```
    FROM continuumio/miniconda3:4.9.2 RUN apt-get update && apt-get install build-essential -y RUN pip install \     mlflow==1.18.0 \     pymysql==1.0.2 \     boto3 COPY ./training_project /src WORKDIR /src
    ```

2.  我们将通过运行以下命令开始构建和训练映像:

    ```
    docker build -t psystock_docker_training_image .
    ```

3.  您可以运行您的映像，指定您的跟踪服务器`$TRACKING_SERVER_URI`值以达到[http://host . docker . internal:5000](http://host.docker.internal:5000)，如下面的代码片段中的所示:

    ```
    docker run -e MLflow_TRACKING_SERVER=$TRACKING_SERVER_URI psystock_docker_training_image
    ```

在此阶段，我们已经完成了完整训练工作流程的所有步骤。在下一章中，我们将继续在生产环境中部署平台的不同组件，利用到目前为止创建的所有 MLflow 项目。

# 总结

在本章中，我们介绍了使用 MLflow 创建生产训练流程的概念和不同功能。

我们从设置 MLflow 训练项目的基本模块开始，并在整个章节中依次训练模型、评估已训练模型和注册已训练模型。我们还深入研究了为您的训练工作创建一个现成的图像。

这是架构的一个重要组成部分，它将允许我们为生产中的 ML 系统构建一个端到端的生产系统。在下一章中，我们将部署不同的组件，并说明模型的部署过程。

# 延伸阅读

为了加深您的知识，您可以参考以下链接中的官方文档:

[https://www.mlflow.org/docs/latest/projects.html](https://www.mlflow.org/docs/latest/projects.html)