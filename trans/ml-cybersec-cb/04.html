<html><head/><body>


    
        <title>Machine Learning for Social Engineering</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">面向社会工程的机器学习</h1>
                
            
            
                
<p>有很多很酷的<strong>机器学习</strong> ( <strong> ML </strong>)的新应用，这些应用在任何地方都不如它们在社会工程中那样大放异彩。ML已经实现了非常成功的自动鱼叉式网络钓鱼，我们将通过Twitter鱼叉式网络钓鱼机器人食谱了解这一点。它还被用来生成假的，但真实的视频，同时，发现这些是假的。它提供了语音传输，检测谎言的能力，以及你将在本章的食谱中看到的许多其他方便的工具，旨在加强你的社会工程游戏。</p>
<p class="mce-root">本章包括以下配方:</p>
<ul>
<li class="mce-root">Twitter鱼叉钓鱼机器人</li>
<li class="mce-root">声音模仿</li>
<li class="mce-root"><strong>开源智能</strong>的语音识别</li>
<li>面部识别</li>
<li class="mce-root">Deepfake</li>
<li class="mce-root">深度伪造识别</li>
<li class="mce-root">使用最大似然法的测谎</li>
<li class="mce-root">人格分析</li>
<li class="mce-root">社交地图</li>
<li class="mce-root">训练一个假评论生成器</li>
<li>产生虚假评论</li>
<li>假新闻</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    






    
        <title>Technical requirements</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">技术要求</h1>
                
            
            
                
<p>在本章中，我们将使用以下内容:</p>
<ul>
<li>马尔科维奇</li>
<li>Twitter开发者账户</li>
<li>十二岁</li>
<li>PyTorch</li>
<li>OpenCV</li>
<li>克拉斯</li>
<li>张量流</li>
<li>IBM的沃森</li>
</ul>
<p>代码和数据集可以在<a href="https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter04">https://github . com/packt publishing/Machine-Learning-for-cyber security-Cookbook/tree/master/chapter 04</a>找到。</p>


            

            
        
    






    
        <title>Twitter spear phishing bot</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">Twitter鱼叉钓鱼机器人</h1>
                
            
            
                
<p>在这个食谱中，我们将使用机器学习来构建一个Twitter鱼叉钓鱼机器人。该机器人将利用人工智能来模仿其目标的推文，从而为自己的推文创造有趣和诱人的内容。此外，推文将包含嵌入式链接，导致目标点击这些钓鱼链接。当然，我们不会利用这个机器人的恶意目的，我们的链接将是虚拟链接。链接本身会被混淆，所以目标只有在点击后才能知道隐藏在它们后面的是什么。</p>
<p>实验表明，这种形式的攻击有很高的成功率，通过模拟这种形式的攻击，您可以测试和改进您的客户或组织的安全状况。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><div><div><div><div><p>该配方的准备工作包括在<kbd>pip</kbd>安装<kbd>tweepy</kbd>和<kbd>markovify</kbd>包。说明如下:</p>
<pre><strong>pip install tweepy markovify</strong></pre>
<p>此外，你需要在Twitter上设置一个开发者账户。这个过程相对简单，账户创建是免费的。</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">在以下步骤中，我们演示了如何使用机器学习来创建鱼叉式钓鱼Twitter bot:</p>
<ol>
<li class="mce-root">在Twitter上建立一个开发者账户。</li>
<li class="mce-root">创建一个新的应用程序，并获取您的消费者API密钥、访问令牌和访问令牌密码。</li>
<li class="mce-root">导入<kbd>tweepy</kbd>库并填写您的凭证以访问Twitter API:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">import json<br/>import tweepy<br/><br/>CONSUMER_API_KEY = "fill me in"<br/>CONSUMER_API_SECRET_KEY = "fill me in"<br/>ACCESS_TOKEN = "fill me in"<br/>ACCESS_TOKEN_SECRET = "fill me in"<br/><br/>auth = tweepy.OAuthHandler(CONSUMER_API_KEY, CONSUMER_API_SECRET_KEY)<br/>auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)<br/><br/>api = tweepy.API(<br/>    auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True<br/>)</pre>
<ol start="4">
<li class="mce-root">我们选择一个我们想要瞄准或模仿的用户。在这种情况下，我选择了一位活跃在Twitter上的杰出技术人士:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">user_id = "elonmusk"</pre>
<ol start="5">
<li class="mce-root">收集用户最新的<kbd>count = 200</kbd>推文:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">count = 200<br/>user_tweets = api.user_timeline(screen_name=user_id, count=count, tweet_mode="extended")</pre>
<ol start="6">
<li class="mce-root">将用户的所有推文收集到一个大文本中:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">tweet_corpus = []<br/>for tweet in user_tweets:<br/>    tweet_corpus.append(tweet.full_text)<br/>tweets_text = ". ".join(tweet_corpus)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="7">
<li>我们现在开始处理文本。我们定义了一个函数，它将用新的URL替换任何找到的URL实例:</li>
</ol>
<pre style="padding-left: 60px">import re<br/><br/>def replace_URLs(string, new_URL):<br/>    """Replaces all URLs in a string with a custom URL."""<br/>    modified_string = re.sub(<br/>        "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\(\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+",<br/>        " " + new_URL + " ",<br/>        string,<br/>    )<br/>    return modified_string</pre>
<ol start="8">
<li>创建一个钓鱼链接，并将其插入推文中。在我们的例子中，我们使用了一个网址缩写来混淆链接将用户带到google.com<a href="http://google.com">的事实:</a></li>
</ol>
<pre style="padding-left: 60px">phishing_link = "https://urlzs.com/u8ZB"<br/>processed_tweets_text = replace_URLs(tweets_text, phishing_link)</pre>
<ol start="9">
<li>在处理后的文本上训练马尔可夫模型并生成推文:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">import markovify<br/><br/>markov_model = markovify.Text(processed_tweets_text)</pre>
<ol start="10">
<li>生成所需数量的包含网络钓鱼链接的推文:</li>
</ol>
<pre style="padding-left: 60px">num_phishing_tweets_desired = 5<br/>num_phishing_tweets_so_far = 0<br/>generated_tweets = []<br/>while num_phishing_tweets_so_far &lt; num_phishing_tweets_desired:<br/>    tweet = markov_model.make_short_sentence(140)<br/>    if phishing_link in tweet and tweet not in generated_tweets:<br/>        generated_tweets.append(tweet)<br/>        num_phishing_tweets_so_far += 1</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">我们将看到以下输出:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1173 image-border" src="img/3e7aedd3-3037-46ce-b1d1-73ed514502ef.png" style="width:73.33em;height:8.17em;"/></p>
<ol start="11">
<li>发布你的推文，并以用户、用户的追随者或用户的朋友为目标。例如，这段代码获取用户的朋友:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">user = api.get_user(user_id)<br/>for friend in user.friends():<br/>    print(friend.screen_name)</pre>
<p style="padding-left: 60px">我们将看到的输出如下:</p>
<div><pre style="padding-left: 60px">wonderofscience<br/>SpaceComCC<br/>AFSpace<br/>Liv_Boeree<br/>shivon<br/>Teslarati<br/>neiltyson<br/>SciGuySpace<br/>wlopwangling<br/>Berger_SN<br/>pewdiepie<br/>CathieDWood<br/>lexfridman<br/>ccsakuras<br/>4thFromOurStar<br/>TheOnion<br/>BBCScienceNews<br/>sciencemagazine<br/>NatureNews<br/>TheStoicEmperor</pre></div>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p class="mce-root">在第1步和第2步中，您将需要进入Twitter开发者网页来创建您的API帐户，这将是免费的。为了通过Python访问Twitter API，我们使用了<kbd>tweepy</kbd>库(步骤3)。我们的目标是从目标Twitter用户的推文中学习，以便我们的推文具有与该用户相同的风格和主题。这样的推文可能会吸引对相同话题和风格感兴趣的人。我们选择模仿埃隆·马斯克的风格来发布推文(第四步)。我们继续收集Elon发布的最后200条推文(步骤5和6)。一般来说，从用户那里获得的tweets越多，模型就越有说服力。然而，考虑时间和相关性可能很重要——也就是说，用户更有可能点击及时和相关的推文，而不是那些处理陈旧话题的推文。</p>
<p class="mce-root">我们定义一个函数来处理文本，以便所有的URL都被替换为所需的URL(步骤7)，然后将其应用于我们的文本(步骤8)。我们使用了一个网址缩写来隐藏钓鱼链接的目的地，就是谷歌。在处理推文的这个阶段，有很大的创造力空间。例如，我们可以定制<kbd>@</kbd>屏幕名称，使它们与我们的目标更加相关。在第9步和第10步中，我们在已经处理过的推文中训练一个马尔可夫模型，然后生成几条嵌入了钓鱼链接的推文。最后，关于步骤11，请记住，使机器人更有效的其他修改包括选择一天、一周、一月或其他时间(例如，与事件相关的时间)发送推文，或者在推文中添加带有链接的照片。</p>


            

            
        
    






    
        <title>Voice impersonation</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">声音模仿</h1>
                
            
            
                
<p class="mce-root">使用通过神经网络传输声音风格的新技术，令人信服地模仿目标的声音变得越来越容易。在这一节中，我们将向您展示如何使用深度学习来录制目标说任何您希望他们说的话，例如，将目标的声音用于社会工程目的，或者更有趣的例子，使用奥巴马的声音来唱碧昂斯的歌曲。我们在<kbd>mazzzystar/randomCNN-voice-transfer</kbd>中选择了能够快速获得高质量结果的架构。特别地，不需要在记录的音频的大数据集上预先训练模型。</p>
<p class="mce-root">在本书的随附代码中，您会发现两个版本的语音传输神经网络代码，一个用于GPU，一个用于CPU。我们这里描述的是CPU的，虽然GPU的非常相似。</p>
<p class="mce-root"/>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><p>该配方的准备工作包括在<kbd>pip</kbd>中安装<kbd>pytorch</kbd>和<kbd>librosa</kbd>。说明如下:</p>
</div>
<div><pre><strong>pip install torch librosa</strong></pre>
<p>另外，将两个文件放在<kbd>voice_impersonation_input</kbd>文件夹中。一个文件是你想表达的信息的录音，另一个文件是你想表达的信息的声音。</p>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">在下面的步骤中，我们提供了一个将一个说话者的声音转换成另一个说话者的录音的方法。代码由三部分组成:CPU的声音模拟(主)、模型和实用程序。我们将讨论如何运行main并解释它正在做什么。每当出现对代码其他部分的引用时，我们将提供对被引用方法的高级解释，但为了简洁起见，省略了细节。</p>
<p class="mce-root">以下代码可以在<kbd>Voice Impersonation.ipynb</kbd>中找到:</p>
<ol>
<li class="mce-root">导入PyTorch实用程序、神经网络模型和用于一些基本计算的<kbd>math</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">import math<br/>from torch.autograd import Variable<br/>from voice_impersonation_utils import *<br/>from voice_impersonation_model import *</pre>
<ol start="2">
<li class="mce-root">在<kbd>style_file</kbd>中指定我们希望使用的声音，在<kbd>content_file</kbd>中指定我们希望以该声音发出的音频:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">input_files = "voice_impersonation_input/"<br/>content_file = input_files + "male_voice.wav"<br/>style_file = input_files + "Eleanor_Roosevelt.wav"</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="3">
<li class="mce-root">我们提取内容和样式文件的频谱，并将其转换为PyTorch张量:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">audio_content, sampling_rate = wav2spectrum(content_file)<br/>audio_style, sampling_rate = wav2spectrum(style_file)<br/>audio_content_torch = torch.from_numpy(audio_content)[None, None, :, :]<br/>audio_style_torch = torch.from_numpy(audio_style)[None, None, :, :]</pre>
<ol start="4">
<li class="mce-root">我们实例化一个随机CNN模型，并将其设置为<kbd>eval</kbd>模式:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">voice_impersonation_model = RandomCNN()<br/>voice_impersonation_model.eval()</pre>
<ol start="5">
<li class="mce-root">我们为即将到来的神经网络训练准备张量，并选择Adam优化器和学习速率:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">audio_content_variable = Variable(audio_content_torch, requires_grad=False).float()<br/>audio_style_variable = Variable(audio_style_torch, requires_grad=False).float()<br/>audio_content = voice_impersonation_model(audio_content_variable)<br/>audio_style = voice_impersonation_model(audio_style_variable)<br/><br/>learning_rate = 0.003<br/>audio_G_var = Variable(<br/>    torch.randn(audio_content_torch.shape) * 1e-3, requires_grad=True<br/>)<br/>opt = torch.optim.Adam([audio_G_var])</pre>
<ol start="6">
<li class="mce-root">我们指定<kbd>style</kbd>和<kbd>content</kbd>参数以及我们希望训练模型的时间:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">style_param = 1<br/>content_param = 5e2<br/><br/>num_epochs = 500<br/>print_frequency = 50</pre>
<ol start="7">
<li>我们训练我们的模型:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">for epoch in range(1, num_epochs + 1):<br/>    opt.zero_grad()<br/>    audio_G = voice_impersonation_model(audio_G_var)<br/><br/>    content_loss = content_param * compute_content_loss(audio_content, audio_G)<br/>    style_loss = style_param * compute_layer_style_loss(audio_style, audio_G)<br/>    loss = content_loss + style_loss<br/>    loss.backward()<br/>    opt.step()</pre>
<ol start="8">
<li>我们打印正在进行的训练进度，指定输出文件的名称，最后，将神经网络的输出频谱转换为音频文件:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">    if epoch % print_frequency == 0:<br/>        print("epoch: "+str(epoch))<br/>        print("content loss: "+str(content_loss.item()))<br/>        print("style loss: "+str(style_loss.item()))<br/>        print("loss: "+str(loss.item()))<br/><br/>gen_spectrum = audio_G_var.cpu().data.numpy().squeeze()<br/>output_audio_name = "Eleanor_saying_there_was_a_change_now.wav"<br/>spectrum2wav(gen_spectrum, sampling_rate, output_audio_name)</pre>
<p class="mce-root">我们计算的最终结果可以在名为<kbd>Eleanor_saying_there_was_a_change_now.wav</kbd>的音频文件中看到。</p>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>我们首先导入PyTorch，神经网络模型，以及用于一些基本计算的<kbd>math</kbd>(步骤1)。更有趣的是，在步骤2中，我们指定音频的内容和样式。在内容文件中，你可以说出任何你想说的短语，例如<em>没有机器学习就做不了网络安全</em>。然后，在样式文件中，选择某人的录音，例如，某个名人(如Elon Musk)的录音。语音模仿的最终结果是，埃隆·马斯克说<em>没有机器学习</em>就做不了网络安全。第3、4和5步涉及一些跑腿工作，准备将我们的数据输入到我们的模型中，然后实例化一个随机CNN模型及其优化器。该模型的主要特点是，它对音频频谱图使用2D卷积层而不是1D层，并在时间轴上计算<kbd>grams</kbd>。将模型设置为评估模式(与训练模式相对照)会影响某些图层的行为，例如在训练和测试中使用不同的dropout和batch norm。在下一步(步骤6)，我们定义<kbd>style</kbd>和<kbd>content</kbd>参数，它们为样式和内容分配相对权重。具体来说，它们决定了最终音频对各自文件的风格和内容的继承程度。我们现在准备好训练我们的模型，这是我们在步骤7中通过执行前向和后向传播来完成的。我们监控训练的进度(步骤8)，然后最终输出一个音频文件到磁盘，使用样式文件的样式来发音内容文件。你可以在这本书的知识库中找到这个文件。</p>
<p class="mce-root"/>


            

            
        
    






    
        <title>Speech recognition for OSINT</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">面向OSINT的语音识别</h1>
                
            
            
                
<p class="mce-root">故事是这样的，一个钢笔测试员正在对当时的联邦调查局局长詹姆斯·科米进行情报收集。通过听科米的录像，钢笔测试员注意到科米提到有几个社交媒体账户，包括一个Twitter账户。然而，在当时，没有他的账户是已知的。</p>
<p class="mce-root">通过彻底的调查，钢笔测试员最终发现了科米的秘密推特账户，网名雷茵霍尔德·尼布尔。这个方法的目标是帮助笔测试人员在搜索关键字时，自动并加速筛选大量关于目标的音频/视频镜头。具体来说，我们用机器学习把语音转换成文本，收集这个文本，然后搜索感兴趣的关键词。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><p>该食谱的准备工作包括在<kbd>pip</kbd>安装<kbd>speechrecognition</kbd>包。说明如下:</p>
</div>
<div><pre><strong>pip install speechrecognition</strong></pre>
<p>此外，收集一些您想识别其语音的音频文件。</p>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">在以下步骤中，我们将展示如何使用语音识别库将语音录音转换为文本，然后在这些文本中搜索所需的关键字:</p>
<ol>
<li class="mce-root">导入语音识别库，并选择我们希望将其语音转换为文本的音频文件列表。此外，创建您想要在这些音频文件中自动检测的关键词列表:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">import speech_recognition<br/><br/>list_of_audio_files = ["Eleanor_Roosevelt.wav", "Comey.wav"]<br/>keywords = ["Twitter", "Linkedin", "Facebook", "Instagram", "password", "FBI"]</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<ol start="2">
<li class="mce-root">定义一个使用Google语音识别API将音频文件转换为文本的函数:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">def transcribe_audio_file_to_text(audio_file):<br/>    """Takes an audio file and produces a text transcription."""<br/>    recognizer = speech_recognition.Recognizer()<br/>    with speech_recognition.AudioFile(audio_file) as audio_source:<br/>        audio = recognizer.record(audio_source)<br/>        return recognizer.recognize_google(audio)</pre>
<ol start="3">
<li class="mce-root">将音频文件转换为文本，并创建一个字典来记住文本来自哪个音频文件:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">audio_corpus = {}<br/>for audio_file in list_of_audio_files:<br/>    audio_corpus[transcribe_audio_file_to_text(audio_file)] = audio_file<br/><br/>print(audio_corpus)</pre>
<p style="padding-left: 60px" class="mce-root">语料库输出如下:</p>
<pre style="padding-left: 60px">{"I'm very glad to be able to take part in this celebration dim sum Direct on human rights day": 'Eleanor_Roosevelt.wav', "have you met read recently that I'm on Twitter I am not a tweeter I am there to listen to read especially what's being said about the FBI and its mission": 'Comey.wav'}</pre>
<ol start="4">
<li class="mce-root">在文本语料库中搜索关键词，并打印出包含这些关键词的音频文件:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">for keyword in keywords:<br/>    for transcription in audio_corpus:<br/>        if keyword in transcription:<br/>            print(<br/>                "keyword "<br/>                + keyword<br/>                + " found in audio "<br/>                + '"'<br/>                + audio_corpus[transcription]<br/>                + '"'<br/>            )</pre>
<p style="padding-left: 60px">我们的运行检测到关键字<kbd>Twitter</kbd>:</p>
<pre style="padding-left: 60px" class="mce-root">keyword Twitter found in audio "Comey.wav"<br/>keyword FBI found in audio "Comey.wav"</pre>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p class="mce-root">我们首先导入语音识别库，并选择我们希望将其语音转换为文本的音频文件列表。此外，我们创建一个我们希望在这些音频文件中自动检测的关键字列表(步骤1)。通过词干化或词元化，可以使检测这些关键词的发声的方法更加健壮，这有效地说明了具有相同含义的关键词的变体。例如，如果这种方法实施得当，Twitter、Twitted和Tweet都可以被检测到。在步骤2中，我们指定将使用Google的语音识别API来转录音频。其他语音识别服务，如pocketsphinx，也是可用的。我们现在准备转录我们的音频文件，这是我们在步骤3。现在我们有了文本格式的音频，一切都很顺利。只需搜索感兴趣的关键词(步骤4)。当语料库和文本变得更大时，另一个可能卓有成效的优化是打印找到关键字的句子，以便更容易理解上下文。</p>


            

            
        
    






    
        <title>Facial recognition</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">面部识别</h1>
                
            
            
                
<p>面部识别系统是一种用于识别或验证图像或视频中的人的技术。当对目标或潜在目标执行OSINT时，面部识别系统可以是无价的。在这个菜谱中，你将学习如何使用开发良好的<kbd>face_recognition</kbd> Python库。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><p>这个菜谱的准备工作包括在<kbd>pip</kbd>中安装<kbd>face_recognition</kbd>和OpenCV包。说明如下:</p>
</div>
<div><pre><strong>pip install face_recognition opencv-python</strong></pre>
<p>此外，您还需要一张个人的肖像和一组图像，您可以通过这些图像来搜索该个人。</p>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做…</h1>
                
            
            
                
<p>在接下来的步骤中，你将训练<kbd>face_recognition</kbd>在一系列图像中找到并标记给定的个人:</p>
<ol>
<li>首先导入<kbd>face_recognition</kbd>库:</li>
</ol>
<pre style="padding-left: 60px">import face_recognition</pre>
<ol start="2">
<li>首先加载一个有标签的个人肖像，您将对其执行OSINT:</li>
</ol>
<pre style="padding-left: 60px">known_image = face_recognition.load_image_file("trump_official_portrait.jpg")</pre>
<p style="padding-left: 60px">个人的脸必须清晰可见:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1107 image-border" src="img/ab1cb3f4-c88f-407d-854f-84fdda2fe552.png" style="width:17.58em;height:22.25em;"/></p>
<ol start="3">
<li>接下来，加载一张<kbd>unknown</kbd>图像，在该图像中，您想要自动检测个人的面部:</li>
</ol>
<pre style="padding-left: 60px">unknown_image = face_recognition.load_image_file("trump_and_others.jpg")</pre>
<p style="padding-left: 60px">正在搜索其面部的个人出现在此截图中:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1108 image-border" src="img/6dc5fd33-e04a-4c6a-b76b-342c63c0e8c3.png" style="width:25.50em;height:17.00em;"/></p>
<ol start="4">
<li>给个人的脸编码:</li>
</ol>
<pre style="padding-left: 60px">trump_encoding = face_recognition.face_encodings(known_image)[0]</pre>
<ol start="5">
<li>对未知图像中所有人的面部进行编码:</li>
</ol>
<pre style="padding-left: 60px">unknown_faces = face_recognition.face_encodings(unknown_image)</pre>
<ol start="6">
<li>搜索个人的面部:</li>
</ol>
<pre style="padding-left: 60px">matches = face_recognition.compare_faces(unknown_faces, trump_encoding)<br/>print(matches)</pre>
<p style="padding-left: 60px" class="mce-root">输出如下所示:</p>
<pre style="padding-left: 60px">[False, False, False, True]</pre>
<ol start="7">
<li>加载未知图像中所有人脸的位置，并将匹配位置保存到一个变量中:</li>
</ol>
<pre style="padding-left: 60px">face_locations = face_recognition.face_locations(unknown_image)<br/>trump_face_location = face_locations[3]</pre>
<ol start="8">
<li>将未知图像读入<kbd>cv2</kbd>:</li>
</ol>
<pre style="padding-left: 60px">import cv2<br/>unknown_image_cv2 = cv2.imread("trump_and_others.jpg")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="9">
<li>在未知图像上画一个矩形，表示匹配面所在的位置:</li>
</ol>
<pre style="padding-left: 60px">(top, right, bottom, left) = trump_face_location<br/>cv2.rectangle(unknown_image_cv2, (left, top), (right, bottom), (0, 0, 255), 2)</pre>
<ol start="10">
<li>标记矩形:</li>
</ol>
<pre style="padding-left: 60px">cv2.rectangle(unknown_image_cv2, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)<br/>font = cv2.FONT_HERSHEY_DUPLEX<br/>cv2.putText(unknown_image_cv2, "Trump", (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)</pre>
<ol start="11">
<li>显示带有标记矩形的图像:</li>
</ol>
<pre style="padding-left: 60px">cv2.namedWindow('image', cv2.WINDOW_NORMAL)<br/>cv2.imshow('image',unknown_image_cv2)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</pre>
<p style="padding-left: 60px">下面的屏幕截图显示输出已经成功:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1109 image-border" src="img/a50ba5dd-c7f1-4134-bdb9-bf958eea114b.png" style="width:31.33em;height:20.83em;"/></p>
<p>自动执行这一搜索和标记过程非常简单。</p>
<p class="mce-root"/>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>首先简单地导入面部识别库(步骤1)。在下一步中，我们在笔测试中加载我们希望在图像集合中定位的目标的图像。接下来，准备一个示例图像，我们希望对其进行扫描以确定目标面部的存在(步骤3)。对图像中所有找到的人脸进行编码(步骤4和5)，然后搜索目标的人脸(步骤6)。为了方便起见，我们打印出与目标人脸匹配的结果。在步骤7-10中，我们希望证明我们已经找到了匹配。为此，我们加载已扫描的图像。然后，我们在分类器检测到目标面部的地方绘制一个矩形和一个标签。看看第11步的结果，我们看到了巨大的成功。我们成功地探测到了。</p>
<p>顺便说一句，注意到<kbd>face_recognition</kbd>工具背后的技术是深度学习，作为一个推论，可以使用GPU加速人脸的搜索过程。</p>


            

            
        
    






    
        <title>Deepfake</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">Deepfake</h1>
                
            
            
                
<p><strong> Deepfake </strong>是使用神经网络拍摄视频或图像，在其上叠加一些内容，使结果看起来逼真的技术。例如，该技术可以拍摄爱丽丝说她支持一项运动的视频，然后用鲍勃代替爱丽丝，创建鲍勃说他支持这项运动的逼真视频。显然，这种技术对我们对视频和图像的信任有着深刻的影响，同时也为社会工程师提供了一个有用的工具。</p>
<p class="mce-root">在这个配方中，我们使用一个Deepfake变体来拍摄一个目标的面部图像，并逼真地将其叠加到另一个目标的面部图像上。菜谱是GitHub库<kbd>wuhuikai/FaceSwap</kbd>中代码的重构和简化版本。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><p>该配方的准备包括在<kbd>pip</kbd>中安装<kbd>opencv</kbd>、<kbd>dlib</kbd>和<kbd>scipy</kbd>。说明如下:</p>
</div>
<div><pre><strong>pip install opencv-python dlib scipy</strong></pre>
<p>此外，你会想要两个图像；一个是个人的肖像，一个是包含人脸的图像。前一个面将转移到后一个面上。在<kbd>deepfake_input</kbd>文件夹中为您提供了一个样本。</p>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">在下面的步骤中，我们提供了一个用另一个人的脸替换图像中一个人的脸的方法。代码由五部分组成:<kbd>Deepfake.ipynb</kbd>(主代码)、<kbd>deepfake_config</kbd>配置文件、<kbd>deepfake_face_detection</kbd>、<kbd>deepfake_face_points_detection</kbd>和<kbd>deepfake_face_swap</kbd>。此外，还包括一个模型文件夹。</p>
<p class="mce-root">以下代码可以在<kbd>Deepfake.ipynb</kbd>中找到:</p>
<ol>
<li class="mce-root">从相关代码中导入<kbd>opencv</kbd>图像操作和交换人脸所需的方法:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">import os<br/>import cv2<br/>import numpy as np<br/>from deepfake_face_detection import select_face<br/>from deepfake_face_swap import (<br/>    warp_image_2d,<br/>    warp_image_3d,<br/>    mask_from_points,<br/>    apply_mask,<br/>    correct_colours,<br/>    transformation_from_points,<br/>    ProcessFace,<br/>)</pre>
<ol start="2">
<li class="mce-root">指定包含我们希望在<kbd>content_image</kbd>中使用的面部的图像，以及我们希望在<kbd>target_image</kbd>中将面部转移到的图像。最后，指定您希望在哪里创建结果:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">content_image = "deepfake_input/author.jpg"<br/>target_image = "deepfake_input/gymnast.jpg"<br/>result_image_path = "deepfake_results/author_gymnast.jpg"</pre>
<p style="padding-left: 60px" class="mce-root">在运行的示例中，源图像是作者脸部的图片:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1110 image-border" src="img/496dcb42-9f33-42d4-a495-d0a6af15168c.png" style="width:17.17em;height:17.08em;"/></p>
<p style="padding-left: 60px" class="mce-root">目标图像是一张正在表演的体操运动员的照片:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1111 image-border" src="img/2bb0fc84-9761-4944-89fe-61015978deb6.png" style="width:18.75em;height:21.50em;"/></p>
<ol start="3">
<li class="mce-root CDPAlignLeft CDPAlign">将图像读入<kbd>opencv</kbd>，然后提取源面和目的面:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">content_img = cv2.imread(content_image)<br/>destination_img = cv2.imread(target_image)<br/>content_img_points, content_img_shape, content_img_face = select_face(content_img)<br/>destination_img_points, destination_img_shape, destination_img_face = select_face(<br/>    destination_img<br/>)</pre>
<ol start="4">
<li class="mce-root">计算源面的变换版本:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">result_image = ProcessFace(<br/>    content_img_points, content_img_face, destination_img_points, destination_img_face<br/>)</pre>
<ol start="5">
<li class="mce-root">将变换后的面部绘制到目标图像中，并将文件写入磁盘:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">x, y, w, h = destination_img_shape<br/>destination_img_copy = destination_img.copy()<br/>destination_img_copy[y : y + h, x : x + w] = result_image<br/>result_image = destination_img_copy<br/>cv2.imwrite(result_image_path, result_image)</pre>
<p style="padding-left: 60px" class="mce-root">本例中的<kbd>deepfake</kbd>操作的最终结果是一个带有体操运动员的身体和作者的脸的图像:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1112 image-border" src="img/cb7b4948-d6ec-482f-a1fa-4f3a56f0558e.png" style="width:17.17em;height:19.50em;"/></p>
<p>通过逐帧应用该方法，可以将其扩展到视频。</p>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>像往常一样，首先导入适当的库(步骤1)。在步骤2中，指定样式和内容图像。这里，内容是目标图像，而样式是要绘制的面。在第3步中，请注意，如果图像中有几个人脸，将会出现一个屏幕，询问您想要使用哪个人脸。下一步是确定如何绘制叠加面的计算(步骤4)。完成该步骤后，我们现在可以在步骤5中绘制并显示<kbd>deepfake</kbd>叠加面。显然，这个实现还有改进的空间，但是做得还不错。</p>


            

            
        
    






    
        <title>Deepfake recognition</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">深度伪造识别</h1>
                
            
            
                
<p class="mce-root">随着deepfake和类似图像伪造技术的出现，越来越难区分伪造和真实媒体。幸运的是，就像神经网络可以合成假媒体一样，它们也可以检测到它。在这个食谱中，我们将利用深度神经网络来检测假图像。该配方利用了GitHub资源库中的MesoNet架构。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><p>该配方的准备工作包括在<kbd>pip</kbd>中安装<kbd>keras</kbd>、<kbd>tensorflow</kbd>和<kbd>pillow</kbd>。说明如下:</p>
</div>
<div><pre><strong>pip install keras tensorflow pillow</strong></pre>
<p>此外，在<kbd>mesonet_test_images</kbd>文件夹中还为您提供了一组假图像和真图像，您可以向其中添加其他图像。</p>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">在下面的步骤中，我们提供了一个检测deepfake何时生成图像的方法。代码由四部分组成:Deepfake <kbd>Recognition.ipynb</kbd> (main)、定义MesoNet分类器的<kbd>mesonet_classifiers.py</kbd>文件、保存训练好的权重的<kbd>mesonet_weights</kbd>文件夹以及包含我们的测试图像的<kbd>mesonet_test_images</kbd>文件夹。</p>
<p class="mce-root">下面的代码可以在Deepfake <kbd>Recognition.ipynb</kbd>中找到:</p>
<ol>
<li class="mce-root">从<kbd>keras</kbd>导入MesoNet神经网络和图像数据生成器:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">from mesonet_classifiers import *<br/>from keras.preprocessing.image import ImageDataGenerator</pre>
<ol start="2">
<li class="mce-root">实例化MesoNet并加载其权重:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">MesoNet_classifier = Meso4()<br/>MesoNet_classifier.load("mesonet_weights/Meso4_DF")</pre>
<ol start="3">
<li class="mce-root">创建图像数据生成器以从目录中读入图像，并指定存储未知图像的路径:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">image_data_generator = ImageDataGenerator(rescale=1.0 / 255)<br/>data_generator = image_data_generator.flow_from_directory(<br/>    "", classes=["mesonet_test_images"]<br/>)</pre>
<p style="padding-left: 60px">以下是输出:</p>
<pre style="padding-left: 60px">Found 3 images belonging to 1 classes.</pre>
<ol start="4">
<li class="mce-root">定义一个字典，将数字标签转换为文本标签，<kbd>"real"</kbd>和<kbd>"fake"</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">num_to_label = {1: "real", 0: "fake"}</pre>
<p style="padding-left: 60px" class="mce-root">在我们的例子中，我们在文件夹中放了三张图片，一张真的，两张假的:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1113 image-border" src="img/3d2752b4-ff56-4583-b0a1-5d89d389546f.png" style="width:19.83em;height:6.58em;"/></p>
<p style="padding-left: 60px">你能分辨出哪些是哪些吗？</p>
<ol start="5">
<li class="mce-root">运行MesoNet会显示以下输出:</li>
</ol>
<pre style="padding-left: 60px">X, y = data_generator.next()<br/>probabilistic_predictions = MesoNet_classifier.predict(X)<br/>predictions = [num_to_label[round(x[0])] for x in probabilistic_predictions]<br/>print(predictions)</pre>
<p style="padding-left: 60px">以下是输出:</p>
<pre style="padding-left: 60px">['real', 'fake', 'fake']</pre>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>对于大多数食谱，我们从导入必要的库开始。然后，我们在步骤2中加载MesoNet模型，即加载其结构和预训练的权重。为清楚起见，架构可在<kbd>MesoNet_classifiers</kbd>文件中找到，如下所示:</p>
<pre class="mce-root">         x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))<br/>         x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)<br/>         x1 = BatchNormalization()(x1)<br/>         x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)<br/>         <br/>         x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)<br/>         x2 = BatchNormalization()(x2)<br/>         x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)<br/>         <br/>         x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)<br/>         x3 = BatchNormalization()(x3)<br/>         x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)<br/>         <br/>         x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)<br/>         x4 = BatchNormalization()(x4)<br/>         x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)<br/>         <br/>         y = Flatten()(x4)<br/>         y = Dropout(0.5)(y)<br/>         y = Dense(16)(y)<br/>         y = LeakyReLU(alpha=0.1)(y)<br/>         y = Dropout(0.5)(y)<br/>         y = Dense(1, activation = 'sigmoid')(y)</pre>
<p class="mce-root">在第3步中，我们定义并使用一个<kbd>ImageDataGenerator</kbd>，一个方便的<kbd>keras</kbd>对象，它允许我们在一个地方执行图像处理——在手头的例子中，重新缩放和归一化像素的数值。很难说标签<kbd>0</kbd>和<kbd>1</kbd>代表什么。出于这个原因，出于可读性的目的，我们定义了一个字典来将0和1翻译成单词<kbd>real</kbd>和<kbd>fake</kbd>(步骤4)。最后，在步骤5中，我们看到MesoNet模型能够正确预测测试图像的标签。</p>


            

            
        
    






    
        <title>Lie detection using machine learning</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">使用机器学习的测谎</h1>
                
            
            
                
<p class="mce-root">当出于社会工程的目的收集情报时，能够辨别一个人什么时候在说真话，什么时候在撒谎是至关重要的。为此，机器学习可以帮助我们。通过分析视频的微表情和声音质量，机器学习系统可以帮助识别不诚实的演员。在这份食谱中，我们将使用稍微修改过的“对我撒谎”进行测谎循环，这是一种使用面部和声音识别的测谎系统。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><p>该食谱的准备工作包括在<kbd>pip</kbd>中安装几个软件包。包的列表可以在<kbd>requirements.txt</kbd>文件中找到。要一次安装所有这些程序，请运行以下命令:</p>
</div>
<div><pre><strong>pip install -r requirements.txt</strong></pre>
<p>你需要一个带音频的视频文件来分析。</p>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">在下面的步骤中，我们提供了一个分析视频说谎行为的方法:</p>
<ol>
<li class="mce-root">运行“对我撒谎”应用程序:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>Python application.py</strong> </pre>
<ol start="2">
<li class="mce-root">通过转到指定的IP地址，例如<kbd>127.0.0.1:5000</kbd>，打开web浏览器并键入此地址，打开“对我撒谎”的门户。</li>
</ol>
<ol start="3">
<li class="mce-root">点击<strong>上传</strong>并选择您想要分析的视频:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1097 image-border" src="img/11288da4-2f84-4c91-95d7-ff9c6755378a.png" style="width:159.92em;height:75.42em;"/></p>
<ol start="4">
<li class="mce-root">一旦分析完成，您将注意到以下内容。</li>
</ol>
<p style="padding-left: 60px">以下截图显示了<strong>眨眼分析</strong>图中发生的变化:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1098 image-border" src="img/f8a14ee8-ae4a-41f8-9d12-6a382936c6d3.png" style="width:159.92em;height:63.25em;"/></p>
<p style="padding-left: 60px">以下截图显示了<strong>微表情分析</strong>图中发生的变化:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1099 image-border" src="img/37cbad82-7c4f-49c9-9244-4833f8a0d7be.png" style="width:159.92em;height:63.67em;"/></p>
<p style="padding-left: 60px">以下截图显示了<strong>声音能量分析</strong>图中发生的变化:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1100 image-border" src="img/3cbcdef4-2f40-424e-a442-d6ac9641429b.png" style="width:159.92em;height:62.33em;"/></p>
<p style="padding-left: 60px">以下截图显示了<strong>语音音高分析</strong>图中发生的变化:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1101 image-border" src="img/c1a025b9-ed03-47e4-9627-24da5b18cde5.png" style="width:159.92em;height:67.17em;"/></p>
<p style="padding-left: 60px">以下截图显示了<strong>语音音高轮廓分析</strong>图中发生的变化:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1102 image-border" src="img/d7763af6-b146-4219-bc7d-117c4858eb58.png" style="width:159.92em;height:61.00em;"/></p>
<p style="padding-left: 60px">以下截图显示了<strong>元音时长分析</strong>图中发生的变化:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1103 image-border" src="img/47bdbdee-d25d-4d57-87ce-590541dc5efd.png" style="width:159.75em;height:63.50em;"/></p>
<ol start="5">
<li>最后，点击结果会显示对视频中发现的谎言的分析:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1104 image-border" src="img/12a286af-cc3f-41bf-af79-068412c04c50.png" style="width:159.92em;height:71.67em;"/></p>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>在步骤1中，我们使用Python运行了“对我撒谎”应用程序。我们进入应用程序的门户并上传候选人视频(步骤2和3)。在完成视频分析后,“对我撒谎”应用程序会显示几个探索性屏幕(步骤4)。这些代表了可能表明说谎的特征。最后，在步骤5中，我们看到一个屏幕，显示该视频是否包含任何说谎的个人，如果是，何时以及说谎了多少次。</p>


            

            
        
    






    
        <title>Personality analysis</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">人格分析</h1>
                
            
            
                
<p>了解目标的性格类型和沟通方式会极大地增加潜在的影响力。因此，性格分析是社会工程师工具箱中的一个很好的工具。在这个菜谱中，我们将利用IBM Watson的Personality Insights API来分析目标的Tweets，以获得一个个性档案。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><p>这个菜谱的准备工作包括在<kbd>pip</kbd>中安装IBM Watson包。说明如下:</p>
</div>
<div><pre><strong>pip install ibm-watson</strong></pre>
<p>此外，你还需要注册一个沃森个性洞察账户。</p>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>在下面的步骤中，我们设置了一个API调用来分析tweets作者的个性:</p>
<ol>
<li>注册一个沃森个性洞察账户。它又快又免费。</li>
<li>为Watson导入Python库并记录今天的日期:</li>
</ol>
<pre style="padding-left: 60px">from ibm_watson import PersonalityInsightsV3<br/>from datetime import date<br/><br/>v = str(date.today())<br/>api_key = "fill me in"</pre>
<ol start="3">
<li>指定您在步骤1中获得的API键，并声明Personality Insights实例:</li>
</ol>
<pre style="padding-left: 60px">personality_insights_service = PersonalityInsightsV3(version=v, iam_apikey=api_key)</pre>
<ol start="4">
<li>管理一个文本文件，例如一组推文:</li>
</ol>
<pre style="padding-left: 60px">tweets_file = "ElonMuskTweets.txt"</pre>
<ol start="5">
<li>在文本文件中调用个性洞察API:</li>
</ol>
<pre style="padding-left: 60px">with open(tweets_file) as input_file:<br/>    profile = personality_insights_service.profile(<br/>        input_file.read(),<br/>        "application/json",<br/>        raw_scores=False,<br/>        consumption_preferences=True,<br/>    ).get_result()</pre>
<ol start="6">
<li>最后，打印出个性简介:</li>
</ol>
<pre style="padding-left: 60px">import json<br/><br/>print(json.dumps(profile, indent=2))<br/><br/>{ "word_count": 2463, "processed_language": "en", "personality": [ { "trait_id": "big5_openness", "name": "Openness", "category": "personality", "percentile": 0.7417085532819794, "significant": true, "children": [ { "trait_id": "facet_adventurousness", "name": "Adventurousness", "category": "personality", "percentile": 0.9589655282562557, "significant": true }, { "trait_id": "facet_artistic_interests", "name": "Artistic interests", "category": "personality", "percentile": 0.44854779978198406, "significant": true }, { "trait_id": "facet_emotionality", "name": "Emotionality", "category": "personality", "percentile": 0.0533351337262023, "significant": true },<br/> &lt;snip&gt;<br/> "consumption_preference_id": "consumption_preferences_books_financial_investing", "name": "Likely to read financial investment books", "score": 0.0 }, { "consumption_preference_id": "consumption_preferences_books_autobiographies", "name": "Likely to read autobiographical books", "score": 1.0 } ] }, { "consumption_preference_category_id": "consumption_preferences_volunteering", "name": "Volunteering Preferences", "consumption_preferences": [ { "consumption_preference_id": "consumption_preferences_volunteer", "name": "Likely to volunteer for social causes", "score": 0.0 } ] } ], "warnings": [] }</pre>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>首先注册一个沃森个性洞察账户。该服务有不同的层次，对API调用率有不同的限制，价格也不同，但最低的层次很容易设置，免费，而且对这个方法来说足够了。我们将今天的日期保存到一个变量中，并导入IBM Watson库(步骤2)。通过指定最晚日期，我们可以确保使用最新版本的Watson。下一步，我们使用API键实例化IBM Watson personality insights。</p>
<p>对于步骤4，我们必须整理由目标生成的文本数据集。利用Twitter鱼叉钓鱼机器人的配方来收集用户的推文可能会有所帮助。在第5步中，我们在我们的文本集上运行personality insights应用程序，该文本集由Elon Musk最近的推文组成。我们选择将个性资料显示为JSON。它也可以以其他格式显示，如CSV，详细信息可以在personality insights的API文档中找到。最后，在第6步中，我们打印了一个来自个性简介的小片段。如你所见，它甚至提供了可操作的见解，例如目标同意志愿服务的可能性有多大。</p>


            

            
        
    






    
        <title>Social Mapper</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">社交地图</h1>
                
            
            
                
<p><strong> Social Mapper </strong>是一款OSINT工具，可以让你通过面部识别将目标的大量社交媒体资料关联起来。它会自动在流行的社交媒体网站上搜索目标的名字和图片，毫不费力地找到用户的社交媒体资料，然后将结果输出到一份报告中，您可以用它来进一步调查。</p>
<p>Social Mapper的最大好处是，通过将姓名搜索与图像识别相结合，而不仅仅是姓名搜索，它可以消除误报，从而节省社会工程师的宝贵时间。</p>
<p>社交地图目前支持LinkedIn、脸书、Twitter、Google Plus、Instagram、VKontakte、微博和豆瓣。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p class="a-b-r-La">对于这个菜谱，建议您准备一个Python 2.7环境。社交映射器设计用于Python 2.7，可能不适用于其他Python环境。安装的先决条件在<a href="https://github.com/Greenwolf/social_mapper">https://github.com/Greenwolf/social_mapper</a>中描述。此外，你会想要使用Mac或Linux机器来制作这个食谱。</p>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>在以下步骤中，我们提供了使用社交映射器关联个人社交媒体账户的方法:</p>
<ol start="1">
<li>按照位于https://github.com/Greenwolf/social_mapper<a href="https://github.com/Greenwolf/social_mapper">的GitHub页面上的说明，安装Social Mapper及其先决条件。</a></li>
<li>将目标的脸部图像放入<kbd>Input, Examples/imagefolder/</kbd>中，并附上文件名和目标的全名:</li>
</ol>
<div><img class="alignnone size-full wp-image-1114 image-border" src="img/886752a2-59ff-46f1-bd42-96828f5dfa22.png" style="width:16.67em;height:16.67em;"/></div>
<ol start="3">
<li>为你希望搜索目标的社交媒体网站创建一次性账户。例如，创建一次性的脸书、LinkedIn和Twitter账户。</li>
<li>打开<kbd>social_mapper.py</kbd>文件并填写您的一次性帐户凭证。例如，你可能只对Twitter感兴趣:</li>
</ol>
<pre style="padding-left: 60px"> global linkedin_username<br/> global linkedin_password<br/> linkedin_username = ""<br/> linkedin_password = ""<br/> global facebook_username<br/> global facebook_password<br/> facebook_username = ""<br/> facebook_password = ""<br/> global twitter_username<br/> global twitter_password<br/> twitter_username = "FILL ME IN"<br/> twitter_password = "FILL ME IN"<br/> global instagram_username<br/> global instagram_password<br/> instagram_username = ""<br/> instagram_password = ""<br/> global google_username<br/> global google_password<br/> google_username = ""<br/> google_password = ""<br/> global vk_username<br/> global vk_password</pre>
<ol start="5">
<li>在终端中，运行命令搜索目标的社交媒体配置文件:</li>
</ol>
<pre style="padding-left: 60px"><strong> Python social_mapper.py -f imagefolder -I ./Input-Examples/imagefolder -m fast -tw</strong> </pre>
<ol start="6">
<li>检查<kbd>social_mapper/results-social-mapper.html</kbd>文件中的输出:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1105 image-border" src="img/d22a0574-be38-4681-b197-c5c9a9e765db.png" style="width:53.83em;height:13.25em;"/></p>
<p>对于每个目标个人，添加具有该个人的社交网络数据的附加行。</p>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>首先在您的环境中准备社交映射器(步骤1)。将目标的图像放入输入目录中(步骤2)。图像必须以目标的全名命名；否则，应用程序将无法找到目标的帐户。接下来，在步骤3中，为您希望搜索目标的社交媒体网站创建一次性账户，并将其填入<kbd>social_mapper.py</kbd>中的适当位置(步骤4)。请注意，您拥有的不同帐户越多，您可以通过社交地图收集的目标数据就越多。现在，您可以对目标执行搜索了。在终端中，运行命令搜索目标的社交媒体配置文件(步骤5)。您可能希望使用的参数和选项有很多种。例如，我们已经使用<kbd>-tw</kbd>参数指定了Twitter。然而，你可能希望添加额外的社交媒体网站，如LinkedIn ( <kbd>-li</kbd>)或Instagram ( <kbd>-ig</kbd>)。最后，在步骤6中，观察到社交映射器能够找到比尔·盖茨的Twitter账户。</p>


            

            
        
    






    
        <title>Fake review generator</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">假评论生成器</h1>
                
            
            
                
<p>社会工程的一个重要部分是模仿。一个社会工程师可能想要假装代表一个目前并不存在的公司或企业。通过创建一个档案，并填充令人信服的评论，社会工程师可以增加虚假业务的可信度。在这个食谱中，我们展示了如何训练RNN，使其能够生成新的评论，类似于训练数据集中的评论。</p>


            

            
        
    






    
        <title>Training a fake review generator</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">训练一个假评论生成器</h1>
                
            
            
                
<p>我们的第一步是训练模型。稍后，我们将利用它来生成新的评论。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><div><div><div><div><p>该配方的准备工作包括在<kbd>pip</kbd>中安装<kbd>keras</kbd>和<kbd>tensorflow</kbd>。说明如下:</p>
</div>
<div><pre><strong>pip install keras tensorflow</strong></pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>在下面的步骤中，我们提供了使用评论集训练递归神经网络(RNN)的方法:</p>
<ol>
<li>收集你想要模仿的评论类型。有关这方面的更多信息，请参见<em>中关于其工作原理的讨论...</em>章节:</li>
</ol>
<pre style="padding-left: 60px">with open("airport_reviews_short.csv", encoding="utf-8") as fp:<br/>    reviews_text = fp.read()</pre>
<ol start="2">
<li>创建一个字典来矢量化文本的字符:</li>
</ol>
<pre style="padding-left: 60px">chars_list = sorted(list(set(reviews_text)))<br/>char_to_index_dict = {<br/>    character: chars_list.index(character) for character in chars_list<br/>}</pre>
<p style="padding-left: 60px">词典可能是这样的，这取决于您的语料库包含哪些字符:</p>
<pre style="padding-left: 60px">{' ': 0, '!': 1, "'": 2, '(': 3, ')': 4, ',': 5, '-': 6, '.': 7, '/': 8, '2': 9, '5': 10, '&lt;': 11, '&gt;': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'L': 23, 'M': 24, 'O': 25, 'R': 26, 'S': 27, 'T': 28, 'U': 29, 'W': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54}</pre>
<ol start="3">
<li>构建一个RNN来学习和预测字符序列:</li>
</ol>
<pre style="padding-left: 60px">import keras<br/>from keras import layers<br/><br/>max_length = 40<br/>rnn = keras.models.Sequential()<br/>rnn.add(<br/>    layers.LSTM(1024, input_shape=(max_length, len(chars_list)), return_sequences=True)<br/>)<br/>rnn.add(layers.LSTM(1024, input_shape=(max_length, len(chars_list))))<br/>rnn.add(layers.Dense(len(chars_list), activation="softmax"))</pre>
<ol start="4">
<li>选择优化器并编译模型:</li>
</ol>
<pre style="padding-left: 60px">optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, nesterov=True)<br/>rnn.compile(loss="categorical_crossentropy", optimizer=optimizer)</pre>
<ol start="5">
<li>定义一个便利函数来矢量化文本:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/><br/>def text_to_vector(input_txt, max_length):<br/>    """Reads in the text and vectorizes it.<br/>    X will consist of consecutive sequences of characters. <br/>    Y will consist of the next character.<br/>    """<br/>    sentences = []<br/>    next_characters = []<br/>    for i in range(0, len(input_txt) - max_length):<br/>        sentences.append(input_txt[i : i + max_length])<br/>        next_characters.append(input_txt[i + max_length])<br/>    X = np.zeros((len(sentences), max_length, len(chars_list)))<br/>    y = np.zeros((len(sentences), len(chars_list)))<br/>    for i, sentence in enumerate(sentences):<br/>        for t, char in enumerate(sentence):<br/>            X[i, t, char_to_index_dict[char]] = 1<br/>            y[i, char_to_index_dict[next_characters[i]]] = 1<br/>    return [X, y]</pre>
<ol start="6">
<li>对我们的样本输入文本进行矢量化，并批量训练模型:</li>
</ol>
<pre style="padding-left: 60px">X, y = text_to_vector(reviews_text, max_length)<br/>rnn.fit(X, y, batch_size=256, epochs=1)</pre>
<ol start="7">
<li>最后，保存模型的权重以备将来使用。</li>
</ol>
<pre style="padding-left: 60px">rnn.save_weights("weights.hdf5")</pre>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>从收集你想要模仿的评论数据集开始(第一步)。一个实际的例子需要大量的评论。有许多这样的数据集可用，如Yelp评论数据集。继续第2步，我们创建字符和数字之间的映射。这将允许我们向量化文本。根据您的应用，您可能希望使用标准的ASCII代码。然而，如果你只使用少量的字符，那么这将会不必要地降低你的模型的速度。我们继续声明RNN的体系结构，以学习和预测字符序列(步骤3)。我们使用了相对简单的架构。正如下一节将要展示的，它仍然提供了令人信服的结果。有兴趣的读者可以自由尝试其他架构。接下来，我们声明一个(标准的)优化器(步骤4)，定义一个接收文本的函数，然后对其进行矢量化，以便我们可以将其输入到我们的神经网络中(步骤5)。在步骤5中，注意向量的形状如下:</p>
<ul>
<li><strong> X </strong>:(评论数，<kbd>maxlen</kbd>，字符数)</li>
<li><strong> Y </strong>:(评论数，字符数)</li>
</ul>
<p>特别是，我们设置<kbd>max_length=40</kbd>来简化计算，表明我们将只考虑评论的前<kbd>40</kbd>个字符。做好所有必要的准备后，我们现在传递要矢量化的文本，然后在其上训练我们的模型(步骤6)。具体来说，我们的<kbd>text_to_vector</kbd>函数获取文本并将其转换为矢量化的句子，以及一个矢量化的标签，即下面的字符。最后，我们保存模型的权重，这样我们就不必在将来重新训练它(步骤7)。</p>


            

            
        
    






    
        <title>Generating fake reviews</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">产生虚假评论</h1>
                
            
            
                
<p>训练了一个网络后，我们的下一步是利用它来产生新的虚假评论。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><div><div><div><div><p>该配方的准备工作包括在<kbd>pip</kbd>中安装<kbd>keras</kbd>和<kbd>tensorflow</kbd>。说明如下:</p>
</div>
<div><pre><strong>pip install keras tensorflow</strong></pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>在下面的步骤中，我们提供了一个使用先前训练过的RNN来生成评论的方法:</p>
<ol>
<li>我们将从导入<kbd>keras</kbd>开始:</li>
</ol>
<pre style="padding-left: 60px">import keras<br/>from keras import layers</pre>
<ol start="2">
<li>为角色创建一个索引字典，或者从上一个配方中加载一个:</li>
</ol>
<pre style="padding-left: 60px">char_indices = dict((char, chars.index(char)) for char in chars) </pre>
<ol start="3">
<li>读入种子文本并声明由神经网络接受的句子的<kbd>max_length</kbd>:</li>
</ol>
<pre style="padding-left: 60px">text = open("seed_text.txt").read()<br/>max_length = 40</pre>
<ol start="4">
<li>构建一个RNN模型，并加载您预先训练好的重量:</li>
</ol>
<pre style="padding-left: 60px">rnn = keras.models.Sequential()<br/>rnn.add(<br/>    layers.LSTM(1024, input_shape=(max_length, len(chars_list)), return_sequences=True)<br/>)<br/>rnn.add(layers.LSTM(1024, input_shape=(max_length, len(chars_list))))<br/>rnn.add(layers.Dense(len(chars_list), activation="softmax"))<br/>rnn.load_weights("weights.hdf5")<br/>optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, nesterov=True)<br/>rnn.compile(loss="categorical_crossentropy", optimizer=optimizer)</pre>
<ol start="5">
<li>定义从概率向量采样的函数:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/><br/>def sample_next_char(preds):<br/>    """Samples the subsequent character based on a probability distribution."""<br/>    return np.random.choice(chars_list, p=preds)</pre>
<ol start="6">
<li>根据初始种子文本生成随机评论:</li>
</ol>
<pre style="padding-left: 60px">import sys<br/><br/>start_index = np.random.randint(0, len(text) - max_length - 1)<br/>generated_text = text[start_index : start_index + max_length]<br/>sys.stdout.write(generated_text)<br/>sentence_length = 1000<br/>for i in range(sentence_length):<br/>    vec_so_far = np.zeros((1, max_length, len(chars_list)))<br/>for t, char in enumerate(generated_text):<br/>    vec_so_far[0, t, char_to_index_dict[char]] = 1.0<br/>preds = rnn.predict(vec_so_far)[0]<br/>next_char = sample_next_char(preds)<br/>generated_text += next_char<br/>generated_text = generated_text[1:]<br/>sys.stdout.write(next_char)<br/>sys.stdout.flush()<br/>print(generated_text)</pre>
<p>下面是代码运行的检查输出:</p>
<div><img class="alignnone size-full wp-image-1106 image-border" src="img/76e836af-49a3-417c-8a78-83248d10534e.png" style="width:38.25em;height:7.92em;"/></div>


            

            
        
    






    
        <title>How it works...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p>我们的初始步骤(步骤1、2和4)是我们在培训阶段执行的操作，我们在这里重复这些操作，以使配方是独立的。在步骤3中，我们读入一个种子文本来初始化我们的RNN。种子文本可以是由所列字符组成的任何文本，只要它比<kbd>max_length</kbd>长。现在，我们必须能够使用我们预先训练、预先加载并基于种子文本初始化的神经网络来创建有趣的文本。为此，我们定义一个便利函数来采样神经网络将生成的结果字符(步骤5)。从概率向量采样确保RNN不会简单地选择最可能的后续字符，从而导致重复生成文本。还有更聪明的采样方法，采用温度参数和指数称重，但这种方法解决了基本问题。最后，在第6步，我们继续使用我们的神经网络生成文本。我们指定1000作为要生成的字符数。改变这个参数将会改变输出中的评论数量。</p>


            

            
        
    






    
        <title>Fake news</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">假新闻</h1>
                
            
            
                
<p>假新闻是一种通过传统新闻媒体或在线社交媒体传播的虚假信息或宣传。像任何虚假信息运动一样，它的影响可能是毁灭性的。在这个菜谱中，您将加载一个真实和虚假新闻的数据集，并利用ML来确定新闻故事何时是虚假的。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><div><div><div><div><div><div><div><p>该配方的准备工作包括在<kbd>pip</kbd>安装<kbd>pandas</kbd>和scikit-learn。说明如下:</p>
</div>
<div><pre><strong>pip install pandas sklearn</strong></pre>
<p>还有，提取<kbd>fake_news_dataset.7z</kbd>。</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            

            
        
    






    
        <title>How to do it…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做…</h1>
                
            
            
                
<p>在以下步骤中，您将读入假新闻数据集，对其进行预处理，然后训练一个随机森林分类器来检测假新闻:</p>
<ol>
<li>导入<kbd>pandas</kbd>并读入CSV文件，<kbd>fake_news_dataset.csv</kbd>:</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/><br/>columns = [<br/>    "text",<br/>    "language",<br/>    "thread_title",<br/>    "spam_score",<br/>    "replies_count",<br/>    "participants_count",<br/>    "likes",<br/>    "comments",<br/>    "shares",<br/>    "type",<br/>]<br/>df = pd.read_csv("fake_news_dataset.csv", usecols=columns)</pre>
<ol start="2">
<li>通过关注英文文章并删除缺少值的行来预处理数据集:</li>
</ol>
<pre style="padding-left: 60px">df = df[df["language"] == "english"]<br/>df = df.dropna()<br/>df = df.drop("language", axis=1</pre>
<ol start="3">
<li>定义一个便利函数，将分类特征转换为数字特征:</li>
</ol>
<pre style="padding-left: 60px">features = 0<br/>feature_map = {}<br/><br/>def add_feature(name):<br/>    """Adds a feature to the dictionary of features."""<br/>    if name not in feature_map:<br/>        global features<br/>        feature_map[name] = features<br/>        features += 1</pre>
<ol start="4">
<li>将<kbd>"fake"</kbd>和<kbd>"real"</kbd>特征转换成数字:</li>
</ol>
<pre style="padding-left: 60px">add_feature("fake")<br/>add_feature("real")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>定义一个将所有标签转换成<kbd>real</kbd>或<kbd>fake</kbd>的函数:</li>
</ol>
<pre style="padding-left: 60px">def article_type(row):<br/>    """Binarizes target into fake or real."""<br/>    if row["type"] == "fake":<br/>        return feature_map["fake"]<br/>    else:<br/>        return feature_map["real"]</pre>
<ol start="6">
<li>将函数应用于数据帧，将标签转换为0和1:</li>
</ol>
<pre style="padding-left: 60px">df["type"] = df.apply(article_type, axis=1)</pre>
<ol start="7">
<li>在数据帧上创建列车测试分割:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.model_selection import train_test_split<br/><br/>df_train, df_test = train_test_split(df)</pre>
<ol start="8">
<li>实例化两个Tf-Idf矢量器，一个用于文章的文本，一个用于标题:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.feature_extraction.text import TfidfVectorizer<br/><br/>vectorizer_text = TfidfVectorizer()<br/>vectorizer_title = TfidfVectorizer()</pre>
<ol start="9">
<li>使用Tf-Idf矢量器拟合和转换文本和标题数据:</li>
</ol>
<pre style="padding-left: 60px">vectorized_text = vectorizer_text.fit_transform(df_train.pop("text").values)<br/>vectorized_title = vectorizer_title.fit_transform(df_train.pop("thread_title").values</pre>
<ol start="10">
<li>将数据帧的剩余数值字段转换成矩阵:</li>
</ol>
<pre style="padding-left: 60px">from scipy import sparse<br/><br/>spam_score_train = sparse.csr_matrix(df_train["spam_score"].values).transpose()<br/>replies_count_train = sparse.csr_matrix(df_train["replies_count"].values).transpose()<br/>participants_count_train = sparse.csr_matrix(<br/>    df_train["participants_count"].values<br/>).transpose()<br/>likes_train = sparse.csr_matrix(df_train["likes"].values).transpose()<br/>comments_train = sparse.csr_matrix(df_train["comments"].values).transpose()<br/>shares_train = sparse.csr_matrix(df_train["shares"].values).transpose()</pre>
<ol start="11">
<li>将所有矩阵合并为一个特征矩阵，并创建一组标签:</li>
</ol>
<pre style="padding-left: 60px">from scipy.sparse import hstack<br/><br/>X_train = hstack(<br/>    [<br/>        vectorized_text,<br/>        vectorized_title,<br/>        spam_score_train,<br/>        replies_count_train,<br/>        participants_count_train,<br/>        likes_train,<br/>        comments_train,<br/>        shares_train,<br/>    ]<br/>)<br/>y_train = df_train.pop("type").values</pre>
<ol start="12">
<li>实例化一个随机森林分类器，并根据训练数据对其进行训练:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.ensemble import RandomForestClassifier<br/><br/>clf = RandomForestClassifier()<br/>clf.fit(X_train, y_train)</pre>
<ol start="13">
<li>使用之前训练的Tf-Idf矢量器将测试数据的文本和标题转换成数字形式:</li>
</ol>
<pre style="padding-left: 60px">vectorized_text_test = vectorizer_text.transform(df_test.pop("text").values)<br/>vectorized_title_test = vectorizer_title.transform(df_test.pop("thread_title").values)</pre>
<ol start="14">
<li>如前所述，将所有数字特征组合成一个特征矩阵:</li>
</ol>
<pre style="padding-left: 60px">spam_score_test = sparse.csr_matrix(df_test["spam_score"].values).transpose()<br/>replies_count_test = sparse.csr_matrix(df_test["replies_count"].values).transpose()<br/>participants_count_test = sparse.csr_matrix(<br/>    df_test["participants_count"].values<br/>).transpose()<br/>likes_test = sparse.csr_matrix(df_test["likes"].values).transpose()<br/>comments_test = sparse.csr_matrix(df_test["comments"].values).transpose()<br/>shares_test = sparse.csr_matrix(df_test["shares"].values).transpose()<br/>X_test = hstack(<br/>    [<br/>        vectorized_text_test,<br/>        vectorized_title_test,<br/>        spam_score_test,<br/>        replies_count_test,<br/>        participants_count_test,<br/>        likes_test,<br/>        comments_test,<br/>        shares_test,<br/>    ]<br/>)<br/>y_test = df_test.pop("type").values</pre>
<ol start="15">
<li>测试随机森林分类器:</li>
</ol>
<pre style="padding-left: 60px">clf.score(X_test, y_test)</pre>
<p style="padding-left: 60px">以下是输出:</p>
<pre style="padding-left: 60px">0.9977324263038548</pre>


            

            
        
    






    
        <title>How it works…</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的…</h1>
                
            
            
                
<p>我们最初的步骤是导入假新闻数据集，并执行基本的数据管理(步骤1-6)，比如将目标转换成数字类型。接下来，在步骤7中，我们对数据集进行训练测试分割，为构建分类器做准备。因为我们在处理文本数据，所以我们必须特征化它们。为此，在步骤8和9中，我们在文本上实例化了用于NLP的Tf-Idf矢量器，并对它们进行拟合。其他的自然语言处理方法在这里可能是卓有成效的。继续特征化，我们提取数据帧的数字特征(步骤10和11)。完成数据集的特征化后，我们现在可以实例化一个基本分类器，并将其安装到数据集上(步骤12)。在步骤13-15中，我们在测试集上重复该过程，并测量我们的性能。观察卓越的性能。即使是现在，提高分类器性能的可能步骤包括说明文章的来源，包括图像，以及执行与其他事件的更复杂的关联。</p>


            

            
        
    


</body></html>