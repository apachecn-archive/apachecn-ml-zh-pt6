<html><head/><body>









<title>Chapter 8: Model Monitoring and Management Solutions</title>







<div><div><h1 class="chapter-number" id="_idParaDest-161"><a id="_idTextAnchor172"/> <a id="_idTextAnchor173"/> 8</h1>

<h1 id="_idParaDest-162"><a id="_idTextAnchor174"/>模型监控和管理解决方案</h1>

<p>在<a href="B18638_06.xhtml#_idTextAnchor132"> <em class="italic">第六章</em> </a>、<em class="italic"> SageMaker训练和调试解决方案</em>和<a href="B18638_07.xhtml#_idTextAnchor151"> <em class="italic">第七章</em> </a>、<em class="italic"> SageMaker部署解决方案</em>中，我们重点使用<strong class="bold"> SageMaker </strong>训练和部署<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)模型。如果您能够完成这些章节中介绍的动手解决方案，您应该能够使用其他算法和数据集执行类似类型的实验和部署。这两章是很好的起点，尤其是在开始使用托管服务时。然而，在某些时候，您将不得不使用它的其他功能来管理、排除故障和监视生产ML环境中的不同类型的资源。</p>

<p>使用SageMaker的一个明显优势是，数据科学家和ML实践者的许多经常执行的任务已经作为这种完全托管服务的一部分实现了自动化。这意味着我们通常不需要构建一个定制的解决方案，尤其是如果SageMaker已经有了那个能力或者特性的话。这些功能的例子包括<strong class="bold"> SageMaker调试器</strong>、<strong class="bold"> SageMaker特征库</strong>、<strong class="bold"> SageMaker训练编译器</strong>、<strong class="bold"> SageMaker推理推荐器</strong>、<strong class="bold"> SageMaker澄清</strong>、<strong class="bold"> SageMaker处理</strong>等等！如果我们需要使用这些功能中的一个或多个，我们需要做的就是使用<strong class="bold"> boto3 </strong>以及<strong class="bold"> SageMaker Python SDK </strong>，运行几行代码，在几个小时(甚至几分钟)内获得想要的功能和结果！).</p>

<p>在本章中，我们将重点介绍如何使用SageMaker内置的<strong class="bold">模型注册表</strong>，我们将使用它来注册和管理经过训练的ML模型。我们还将展示如何将模型从模型注册中心部署到ML推理端点的快速演示。除了模型注册之外，我们将使用<strong class="bold"> SageMaker模型监视器</strong>，这是另一个内置功能，我们将使用它来捕获和分析通过ML推理端点的数据。</p>

<p>在本章中，我们将讨论以下主题:</p>

<ul>

<li>将模型注册到SageMaker模型注册中心</li>

<li>从SageMaker模型注册中心部署模型</li>

<li>启用数据捕获和模拟预测</li>

<li>使用SageMaker型号监视器进行定期监控</li>

<li>分析捕获的数据</li>

<li>使用监控计划删除端点</li>

<li>清理</li>

</ul>

<p>一旦您完成了本章中的实践解决方案，您将更容易理解、使用和配置SageMaker的其他内置特性。考虑到这一点，我们开始吧！</p>

<h1 id="_idParaDest-163"><a id="_idTextAnchor175"/>技术先决条件</h1>

<p>开始之前，我们必须准备好以下内容:</p>

<ul>

<li>网络浏览器(最好是Chrome或Firefox)</li>

<li>访问AWS账户和本书第一章使用的<strong class="bold"> SageMaker Studio </strong>域名</li>

</ul>

<p>Jupyter笔记本、源代码和其他用于每章的文件都可以在本书的GitHub资源库中找到:<a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS">https://GitHub . com/packt publishing/Machine-Learning-Engineering-on-AWS</a>。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">运行本书中的示例时，建议使用具有有限权限的IAM用户，而不是root帐户。我们将在<a href="B18638_09.xhtml#_idTextAnchor187"> <em class="italic">第9章</em> </a>、<em class="italic">安全、治理和遵从性策略</em>中详细讨论这一点以及其他安全最佳实践。如果您刚刚开始使用AWS，您可以同时继续使用root帐户。</p>

<h1 id="_idParaDest-164"><a id="_idTextAnchor176"/>向SageMaker模型注册中心注册模型</h1>

<p>在<a href="B18638_06.xhtml#_idTextAnchor132"> <em class="italic">第六章</em> </a>，<em class="italic"> SageMaker训练和调试解决方案</em>中，我们<a id="_idIndexMarker905"/>使用<code>Estimator</code>实例的<a id="_idIndexMarker906"/><code>deploy()</code>方法，在使用<code>fit()</code>方法训练模型之后，立即将我们的ML模型部署到推理端点。当在生产中执行ML实验和部署时，在进行部署步骤之前，可能必须首先对模型进行分析和评估。执行分析的个人或团队将审查输入配置参数、训练数据和用于训练模型的算法，以及其他可用的相关信息。一旦数据科学团队不得不处理多个模型，使用<strong class="bold">模型注册中心</strong>管理和组织所有这些模型将变得更加容易<a id="_idIndexMarker907"/>。</p>

<p>什么是模型注册中心？模型注册中心是一个简单的存储库，致力于帮助数据科学家和ML实践者管理、组织和编目ML模型。在训练步骤之后，数据科学团队可以将训练好的ML模型存储在模型注册表中，并将其状态标记为<em class="italic">以供审查</em>或<em class="italic">待批准</em>。这将允许评审团队轻松定位要评审的模型，以及与这些模型<a id="_idIndexMarker909"/>相关联的历史和信息<a id="_idIndexMarker908"/>:</p>

<div><div><img alt="Figure 8.1 – Working with a model registry&#10;&#10;" height="588" src="img/B18638_08_001.jpg" width="958"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.1–使用模型注册中心</p>

<p>一旦评审团队完成了评审过程，并且批准了模型的部署，模型的状态现在就可以更改为<em class="italic"> Approved </em>，类似于上图所示。一旦ML模型的状态变为<em class="italic">已批准</em>，就可以使用<strong class="bold"> MLOps管道</strong>手动甚至自动部署。在<a id="_idIndexMarker910"/>中，除此之外，还可以触发其他自动操作，如自动报告和通知。</p>

<p class="callout-heading">注意</p>

<p class="callout">有关MLOps管道的更多信息，请随时查看第10章<a href="B18638_10.xhtml#_idTextAnchor215"/>、<em class="italic">亚马逊EKS上Kubeflow的机器学习管道</em>，以及<a href="B18638_11.xhtml#_idTextAnchor231"> <em class="italic">第11章</em> </a>、【SageMaker管道的机器学习管道。</p>

<p>既然您对数据科学团队如何使用模型注册中心来简化他们的工作有了更好的了解，那么您可能已经计划从头开始编写模型注册中心了！停在那里——sage maker已经为我们提供了一个！在本章<a id="_idIndexMarker912"/>的<a id="_idIndexMarker911"/>的后续页面中，我们将使用<a id="_idIndexMarker913"/><strong class="bold">bot O3</strong>库<a id="_idIndexMarker914"/> <a id="_idIndexMarker915"/>和<strong class="bold"> SageMaker Python SDK </strong>来利用SageMaker中可用的模型注册表。</p>

<h2 id="_idParaDest-165"><a id="_idTextAnchor177"/>在SageMaker Studio中创建新笔记本</h2>

<p>我们将通过打开SageMaker Studio并在新目录下创建一个新的Jupyter笔记本来开始本节<a id="_idIndexMarker917"/>的<a id="_idIndexMarker916"/>实践部分。</p>

<p class="callout-heading">注意</p>

<p class="callout">在继续之前，确保您已经完成了<em class="italic">第1章</em>、<em class="italic">AWS上的ML工程介绍</em>的<em class="italic">sage maker和SageMaker Studio </em>部分中的动手解决方案。请注意，本章的实际操作部分是<em class="italic">而不是</em>我们在<a href="B18638_06.xhtml#_idTextAnchor132"> <em class="italic">第6章</em> </a>、<em class="italic"> SageMaker培训和调试解决方案</em>和<a href="B18638_07.xhtml#_idTextAnchor151"> <em class="italic">第7章</em> </a>、<em class="italic"> SageMaker部署解决方案</em>中完成的内容的延续。</p>

<p>按照以下步骤启动SageMaker Studio，然后创建一个新的笔记本，用于运行本章中的Python脚本:</p>

<ol>

<li>在AWS管理控制台的搜索栏中导航到<code>sagemaker studio</code>，并从<strong class="bold">功能</strong>下的结果列表中选择<strong class="bold"> SageMaker Studio </strong>。</li>

</ol>

<p class="callout-heading">重要说明</p>

<p class="callout">本章假设我们在使用服务管理和创建不同类型的资源时使用了<code>us-west-2</code>区域。您可以使用不同的地区，但请确保进行必要的调整，以防某些资源需要转移到您选择的地区。</p>

<ol>

<li value="2">接下来，点击侧边栏中<strong class="bold"> SageMaker域</strong>下的<strong class="bold"> Studio </strong>。</li>

<li>点击<strong class="bold">启动app </strong>，如下图截图所示。从<a id="_idIndexMarker919"/>下拉选项的列表<a id="_idIndexMarker918"/>中选择<strong class="bold">工作室</strong>:</li>

</ol>

<div><div><img alt="Figure 8.2 – Opening SageMaker Studio&#10;&#10;" height="447" src="img/B18638_08_002.jpg" width="1018"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.2–打开SageMaker工作室</p>

<p class="list-inset">这将把你重定向到SageMaker工作室。等待几秒钟，让界面加载。</p>

<ol>

<li value="4">右键单击<strong class="bold">文件浏览器</strong>侧栏窗格中的空白区域，打开类似如下的上下文菜单:</li>

</ol>

<div><div><img alt="Figure 8.3 – Creating a new folder&#10;&#10;" height="366" src="img/B18638_08_003.jpg" width="860"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.3–创建新文件夹</p>

<p class="list-inset">选择<code>CH08</code>。</p>

<ol>

<li value="5">双击侧边栏中相应的文件夹名称，导航至<strong class="bold"> CH08 </strong>目录。</li>

<li>点击<strong class="bold">文件</strong>菜单，从<strong class="bold">新建</strong>子菜单下的选项列表中选择<strong class="bold">笔记本</strong>，创建一个<a id="_idIndexMarker920"/>新<a id="_idIndexMarker921"/>笔记本:</li>

</ol>

<div><div><img alt="Figure 8.4 – Creating a new Notebook&#10;&#10;" height="283" src="img/B18638_08_004.jpg" width="830"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.4–创建新笔记本</p>

<p class="list-inset">在前面的截图中，我们可以看到其他选项，包括创建一个新的<code>.ipynb</code>笔记本文件，它将用于运行不同的代码块。</p>

<ol>

<li value="7">在<code>Data Science</code>(在<strong class="bold"> SageMaker图像</strong>下找到的选项)</li>

<li><code>Python 3</code></li>

<li><code>No script</code></li>



<li>之后点击<strong class="bold">选择</strong>按钮。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">等待内核启动。在配置ML实例以运行Jupyter笔记本单元时，此步骤可能需要大约3到5分钟。</p>

<ol>

<li value="9">右键单击选项卡名称上的<a id="_idIndexMarker922"/>，如下图中突出显示的<a id="_idIndexMarker923"/>:</li>

</ol>

<div><div><img alt="Figure 8.5 – Renaming a notebook&#10;&#10;" height="278" src="img/B18638_08_005.jpg" width="1079"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.5–重命名笔记本</p>

<p class="list-inset">从上下文菜单的选项列表中选择<strong class="bold">重命名笔记本… </strong>。</p>

<ol>

<li value="10">在<code>01 - Registering Models to the SageMaker Model Registry.ipynb</code>下<strong class="bold">新名称</strong>。之后点击<strong class="bold">重命名</strong>按钮。</li>

</ol>

<p>现在我们的<a id="_idIndexMarker924"/>笔记本<a id="_idIndexMarker925"/>已经准备好了，我们可以继续向SageMaker模型注册中心注册预训练模型了！</p>

<h2 id="_idParaDest-166"><a id="_idTextAnchor178"/>使用boto3库将模型注册到SageMaker模型注册表</h2>

<p>在此<a id="_idIndexMarker926"/>部分，我们<a id="_idIndexMarker927"/>将<a id="_idIndexMarker928"/>使用存储在<code>.tar.gz</code>文件中的两个预训练模型。我们将在使用SageMaker的<strong class="bold"> K最近邻</strong>和<strong class="bold">线性学习器</strong>内置算法<a id="_idIndexMarker930"/>执行两个单独的ML训练作业<a id="_idIndexMarker929"/>生成的<code>.tar.gz</code>文件中存储和注册这些模型。这些模型接受<em class="italic"> x </em>和<em class="italic"> y </em>值作为输入，并返回一个预测的<em class="italic">标签</em>值作为输出。这些<em class="italic"> x </em>和<em class="italic"> y </em>值分别代表什么？让我们来看看:</p>

<div><div><img alt="Figure 8.6 – Predicting the preferred vaccination site&#10;&#10;" height="639" src="img/B18638_08_006.jpg" width="1650"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.6-预测首选疫苗接种地点</p>

<p>如前面的屏幕截图所示，这些<em class="italic"> x </em>和<em class="italic"> y </em>值对应于使用地图中的指定点作为参考的人口中某些成员居住的经过变换和缩放的坐标值。在第一轮疫苗接种中，这些成员中有几个选择了他们喜欢的疫苗接种地点。这些疫苗接种点标有适当的<em class="italic">标签</em>值—<em class="italic">0</em>、<em class="italic"> 1 </em>和<em class="italic"> 2 </em>。使用以前的疫苗接种地点数据作为我们的训练数据，我们能够生成两个模型，它们可以自动预测未接种成员的首选疫苗接种地点，给定一组坐标值——即<em class="italic"> x </em>和<em class="italic"> y </em>。</p>

<p>按照以下步骤下载上述两个预训练模型的工件，并在我们在上一节准备的<code>01 - Registering Models to the SageMaker Model Registry.ipynb</code>笔记本中的SageMaker模型注册表中注册这些工件:</p>

<ol>

<li value="1">我们<a id="_idIndexMarker931"/>将<a id="_idIndexMarker932"/>通过使用<code>wget</code>命令:<pre class="source-code">%%bash</pre> <pre class="source-code">mkdir -p <strong class="bold">tmp</strong></pre> <pre class="source-code"><strong class="bold">wget</strong> -O tmp/<strong class="bold">knn.model.tar.gz</strong> https://bit.ly/3yZ6qHE</pre> <pre class="source-code"><strong class="bold">wget</strong> -O tmp/<strong class="bold">ll.model.tar.gz</strong> https://bit.ly/3ahj1fd</pre>将预先训练好的模型工件下载到<code>tmp</code>目录来启动<a id="_idIndexMarker933"/></li>

</ol>

<p class="list-inset">在这里，我们下载了两个<code>.tar.gz</code>文件:</p>

<ul>

<li><code>knn.model.tar.gz</code>:包含预训练<strong class="bold"> K近邻</strong>模型的模型工件</li>

<li><code>ll.model.tar.gz</code>:包含预训练<strong class="bold">线性学习者</strong>模型的模型工件</li>

</ul>

<ol>

<li value="2">指定唯一的S3时段名称和前缀。确保在运行下面的代码块之前，用一个唯一的S3桶名替换了<code>&lt;INSERT S3 BUCKET HERE&gt;</code>的值:<pre class="source-code">s3_bucket = "<strong class="bold">&lt;INSERT S3 BUCKET HERE&gt;</strong>"</pre> <pre class="source-code">prefix = "chapter08"</pre></li>

</ol>

<p class="list-inset">确保您为不存在<em class="italic">也不存在</em>的S3存储桶指定了存储桶名称。如果您想重复使用您在前面章节中创建的一个桶，您可以这样做，但是请确保在设置和配置<strong class="bold"> SageMaker Studio </strong>的同一区域使用S3桶。</p>

<ol>

<li value="3">让我们创建一个S3桶，在这里我们将上传我们之前下载的<code>ll.model.tar.gz</code>和<code>knn.model.tar.gz</code>文件:<pre class="source-code">!<strong class="bold">aws s3 mb</strong> s3://{s3_bucket}</pre></li>

</ol>

<p class="list-inset">如果您计划重用您在前面章节中<a id="_idIndexMarker935"/>创建<a id="_idIndexMarker936"/>的现有S3 <a id="_idIndexMarker934"/>桶，您可以跳过这一步。</p>

<ol>

<li value="4">现在我们的S3存储桶已经准备好了，让我们准备S3路径，以便它们指向我们将要上传预先训练好的模型工件的地方:<pre class="source-code"><strong class="bold">ll_model_data</strong> = \</pre> <pre class="source-code">f's3://{s3_bucket}/{prefix}/models/<strong class="bold">ll.model.tar.gz</strong>'</pre> <pre class="source-code"><strong class="bold">knn_model_data</strong> = \</pre> <pre class="source-code">f's3://{s3_bucket}/{prefix}/models/<strong class="bold">knn.model.tar.gz</strong>'</pre></li>

</ol>

<p class="list-inset">注意，此时，<code>ll.model.tar.gz</code>和<code>knn.model.tar.gz</code>文件还不存在于<code>ll_model_data</code>和<code>knn_model_data</code>变量中存储的指定S3路径中。在这里，我们简单地准备了S3位置路径(字符串)来上传<code>.tar.gz</code>文件。</p>

<ol>

<li value="5">现在，让<a id="_idIndexMarker938"/>使用<code>aws s3 cp</code>命令将<code>.tar.gz</code>文件复制并上传到它们对应的S3位置:<pre class="source-code">!<strong class="bold">aws s3 cp</strong> tmp/<strong class="bold">ll.model.tar.gz</strong> {ll_model_data}</pre> <pre class="source-code">!<strong class="bold">aws s3 cp</strong> tmp/<strong class="bold">knn.model.tar.gz</strong> {knn_model_data}</pre></li>

</ol>

<p class="list-inset">这将把<code>ll.model.tar.gz</code>和<code>knn.model.tar.gz</code>文件从<code>tmp</code>目录上传到S3存储桶。</p>

<ol>

<li value="6">预训练的模型工件已经在S3，让我们继续获取用于训练这些模型的ML算法的ECR容器图像URI。我们将使用<code>retrieve()</code>函数为<strong class="bold">线性学习器</strong>和<strong class="bold"> K近邻</strong>算法:<pre class="source-code">from sagemaker.image_uris import retrieve</pre><pre class="source-code">ll_image_uri = <strong class="bold">retrieve</strong>(</pre><pre class="source-code">    "<strong class="bold">linear-learner</strong>", </pre><pre class="source-code">    region="us-west-2", </pre><pre class="source-code">    version="1"</pre><pre class="source-code">)</pre><pre class="source-code">knn_image_uri = <strong class="bold">retrieve</strong>(</pre><pre class="source-code">    "<strong class="bold">knn</strong>", </pre><pre class="source-code">    region="us-west-2", </pre><pre class="source-code">    version="1"</pre><pre class="source-code">)</pre></li>

<li>为<a id="_idIndexMarker941"/> SageMaker初始化<a id="_idIndexMarker939"/>客户端<a id="_idIndexMarker940"/>。我们将使用这个客户端来调用几个SageMaker APIs，这将帮助我们在后续的步骤中创建模型包和模型包组:<pre class="source-code">import boto3</pre> <pre class="source-code">client = boto3.client(service_name="<strong class="bold">sagemaker</strong>")</pre></li>

<li>接下来，定义<code>generate_random_string()</code>功能:<pre class="source-code">import string </pre><pre class="source-code">import random</pre><pre class="source-code">def <strong class="bold">generate_random_string()</strong>:</pre><pre class="source-code">    return ''.join(</pre><pre class="source-code">        random.sample(</pre><pre class="source-code">        string.ascii_uppercase,12)</pre><pre class="source-code">    )</pre></li>

</ol>

<p class="list-inset"><em class="italic">这是干什么用的？</em>我们将在创建新资源时使用<code>generate_random_string()</code>函数(在后续步骤中)。这将帮助我们为将要创建的每个资源生成一个随机标识符或标签。</p>

<ol>

<li value="9">准备好<code>generate_random_string()</code>函数后，让我们生成一个随机的<code>group_id</code>值。这将用于生成一个<em class="italic">包组名称</em> ( <code>package_group_name</code>)和一个<em class="italic">包组描述</em> ( <code>package_group_desc</code>)。然后，我们<a id="_idIndexMarker942"/>将<a id="_idIndexMarker943"/>使用boto3客户端的<code>create_model_package_group()</code>方法<pre class="source-code">group_id = <strong class="bold">generate_random_string()</strong></pre><pre class="source-code"><strong class="bold">package_group_name</strong> = f"group-{<strong class="bold">group_id</strong>}"</pre><pre class="source-code"><strong class="bold">package_group_desc</strong> = f"Model package group {<strong class="bold">group_id</strong>}"</pre><pre class="source-code">response = client.<strong class="bold">create_model_package_group</strong>(</pre><pre class="source-code">    ModelPackageGroupName=<strong class="bold">package_group_name</strong>,</pre><pre class="source-code">    ModelPackageGroupDescription=<strong class="bold">package_group_desc</strong></pre><pre class="source-code">)</pre><pre class="source-code">package_group_arn = response['ModelPackageGroupArn']</pre><pre class="source-code">package_group_arn</pre>创建<a id="_idIndexMarker944"/>模型包组</li>

<li>接下来，让我们定义<code>prepare_inference_specs()</code>函数，我们将在下一步使用它来配置和设置我们的模型包:<pre class="source-code">def <strong class="bold">prepare_inference_specs</strong>(image_uri, model_data):</pre><pre class="source-code">    return {</pre><pre class="source-code">        "Containers": [</pre><pre class="source-code">            {</pre><pre class="source-code">                "Image": image_uri,</pre><pre class="source-code">                "ModelDataUrl": model_data</pre><pre class="source-code">            }</pre><pre class="source-code">        ],</pre><pre class="source-code">        "SupportedContentTypes": [ </pre><pre class="source-code">            "text/csv" </pre><pre class="source-code">        ],</pre><pre class="source-code">        "SupportedResponseMIMETypes": [ </pre><pre class="source-code">            "application/json" </pre><pre class="source-code">        ],</pre><pre class="source-code">    }</pre></li>

</ol>

<p class="list-inset">这里，我们使用<a id="_idIndexMarker947"/><em class="italic">ECR容器图像URI </em>和<em class="italic">模型工件S3路径</em>作为输入参数，创建了一个准备并返回必要的嵌套配置<a id="_idIndexMarker945"/>结构<a id="_idIndexMarker946"/>的函数。</p>

<ol>

<li value="11">接下来，让我们定义一个名为<code>create_model_package()</code>的自定义函数。该功能接受<a id="_idIndexMarker948"/>几个输入参数值，如下所示:<ul><li>模型包组的<strong class="bold">亚马逊资源名称</strong> ( <strong class="bold"> ARN </strong> ) <em class="italic"/></li>

<li><em class="italic">推理规范配置</em></li>

<li>(可选)<code>boto3</code>客户端为SageMaker:<pre class="source-code">def <strong class="bold">create_model_package</strong>(</pre><pre class="source-code">        package_group_arn, </pre><pre class="source-code">        inference_specs, </pre><pre class="source-code">        client=client):</pre><pre class="source-code">    input_dict = {</pre><pre class="source-code">        "ModelPackageGroupName" : package_group_arn,</pre><pre class="source-code">        "ModelPackageDescription" : "Description",</pre><pre class="source-code">        "ModelApprovalStatus" : "Approved",</pre><pre class="source-code">        "InferenceSpecification" : inference_specs</pre><pre class="source-code">    }</pre><pre class="source-code">    </pre><pre class="source-code">    response = client.<strong class="bold">create_model_package</strong>(</pre><pre class="source-code">        **input_dict</pre><pre class="source-code">    )</pre><pre class="source-code">    return response["ModelPackageArn"]</pre></li>

</ul></li>

</ol>

<p class="list-inset">这里，我们<a id="_idIndexMarker949"/>在创建模型包时自动<a id="_idIndexMarker950"/>将<a id="_idIndexMarker951"/>的<code>ModelApprovalStatus</code>值设置为<code>Approved</code>。请注意，我们可以选择在将其转换到<code>Approved</code>之前先将值设置为<code>PendingManualApproval</code>。不过我们会把事情简化一点，直接把值设为<code>Approved</code>。</p>

<p class="callout-heading">注意</p>

<p class="callout">模型的批准状态可以用来标记和识别哪些模型可以部署到生产端点。理想情况下，ML模型在部署之前首先经过评估和人工批准。如果模型通过评估步骤，我们可以将批准状态设置为<code>Approved</code>。否则，我们将状态设置为<code>Rejected</code>。</p>

<ol>

<li value="12">使用<code>prepare_inference_specs()</code>函数为<strong class="bold"> K近邻</strong>和<strong class="bold">线性学习器</strong>模型包准备前提推理规范配置:<pre class="source-code">knn_inference_specs = <strong class="bold">prepare_inference_specs</strong>(</pre><pre class="source-code">    image_uri=knn_image_uri,</pre><pre class="source-code">    model_data=knn_model_data</pre><pre class="source-code">)</pre><pre class="source-code">ll_inference_specs = <strong class="bold">prepare_inference_specs</strong>(</pre><pre class="source-code">    image_uri=ll_image_uri,</pre><pre class="source-code">    model_data=ll_model_data</pre><pre class="source-code">)</pre></li>

<li>有了<a id="_idIndexMarker952"/><a id="_idIndexMarker953"/>推论<a id="_idIndexMarker954"/>规格配置准备好了，让我们用<code>create_model_package()</code>来创建模型包:<pre class="source-code">knn_package_arn = <strong class="bold">create_model_package</strong>(</pre> <pre class="source-code">    package_group_arn=package_group_arn,</pre> <pre class="source-code">    inference_specs=knn_inference_specs</pre> <pre class="source-code">)</pre> <pre class="source-code">ll_package_arn = <strong class="bold">create_model_package</strong>(</pre> <pre class="source-code">    package_group_arn=package_group_arn,</pre> <pre class="source-code">    inference_specs=ll_inference_specs</pre> <pre class="source-code">)</pre></li>

<li>最后，让我们使用IPython的<code>%store</code>魔法来存储<code>knn_package_arn</code>、<code>ll_package_arn</code>、<code>s3_bucket</code>和<code>prefix</code> : <pre class="source-code">%store <strong class="bold">knn_package_arn</strong></pre> <pre class="source-code">%store <strong class="bold">ll_package_arn</strong></pre> <pre class="source-code">%store <strong class="bold">s3_bucket</strong></pre> <pre class="source-code">%store <strong class="bold">prefix</strong></pre>的变量值</li>

</ol>

<p class="list-inset">我们将在本章的后续章节中使用这些存储的变量值。</p>

<p>至此，两个<a id="_idIndexMarker955"/>模型<a id="_idIndexMarker956"/>包<a id="_idIndexMarker957"/>已经创建完毕，可以使用了。</p>

<p class="callout-heading">注意</p>

<p class="callout">您可以使用<code>client.list_model_package_groups()</code>和<code>client.list_model_packages(ModelPackageGroupName='&lt;INSERT GROUP NAME&gt;')</code>查看已注册的模型包组和模型包列表。我们将把这个留给您作为练习！</p>

<h1 id="_idParaDest-167"><a id="_idTextAnchor179"/>从SageMaker模型注册中心部署模型</h1>

<p>在一个ML模型被注册到一个模型注册中心之后，有许多<a id="_idIndexMarker958"/>可能的后续步骤可用<a id="_idIndexMarker959"/>。在本节中，我们将集中于将第一个注册的ML模型(预训练的<strong class="bold">K-最近邻</strong>模型)手动<a id="_idIndexMarker960"/>部署到新的推理端点。在部署了第一个注册的ML模型之后，我们将继续在已经部署了第一个ML模型的<a id="_idIndexMarker961"/>相同端点中部署第二个注册的模型(预训练的<strong class="bold">线性学习器</strong>模型)，类似于下图所示:</p>

<div><div><img alt="Figure 8.7 – Deploying models from the model registry&#10;&#10;&#10;&#10;&#10;&#10;" height="683" src="img/B18638_08_007.jpg" width="1473"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.7–从模型注册中心部署模型</p>

<p>在这里，我们可以<a id="_idIndexMarker962"/>看到<a id="_idIndexMarker963"/>我们可以直接替换正在运行的ML推理端点内部署的ML模型，而无需创建新的单独的推理端点。这意味着我们不需要担心在我们的设置中改变“目标基础结构服务器”,因为模型替换操作是在幕后进行的。同时，SageMaker已经为我们自动化了这个过程，所以我们需要做的就是调用正确的API来启动这个过程。</p>

<p>这里，我们将继续我们在<em class="italic">将模型注册到SageMaker模型注册表</em>部分中停止的地方，并将两个注册的模型部署到一个ML推理端点。也就是说，我们将执行以下一组步骤:</p>

<ol>

<li value="1">点击<strong class="bold">文件</strong>菜单，从<strong class="bold">新建</strong>子菜单下的选项列表中选择<strong class="bold">笔记本</strong>，创建一个新笔记本。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">请注意，我们将在前面章节中使用的<code>01 - Registering Models to the SageMaker Model Registry.ipynb</code>笔记本文件旁边的<code>CH08</code>目录中创建新的笔记本。</p>

<ol>

<li value="2">在<code>Data Science</code>(在<strong class="bold"> SageMaker图像</strong>下找到的选项)</li>

<li><code>Python 3</code></li>

<li><code>No script</code></li>



</ol>

<p class="list-inset">之后点击<strong class="bold">选择</strong>按钮。</p>

<ol>

<li value="3">右键点击新笔记本的标签名称，选择<strong class="bold">新名称</strong>下的<code>02 - Deploying Models from the SageMaker Model Registry.ipynb</code>。点击<strong class="bold">重命名</strong>按钮。</li>

<li>现在我们<a id="_idIndexMarker964"/>已经准备好了<a id="_idIndexMarker965"/>新笔记本，让我们继续使用IPython: <pre class="source-code">%store -r <strong class="bold">knn_package_arn</strong></pre> <pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre>的<code>%store</code>魔法加载<code>knn_package_arn</code>和<code>ll_package_arn</code>的存储变量的值</li>

<li>让我们使用下面的代码块初始化一个<code>ModelPackage</code>实例:<pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker import ModelPackage</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">model = <strong class="bold">ModelPackage</strong>(</pre><pre class="source-code">    role=role,</pre><pre class="source-code">    model_package_arn=<strong class="bold">knn_package_arn</strong>,</pre><pre class="source-code">    sagemaker_session=session</pre><pre class="source-code">)</pre><pre class="source-code">model.predictor_cls = Predictor</pre></li>

</ol>

<p class="list-inset">这里我们传递了<em class="italic"> IAM执行角色</em>、<em class="italic"> K近邻模型包ARN </em>，以及初始化<code>ModelPackage</code>实例时的<code>Session</code>实例。</p>

<ol>

<li value="6">既然<a id="_idIndexMarker966"/>我们<a id="_idIndexMarker967"/>已经初始化了<code>ModelPackage</code>实例，我们将调用它的<code>deploy()</code>方法来将预训练的模型部署到实时推理端点:<pre class="source-code">from sagemaker.serializers import JSONSerializer</pre><pre class="source-code">from sagemaker.deserializers import JSONDeserializer</pre><pre class="source-code">predictor = model.<strong class="bold">deploy</strong>(</pre><pre class="source-code">    instance_type='ml.m5.xlarge', </pre><pre class="source-code">    initial_instance_count=1,</pre><pre class="source-code">    serializer=JSONSerializer(),</pre><pre class="source-code">    deserializer=JSONDeserializer()</pre><pre class="source-code">)</pre></li>

</ol>

<p class="list-inset">由于我们在上一步中将<code>predictor_class</code>属性设置为<code>Predictor</code>，因此<code>deploy()</code>方法将返回一个<code>Predictor</code>实例，而不是<code>None</code>。</p>

<p class="callout-heading">注意</p>

<p class="callout">完成模型部署大约需要5到10分钟。请随意喝杯咖啡或茶！</p>

<ol>

<li value="7">一旦我们的ML推理端点准备就绪，我们将使用<code>Predictor</code>实例的<code>predict()</code>方法执行一个样本预测来测试我们的设置:<pre class="source-code">payload = {</pre><pre class="source-code">    'instances': [</pre><pre class="source-code">        {</pre><pre class="source-code">          "features": [ <strong class="bold">1.5</strong>, <strong class="bold">2</strong> ]</pre><pre class="source-code">        },</pre><pre class="source-code">    ]</pre><pre class="source-code">}</pre><pre class="source-code">predictor.<strong class="bold">predict</strong>(data=payload)</pre></li>

</ol>

<p class="list-inset">该<a id="_idIndexMarker968"/>应<a id="_idIndexMarker969"/>产生等于或类似于<code>{'predictions': [{'predicted_label': 2.0}]}</code>的输出值。</p>

<ol>

<li value="8">接下来，我们来定义一下<code>process_prediction_result()</code>功能:<pre class="source-code">def <strong class="bold">process_prediction_result</strong>(raw_result):</pre> <pre class="source-code">    first = raw_result['predictions'][0]</pre> <pre class="source-code">    return first['predicted_label']</pre></li>

</ol>

<p class="list-inset">这将从<code>Predictor</code>实例的<code>predict()</code>方法返回的嵌套结构中提取<code>label</code>值。当然，函数中的代码假设我们在调用<code>predict()</code>方法时一次只传递一个有效载荷。</p>

<ol>

<li value="9">让我们定义一个自定义的<code>predict()</code>函数，它接受输入的<code>x</code>和<code>y</code>值，以及一个可选的<code>Predictor</code>实例参数值:<pre class="source-code">def <strong class="bold">predict</strong>(x, y, predictor=predictor):</pre><pre class="source-code">    payload = {</pre><pre class="source-code">        'instances': [</pre><pre class="source-code">            {</pre><pre class="source-code">              "features": [ x, y ]</pre><pre class="source-code">            },</pre><pre class="source-code">        ]</pre><pre class="source-code">    }</pre><pre class="source-code">    </pre><pre class="source-code">    raw_result = predictor.predict(</pre><pre class="source-code">        data=payload</pre><pre class="source-code">    )</pre><pre class="source-code">    </pre><pre class="source-code">    return process_prediction_result(raw_result)</pre></li>

<li>让我们使用<code>x</code>和<code>y</code> : <pre class="source-code">predict(x=3, y=4)</pre>的一组样本值来测试<a id="_idIndexMarker970"/>我们的<a id="_idIndexMarker971"/>自定义<code>predict()</code>函数</li>

</ol>

<p class="list-inset">这将返回等于或类似于<code>1.0</code>的预测<code>label</code>值。我们如何解释这个结果？居住在用指定输入值<code>x</code>和<code>y</code>表示的位置的顾客可能会去标记有标签<code>1</code>的接种点(即第二个接种点)。</p>

<p class="callout-heading">注意</p>

<p class="callout">随意修改<code>process_prediction_result()</code>函数，将得到的预测<code>label</code>值的类型转换成一个<em class="italic">整数</em>而不是一个<em class="italic">浮点数</em>。</p>

<ol>

<li value="11">接下来，我们来定义一下<code>test_different_values()</code>的功能:<pre class="source-code">from time import sleep</pre><pre class="source-code">def <strong class="bold">test_different_values</strong>(predictor=predictor):</pre><pre class="source-code">    for <strong class="bold">x</strong> in range(-3, 3+1):</pre><pre class="source-code">        for <strong class="bold">y</strong> in range(-3, 3+1):</pre><pre class="source-code">            label = <strong class="bold">predict</strong>(</pre><pre class="source-code">                        x=<strong class="bold">x</strong>, </pre><pre class="source-code">                        y=<strong class="bold">y</strong>, </pre><pre class="source-code">                        predictor=predictor</pre><pre class="source-code">                    )</pre><pre class="source-code">            print(f"x={x}, y={y}, label={label}")</pre><pre class="source-code">            sleep(0.2)</pre></li>

</ol>

<p class="list-inset">这里，我们只是使用<em class="italic"> x </em>和<em class="italic"> y </em>的不同值组合多次调用我们的自定义<code>predict()</code>函数(每次预测请求之间有200毫秒的延迟)。</p>

<ol>

<li value="12">在<a id="_idIndexMarker972"/>继续之前，让我们检查一下<a id="_idIndexMarker973"/>我们的<code>test_different_values()</code>功能是否按预期工作:<pre class="source-code"><strong class="bold">test_different_values()</strong></pre></li>

</ol>

<p class="list-inset">给定<em class="italic"> x </em>和<em class="italic"> y </em>的不同组合，这将向我们显示预测的<code>label</code>值。</p>

<ol>

<li value="13">接下来，让我们定义一个定制的<code>create_model()</code>函数，该函数利用boto3客户端的<code>create_model()</code>方法与SageMaker API一起工作:<pre class="source-code">import boto3</pre><pre class="source-code">client = <strong class="bold">boto3.client(service_name="sagemaker")</strong></pre><pre class="source-code">def <strong class="bold">create_model</strong>(model_package_arn, </pre><pre class="source-code">                 model_name, </pre><pre class="source-code">                 role=role, </pre><pre class="source-code">                 client=client):</pre><pre class="source-code">    container_list = [</pre><pre class="source-code">        {'ModelPackageName': model_package_arn}</pre><pre class="source-code">    ]</pre><pre class="source-code">    response = client.<strong class="bold">create_model</strong>(</pre><pre class="source-code">        ModelName = model_name,</pre><pre class="source-code">        ExecutionRoleArn = role,</pre><pre class="source-code">        Containers = container_list</pre><pre class="source-code">    )</pre><pre class="source-code">    </pre><pre class="source-code">    return response["ModelArn"]</pre></li>

<li>让我们定义<code>generate_random_string()</code>函数，我们将使用它来生成一个随机的模型名称。之后，我们将调用前面定义的自定义<code>create_model()</code>函数<a id="_idIndexMarker974"/>我们<a id="_idIndexMarker975"/>，传递我们<strong class="bold">线性学习器</strong>模型的模型包ARN以及生成的模型名称:<pre class="source-code">import string </pre><pre class="source-code">import random</pre><pre class="source-code">def <strong class="bold">generate_random_string</strong>():</pre><pre class="source-code">    return ''.join(</pre><pre class="source-code">        random.sample(</pre><pre class="source-code">        string.ascii_uppercase,12)</pre><pre class="source-code">    )</pre><pre class="source-code">model_name = f"ll-{<strong class="bold">generate_random_string()</strong>}"</pre><pre class="source-code">model_arn = <strong class="bold">create_model</strong>(</pre><pre class="source-code">    model_package_arn=<strong class="bold">ll_package_arn</strong>,</pre><pre class="source-code">    model_name=<strong class="bold">model_name</strong></pre><pre class="source-code">)</pre></li>

<li>接下来，我们来定义一下<code>create_endpoint_config()</code>函数:<pre class="source-code">def <strong class="bold">create_endpoint_config</strong>(</pre><pre class="source-code">        model_name, </pre><pre class="source-code">        config_name, </pre><pre class="source-code">        client=client):</pre><pre class="source-code">    response = client.<strong class="bold">create_endpoint_config</strong>(</pre><pre class="source-code">        EndpointConfigName = config_name,</pre><pre class="source-code">        ProductionVariants=[{</pre><pre class="source-code">            'InstanceType': "ml.m5.xlarge",</pre><pre class="source-code">            'InitialInstanceCount': 1,</pre><pre class="source-code">            'InitialVariantWeight': 1,</pre><pre class="source-code">            'ModelName': model_name,</pre><pre class="source-code">            'VariantName': 'AllTraffic'</pre><pre class="source-code">        }]</pre><pre class="source-code">    )</pre><pre class="source-code">    return response["EndpointConfigArn"]</pre></li>

</ol>

<p class="list-inset">这个函数<a id="_idIndexMarker976"/>简单地说就是<a id="_idIndexMarker977"/>利用SageMaker的boto3客户端的<code>create_endpoint_config()</code>方法来准备想要的端点配置。</p>

<ol>

<li value="16">使用我们在上一步中定义的<code>create_endpoint_config()</code>函数，让我们创建一个SageMaker ML推理端点配置:<pre class="source-code">config_name = f"config-{generate_random_string()}"</pre> <pre class="source-code">config_arn = <strong class="bold">create_endpoint_config</strong>(</pre> <pre class="source-code">    model_name=model_name,</pre> <pre class="source-code">    config_name=config_name</pre> <pre class="source-code">)</pre></li>

<li>现在，让我们使用<code>update_endpoint()</code>方法更新端点配置:<pre class="source-code">response = client.<strong class="bold">update_endpoint</strong>(</pre> <pre class="source-code">    EndpointName=predictor.endpoint_name,</pre> <pre class="source-code">    EndpointConfigName=config_name</pre> <pre class="source-code">)</pre></li>

</ol>

<p class="list-inset">这里，我们使用了在上一步中创建的端点配置。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">这里会发生什么？一旦我们调用了<code>update_endpoint()</code>方法，SageMaker将在后台执行所需的步骤来更新端点，并用最新端点配置中指定的新模型(<strong class="bold">线性学习器</strong>)替换旧的已部署模型(<strong class="bold"> K近邻</strong>)。注意，这只是我们可以使用<strong class="bold"> SageMaker Python SDK </strong>和<strong class="bold"> boto3 </strong>库实现的可能解决方案之一。其他可能的<a id="_idIndexMarker978"/>部署解决方案<a id="_idIndexMarker979"/>包括<strong class="bold">多模型端点</strong>、<strong class="bold"> A/B测试</strong>端点设置、使用<strong class="bold">推理管道模型</strong>的端点<a id="_idIndexMarker980"/>等等！我们不会深入研究这些其他变体和解决方案，所以请随意查看《亚马逊SageMaker烹饪书的<em class="italic">机器学习一书中的部署方法。</em></p>

<ol>

<li value="18">在<a id="_idIndexMarker981"/>继续进行<a id="_idIndexMarker982"/>的下一组步骤之前，让我们使用下面的代码块等待5分钟:<pre class="source-code">print('Wait for update operation to complete')</pre> <pre class="source-code"><strong class="bold">sleep</strong>(60*5)</pre></li>

</ol>

<p class="list-inset">这里，我们使用了<code>sleep()</code>函数，它接受一个输入值，该值等于我们希望代码等待或休眠的秒数。</p>

<p class="callout-heading">注意</p>

<p class="callout">我们使用<code>sleep()</code>函数等待5分钟，以确保更新端点操作已经完成(假设大约需要5分钟或更少的时间来完成)。</p>

<ol>

<li value="19">初始化一个<code>Predictor</code>对象，并将其附加到我们在本节前面准备的现有ML推理端点:<pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre> <pre class="source-code">    endpoint_name=predictor.endpoint_name,</pre> <pre class="source-code">    sagemaker_session=session,</pre> <pre class="source-code">    serializer=<strong class="bold">JSONSerializer()</strong>,</pre> <pre class="source-code">    deserializer=<strong class="bold">JSONDeserializer()</strong></pre> <pre class="source-code">)</pre></li>

<li>让我们通过使用一个样本有效载荷进行预测来测试我们的<a id="_idIndexMarker984"/>设置:<pre class="source-code">payload = {</pre><pre class="source-code">    'instances': [</pre><pre class="source-code">        {</pre><pre class="source-code">          "features": [ <strong class="bold">1.5</strong>, <strong class="bold">2</strong> ]</pre><pre class="source-code">        },</pre><pre class="source-code">    ]</pre><pre class="source-code">}</pre><pre class="source-code"><strong class="bold">predictor.predict(data=payload)</strong></pre></li>

</ol>

<p class="list-inset">这将产生一个结构类似于<code> {'predictions': [{'score': [0.04544410854578018, 0.3947080075740814, 0.5598478317260742], 'predicted_label': 2}]}</code>的输出值。</p>

<p class="list-inset">我们如何解释这个结果？居住在用指定的输入<code>x</code>和<code>y</code>值(即<em class="italic"> x </em> = <code>1.5</code>和<em class="italic"> y </em> = <code>2</code>)表示的位置的客户有以下概率:</p>

<ul>

<li><code>4.5%</code>前往首个疫苗接种点的概率(标签= 0)</li>

<li><code>39.5%</code>前往第二个接种点的概率(标签= 1)</li>

<li><code>56%</code>去第三个接种点的概率(标签= 2)</li>

</ul>

<p class="list-inset">假设第三个接种点具有最高的概率值，模型将<code>predicted_label</code>值设置为<code>2</code>(假设计数从0开始)。</p>

<p class="callout-heading">注意</p>

<p class="callout">请注意，部署的<strong class="bold">线性学习器</strong>模型返回了每个类别的<em class="italic">概率分数，以及<em class="italic">预测标签</em>，而我们在本节开始时部署的<strong class="bold"> k近邻</strong>模型仅返回了<em class="italic">预测标签</em>。当用来自不同实例家族的模型替换已部署的模型时，我们需要小心(这可能需要使用不同的算法容器映像进行推断)，因为新的模型可能涉及一组不同的输入和输出结构和值。</em></p>

<ol>

<li value="21">与我们之前在托管我们的<strong class="bold">K-最近邻</strong>模型的ML推理端点上执行的<a id="_idIndexMarker985"/>类似，我们将使用不同的值<em class="italic"> x </em>和<em class="italic"> y </em> : <pre class="source-code"><strong class="bold">test_different_values</strong>(predictor=predictor)</pre>来执行多个样本预测</li>

<li>使用<code>%store</code>魔法为<code>endpoint_name</code> : <pre class="source-code">endpoint_name = predictor.endpoint_name</pre> <pre class="source-code">%store <strong class="bold">endpoint_name</strong></pre>存储变量值</li>

</ol>

<p>如果你想知道为什么我们还没有删除ML推理端点…我们将重用这个端点<a id="_idIndexMarker987"/>并在下一节用它来演示<a id="_idIndexMarker988"/>如何使用SageMaker的模型监控功能和特性！</p>

<h1 id="_idParaDest-168"><a id="_idTextAnchor180"/>启用数据捕获和模拟预测</h1>

<p>在一个ML <a id="_idIndexMarker989"/>模型<a id="_idIndexMarker990"/>被部署到一个推理端点之后，它的质量需要被监控和检查，这样我们就可以在检测到质量问题或偏差时很容易地执行纠正措施。这类似于web应用程序开发，即使质量保证团队已经花了几天(或几周)来测试应用程序的最终版本，仍然有其他问题只有在web应用程序已经运行时才能检测到:</p>

<div><div><img alt="Figure 8.8 – Capturing the request and response data of the ML inference endpoint&#10;&#10;" height="628" src="img/B18638_08_008.jpg" width="1208"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.8–捕获ML推理端点的请求和响应数据</p>

<p>如上图所示，模型监控从捕获请求和响应数据开始，这些数据通过一个正在运行的ML推断端点。收集的数据将在后续步骤中使用单独的自动化任务或作业进行处理和分析，该任务或作业可以生成报告并标记问题或异常。如果我们在定制的web应用程序端点中部署ML模型，我们可能需要自己构建这个数据捕获和模型监控设置。然而，如果我们使用SageMaker，我们不需要从头开始编写任何代码，因为我们可以利用内置的模型监控功能，只需要启用和配置即可。</p>

<p class="callout-heading">注意</p>

<p class="callout">在我们的“首选疫苗接种位置预测”示例中，捕获的数据(理想情况下)包括输入值(<em class="italic"> x </em>和<em class="italic"> y </em>值)和输出值(预测的<em class="italic">标签</em>值)。</p>

<p>按照以下步骤在运行的ML推理端点中启用数据捕获，并使用随机生成的有效负载值模拟推理请求:</p>

<ol>

<li value="1">点击<strong class="bold">文件</strong>菜单，从<strong class="bold">新建</strong>子菜单下的<a id="_idIndexMarker991"/>选项列表<a id="_idIndexMarker992"/>中选择<strong class="bold">笔记本</strong>，创建一个新的笔记本。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">请注意，我们将在本章前面章节中使用的<code>01 - Registering Models to the SageMaker Model Registry.ipynb</code>和<code>02 - Deploying Models from the SageMaker Model Registry.ipynb</code>笔记本文件旁边的<code>CH08</code>目录中创建新笔记本。</p>

<ol>

<li value="2">在<code>Data Science</code>(在<strong class="bold"> SageMaker图像</strong>下找到的选项)</li>

<li><code>Python 3</code></li>

<li><code>No script</code></li>



</ol>

<p class="list-inset">之后点击<strong class="bold">选择</strong>按钮。</p>

<ol>

<li value="3">右键点击新笔记本的标签名称，选择<strong class="bold">新名称</strong>下的<code>03 - Enabling Data Capture and Simulating Predictions.ipynb</code>。点击<strong class="bold">重命名</strong>按钮。</li>

<li>现在我们已经准备好了新的笔记本，让我们使用IPython的<code>%store</code>魔法来加载<code>s3_bucket</code>、<code>prefix</code>、<code>ll_package_arn</code>和<code>endpoint_name</code> : <pre class="source-code">%store -r <strong class="bold">s3_bucket</strong></pre> <pre class="source-code">%store -r <strong class="bold">prefix</strong></pre> <pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre> <pre class="source-code">%store -r <strong class="bold">endpoint_name</strong></pre>的存储变量的值</li>

<li>初始化一个<code>Predictor</code>对象并将其附加到我们在本章<pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">from sagemaker.serializers import CSVSerializer</pre><pre class="source-code">from sagemaker.deserializers import CSVDeserializer</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre><pre class="source-code">    endpoint_name=endpoint_name,</pre><pre class="source-code">    sagemaker_session=session,</pre><pre class="source-code">    role=role,</pre><pre class="source-code">    serializer=<strong class="bold">CSVSerializer</strong>(),</pre><pre class="source-code">    deserializer=<strong class="bold">CSVDeserializer</strong>()</pre><pre class="source-code">)</pre>的<em class="italic">从SageMaker模型注册表</em>中准备的<a id="_idIndexMarker993"/>ML推理端点</li>

<li>接下来，让我们使用下面的代码块准备并初始化<code>DataCaptureConfig</code>实例:<pre class="source-code">from sagemaker.model_monitor import DataCaptureConfig</pre><pre class="source-code">base = f"s3://{s3_bucket}/{prefix}"</pre><pre class="source-code">capture_upload_path = f"{base}/data-capture"</pre><pre class="source-code"><strong class="bold">capture_config_dict</strong> = {</pre><pre class="source-code">    'enable_capture': True,</pre><pre class="source-code">    'sampling_percentage': 100,</pre><pre class="source-code">    'destination_s3_uri': capture_upload_path,</pre><pre class="source-code">    'kms_key_id': None,</pre><pre class="source-code">    'capture_options': ["REQUEST", "RESPONSE"],</pre><pre class="source-code">    'csv_content_types': ["text/csv"],</pre><pre class="source-code">    'json_content_types': ["application/json"]</pre><pre class="source-code">}</pre><pre class="source-code">data_capture_config = <strong class="bold">DataCaptureConfig</strong>(</pre><pre class="source-code">    **<strong class="bold">capture_config_dict</strong></pre><pre class="source-code">)</pre></li>

</ol>

<p class="list-inset">这里，我们<a id="_idIndexMarker995"/>为<a id="_idIndexMarker996"/>指定了一个<code>100</code>的<code>sampling_percentage</code>值，这意味着所有的数据都将被捕获。我们还通过<code>capture_options</code>配置值指定，我们计划捕获通过ML推理端点的请求和响应数据。</p>

<ol>

<li value="7">现在我们的配置已经准备好了，让我们调用<code>Predictor</code>实例的<code>update_data_capture_config()</code>方法:<pre class="source-code">%%time</pre> <pre class="source-code">predictor.<strong class="bold">update_data_capture_config</strong>(</pre> <pre class="source-code">    data_capture_config=data_capture_config</pre> <pre class="source-code">)</pre></li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">这大约需要5到15分钟才能完成。请随意喝杯咖啡或茶！</p>

<ol>

<li value="8">使用<code>%store</code>魔术<a id="_idIndexMarker997"/>到<a id="_idIndexMarker998"/>为<code>capture_upload_path</code> : <pre class="source-code">%store <strong class="bold">capture_upload_path</strong></pre>存储变量值</li>

<li>定义<code>generate_random_payload()</code>功能:<pre class="source-code">import random</pre> <pre class="source-code">def <strong class="bold">generate_random_payload</strong>():</pre> <pre class="source-code">    x = random.randint(-5,5)</pre> <pre class="source-code">    y = random.randint(-5,5)</pre> <pre class="source-code">    </pre> <pre class="source-code">    return f"{x},{y}"</pre></li>

<li>定义<code>perform_good_input()</code>和<code>perform_bad_input()</code>功能:<pre class="source-code">def <strong class="bold">perform_good_input</strong>(predictor):</pre><pre class="source-code">    print("&gt; PERFORM REQUEST WITH GOOD INPUT")</pre><pre class="source-code">    payload = generate_random_payload()</pre><pre class="source-code">    result = predictor.predict(data=payload)</pre><pre class="source-code">    print(result)</pre><pre class="source-code">def <strong class="bold">perform_bad_input</strong>(predictor):</pre><pre class="source-code">    print("&gt; PERFORM REQUEST WITH BAD INPUT")</pre><pre class="source-code">    payload = generate_random_payload() + ".50"</pre><pre class="source-code">    result = predictor.predict(data=payload)</pre><pre class="source-code">    print(result)</pre></li>

</ol>

<p class="callout-heading">重要说明</p>

<p class="callout">在这一点上，你可能想知道为什么我们把<em class="italic"> y </em>输入有效载荷的浮点值视为<em class="italic">错误输入</em>。请注意，这只是出于演示目的，因为我们计划<a id="_idIndexMarker999"/>配置<strong class="bold"> SageMaker模型监视器</strong>以便在<em class="italic">使用SageMaker模型监视器</em>部分配置约束时，将<em class="italic"> x </em>和<em class="italic"> y </em>的浮点输入值标记为无效值。</p>

<ol>

<li value="11">使用<code>perform_good_input()</code>函数运行一个包含“有效值:<pre class="source-code"><strong class="bold">perform_good_input</strong>(predictor)</pre>”的示例推理请求</li>

<li>使用<code>perform_bad_input()</code>函数运行一个包含“无效<a id="_idIndexMarker1001"/>值:<pre class="source-code"><strong class="bold">perform_bad_input</strong>(predictor)</pre>的样本推断<a id="_idIndexMarker1000"/>请求</li>

<li>定义<code>generate_sample_requests()</code>函数，交替调用<code>perform_good_input()</code>和<code>perform_bad_input()</code>函数:<pre class="source-code">from time import sleep</pre><pre class="source-code">def <strong class="bold">generate_sample_requests</strong>(predictor):</pre><pre class="source-code">    for i in range(0, 2 * 240):</pre><pre class="source-code">        print(f"ITERATION # {i}")</pre><pre class="source-code">        perform_good_input(predictor)</pre><pre class="source-code">        perform_bad_input(predictor)</pre><pre class="source-code">        </pre><pre class="source-code">        print("&gt; SLEEPING FOR 30 SECONDS")</pre><pre class="source-code">        sleep(30)</pre></li>

<li>一切准备就绪后，让我们使用<code>generate_sample_requests()</code>函数:<pre class="source-code"><strong class="bold">generate_sample_requests</strong>(predictor)</pre>向ML推理端点连续发送样本请求</li>

</ol>

<p class="callout-heading">重要说明</p>

<p class="callout">请注意，本节中的最后一步将每30秒连续发送一次样本推断请求，并循环480次。我们将让它继续运行，并继续下一部分。只有在完成本章的【SageMaker Model Monitor 部分的<em class="italic">预定监控后，我们才应停止<code>generate_sample_requests()</code>功能的执行。</em></p>

<p>此时，您<a id="_idIndexMarker1002"/>可能<a id="_idIndexMarker1003"/>想知道数据存储在哪里，以及这些数据将如何用于分析。在接下来的几节中，我们将回答这些问题，并提供更多关于SageMaker中模型监控如何工作的细节。</p>

<h1 id="_idParaDest-169"><a id="_idTextAnchor181"/>使用SageMaker型号监控器进行计划监控</h1>

<p>如果您已经在数据科学和ML行业工作了相当长一段时间，您可能知道ML模型在部署后的性能没有保证。必须实时(或接近实时)监控生产中部署的模型，以便一旦检测到<a id="_idIndexMarker1005"/>任何<strong class="bold">漂移</strong>或与预期值集的偏差，我们可以替换部署的模型并修复任何问题:</p>

<div><div><img alt="Figure 8.9 – Analyzing captured data and detecting violations using Model Monitor &#10;&#10;&#10;&#10;&#10;&#10;" height="637" src="img/B18638_08_009.jpg" width="1330"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.9–使用模型监视器分析捕获的数据并检测违规</p>

<p>在上图中，我们可以看到，我们可以通过一个监视(处理)作业来处理和分析捕获的数据。这项工作预计将生成一个自动化的报告，可用于分析部署的模型和数据。同时，任何检测到的<a id="_idIndexMarker1006"/>违规都会被标记并作为报告的一部分进行报告。</p>

<p class="callout-heading">注意</p>

<p class="callout">假设我们已经训练了一个ML模型，该模型在给定专业人员的<em class="italic">年龄</em>、<em class="italic">工作经验年限</em>、<em class="italic">角色</em>和<em class="italic">子女数量</em>的情况下，预测该专业人员的<em class="italic">工资</em>。一旦ML模型被部署到推理端点，各种应用程序就会向ML推理端点发送请求数据，以获得预测的工资值。<em class="italic">如果其中一个应用程序开始发送错误的值，该怎么办？</em>例如，为输入有效载荷中的<em class="italic">子节点数量</em>指定的值为负。鉴于该字段不可能有负数，监控作业应该将该违反<a id="_idIndexMarker1007"/>标记为<strong class="bold">数据质量问题</strong>。</p>

<p>在本节中，我们将配置<strong class="bold"> SageMaker Model Monitor </strong>来使用计划的每小时处理作业分析捕获的数据。一旦处理作业结果准备就绪，我们将看到监视作业已经标记了一个违规，该违规是由于将“错误输入”作为有效负载的一部分发送到上一节中的ML推断端点而导致的。模型监视器<a id="_idIndexMarker1008"/>可配置为检测关于<strong class="bold">数据质量</strong>、<strong class="bold">模型质量</strong>、<strong class="bold">偏差漂移</strong>和<strong class="bold">特征属性漂移</strong>的<a id="_idIndexMarker1009"/>违规<a id="_idIndexMarker1010"/>。在本节的<a id="_idIndexMarker1011"/>动手解决方案中，我们将只关注检测有关数据质量的违规行为。然而，检测其他类型的漂移和违规应该遵循一组类似的步骤，稍后将介绍这些步骤。</p>

<p>按照以下步骤配置<strong class="bold"> SageMaker模型监视器</strong>每小时运行一次监视任务，并分析通过ML推理端点捕获的数据:</p>

<ol>

<li value="1">点击<strong class="bold">文件</strong>菜单，从<strong class="bold">新建</strong>子菜单下的选项列表中选择<strong class="bold">笔记本</strong>，创建一个新笔记本。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">请注意，我们将在本章前面几节中创建的其他笔记本文件旁边的<code>CH08</code>目录中创建新笔记本。</p>

<ol>

<li value="2">在<a id="_idIndexMarker1012"/>中的<code>Data Science</code>(在<strong class="bold"> SageMaker图像</strong>下找到的选项)</li>

<li><code>Python 3</code></li>

<li><code>No script</code></li>



</ol>

<p class="list-inset">之后点击<strong class="bold">选择</strong>按钮。</p>

<ol>

<li value="3">右键点击新笔记本的标签名称，选择<strong class="bold">新名称</strong>下的<code>04 - Scheduled Monitoring with SageMaker Model Monitor.ipynb</code>。之后点击<strong class="bold">重命名</strong>按钮。</li>

<li>现在我们已经准备好了新的笔记本，让我们使用IPython的<code>%store</code>魔法来加载<code>s3_bucket</code>、<code>prefix</code>、<code>endpoint_name</code>和<code>ll_package_arn</code> : <pre class="source-code">%store -r <strong class="bold">s3_bucket</strong></pre> <pre class="source-code">%store -r <strong class="bold">prefix</strong></pre> <pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre> <pre class="source-code">%store -r <strong class="bold">endpoint_name</strong></pre> <pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre>的存储变量的值</li>

<li>初始化一个<code>Predictor</code>对象，并将其附加到我们在<a id="_idIndexMarker1013"/>中部署的ML推理端点上<em class="italic">从SageMaker模型注册表</em>部分部署模型:<pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre><pre class="source-code">    endpoint_name=endpoint_name,</pre><pre class="source-code">    sagemaker_session=session,</pre><pre class="source-code">    role=role</pre><pre class="source-code">)</pre></li>

<li>使用<code>wget</code>命令下载<code>baseline.csv</code>文件:<pre class="source-code">%%bash</pre> <pre class="source-code"><strong class="bold">mkdir</strong> -p tmp</pre> <pre class="source-code"><strong class="bold">wget</strong> -O tmp/<strong class="bold">baseline.csv</strong> <a href="https://bit.ly/3td5vjx">https://bit.ly/3td5vjx</a></pre></li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout"><code>baseline.csv</code>文件是干什么用的？该CSV文件稍后将用作<strong class="bold">基线数据集</strong>，该数据集<a id="_idIndexMarker1014"/>将被<strong class="bold"> SageMaker模型监视器</strong>用作“参考”，以检查捕获数据的偏差和问题。</p>

<ol>

<li value="7">让我们也准备好S3路径位置，我们将在这里存储基线分析输出文件:<pre class="source-code">base = f's3://{s3_bucket}/{prefix}'</pre> <pre class="source-code">baseline_source_uri = f'{base}/<strong class="bold">baseline.csv</strong>'</pre> <pre class="source-code">baseline_output_uri = f"{base}/baseline-output"</pre></li>

<li>使用<code>aws s3 cp</code>命令将<code>baseline.csv</code>文件从<code>tmp</code>目录上传到<code>baseline_source_uri</code> : <pre class="source-code">!aws s3 cp tmp/baseline.csv {baseline_source_uri}</pre>中存储的S3目标位置</li>

<li>使用以下代码块初始化和<a id="_idIndexMarker1015"/>配置<code>DefaultModelMonitor</code>实例:<pre class="source-code">from sagemaker.model_monitor import DefaultModelMonitor</pre><pre class="source-code"><strong class="bold">monitor_dict</strong> = {</pre><pre class="source-code">    'role': role,</pre><pre class="source-code">    'instance_count': 1,</pre><pre class="source-code">    'instance_type': 'ml.m5.large',</pre><pre class="source-code">    'volume_size_in_gb': 10,</pre><pre class="source-code">    'max_runtime_in_seconds': 1800,</pre><pre class="source-code">}</pre><pre class="source-code">default_monitor = <strong class="bold">DefaultModelMonitor</strong>(</pre><pre class="source-code">    **<strong class="bold">monitor_dict</strong></pre><pre class="source-code">)</pre></li>

</ol>

<p class="list-inset">这里，我们在处理捕获的数据时配置了<code>ml.m5.large</code>实例。</p>

<p class="callout-heading">注意</p>

<p class="callout">为了监控部署的ML模型和通过推理端点的数据，<code>monitor_dict</code>对应于用于监控ML模型和数据的SageMaker处理作业的配置。</p>

<ol>

<li value="10">让我们使用下面的代码块运行<a id="_idIndexMarker1017"/>基线作业:<pre class="source-code">%%time</pre><pre class="source-code">from sagemaker.model_monitor import dataset_format</pre><pre class="source-code">dataset_format = dataset_format.DatasetFormat.csv(</pre><pre class="source-code">    header=True</pre><pre class="source-code">)</pre><pre class="source-code"><strong class="bold">baseline_dict</strong> = {</pre><pre class="source-code">    'baseline_dataset': baseline_source_uri,</pre><pre class="source-code">    'dataset_format': dataset_format,</pre><pre class="source-code">    'output_s3_uri': baseline_output_uri,</pre><pre class="source-code">    'wait': True</pre><pre class="source-code">}</pre><pre class="source-code">default_monitor.<strong class="bold">suggest_baseline</strong>(</pre><pre class="source-code">    **<strong class="bold">baseline_dict</strong></pre><pre class="source-code">)</pre></li>

</ol>

<p class="list-inset">这里，我们使用了<code>baseline.csv</code>文件作为将通过ML推断端点的数据的预期属性的参考。假设<code>baseline.csv</code>文件中有一列只包含正整数。使用这个CSV文件作为基线，我们将能够配置<strong class="bold"> SageMaker模型监视器</strong>来标记负的或浮点输入值(对于所述列或特性)为“错误输入”</p>

<p class="callout-heading">注意</p>

<p class="callout">当然，检测违规和问题只是故事的一半。解决问题是另一半。</p>

<ol>

<li value="11">定义一个自定义的<code>flatten()</code>函数，它将帮助我们检查和查看数据帧中的一个字典<a id="_idIndexMarker1018"/>对象:<pre class="source-code">import pandas as pd</pre> <pre class="source-code">def <strong class="bold">flatten</strong>(input_dict):</pre> <pre class="source-code">    df = pd.json_normalize(input_dict)</pre> <pre class="source-code">    return df.head()</pre></li>

<li>下面我们来看一下由基线化作业生成的统计报表:<pre class="source-code">baseline_job = default_monitor.<strong class="bold">latest_baselining_job</strong></pre> <pre class="source-code">stats = baseline_job.<strong class="bold">baseline_statistics()</strong></pre> <pre class="source-code">schema_dict = stats.body_dict["features"]</pre> <pre class="source-code">flatten(<strong class="bold">schema_dict</strong>)</pre></li>

</ol>

<p class="list-inset">这将产生如下所示的数据帧:</p>

<div><div><img alt="Figure 8.10 – DataFrame containing the baseline statistics&#10;&#10;" height="197" src="img/B18638_08_010.jpg" width="1220"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.10–包含基线统计数据的数据帧</p>

<p class="list-inset">在这里，我们可以看到<code>baseline.csv</code>文件中每一列的<code>inferred_type</code>值，以及其他统计值。</p>

<ol>

<li value="13">接下来，让我们查看由基准作业准备的建议约束:<pre class="source-code">constraints = baseline_job.<strong class="bold">suggested_constraints()</strong></pre> <pre class="source-code">constraints_dict = constraints.body_dict["features"]</pre> <pre class="source-code">flatten(<strong class="bold">constraints_dict</strong>)</pre></li>

</ol>

<p class="list-inset">这将为我们提供一个类似如下的值的数据框架:</p>

<div><div><img alt="Figure 8.11 – DataFrame with the suggested constraints of each of the features&#10;&#10;" height="139" src="img/B18638_08_011.jpg" width="736"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.11–每个特征的建议约束的数据框架</p>

<p class="list-inset">在这里，我们可以<a id="_idIndexMarker1019"/>在分析了所使用的基线数据集之后，看到基线作业推荐的约束。</p>

<p class="callout-heading">注意</p>

<p class="callout">这些(建议的)约束将在稍后由基准数据集中的<code>a</code>使用。基准数据集中的约束应仅包含整数值，如果捕获的数据包含记录，处理作业将进行标记，其中列<code>a</code>值是浮点数。</p>

<ol>

<li value="14">接下来，我们将修改列<code>a</code>和<code>b</code>的约束(包含输入的<em class="italic"> x </em>和<em class="italic"> y </em>值)，并假设这些值的有效值是整数类型，而不是浮点数或小数:<pre class="source-code">constraints.body_dict['features'][1]['inferred_type'] = '<strong class="bold">Integral</strong>'</pre> <pre class="source-code">constraints.body_dict['features'][2]['inferred_type'] = '<strong class="bold">Integral</strong>'</pre> <pre class="source-code">constraints.<strong class="bold">save()</strong></pre></li>

</ol>

<p class="list-inset">一旦每小时处理作业分析了捕获的数据，<strong class="bold"> SageMaker模型监视器</strong>将把包含浮点值<em class="italic"> y </em>的有效负载标记为“错误输入”</p>

<p class="callout-heading">重要说明</p>

<p class="callout">如果我们将建议约束的列<code>a</code>和<code>b</code>的<code>inferred_type</code>值(分别包含<em class="italic"> x </em>和<em class="italic"> y </em>值)改为<code>'Fractional'</code>而不是<code>'Integral'</code>，会发生什么？由于由<em class="italic">启用数据捕获和模拟预测</em>部分中的<code>generate_sample_requests()</code>功能生成的有效载荷值涉及整数和浮点值的组合，<strong class="bold"> SageMaker模型监视器</strong>会将所有输入请求有效载荷标记为“良好输入”，并且不会报告任何检测到的违规。</p>

<ol>

<li value="15">让我们定义<code>generate_label()</code>函数，它将帮助我们在后面的步骤中为监视计划名称生成一个随机的字符串标签:<pre class="source-code">from sagemaker.model_monitor import (</pre><pre class="source-code">    CronExpressionGenerator</pre><pre class="source-code">)</pre><pre class="source-code">from string import ascii_uppercase</pre><pre class="source-code">import random</pre><pre class="source-code">def <strong class="bold">generate_label</strong>():</pre><pre class="source-code">    chars = random.choices(ascii_uppercase, k=5)</pre><pre class="source-code">    output = 'monitor-' + ''.join(chars)</pre><pre class="source-code">    return output</pre></li>

<li>让我们分别使用<code>baseline_statistics()</code>和<code>suggested_constraints()</code>方法加载基线统计数据和建议的约束:<pre class="source-code">s3_report_path = f'{base}/report'</pre> <pre class="source-code">baseline_statistics = default_monitor.<strong class="bold">baseline_statistics()</strong></pre> <pre class="source-code">constraints = default_monitor.<strong class="bold">suggested_constraints()</strong></pre></li>

<li>让我们准备一下<strong class="bold"> cron表达式</strong>，我们将在后面的步骤<pre class="source-code">cron_expression = <strong class="bold">CronExpressionGenerator.hourly()</strong></pre>中使用它来配置监控<a id="_idIndexMarker1023"/>作业，使其每小时运行一次</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">有关其他<a id="_idIndexMarker1024"/>支持的<strong class="bold"> cron表达式</strong>的更多详细信息，请随时查看<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml">https://docs . AWS . Amazon . com/sagemaker/latest/DG/model-monitor-schedule-expression . XHTML</a>。</p>

<ol>

<li value="18">准备好先决条件后，让我们使用<code>DefaultModelMonitor</code>实例的<code>create_monitoring_schedule()</code>方法创建监视时间表:<pre class="source-code"><strong class="bold">schedule_dict</strong> = {</pre><pre class="source-code">    'monitor_schedule_name': generate_label(),</pre><pre class="source-code">    'endpoint_input': predictor.endpoint,</pre><pre class="source-code">    'output_s3_uri': s3_report_path,</pre><pre class="source-code">    'statistics': baseline_statistics,</pre><pre class="source-code">    'constraints': constraints,</pre><pre class="source-code">    'schedule_cron_expression': cron_expression,</pre><pre class="source-code">    'enable_cloudwatch_metrics': True</pre><pre class="source-code">}</pre><pre class="source-code">default_monitor.<strong class="bold">create_monitoring_schedule</strong>(</pre><pre class="source-code">    **<strong class="bold">schedule_dict</strong></pre><pre class="source-code">)</pre></li>

</ol>

<p class="list-inset">在运行这个代码块之后，<code>schedule</code>运行一个<strong class="bold"> SageMaker处理</strong>作业(每小时一次),该作业处理<a id="_idIndexMarker1025"/>并监控已经捕获的数据。</p>

<p class="callout-heading">注意</p>

<p class="callout">如果您在使用<code>predictor.endpoint</code>时遇到反对警告或问题，您可以用<code>predictor.endpoint_name</code>代替。要了解更多关于使用2.x版本的<strong class="bold"> SageMaker Python SDK </strong>时的弃用(以及破坏性和非破坏性更改)的信息，请随时查看<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml">https://sagemaker.readthedocs.io/en/stable/v2.xhtml</a>。</p>

<ol>

<li value="19">让我们快速检查一下监视器的时间表属性:<pre class="source-code">flatten(default_monitor.<strong class="bold">describe_schedule()</strong>)</pre></li>

</ol>

<p class="list-inset">这将产生如下所示的数据帧:</p>

<div><div><img alt="Figure 8.12 – DataFrame describing the properties of the monitoring schedule&#10;&#10;" height="154" src="img/B18638_08_012.jpg" width="899"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.12–描述监控计划属性的数据框架</p>

<p class="list-inset">这里我们可以看到<code>MonitoringScheduleStatus</code>的值还是<code>Pending</code>。</p>

<ol>

<li value="20">使用<code>sleep()</code>功能等待5分钟后执行下一个单元格:<pre class="source-code">from time import sleep</pre> <pre class="source-code"><strong class="bold">sleep</strong>(300)</pre></li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">在这里，我们等待几分钟，同时创建监视计划(假设它是在5分钟内创建的)。</p>

<ol>

<li value="21">使用<code>DefaultModelMonitor</code>实例的<pre class="source-code">dm = default_monitor</pre> <pre class="source-code">monitoring_violations = \</pre> <pre class="source-code">dm.<strong class="bold">latest_monitoring_constraint_violations()</strong></pre> <pre class="source-code">monitoring_statistics = \</pre> <pre class="source-code">dm.<strong class="bold">latest_monitoring_statistics()</strong></pre>的<code>latest_monitoring_constraint_violations() </code>和<code>latest_monitoring_statistics()</code>方法，测试并加载监视器的约束违反和统计<a id="_idIndexMarker1026"/>的初始值集</li>

<li>定义<code>get_violations()</code>和<code>load_and_load_violations()</code>功能:<pre class="source-code">%%time</pre><pre class="source-code">from time import sleep</pre><pre class="source-code">def <strong class="bold">get_violations()</strong>:</pre><pre class="source-code">    return \</pre><pre class="source-code">    dm.<strong class="bold">latest_monitoring_constraint_violations()</strong></pre><pre class="source-code">def <strong class="bold">loop_and_load_violations</strong>():</pre><pre class="source-code">    for i in range(0, 2 * 120):</pre><pre class="source-code">        print(f"ITERATION # {i}")</pre><pre class="source-code">        print("&gt; SLEEPING FOR 60 SECONDS")</pre><pre class="source-code">        sleep(60)</pre><pre class="source-code">        </pre><pre class="source-code">        try:</pre><pre class="source-code">            v = get_violations()</pre><pre class="source-code">            violations = v</pre><pre class="source-code">            </pre><pre class="source-code">            if violations:</pre><pre class="source-code">                return violations</pre><pre class="source-code">        except:</pre><pre class="source-code">            pass</pre><pre class="source-code">    print("&gt; DONE!")</pre><pre class="source-code">    return None              </pre></li>

<li>调用<a id="_idIndexMarker1027"/>我们在上一步定义的<code>load_and_load_violations()</code>函数:<pre class="source-code"><strong class="bold">loop_and_load_violations()</strong></pre></li>

</ol>

<p class="list-inset">这应该会生成一组日志，如下所示:</p>

<div><div><img alt="Figure 8.13 – Logs generated while running the loop_and_load_violations() function&#10;&#10;" height="414" src="img/B18638_08_013.jpg" width="981"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.13–运行loop_and_load_violations()函数时生成的日志</p>

<p class="list-inset">在这里，我们简单地迭代并等待预定的模型监视器处理作业生成包含检测到的违规的分析报告，以及从捕获的数据中计算出的其他统计值。</p>

<p class="callout-heading">重要说明</p>

<p class="callout">完成此步骤可能需要一个小时或更长时间。随意拿一杯(更大的)咖啡或茶！在等待该步骤完成的同时，您可以继续本章下一节的动手解决方案，<em class="italic">分析捕获的数据</em>。</p>

<ol>

<li value="24">一旦<code>loop_and_load_violations()</code>函数完成运行，您就可以使用<code>DefaultModelMonitor</code>实例的<code>latest_monitoring_constraint_violations()</code>方法:<pre class="source-code">violations = dm.<strong class="bold">latest_monitoring_constraint_violations()</strong></pre> <pre class="source-code">violations.__dict__</pre>继续加载和检查检测到的违规</li>

</ol>

<p class="list-inset">这将为我们提供一个嵌套的值字典，类似于下面的代码:</p>

<pre class="list-inset1 source-code">{'body_dict': {'violations': [

  {'feature_name': 'b',

    'constraint_check_type': 'data_type_check',

    'description': '<strong class="bold">Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 50.0% of data is Integral.</strong>'}]

  },

 'file_s3_uri': 's3://&lt;BUCKET&gt;/chapter08/report/1-2022-05-23-14-39-16-279/monitor-YTADH/2022/05/23/16/constraint_violations.json',

 'kms_key': None,

 'session': None

}</pre>

<p class="list-inset">在这里，我们可以看到对于特性<code>b</code>(对应于<em class="italic"> y </em>输入值)我们有几个检测到的违规。为了更好地了解这些检测到的违规是什么，我们可以查看可用的描述–<code>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 50.0% of data is Integral</code>。</p>

<ol>

<li value="25">使用<code>DefaultModelMonitor</code>实例<pre class="source-code">monitoring_statistics = dm.<strong class="bold">latest_monitoring_statistics()</strong></pre> <pre class="source-code">monitoring_statistics.__dict__</pre>的<code>latest_monitoring_statistics()</code>方法加载并<a id="_idIndexMarker1029"/>检查统计数据</li>

</ol>

<p class="list-inset">这将为我们提供一个嵌套的值结构，如下所示:</p>

<pre class="list-inset1 source-code">{'body_dict': {'version': 0.0,

  'dataset': {'item_count': 190},

  'features': [{'name': 'label',

    'inferred_type': 'Integral',

    'numerical_statistics': {'common': {'num_present': 190, 'num_missing': 0},

     'mean': 1.2052631578947368,

     'sum': 229.0,

     'std_dev': 0.7362591679068381,

     'min': 0.0,

     'max': 2.0,

      ... (and more) ...</pre>

<p>那不是很容易吗？想象一下尝试自己构建这个！你可能要花几天时间自己从头开始编码和构建。</p>

<p>至此，您应该对如何配置和使用<strong class="bold"> SageMaker Model Monitor </strong>来检测模型和数据中的违规和潜在问题有了更好的了解。在清理我们在本章中创建和使用的资源之前，我们将看看关于<a id="_idIndexMarker1030"/>如何分析和处理模型监视器在S3桶中捕获和收集的数据的另一种方法。</p>

<h1 id="_idParaDest-170"><a id="_idTextAnchor182"/>分析捕获的数据</h1>

<p>当然，还有其他方法来处理被捕获并存储在S3桶中的数据。除了使用前一节中讨论的内置模型监控功能和特性，我们还可以从S3桶下载收集的ML推断端点数据，并直接在笔记本中进行分析。</p>

<p class="callout-heading">注意</p>

<p class="callout">仍然建议利用SageMaker的内置模型监控功能和特性。然而，了解这种方法将有助于我们解决在使用和运行SageMaker中可用的自动化解决方案时可能遇到的任何问题。</p>

<p>按照以下步骤使用各种Python库来处理、清理和分析在S3收集的ML推断数据:</p>

<ol>

<li value="1">点击<strong class="bold">文件</strong>菜单，从<strong class="bold">新建</strong>子菜单下的选项列表中选择<strong class="bold">笔记本</strong>，创建一个新的笔记本。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">请注意，我们将在本章前面几节中创建的其他笔记本文件旁边的<code>CH08</code>目录中创建新笔记本。</p>

<ol>

<li value="2">在<code>Data Science</code>(在<strong class="bold"> SageMaker图像</strong>下找到的选项)</li>

<li><code>Python 3</code></li>

<li><code>No script</code></li>



</ol>

<p class="list-inset">之后点击<strong class="bold">选择</strong>按钮。</p>

<ol>

<li value="3">右键点击新笔记本的<a id="_idIndexMarker1032"/>标签名称，选择<strong class="bold">新名称</strong>下的<code>05 - Analyzing the Captured Data.ipynb</code>。点击<strong class="bold">重命名</strong>按钮。</li>

<li>现在我们已经创建了我们的新笔记本，让我们使用来自<code>s3_bucket</code>和<code>capture_upload_path</code> : <pre class="source-code">%store -r <strong class="bold">s3_bucket</strong></pre> <pre class="source-code">%store -r <strong class="bold">capture_upload_path</strong></pre>的<code>%store</code>魔法</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">等等！<code>capture_upload_path</code>从何而来？在<em class="italic">启用数据捕获和模拟预测</em>部分，我们初始化<code>capture_upload_path</code>并将其值设置为S3路径，捕获的数据(属于<strong class="bold"> SageMaker模型监视器</strong>)将存储在该路径中。</p>

<ol>

<li value="5">获取每个生成的包含推理请求输入输出数据的<code>jsonl</code>文件的S3路径:<pre class="source-code">results = !<strong class="bold">aws s3 ls</strong> {capture_upload_path} --recursive</pre><pre class="source-code">processed = []</pre><pre class="source-code">for result in results:</pre><pre class="source-code">    partial = result.split()[-1]</pre><pre class="source-code">    path = f"s3://{s3_bucket}/{partial}"</pre><pre class="source-code">    processed.append(path)</pre><pre class="source-code">    </pre><pre class="source-code">processed</pre></li>

<li>使用<code>mkdir</code>命令:<pre class="source-code">!mkdir -p <strong class="bold">captured</strong></pre>创建<code>captured</code>目录<a id="_idIndexMarker1033"/></li>

<li>接下来，使用<code>aws s3 cp</code>命令将每个生成的<code>jsonl</code>文件复制到我们在上一步刚刚创建的<code>captured</code>目录中:<pre class="source-code">for index, path in enumerate(processed):</pre> <pre class="source-code">    print(index, path)</pre> <pre class="source-code">    !<strong class="bold">aws s3 cp</strong> {path} captured/{index}.jsonl</pre></li>

<li>定义<code>load_json_file()</code>功能:<pre class="source-code">import json</pre><pre class="source-code">def <strong class="bold">load_json_file</strong>(path):</pre><pre class="source-code">    output = []</pre><pre class="source-code">    </pre><pre class="source-code">    with open(path) as f:</pre><pre class="source-code">        output = [json.loads(line) for line in f]</pre><pre class="source-code">        </pre><pre class="source-code">    return output</pre></li>

<li>从<code>captured</code>目录下每个下载的<code>jsonl</code>文件中提取JSON值:<pre class="source-code">all_json = []</pre><pre class="source-code">for index, _ in enumerate(processed):</pre><pre class="source-code">    print(f"INDEX: {index}")</pre><pre class="source-code">    new_records = <strong class="bold">load_json_file</strong>(</pre><pre class="source-code">        f"captured/{index}.jsonl"</pre><pre class="source-code">    )</pre><pre class="source-code">    all_json = all_json + new_records</pre><pre class="source-code">    </pre><pre class="source-code">    </pre><pre class="source-code"><strong class="bold">all_json</strong></pre></li>

<li>使用<code>pip</code>安装<code>flatten-dict</code>库:<pre class="source-code">!pip3 install <strong class="bold">flatten-dict</strong></pre></li>

</ol>

<p class="list-inset">正如我们将在<a id="_idIndexMarker1034"/>的后续步骤中看到的，<code>flatten-dict</code>包在“展平”任何嵌套字典结构中是有用的。</p>

<ol>

<li value="11">在<code>all_json</code>列表中存储的第一个条目上测试<code>flatten-dict</code>库中的<code>flatten()</code>功能:<pre class="source-code">from flatten_dict import flatten</pre> <pre class="source-code">first = <strong class="bold">flatten</strong>(all_json[0], reducer='dot')</pre> <pre class="source-code">first</pre></li>

</ol>

<p class="list-inset">这将为我们提供一个类似如下的扁平结构:</p>

<pre class="list-inset1 source-code">{'captureData.endpointInput.observedContentType': 'text/csv',

 'captureData.endpointInput.mode': 'INPUT',

 'captureData.endpointInput.data': '0,0',

 'captureData.endpointInput.encoding': 'CSV',

 'captureData.endpointOutput.observedContentType': 'text/csv; charset=utf-8',

 'captureData.endpointOutput.mode': 'OUTPUT',

 'captureData.endpointOutput.data': '2\n',

 'captureData.endpointOutput.encoding': 'CSV',

 'eventMetadata.eventId': 'b73b5e15-06ad-48af-b53e-6b8800e98678',

 'eventMetadata.inferenceTime': '2022-05-23T18:43:42Z',

 'eventVersion': '0'}</pre>

<p class="callout-heading">注意</p>

<p class="callout">我们将很快使用<code>flatten()</code>将存储在<code>all_json</code>中的嵌套JSON值转换成“扁平的”JSON值。这个“扁平化”的JSON值的列表将被转换成一个<strong class="bold">pandas</strong><strong class="bold">data frame</strong>(我们将在后面的步骤中处理和分析它)。</p>

<ol>

<li value="12">使用以下代码块展平存储在<code>all_json</code>列表中的每个<a id="_idIndexMarker1035"/> JSON值:<pre class="source-code">flattened_json = []</pre> <pre class="source-code">for entry in all_json:</pre> <pre class="source-code">    result = <strong class="bold">flatten</strong>(entry, reducer='dot')</pre> <pre class="source-code">    flattened_json.append(result)</pre> <pre class="source-code">    </pre> <pre class="source-code">flattened_json</pre></li>

<li>接下来，将展平的结构加载到pandas DataFrame: <pre class="source-code">import pandas as pd</pre> <pre class="source-code">df = pd.<strong class="bold">DataFrame</strong>(flattened_json)</pre> <pre class="source-code">df</pre></li>

</ol>

<p class="list-inset">这将产生如下所示的数据帧:</p>

<div><div><img alt="Figure 8.14 – DataFrame containing the collected monitoring data &#10;&#10;" height="346" src="img/B18638_08_014.jpg" width="1083"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.14–包含收集的监控数据的数据帧</p>

<p class="list-inset">在这里，我们可以看到收集到的端点数据在数据帧内变平。</p>

<ol>

<li value="14">现在，让我们通过从DataFrame列<code>captureData.endpointInput.data</code>中提取<em class="italic"> x </em>和<em class="italic"> y </em>值来稍微清理一下<a id="_idIndexMarker1036"/>的东西，data frame列包含输入请求数据:<pre class="source-code">df[['<strong class="bold">x</strong>', '<strong class="bold">y</strong>']] = df['captureData.endpointInput.data'].str.split(',', 1, expand=True)</pre></li>

<li>之后，让我们从DataFrame列<code>captureData.endpointOutput.data</code>中提取<code>label</code>值，它包含输出响应数据。将<code>label</code>值存储在名为<code>predicted_label</code> : <pre class="source-code">df['<strong class="bold">predicted_label</strong>'] = df['captureData.endpointOutput.data'].str.strip()</pre>的新列中</li>

<li>让我们准备<code>clean_df</code>数据帧，它只包含原来<code>DataFrame</code>的三列—<code>predicted_label</code>、<code>x</code>和<code>y</code> : <pre class="source-code">clean_df = df[['<strong class="bold">predicted_label</strong>', '<strong class="bold">x</strong>', '<strong class="bold">y</strong>']]</pre>、<pre class="source-code">clean_df.<strong class="bold">head()</strong></pre></li>

</ol>

<p class="list-inset">这将为我们提供如下所示的数据帧:</p>

<div><div><img alt="Figure 8.15 – DataFrame containing the values for predicted_label, x, and y&#10;&#10;" height="285" src="img/B18638_08_015.jpg" width="956"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.15–包含预测标签、x和y值的数据帧</p>

<p class="list-inset">在这里，我们可以看到<code>y</code>列的一些值是整数，而一些值是浮点格式。</p>

<ol>

<li value="17">接下来，让我们使用<code>astype</code>方法:<pre class="source-code">clean_df = clean_df.<strong class="bold">astype</strong>({</pre> <pre class="source-code">    'predicted_label': 'int',</pre> <pre class="source-code">    'x': 'float',</pre> <pre class="source-code">    'y': 'float',</pre> <pre class="source-code">})</pre> <pre class="source-code">clean_df.head()</pre>对<code>clean_df</code>数据帧中存储的值进行<a id="_idIndexMarker1037"/>类型转换</li>

</ol>

<p class="list-inset">这将为我们提供如下所示的数据帧:</p>

<div><div><img alt="Figure 8.16 – Values for x and y cast into floating-point values&#10;&#10;" height="295" src="img/B18638_08_016.jpg" width="898"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.16–x和y值转换成浮点值</p>

<p class="list-inset">现在，<code>x</code>和<code>y</code>列下的所有内容都是浮点格式。</p>

<p>此时，我们可以运行不同类型的分析，例如手动计算不同类型的统计数据，类似于由<strong class="bold"> SageMaker模型监视器</strong>自动执行的操作。我们还可以使用这种方法来解决<a id="_idIndexMarker1038"/>模型监视器处理作业在分析收集的数据时遇到的数据编码问题，类似于我们在<a href="https://github.com/aws/sagemaker-python-sdk/issues/1896">https://github.com/aws/sagemaker-python-sdk/issues/1896</a>所做的。</p>

<h1 id="_idParaDest-171"><a id="_idTextAnchor183"/>删除具有监控时间表的端点</h1>

<p>既然<a id="_idIndexMarker1039"/>我们已经使用完了我们的<a id="_idIndexMarker1040"/> ML推理端点，让我们删除它，连同附加的监视器和监视时间表。</p>

<p>按照以下步骤列出我们的ML推理端点的所有连接的监视器，并删除任何连接的监视时间表以及端点:</p>

<ol>

<li value="1">点击<strong class="bold">文件</strong>菜单，从<strong class="bold">新建</strong>子菜单下的选项列表中选择<strong class="bold">笔记本</strong>，创建一个新笔记本。</li>

</ol>

<p class="callout-heading">注意</p>

<p class="callout">请注意，我们将在本章前面几节中创建的其他笔记本文件旁边的<code>CH08</code>目录中创建新笔记本。</p>

<ol>

<li value="2">在<code>Data Science</code>(在<strong class="bold"> SageMaker图像</strong>下找到的选项)</li>

<li><code>Python 3</code></li>

<li><code>No script</code></li>



</ol>

<p class="list-inset">之后点击<strong class="bold">选择</strong>按钮。</p>

<ol>

<li value="3">右键点击新笔记本的标签名称，选择<strong class="bold">新名称</strong>下的<code>06 - Deleting an Endpoint with a Monitoring Schedule.ipynb</code>。点击<strong class="bold">重命名</strong>按钮。</li>

<li>现在<a id="_idIndexMarker1041"/>我们<a id="_idIndexMarker1042"/>已经准备好了我们的新笔记本，让我们使用IPython的<code>%store</code>魔法来加载<code>endpoint_name</code> : <pre class="source-code">%store -r <strong class="bold">endpoint_name</strong></pre>的存储变量值</li>

<li>使用以下代码块初始化<code>Predictor</code>实例并将其附加到现有的ML推理端点:<pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre><pre class="source-code">    endpoint_name=<strong class="bold">endpoint_name</strong>,</pre><pre class="source-code">    sagemaker_session=session,</pre><pre class="source-code">    role=role</pre><pre class="source-code">)</pre></li>

<li>在下一步删除之前，让我们快速列出所有连接的显示器:<pre class="source-code">monitors = predictor.<strong class="bold">list_monitors()</strong></pre> <pre class="source-code">for monitor in monitors:</pre> <pre class="source-code">    print(monitor.<strong class="bold">__dict__</strong>)</pre></li>

</ol>

<p class="list-inset">这里，我们使用了<code>__dict__</code>属性来检查监视器实例的属性。</p>

<ol>

<li value="7">让我们使用<code>delete_monitoring_schedule()</code>方法删除每一个监视器:<pre class="source-code">for monitor in monitors:</pre> <pre class="source-code">    monitor.<strong class="bold">delete_monitoring_schedule()</strong></pre></li>

</ol>

<p class="list-inset">这将产生类似于<code>Deleting Monitoring Schedule with name: monitor-HWFEL</code>的输出。</p>

<ol>

<li value="8">最后，让我们使用<code>delete_endpoint()</code>方法删除推理端点:<pre class="source-code">predictor.<strong class="bold">delete_endpoint()</strong></pre></li>

</ol>

<p>确保<a id="_idIndexMarker1043"/><a id="_idIndexMarker1044"/>你也停止了本章用到的笔记本中任何正在运行的单元格的执行。</p>

<h1 id="_idParaDest-172"><a id="_idTextAnchor184"/>打扫卫生</h1>

<p>既然我们已经完成了本章的动手解决方案，是时候清理并关闭我们不再使用的资源了。按照以下步骤定位并关闭<strong class="bold"> SageMaker Studio </strong>中任何剩余的运行实例:</p>

<ol>

<li value="1">点击侧边栏中的<strong class="bold">运行实例和内核</strong>图标，如下图所示:</li>

</ol>

<div><div><img alt="Figure 8.17 – Turning off the running instance&#10;&#10;" height="303" src="img/B18638_08_017.jpg" width="1010"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.17–关闭正在运行的实例</p>

<p class="list-inset">点击<strong class="bold">运行实例和内核</strong>图标将打开并显示SageMaker Studio中运行的实例、应用和终端。</p>

<ol>

<li value="2">通过单击每个实例的<strong class="bold">关闭</strong>按钮，关闭<strong class="bold">运行实例</strong>下的所有运行实例，如前面截图中突出显示的。点击<strong class="bold">关闭</strong>按钮将打开一个弹出窗口，验证实例<a id="_idIndexMarker1046"/>关闭操作。点击<strong class="bold">关闭所有</strong>按钮继续。</li>

</ol>

<p class="callout-heading">重要说明</p>

<p class="callout">确保你关闭了<strong class="bold">编辑器</strong>面板中打开的笔记本标签。在某些情况下，当SageMaker检测到有打开的笔记本标签时，它会自动打开一个实例。</p>

<ol>

<li value="3">确保检查并删除<strong class="bold"> SageMaker resources </strong>下所有正在运行的推理端点(如果有的话):</li>

</ol>

<div><div><img alt="Figure 8.18 – Checking the list of running inference endpoints&#10;&#10;" height="601" src="img/B18638_08_018.jpg" width="990"/>

</div>

</div>

<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图8.18–检查正在运行的推理端点列表</p>

<p class="list-inset">要检查是否有正在运行的推理端点，单击前面截图中突出显示的<strong class="bold"> SageMaker resources </strong>图标，然后从下拉菜单的选项列表中选择<strong class="bold">端点</strong>。</p>

<ol>

<li value="4">最后，打开<strong class="bold">文件</strong>菜单，从可用选项列表中选择<strong class="bold">关闭</strong>。这应该确保SageMaker Studio中所有正在运行的实例也已经关闭。</li>

</ol>

<p>注意，该清理<a id="_idIndexMarker1047"/>操作需要在使用<strong class="bold"> SageMaker Studio </strong>后进行。SageMaker不会自动关闭这些资源，即使在不活动期间也是如此。</p>

<h1 id="_idParaDest-173"><a id="_idTextAnchor185"/>总结</h1>

<p>在这一章中，我们利用SageMaker中的模型注册中心来注册、组织和管理我们的ML模型。在部署存储在注册表中的ML模型之后，我们使用<strong class="bold"> SageMaker Model Monitor </strong>来捕获数据并运行处理作业，这些作业分析收集的数据并标记任何检测到的问题或偏差。</p>

<p>在下一章，我们将重点关注使用各种策略和解决方案来保护ML环境和系统。如果你真的想设计和构建安全的ML系统和环境，那么下一章就是为你准备的！</p>

<h1 id="_idParaDest-174"><a id="_idTextAnchor186"/>延伸阅读</h1>

<p>有关本章涵盖的主题的更多信息，请随时查阅以下资源:</p>

<ul>

<li><em class="italic"> SageMaker模型注册表——查看部署历史</em>(<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy-history.xhtml">https://docs . AWS . Amazon . com/sage maker/latest/DG/Model-Registry-deploy-History . XHTML</a>)</li>

<li><em class="italic"> SageMaker模型监视器——监视模型的数据和模型质量、偏差和可解释性</em>(<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.xhtml">https://docs . AWS . Amazon . com/sage maker/latest/DG/Model-Monitor . XHTML</a>)</li>

<li><em class="italic"> SageMaker Python SDK —亚马逊SageMaker模型监视器</em>(<a href="https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.xhtml">https://SageMaker . readthe docs . io/en/stable/Amazon _ SageMaker _ Model _ monitoring . XHTML</a>)</li>

</ul>

</div>

<div><div/>

</div>

</div>



</body></html>