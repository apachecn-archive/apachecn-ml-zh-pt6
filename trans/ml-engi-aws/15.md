

# 10

# 亚马逊 EKS 上 Kubeflow 的机器学习管道

在 [*第 9 章*](B18638_09.xhtml#_idTextAnchor187) 、*安全性、治理和遵从性策略*中，我们讨论了许多概念和解决方案，这些概念和解决方案关注于我们在处理**机器学习** ( **ML** )需求时需要担心的其他挑战和问题。到现在为止，你可能已经意识到 ML 从业者有很多责任和工作要做，要进行外部模型训练和部署！一旦一个模型被部署到产品中，我们就必须监控这个模型，并确保我们能够检测和管理各种各样的问题。除此之外，ML 工程师可能需要构建 ML 管道来自动化 ML 生命周期中的不同步骤。为了确保我们在生产中可靠地部署 ML 模型，以及简化 ML 生命周期，我们最好学习并应用**机器学习操作** ( **MLOps** )的不同原则。通过 MLOps，我们将利用来自**软件工程**、 **DevOps** 和**数据工程**的久经考验的工具和实践来生产 ML 模型。其中包括利用各种自动化技术将手动执行的 Jupyter 笔记本转换为自动化的 ML 工作流程和管道。

在本章中，我们将在 **Kubernetes** 和 **Amazon Elastic Kubernetes 服务** ( **EKS** )的基础上使用 **Kubeflow** 构建并运行一个自动化的 MLOps 管道。如果您想知道这些是什么，不要担心，因为我们稍后将详细讨论这些工具、平台和服务！一旦我们对它们的工作原理有了更好的理解，我们将在构建更复杂的管道时，更深入地研究推荐的策略和最佳实践，以及保护和扩展我们的设置。

也就是说，在本章中，我们将讨论以下主题:

*   深入库伯弗洛、库伯内特和 EKS
*   准备必要的先决条件
*   在亚马逊 EKS 上设置 Kubeflow
*   运行我们的第一条 Kubeflow 管道
*   使用 Kubeflow Pipelines SDK 构建 ML 工作流
*   清理
*   推荐的策略和最佳实践

一旦我们读到本章的结尾，我们应该对使用本章所学的工具、平台和服务来构建复杂的 ML 管道更有信心。

# 技术要求

开始之前，我们必须准备好以下内容:

*   网络浏览器(最好是 Chrome 或 Firefox)
*   访问在*创建您的 Cloud9 环境*和*增加 Cloud9 存储*部分准备的 Cloud9 环境 [*第 1 章*](B18638_01.xhtml#_idTextAnchor017) 、*AWS 上的 ML 工程介绍*

Jupyter 笔记本、源代码和每章使用的其他文件可以从这个资源库获得:[https://github . com/packt publishing/Machine-Learning-Engineering-on-AWS](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS)。

重要说明

建议您在运行本书中的示例时，使用具有有限权限的 IAM 用户，而不是 root 帐户。如果您刚刚开始使用 AWS，可以同时使用 root 帐户。

# 深入库伯弗洛、库伯内特斯和 EKS

在 [*第 3 章*](B18638_03.xhtml#_idTextAnchor060) 、*深度学习容器*中，我们了解到容器有助于保证应用运行环境的一致性。在上述章节的实践解决方案中，我们使用了两个容器——一个容器用于训练我们的深度学习模型，另一个容器用于部署模型。在较大的应用中，我们很可能会遇到运行各种应用、数据库和自动化脚本的多个容器的使用。管理这些容器并不容易，创建定制脚本来管理运行中容器的正常运行时间和伸缩是我们希望避免的开销。也就是说，建议你使用一个工具来帮助你专注于你需要完成的事情。可以帮助我们部署、扩展和管理容器化应用的可用工具之一是 Kubernetes。这是一个开源容器编排系统，为运行弹性分布式系统提供了一个框架。它在后台自动负责伸缩和故障转移工作——这意味着如果您的容器由于某种原因停止工作，Kubernetes 会自动替换它。很酷吧？当然，这只是可用的炫酷功能之一。除此之外，Kubernetes 还提供以下内容:

*   自动化部署和回滚
*   秘密(凭证)管理
*   管理网络流量并将其分配给容器
*   存储编排
*   通过根据 CPU 和 RAM 需求相应地安装容器来充分利用服务器(节点)

注意，这个列表并不详尽，在使用 Kubernetes 时还有更多可用的特性。使用 Kubernetes 时，我们必须很好地理解所使用的术语、概念和工具。在*图 10.1* 中，我们可以看到一个 Kubernetes 集群的例子:

![Figure 10.1 – An example Kubernetes cluster

](img/B18638_10_001.jpg)

图 10.1–Kubernetes 集群示例

让我们快速定义和描述*图 10.1* 中的一些概念:

*   **节点**:这个映射到一个包含正在运行的容器化应用的虚拟机或物理机(或者 EC2 实例)。
*   **集群**:这是一组节点(或服务器)。
*   **Pod** :这个是一组一个或多个应用容器，代表一个服务单元(在一个节点内运行)。
*   **控制平面**:这个管理工作节点(服务器)以及 Kubernetes 集群中的 pod。
*   **kubectl** :这是命令行工具，用于运行命令来管理 Kubernetes 资源。

请注意，这是一个简化的列表，因为我们不会深入本章中的其他概念和术语。了解它们应该足以帮助我们完成本章的动手解决方案。

当在 AWS 上运行 Kubernetes 时，建议您使用托管服务，如**亚马逊 EKS** ，它帮助我们在幕后管理许多事情——包括控制平面节点的可用性和可扩展性(这些节点专注于存储集群数据，确保应用可用性，以及集群中的其他重要流程和任务)。当使用亚马逊 EKS 时，我们不再需要担心控制平面实例的管理，因为 AWS 会自动扩展这些实例，并为我们替换任何不健康的实例。除此之外，亚马逊 EKS 帮助工程师在使用 Kubernetes 时无缝地与其他 AWS 服务和资源(例如， **AWS IAM** 、 **AWS 应用负载平衡器**和**亚马逊云观察**)合作。

注意

可以使用 Kubernetes 和亚马逊 EKS 来设置节点的自动缩放。这是使用解决方案配置的，例如 **Kubernetes 集群自动缩放器**。有关更多信息，请随时查看[https://AWS . github . io/AWS-eks-best-practices/cluster-auto scaling/](https://aws.github.io/aws-eks-best-practices/cluster-autoscaling/)。

管理 EKS 集群的主要工具是eks CTL 命令行工具。使用这个工具，只需一个命令就可以轻松地创建、更新和删除 EKS 集群。一旦集群可用，我们就可以继续使用其他工具，如**ku bectl**命令行工具来创建和管理集群中的 Kubernetes 资源。

由于 Kubernetes 的能力和潜力，许多其他工具都是在它的基础上构建的。其中包括**kube flow**——一个流行的开源 ML 平台，专注于帮助数据科学家和 ML 工程师在 Kubernetes 上编排和管理复杂的 ML 工作流。Kubeflow 汇集了数据科学家和 ML 工程师已经熟悉的数据科学和 ML 工具的集合。其中包括以下内容:

*   **JupyterHub**——这是一个 hub，帮助生成和管理多个 Jupyter 笔记本(数据科学家可以在这里运行 ML 实验的代码)。
*   **Argo 工作流**–这个是一个工作流引擎，自动化管道在其上运行。
*   这个支持快速部署无服务器容器(ML 模型可以在其中运行)。
*   **Istio**–这是一个服务网格，提供了一种轻松管理网络配置和集群中部署的微服务之间的通信的方法。
*   **MinIO**—这是一个多云端对象存储解决方案，原生于 Kubernetes。

有了 Kubeflow，ML 从业者可以执行 ML 实验和部署，而不用担心基础设施。同时，自动化的 ML 工作流和管道可以使用 Kubeflow 中可用的各种工具轻松部署和管理(例如 **Kubeflow 管道**和 **Kubeflow 管道 SDK** )。如果构建得当，这些管道可以帮助数据科学家和 ML 工程师通过 ML 过程不同步骤的自动化节省大量时间。同时，这些管道可以实现自动化的模型再训练，这将有助于确保使用最新的可用训练数据来更新部署的模型。

现在我们对将要使用的工具有了更好的了解，我们将继续准备在亚马逊 EKS 上使用 Kubeflow 运行 ML 管道的必要先决条件！

# 准备必要的先决条件

在此部分，我们将进行以下工作:

*   为 Cloud9 环境的 EC2 实例准备 IAM 角色
*   将 IAM 角色附加到 Cloud9 环境的 EC2 实例
*   用必要的先决条件更新 Cloud9 环境

让我们一个接一个地准备必要的先决条件。

## 为 Cloud9 环境的 EC2 实例准备 IAM 角色

为了让我们从 Cloud9 环境的 EC2 实例内部安全地创建和管理**亚马逊 EKS** 和 **AWS CloudFormation** 资源，我们需要为 EC2 实例附加一个 IAM 角色。在本节中，我们将准备此 IAM 角色，并为其配置创建和管理本章中其他资源所需的权限。

注意

我们将在本章的*在亚马逊 EKS* 上设置 kube flow*部分更详细地讨论**亚马逊 EKS** 和 **AWS CloudFormation** 。*

在下一组步骤中，我们将导航到 IAM 控制台，并创建一个 IAM 角色，该角色将在本章稍后部分附加到(Cloud9 环境的)EC2 实例:

1.  通过在搜索栏中键入`iam`导航到 IAM 控制台，然后从结果列表中单击 **IAM** ，如*图 10.2* 中突出显示的:

![Figure 10.2 – Navigating to the IAM console

](img/B18638_10_002.jpg)

图 10.2–导航至 IAM 控制台

在*图 10.2* 中，我们有一种导航到 IAM 控制台的方法。另一个选项是单击**服务**下拉菜单(在前面的屏幕截图中未显示),并在**安全、身份和合规性**服务组下找到 **IAM** 服务。

1.  在左侧边栏中，找到并点击**角色**(在**访问管理**下)。
2.  在页面的右上角，找到并点击**创建角色**按钮。
3.  在**选择可信实体**页面(第 1 步，共 3 步)，选择**可信实体类型**下的 **AWS 服务**，如图*图 10.3* 中高亮显示:

![Figure 10.3 – The Select trusted entity page

](img/B18638_10_003.jpg)

图 10.3–选择受信任实体页面

这里，我们还确保在**用例>常用用例**下选择 **EC2** 选项。一旦我们检查了选择的选项，我们可以点击**下一个**按钮。

1.  在`administrator`中进入过滤搜索框(如图 10.4*中高亮显示的*，然后按*键进入*过滤结果列表。选中与**管理员访问**策略对应的复选框，向下滚动到页面底部，然后单击**下一个**按钮:

![Figure 10.4 – The Add permissions page

](img/B18638_10_004.jpg)

图 10.4–添加权限页面

确保你不会意外地从过滤结果列表中选择不正确的权限，因为有相似名称的权限可用。**管理员访问**策略应该有**描述**值**提供对 AWS 服务和资源的完全访问**。

重要说明

在本章中，`AdministratorAccess`策略的使用将帮助我们在设置时避免不同的权限相关问题。在您的工作环境中进行设置时，您应该使用一个定制策略，该策略只添加 EC2 实例运行应用所需的权限(仅此而已)。

1.  在**中的`kubeflow-on-eks`角色名称**输入框中。向下滚动到页面底部，然后单击**创建角色**按钮。

没那么容易吧！此时，我们应该有一个 IAM 角色可以附加到 AWS 资源，比如 EC2 实例。

## 将 IAM 角色附加到 Cloud9 环境的 EC2 实例

既然我们已经准备好了 IAM 角色，现在我们可以继续将这个 IAM 角色附加到 EC2 实例。

重要说明

在这一章中，我们将在`us-west-2`区域创建和管理我们的资源。在继续下一步之前，请确保您已经设置了正确的区域。

在下一组步骤中，我们将使用 AWS 管理控制台将 IAM 角色附加到运行 Cloud9 环境的 EC2 实例:

1.  通过在搜索栏中键入`cloud9`导航到 Cloud9 控制台，然后从结果列表中选择 **Cloud9** :

![Figure 10.5 – Navigating to the Cloud9 console

](img/B18638_10_005.jpg)

图 10.5–导航至 Cloud9 控制台

在*图 10.5* 中，我们有一种导航到 Cloud9 服务页面的方法。另一个选择是点击**服务**下拉菜单(在前面的截图中没有显示)并在**开发者工具**服务组中找到 **Cloud9** 服务。

1.  定位并选择我们在 [*第一章*](B18638_01.xhtml#_idTextAnchor017) 、*AWS 上的 ML 工程介绍*中准备的 Cloud9 环境:

![Figure 10.6 – Locating the View details button

](img/B18638_10_006.jpg)

图 10.6–定位查看详细信息按钮

一旦选择了 Cloud9 环境，点击页面右上方的**查看详情**按钮(如图*图 10.6* 中突出显示的)。

注意

您还可能决定从头创建一个新的 Cloud9 环境，并增加附加到运行该环境的 EC2 实例的卷的大小。如果是这种情况，请确保遵循第 1 章 、*AWS*上的*创建您的 Cloud9 环境*和*增加 Cloud9 存储*部分中指定的分步说明。

1.  在**环境细节**下，定位并点击**转到实例**链接，如图*图 10.7* 中高亮显示:

![Figure 10.7 – Locating and clicking on the Go To Instance button

](img/B18638_10_007.jpg)

图 10.7–定位并点击“转到实例”按钮

这应该会将您重定向到 EC2 控制台，在那里您应该会看到 Cloud9 环境正在运行的特定 EC2 实例。

1.  勾选 EC2 实例对应的复选框(从`aws-cloud9`开始)，然后打开**动作**下拉菜单，如图*图 10.8* 所示:

![Figure 10.8 – Modifying the IAM role of the EC2 instance 

](img/B18638_10_008.jpg)

图 10.8–修改 EC2 实例的 IAM 角色

1.  接下来，我们在**安全性**下的选项列表中找到并点击**修改 IAM 角色**选项。这应该会将您重定向到一个页面，在该页面中您可以选择特定的 IAM 角色来附加到所选的 EC2 实例。
2.  在 IAM 角色下拉菜单中(如图*图 10.9* 中突出显示的)，找到并选择我们在本章前面创建的 IAM 角色(即`kubeflow-on-eks` IAM 角色):

![Figure 10.9 – Specifying kubeflow-on-eks as the IAM role

](img/B18638_10_009.jpg)

图 10.9–将 kubeflow-on-eks 指定为 IAM 角色

一旦将 IAM 角色下拉值更新为`kubeflow-on-eks`，您现在可以点击**更新 IAM 角色**按钮(如图*图 10.9* 中突出显示的)。

1.  通过在搜索栏中键入`cloud9`，然后从结果列表中选择 **Cloud9** ，导航回 Cloud9 控制台。
2.  找到并点击与我们的 Cloud9 环境相关的 **Open IDE** 按钮。这将打开一个类似于图 10.10 所示的 Cloud9 环境:

![Figure 10.10 – The Cloud9 environment

](img/B18638_10_010.jpg)

图 10.10–云 9 环境

在这里，我们应该会看到一个熟悉的屏幕(因为我们已经在 [*第一章*](B18638_01.xhtml#_idTextAnchor017) 、*AWS 上的 ML 工程简介*和 [*第三章*](B18638_03.xhtml#_idTextAnchor060) 、*深度学习容器*中使用过这个)。

在 Cloud9 环境的终端中(在屏幕下部的＄符号之后)，运行以下命令来禁用环境中的托管临时凭据:

```
ENV_ID=$C9_PID

aws cloud9 update-environment --managed-credentials-action DISABLE --environment-id $ENV_ID
```

1.  同样，让我们删除`.aws`目录中的凭证文件，以确保临时凭证也不存在:

    ```
    rm -vf /home/ubuntu/.aws/credentials
    ```

2.  最后，让我们验证 Cloud9 环境正在使用我们在本章中准备的 IAM 角色(即`kubeflow-on-eks` IAM 角色):

    ```
    aws sts get-caller-identity --query Arn 
    ```

这应该会产生类似如下的结果:

```
arn:aws:sts::1234567890:assumed-role/kubeflow-on-eks/i-abcdefgh12345
```

一旦我们验证了我们在 Cloud9 环境中使用了正确的 IAM 角色，我们就可以继续下一部分了。

注意

*这里发生了什么？* IAM 角色(附属于 AWS 资源)在环境中生成并提供凭据，这些凭据每隔几小时就会过期。为了能够使用 IAM 角色，我们需要删除任何现有的凭证集(在 Cloud9 环境中),以便环境将使用 IAM 角色凭证。有关这个主题的更多信息，请随时查看[https://docs . AWS . Amazon . com/cloud 9/latest/user-guide/security-iam . XHTML](https://docs.aws.amazon.com/cloud9/latest/user-guide/security-iam.xhtml)。

## 使用必要的先决条件更新 Cloud9 环境

在创建我们的 EKS 集群并在其上设置 Kubeflow 之前，我们需要下载并安装一些先决条件，包括几个命令行工具，比如 **kubectl** 、 **eksctl** 和 **kustomize** 。

注意

我们将在本章的*在亚马逊 EKS 上设置 kube flow*部分讨论这些是如何工作的。

在下一组步骤中，我们将运行几个脚本，将安装让 **Kubernetes** 和 **Kubeflow** 在我们的环境中运行所需的先决条件:

1.  让我们首先使用`wget`命令(在 Cloud9 环境的终端中)下载包含各种安装脚本的`prerequisites.zip`文件。之后，我们将使用`unzip`命令提取我们刚刚下载的 ZIP 文件的内容:

    ```
    wget -O prerequisites.zip https://bit.ly/3ByyDGV
    ```

    ```
    unzip prerequisites.zip
    ```

这将从 ZIP 文件中提取以下文件:

*   `00_install_kubectl_aws_jq_and_more.sh`–这是一个运行所有其他脚本(前缀为`01`到`07`)来安装先决条件的脚本。
*   `01_install_kubectl.sh`–这是一个安装 kubectl 命令行工具的脚本。
*   `02_install_aws_cli_v2.sh`–这是一个脚本，安装 **AWS CLI** 的 v2。
*   `03_install_jq_and_more.sh`——这是一个安装并设置了几个先决条件的脚本，比如 *jq* 和 *yq* 。
*   `04_check_prerequisites.sh`–这是一个检查前几个先决条件是否已经成功安装的脚本。
*   `05_additional_setup_instructions.sh`–这是一个设置 Bash 完成的脚本。
*   `06_download_eksctl.sh`—安装 **eksctl** 命令行工具的脚本。
*   `07_install_kustomize.sh`–这是一个脚本，安装 **kustomize** 的 3.2.3 版本。

1.  导航到`ch10_prerequisites`文件夹并运行`chmod`命令，使文件夹中的脚本可执行:

    ```
    cd ch10_prerequisites
    ```

    ```
    chmod +x *.sh
    ```

2.  现在，运行以下命令开始安装和设置过程:

    ```
    sudo ./00_install_kubectl_aws_jq_and_more.sh
    ```

这将从`01_install_kubectl.sh`到`07_install_kustomize.sh`开始运行`ch10_prerequisites`文件夹中的其他脚本。

注意

一旦`00_install_kubectl_aws_jq_and_more.sh`脚本完成运行，几个先决条件，如 **AWS CLI v2** 、 **eksctl** 和 **kustomize** ，应该已经可供我们用来准备 Kubernetes 集群(如果安装期间没有错误的话)。请确保在继续操作之前查看脚本生成的日志。

1.  验证我们当前拥有的 AWS CLI 的版本:

    ```
    aws --version
    ```

这应该会产生类似如下的结果:

```
aws-cli/2.7.20 Python/3.9.11 Linux/5.4.0-1081-aws exe/x86_64.ubuntu.18 prompt/off
```

1.  接下来，让我们验证我们将使用的`kustomize`的版本:

    ```
    kustomize version
    ```

这应该会产生类似如下的结果:

```
Version: {Version:kustomize/v3.2.3 GitCommit:f8412aa3d39f32151525aff97a351288f5a7470b BuildDate:2019-10-08T23:30:25Z GoOs:linux GoArch:amd64}
```

1.  我们也来验证一下`eksctl`的版本:

    ```
    eksctl version
    ```

这应该会产生类似如下的结果:

```
0.109.0
```

1.  运行以下命令，以便安装脚本中的其他更改(如环境变量值)反映在我们当前的 shell 中:

    ```
    . ~/.bash_completion
    ```

    ```
    . ~/.bash_profile
    ```

    ```
    . ~/.bashrc
    ```

注意每行开头的波浪号(`~`)前有一个点(`.`)和一个空格。

1.  使用 AWS CLI 时，运行下面的命令块来设置一些环境变量并配置默认区域:

    ```
    export AWS_REGION="us-west-2"
    ```

    ```
    echo "export AWS_REGION=${AWS_REGION}" | tee -a ~/.bash_profile
    ```

    ```
    aws configure set default.region ${AWS_REGION}
    ```

2.  最后，验证默认区域设置成功:

    ```
    aws configure get default.region
    ```

这应该产生一个值`us-west-2`(如果我们在俄勒冈州运行我们的 Cloud9 环境)。

既然已经安装、设置并验证了所有的先决条件，我们就可以继续创建一个 EKS 集群并在其上设置 Kubeflow 了！

# 在亚马逊 EKS 上设置 Kubeflow

准备好所有的先决条件后，我们现在可以继续创建我们的 EKS 集群，然后在其上安装 Kubeflow。在安装和设置过程中，我们将使用以下工具:

*   用于创建和管理亚马逊 EKS 集群的 CLI 工具
*   用于创建、配置和删除 Kubernetes 资源的 CLI 工具
*   **AWS CLI**–用于创建、配置和删除 AWS 资源的 CLI 工具
*   用于管理 Kubernetes 对象配置的 CLI 工具

本部分的实践部分包括以下一系列高级步骤:

1.  准备包含 EKS 配置(如节点数量、所需容量和实例类型)的`eks.yaml`文件
2.  使用`eks.yaml`文件运行`eks create cluster`命令来创建亚马逊 EKS 集群
3.  使用 **kustomize** 和 **kubectl** 在我们的集群中安装 Kubeflow

记住这些，我们现在可以开始设置我们的 EKS 集群和 Kubeflow:

1.  继续我们在上一节中停止的地方，让我们在 Cloud9 环境的终端中运行以下命令:

    ```
    cd ~/environment
    ```

    ```
    mkdir ch10
    ```

    ```
    cd ch10
    ```

这里，我们使用`mkdir`命令创建`ch10`目录。之后，我们将使用`cd`命令导航到该目录。

1.  接下来，让我们使用`touch`命令创建一个空的`eks.yaml`文件:

    ```
    touch eks.yaml
    ```

2.  在的**文件树**中，找到带有您的 Cloud9 环境名称的环境目录。右键单击该目录，打开类似于*图 10.11* 所示的上下文菜单:

![Figure 10.11 – Refreshing the displayed directories and files

](img/B18638_10_011.jpg)

图 10.11–刷新显示的目录和文件

从到的选项列表中选择**刷新**，确保最新的更改已经反映在文件树中。

1.  接下来，双击文件树中的`eks.yaml`文件(在`ch10`目录内),在**编辑器**窗格中打开该文件。在这个空白文件里面，指定以下 YAML 配置:

    ```
    ---
    ```

    ```
    apiVersion: eksctl.io/v1alpha5
    ```

    ```
    kind: ClusterConfig
    ```

    ```
    metadata:
    ```

    ```
      name: kubeflow-eks-000
    ```

    ```
      region: us-west-2
    ```

    ```
      version: "1.21"
    ```

    ```
    availabilityZones: ["us-west-2a", "us-west-2b", "us-west-2c", "us-west-2d"]
    ```

    ```
    managedNodeGroups:
    ```

    ```
    - name: nodegroup
    ```

    ```
      desiredCapacity: 5
    ```

    ```
      instanceType: m5.xlarge
    ```

    ```
      ssh:
    ```

    ```
        enableSsm: true
    ```

确保通过按下 *Ctrl* + *S* 键来保存您的更改(或者，当使用 Mac 设备时， *Cmd* + *S* )。此外，您可以使用**文件**菜单中的**保存**选项来保存您的更改。

重要说明

在继续之前，我们必须知道当我们使用这个配置文件运行`eksctl create cluster`命令时将会创建哪些资源。在这里，我们指定希望我们的集群(名为`kubeflow-eks-000`)有五个`5``m5.xlarge`实例。在下一步中运行`eksctl create cluster`命令后，确保在集群创建后的一两个小时内删除集群，以管理成本。一旦您需要删除集群，请随意跳到本章末尾的*清理*部分。

1.  在为我们的集群创建真正的资源之前，让我们使用带有`--dry-run`选项的`eksctl create cluster`命令:

    ```
    eksctl create cluster -f eks.yaml --dry-run
    ```

这应该有助于我们在创建实际的资源集之前检查配置。

1.  现在，让我们使用`eksctl create`命令:

    ```
    eksctl create cluster -f eks.yaml
    ```

    创建我们的集群

这里，我们使用在上一步中准备的`eks.yaml`文件作为运行命令时的配置文件。

重要说明

如果您遇到类似于`eks.yaml`文件中的`version`字符串值的错误消息，并且在错误消息中指定了受支持的最低版本。一旦您更新了`eks.yaml`文件，您可以再次运行`eksctl create cluster`命令并检查问题是否已经解决。关于这个话题的更多信息，请随时查看[https://docs . AWS . Amazon . com/eks/latest/user guide/kubernetes-versions . XHTML](https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.xhtml)。

运行`eksctl create cluster`命令大约需要 15-30 分钟才能完成。它将使用**cloud formation**stacks来启动 AWS 资源。如果您想知道什么是 CloudFormation，它是一种让您在模板中定义基础架构的每个组件及其设置的服务。然后，CloudFormation 读取该模板，以调配您的基础架构所需的资源:

![Figure 10.12 – How EKS resources are created using eksctl

](img/B18638_10_012.jpg)

图 10.12–如何使用 eksctl 创建 EKS 资源

在*图 10.12* 中，我们可以看到`eksctl`命令利用`eks.yaml`文件来准备模板，这些模板将被 CloudFormation 服务用来提供资源。

注意

请注意，`eksctl`也创建了云形成之外的其他资源。这意味着用于准备 EKS 资源的云形成模板将*而不是*包含使用`eksctl`命令创建的所有资源。也就是说，在删除本节创建的资源时，最好使用`eksctl delete cluster`命令。一旦需要删除资源，请确保遵循本章*清理*一节中指定的说明。

1.  让我们使用`kubectl get nodes`命令:

    ```
    kubectl get nodes -o wide
    ```

    快速检查我们的设置

这将为我们提供五个节点，其**状态**值为**就绪**。

重要说明

如果您在部署 EKS 集群时遇到问题，请确保查看[https://docs . AWS . Amazon . com/eks/latest/user guide/trouble shooting . XHTML](https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.xhtml)。

1.  在继续之前，让我们确保`CLUSTER_NAME`和`CLUSTER_REGION`已经设置了适当的值:

    ```
    CLUSTER_NAME=kubeflow-eks-000
    ```

    ```
    CLUSTER_REGION=us-west-2
    ```

这里，我们指定了一个与在`eks.yaml`文件中指定的名称等价的`CLUSTER_NAME`值。注意，如果您需要试验另一组配置参数，您可以指定不同的集群名称(通过更新`CLUSTER_NAME`和`eks.yaml`文件)并在创建新集群时用`kubeflow-eks-001`替换`kubeflow-eks-000`(以此类推)。只需确保在创建新集群之前正确删除任何现有集群。

1.  此外，让我们将 IAM OIDC 提供者与集群相关联:

    ```
    eksctl utils associate-iam-oidc-provider --cluster $CLUSTER_NAME --approve -v4
    ```

那么，什么是 IAM OIDC 提供商呢？嗯，它是一个 IAM 实体，用于在您的 AWS 帐户和外部 OpenID Connect 兼容的身份提供者之间建立信任。这意味着，我们可以使用 IAM OIDC 提供者来代替创建 IAM 用户，并授予这些身份使用我们的 AWS 帐户中的资源的权限。

注意

有关这个主题的更多信息，请随时查看[https://docs . AWS . Amazon . com/IAM/latest/user guide/id _ roles _ providers _ create _ oidc . XHTML](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc.xhtml)。

1.  让我们使用`aws eks update-kubeconfig`命令来配置`kubectl`，这样我们就可以连接到亚马逊 EKS 集群:

    ```
    aws eks update-kubeconfig --name $CLUSTER_NAME --region ${AWS_REGION}
    ```

2.  接下来，我们将克隆两个包含清单(包含 Kubernetes 对象规范的文件)的存储库，用于安装我们需要的东西:

    ```
    export KUBEFLOW_VERSION=v1.5.1
    ```

    ```
    export AWS_VERSION=v1.5.1-aws-b1.0.0
    ```

    ```
    git clone https://github.com/awslabs/kubeflow-manifests.git && cd kubeflow-manifests
    ```

    ```
    git checkout ${AWS_VERSION}
    ```

    ```
    git clone --branch ${KUBEFLOW_VERSION} \
    ```

    ```
    https://github.com/kubeflow/manifests.git upstream
    ```

3.  导航到`deployments/vanilla`目录:

    ```
    cd deployments/vanilla
    ```

我们应该在这个目录中找到一个`kustomization.yaml`文件。有关这个主题的更多信息，请随时查看[https://kubernetes . io/docs/tasks/manage-kubernetes-objects/kustomization/](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/)。

1.  一切准备就绪后，让我们运行这个单行命令来安装 Kubeflow 组件和服务:

    ```
    while ! kustomize build . | kubectl apply -f -; do echo "Retrying"; sleep 30; done
    ```

注意

完成此步骤大约需要 4-10 分钟。如果输出日志似乎已经无限循环了超过 20-30 分钟，您可能需要在`eks.yaml`文件的`version`字符串值中尝试不同的值。我们可以使用哪些价值观？假设目前支持的版本有`1.20`、`1.21`、`1.22`、`1.23`(如[https://docs . AWS . Amazon . com/eks/latest/user guide/kubernetes-versions . XHTML](https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.xhtml)所示)。我们应该尝试使用 1.23 版本吗？如果我们在`eks.yaml`文件中使用最新支持的 Kubernetes 版本`1.23`，我们可能会在安装 Kubeflow 时遇到问题。我们可能需要等待几个月，让 Kubeflow 支持跟上进度(如[https://aw slabs . github . io/kube flow-manifests/docs/about/eks-compatibility/](https://awslabs.github.io/kubeflow-manifests/docs/about/eks-compatibility/)中所示)。也就是说，当使用`eksctl create cluster`命令时，我们可以尝试在`eks.yaml`文件中指定`1.20`、`1.21`或`1.22`(从支持的最低版本的`1.20`开始)。记住这些，下一步是使用`eksctl delete cluster`命令删除集群(请参见*清理*部分)，用所需的 Kubernetes 版本更新`eks.yaml`文件，然后重复本部分中从`eksctl create cluster`命令开始的步骤。

1.  让我们使用以下命令快速地检查创建的资源:

    ```
    ns_array=(kubeflow kubeflow-user-example-com kserve cert-manager istio-system auth knative-eventing knative-serving)
    ```

    ```
    for i in ${ns_array[@]}; do 
    ```

    ```
      echo "[+] kubectl get pods -n $i"
    ```

    ```
      kubectl get pods -n $i; 
    ```

    ```
      echo "---"
    ```

    ```
    done
    ```

这里，我们使用`kubectl get pods`命令来检查集群节点内部创建的资源。

1.  现在，我们运行下面的命令，这样我们就可以通过 Cloud9 环境的端口`8080`访问 Kubeflow 仪表板:

    ```
    kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80 --address=localhost
    ```

2.  点击**预览**(位于页面顶部)，打开类似于*图 10.13* 所示的下拉菜单选项列表:

![Figure 10.13 – Preview Running Application

](img/B18638_10_013.jpg)

图 10.13–预览正在运行的应用

从下拉菜单选项列表中，选择**预览正在运行的应用**，打开屏幕底部终端窗格旁边的一个小窗口。

注意

我们能够直接从我们的 Cloud9 环境中预览该应用，因为该应用当前使用 HTTP 通过端口 8080 运行。关于这个主题的更多信息，请随时查看[https://docs . AWS . Amazon . com/cloud 9/latest/user-guide/app-preview . XHTML](https://docs.aws.amazon.com/cloud9/latest/user-guide/app-preview.xhtml)。

1.  点击按钮，如图*图 10.14* 中突出显示的，在单独的浏览器选项卡中打开预览窗口:

![Figure 10.14 – Previewing in a new window

](img/B18638_10_014.jpg)

图 10.14–在新窗口中预览

在第二个浏览器选项卡中使用应用预览时，请确保不要关闭运行 Cloud9 环境的浏览器选项卡。

1.  在`user@example.com`上指定以下凭证
2.  `12341234`

重要说明

不要与他人共享应用预览选项卡的 URL。要更改默认密码，请随意查看以下链接:https://aw slabs . github . io/kube flow-manifests/docs/deployment/connect-kube flow-dashboard/

这个应该会将您重定向到 **Kubeflow 中央仪表盘**类似于*图 10.15* 中显示的:

![Figure 10.15 – The Kubeflow central dashboard

](img/B18638_10_015.jpg)

图 10.15–kube flow 中央仪表盘

在*图 10.15* 中，我们可以看到 **Kubeflow 中央仪表盘**——一个仪表盘界面，提供对我们创建和使用的组件和资源的直接访问。使用侧边栏随意导航到该控制面板的不同部分。

终于，所有的设置工作都完成了！在下一部分中，我们将运行我们的第一个定制 Kubeflow 管道。在继续之前，请随意喝杯咖啡或茶。

# 运行我们的第一条 Kubeflow 管道

在本节中，我们将运行一个定制管道，该管道将下载一个样本表格数据集，并将其用作训练数据来构建我们的**线性回归**模型。由管道执行的步骤和指令已在 YAML 文件中定义。一旦上传了这个 YAML 文件，我们就能够运行 Kubeflow 管道，该管道将运行以下步骤:

1.  **下载数据集**:这里，我们将下载并使用一个只有 20 条记录的数据集(以及包含标题的行)。除此之外，我们将从一个没有任何缺失或无效值的干净版本开始:

![](img/B18638_10_016.jpg)

图 10.16–表格数据集示例

在*图 10.16* 中，我们可以看到我们的数据集有三列:

*   `last_name`–这是经理的姓氏。
*   `management_experience_months`–这是经理管理团队成员的总月数。
*   `monthly_salary`–这是经理目前的月薪(美元)。

为了稍微简化一下，我们将使用一个只有几条记录的数据集——足以生成一个简单的 ML 模型。除此之外，我们将从一个没有任何缺失或无效值的干净版本开始。

1.  `monthly_salary`)第二列是预测值列(`management_experiment_months`)。同时，我们将执行**训练-测试分割**以便我们可以使用数据集的 70%来训练模型，剩余的 30%用于评估它。
2.  `LinearRegression`对训练数据拟合线性模型的算法。
3.  **评估模型**:一旦训练步骤完成，我们将使用测试集对其进行评估。
4.  `monthly_salary`)给定一个输入值(`management_experiment_months`)。

注意

请注意，我们可以完全控制管道的行为。我们可以将管道看作是一系列步骤，其中每一步都可能生成一个输出，然后由另一步用作输入。

现在我们对我们的管道有了更好的了解，让我们继续运行我们的第一个管道:

1.  让我们首先在另一个浏览器选项卡中打开以下链接:[https://raw . githubusercontent . com/packt publishing/Machine-Learning-Engineering-on-AWS/main/chapter 10/basic _ pipeline . YAML](https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/main/chapter10/basic_pipeline.yaml)。
2.  右键单击页面的任何部分，打开类似于*图 10.17* 所示的上下文菜单:

![Figure 10.17 – Downloading the YAML file

](img/B18638_10_017.jpg)

图 10.17–下载 YAML 文件

将文件另存为`basic_pipeline.yaml`，并将其下载到本地机器的`Downloads`文件夹(或类似文件夹)中。

1.  回到显示 **Kubeflow 中央仪表盘**的浏览器标签，找到并点击侧边栏中的**管道**。
2.  接下来，点击**上传管道**按钮(在**刷新**按钮旁边)
3.  使用提供的文件输入字段，在`basic_pipeline.yaml`文件下的`My first pipeline`(从您的本地机器)中。最后，点击**创建**按钮(在*图 10.18* 中高亮显示):

![Figure 10.18 – Uploading a pipeline (file)

](img/B18638_10_018.jpg)

图 10.18–上传管道(文件)

点击**创建**按钮上的应该会创建管道，并将您重定向到类似于*图 10.19* 所示的管道页面:

![Figure 10.19 – A graph of the first pipeline

](img/B18638_10_019.jpg)

图 10.19–第一条管道的图表

此时，我们的管道应该准备好了！下一步是创建一个实验并运行它。

注意

刚刚发生了什么？上传 YAML 文件后，Kubeflow Pipelines 将 YAML 文件转换为可通过管道运行执行的管道。

1.  接下来，找到并点击**创建实验**按钮(位于页面右上角)。如果您找不到**创建实验**按钮，请随意放大/缩小(并关闭任何可能出现的弹出窗口和覆盖图)。
2.  在**实验名称**下指定`My first experiment`。然后点击**下一个**按钮。
3.  在**开始运行**页面上，向下滚动到页面底部，然后点击**开始**按钮。
4.  定位并点击我的第一条管线的**管路，如图*图 10.20* 中高亮显示:**

![Figure 10.20 – Navigating to the pipeline run

](img/B18638_10_020.jpg)

图 10.20-导航到管道运行

在这里，我们可以看到我们的管道已经开始运行。导航到特定管道运行页面后，您应该会看到一个相对较新或部分完成的管道，类似于*图 10.21* 中所示:

![Figure 10.21 – Waiting for the pipeline to finish running

](img/B18638_10_021.jpg)

图 10.21–等待管道完成运行

这大约需要 1-2 分钟完成。您应该会在每个成功完成的步骤上看到一个复选标记。

1.  当管道运行时，您可以单击任何步骤来检查相应的输入和输出工件、日志和其他细节:

![Figure 10.22 – Inspecting the artifacts

](img/B18638_10_022.jpg)

图 10.22–检查工件

在*图 10.22* 中，我们可以看到，点击**过程数据**步骤对应的方框后，我们可以查看和调试输入和输出工件。此外，我们应该通过导航到其他选项卡(**可视化**、**细节**、**卷**和**日志**)来找到关于当前步骤的其他细节。

祝贺您运行第一条管道！如果你想知道我们是如何准备这个管道的，我们只是使用了 **Kubeflow 管道 SDK** 来定义管道的步骤，并生成包含所有指令和配置的 YAML 文件。在下一节中，我们将更深入地使用 **Kubeflow Pipelines SDK** 来构建定制的 ML 管道。

# 使用 Kubeflow Pipelines SDK 构建 ML 工作流

在这个部分，我们将使用 **Kubeflow Pipelines SDK** 构建 ML 工作流。Kubeflow Pipelines SDK 包含我们构建管道组件所需的内容，这些组件包含我们想要运行的定制代码。使用 Kubeflow Pipelines SDK，我们可以定义映射到管道的管道组件的 Python 函数。

以下是我们在使用 Kubeflow Pipelines SDK 构建基于 Python 函数的组件时需要遵循的一些准则:

*   定义的 Python 函数应该是独立的，不应该使用在函数定义之外声明的任何代码和变量。这意味着`import pandas`)也应该在函数内部实现。这里有一个导入应该如何实现的快速示例:

    ```
    def process_data(...):
    ```

    ```
        import pandas as pd 
    ```

    ```
        df_all_data = pd.read_csv(df_all_data_path)
    ```

    ```
        # and so on...
    ```

*   在组件之间传递大量数据(或具有复杂数据类型的数据)时，数据必须作为文件传递。下面是一个简单的例子:

    ```
    def evaluate_model(
    ```

    ```
        model_path: InputPath(str),
    ```

    ```
        df_test_data_path: InputPath(str)):
    ```

    ```
        import pandas as pd
    ```

    ```
        from joblib import load
    ```

    ```
        df_test_data = pd.read_csv(df_test_data_path)
    ```

    ```
        model = load(model_path)
    ```

    ```
        # and so on...
    ```

*   使用`create_component_from_func()`函数(来自`kfp.components`)将定义的函数转换成管道组件。当调用`create_component_from_func()`函数时，可以在`packages_to_install`参数中指定一个包列表，类似于下面的代码块:

    ```
    process_data_op = create_component_from_func(
    ```

    ```
        process_data, 
    ```

    ```
        packages_to_install=['pandas', 'sklearn']
    ```

    ```
    )
    ```

然后，在执行该功能之前，将安装指定的软件包。

*   或者，我们可以准备一个自定义容器映像，用于 Python 函数运行的环境。当调用`create_component_from_func()`函数时，可以在`base_image`参数中指定自定义容器图像。

也就是说，让我们开始使用 **Kubeflow Pipelines SDK** 定义和配置我们的 ML 管道:

1.  在 **Kubeflow 中央仪表盘**的侧栏中找到并点击**笔记本**。
2.  接下来，点击**新建笔记本**按钮。
3.  为**名称**输入字段值指定`first-notebook`。
4.  向下滚动到页面底部，然后点击**启动**按钮。

注意

等待笔记本变得可用。笔记本准备就绪大约需要 1-2 分钟。

1.  笔记本可用后，点击**连接**按钮。
2.  在 **Jupyter Lab Launcher** 中，选择 **Python 3** 选项(在**笔记本**下)，如*图 10.23* 中高亮显示的:

![Figure 10.23 – Jupyter Lab Launcher

](img/B18638_10_023.jpg)

图 10.23–Jupyter 实验室发射器

这应该会创建一个新的 **Jupyter 笔记本**(在 Kubernetes Pod 的一个容器内)，在这里我们可以运行我们的 Python 代码。

注意

我们将在我们发布的 Jupyter 笔记本中运行后续步骤中的代码块。

1.  让我们从**kube flow Pipelines SDK**:

    ```
    import kfp
    ```

    ```
    from kfp import dsl
    ```

    ```
    from kfp.components import InputPath, OutputPath
    ```

    ```
    from kfp.components import create_component_from_func
    ```

    中执行几个导入
2.  对于管道中的第一步，我们定义了`download_dataset()`函数，该函数下载一个虚拟数据集并将其转换为 CSV 文件。这个 CSV 文件通过`df_all_data_path` `OutputPath`将传递给下一步对象:

    ```
    def download_dataset(
    ```

    ```
        df_all_data_path: OutputPath(str)):
    ```

    ```
        import pandas as pd
    ```

    ```
        url="https://bit.ly/3POP8CI"
    ```

    ```
        df_all_data = pd.read_csv(url)
    ```

    ```
        print(df_all_data)
    ```

    ```
        df_all_data.to_csv(
    ```

    ```
            df_all_data_path, 
    ```

    ```
            header=True, 
    ```

    ```
            index=False)
    ```

3.  对于管道中的第二步，我们定义了`process_data()`函数，其中我们从上一步中读取 CSV 数据，并应用训练-测试分割，这将产生一个训练集和一个测试集。然后可以将这些保存为 CSV 文件并通过`df_training_data_path`和`df_test_data_path` `OutputPath`对象传递给下一步，分别是:

    ```
    def process_data(
    ```

    ```
        df_all_data_path: InputPath(str), 
    ```

    ```
        df_training_data_path: OutputPath(str), 
    ```

    ```
        df_test_data_path: OutputPath(str)):
    ```

    ```
        import pandas as pd
    ```

    ```
        from sklearn.model_selection import \
    ```

    ```
            train_test_split
    ```

    ```
        df_all_data = pd.read_csv(df_all_data_path)
    ```

    ```
        print(df_all_data)
    ```

    ```
        mem = 'management_experience_months'
    ```

    ```
        ms = 'monthly_salary'
    ```

    ```
        X = df_all_data[mem].values 
    ```

    ```
        y = df_all_data[ms].values
    ```

    ```
        X_train, X_test, y_train, y_test = \
    ```

    ```
            train_test_split(
    ```

    ```
                X, y, test_size=0.3, random_state=0
    ```

    ```
            )
    ```

    ```
        df_training_data = pd.DataFrame({ 
    ```

    ```
            'monthly_salary': y_train, 
    ```

    ```
            'management_experience_months': X_train
    ```

    ```
        })
    ```

    ```
            df_training_data_path, 
    ```

    ```
            header=True, index=False
    ```

    ```
        )
    ```

    ```
        df_test_data = pd.DataFrame({ 
    ```

    ```
            'monthly_salary': y_test, 
    ```

    ```
            'management_experience_months': X_test
    ```

    ```
        })
    ```

4.  对于管道中的第三步，我们定义了`train_model()`函数，其中我们使用上一步的训练数据来训练一个样本模型。然后，经过训练的模型通过`model_path` `OutputPath`对象保存并传递给下一步:

    ```
    def train_model(
    ```

    ```
        df_training_data_path: InputPath(str),
    ```

    ```
        model_path: OutputPath(str)):
    ```

    ```
        import pandas as pd
    ```

    ```
        from sklearn.linear_model import LinearRegression
    ```

    ```
        from joblib import dump
    ```

    ```
        df_training_data = pd.read_csv(
    ```

    ```
            df_training_data_path
    ```

    ```
        )
    ```

    ```
        print(df_training_data)
    ```

    ```
        mem = 'management_experience_months'
    ```

    ```
        X_train = df_training_data[mem].values
    ```

    ```
        ms = 'monthly_salary'
    ```

    ```
        y_train = df_training_data[ms].values
    ```

    ```
        model = LinearRegression().fit(
    ```

    ```
            X_train.reshape(-1, 1), y_train
    ```

    ```
        )
    ```

    ```
        print(model)
    ```

    ```
        dump(model, model_path)
    ```

5.  在第四步中，我们定义`evaluate_model()`函数，其中我们使用来自第二步的测试数据来评估我们从上一步获得的训练模型:

    ```
    def evaluate_model(
    ```

    ```
        model_path: InputPath(str),
    ```

    ```
        df_test_data_path: InputPath(str)):
    ```

    ```
        import pandas as pd
    ```

    ```
        from joblib import load
    ```

    ```
        df_test_data = pd.read_csv(df_test_data_path)
    ```

    ```
        mem = 'management_experience_months'
    ```

    ```
        ms = 'monthly_salary'
    ```

    ```
        X_test = df_test_data[mem].values
    ```

    ```
        y_test = df_test_data[ms].values
    ```

    ```
        model = load(model_path)
    ```

    ```
        print(model.score(X_test.reshape(-1, 1), y_test))
    ```

6.  对于流水线的最后一步，我们定义了`perform_sample_prediction()`函数，其中我们使用第三步中训练好的模型来执行样本预测(使用样本输入值):

    ```
    def perform_sample_prediction(
    ```

    ```
        model_path: InputPath(str)):
    ```

    ```
        from joblib import load
    ```

    ```
        model = load(model_path)
    ```

    ```
        print(model.predict([[42]])[0])
    ```

7.  然后，我们将`create_component_from_func()`函数用于我们准备创建组件的每个函数。在这里，我们指定在运行这些函数之前要安装的软件包:

    ```
    download_dataset_op = create_component_from_func(
    ```

    ```
        download_dataset, 
    ```

    ```
        packages_to_install=['pandas']
    ```

    ```
    )
    ```

    ```
    process_data_op = create_component_from_func(
    ```

    ```
        process_data, 
    ```

    ```
        packages_to_install=['pandas', 'sklearn']
    ```

    ```
    )
    ```

    ```
    train_model_op = create_component_from_func(
    ```

    ```
        train_model, 
    ```

    ```
        packages_to_install=[
    ```

    ```
            'pandas', 'sklearn', 'joblib'
    ```

    ```
        ]
    ```

    ```
    )
    ```

    ```
    evaluate_model_op = create_component_from_func(
    ```

    ```
        evaluate_model, 
    ```

    ```
        packages_to_install=[
    ```

    ```
            'pandas', 'joblib', 'sklearn'
    ```

    ```
        ]
    ```

    ```
    )
    ```

    ```
    perform_sample_prediction_op = \
    ```

    ```
        create_component_from_func(
    ```

    ```
            perform_sample_prediction, 
    ```

    ```
            packages_to_install=['joblib', 'sklearn']
    ```

    ```
        )
    ```

8.  现在，让我们把的所有东西放在一起，用`basic_pipeline()`函数定义管道:

    ```
    @dsl.pipeline(
    ```

    ```
        name='Basic pipeline',
    ```

    ```
        description='Basic pipeline'
    ```

    ```
    )
    ```

    ```
    def basic_pipeline():
    ```

    ```
        DOWNLOAD_DATASET = download_dataset_op()
    ```

    ```
        PROCESS_DATA = process_data_op(
    ```

    ```
            DOWNLOAD_DATASET.output
    ```

    ```
        )
    ```

    ```
        TRAIN_MODEL = train_model_op(
    ```

    ```
            PROCESS_DATA.outputs['df_training_data']
    ```

    ```
        )
    ```

    ```
        EVALUATE_MODEL = evaluate_model_op(
    ```

    ```
            TRAIN_MODEL.outputs['model'], 
    ```

    ```
            PROCESS_DATA.outputs['df_test_data']
    ```

    ```
        )
    ```

    ```
        PERFORM_SAMPLE_PREDICTION = \
    ```

    ```
            perform_sample_prediction_op(
    ```

    ```
                TRAIN_MODEL.outputs['model']
    ```

    ```
            )
    ```

    ```
        PERFORM_SAMPLE_PREDICTION.after(EVALUATE_MODEL)
    ```

9.  最后，让我们使用下面的代码块生成管道的 YAML 文件:

    ```
    kfp.compiler.Compiler().compile(
    ```

    ```
        basic_pipeline, 
    ```

    ```
        'basic_pipeline.yaml'
    ```

    ```
    )
    ```

此时，我们应该在文件浏览器中看到一个 YAML 文件。如果没有，请随意使用刷新按钮来更新显示的文件列表。

1.  在文件浏览器中，右击生成的`basic_pipeline.yaml`文件，打开类似于*图 10.24* 所示的上下文菜单:

![Figure 10.24 – Downloading the basic_pipeline.yaml file

](img/B18638_10_024.jpg)

图 10.24–下载 basic_pipeline.yaml 文件

从右键菜单的选项列表中选择**下载**(如图*图 10.24* 中高亮显示)。这会将 YAML 文件下载到本地机器的下载文件夹(或类似的文件夹)中。

1.  下载完`basic_pipeline.yaml`文件后，导航至浏览器选项卡，在此我们打开了 **Kubeflow 中央仪表盘**。之后，通过点击侧边栏中的**管道**导航到**管道**页面(在 **Kubeflow 中央仪表盘**中)。
2.  接下来，单击我们在本节中生成的`basic_pipeline.yaml`文件来运行另一个管道。

重要说明

运行新管道时，请随意检查并遵循本章*运行我们的第一个 Kubeflow 管道*一节中指定的步骤。我们将把这个留给您作为练习！(生成的管道应该是相同的。)

这比预期的要容易，对吗？完成本章的动手解决方案后，我们应该恭喜自己！能够在 EKS 上正确地设置 Kubeflow，并让定制的 ML 管道使用 Kubeflow 工作是一项成就。这应该让我们有信心使用我们现在使用的技术栈来构建更复杂的 ML 管道。

在下一节中，我们将快速清理并删除我们在本章中创建的资源。

# 清理

现在我们已经完成了本章的动手解决方案，是时候清理并关闭我们不再使用的资源了。此时，我们有一个 EKS 集群在运行，其中有`5` x `m5.xlarge`个实例在运行。我们需要终止这些资源来控制成本。

注意

如果我们(一个月内)不关闭这些，会花多少钱？假设我们在俄勒冈州地区(`us-west-2`)运行 EKS 集群，运行 EC2 实例的最低成本(每月)约为 700.80 美元( *5 个实例 x 每月 0.192 美元 x 730 小时*)加上 EKS 集群的*73 美元*(*1 个集群 x 每小时 0.10 美元 x 每月 730 小时*)。请注意，除了本章中使用的其他资源之外，还会有与这些实例附带的 EBS 卷相关的其他额外成本。

在下一组步骤中，我们将卸载并删除 Cloud9 环境终端中的资源:

1.  让我们导航回 Cloud9 环境**终端**选项卡，在这里我们最后运行了以下命令(*注意:不要运行以下命令，因为我们只需要导航回运行该命令的选项卡* ):

    ```
    kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80 --address=localhost
    ```

我们应该在这个终端中为 8080 日志找到几个**处理连接。**

1.  通过按下终端内的 *Ctrl* + *C* (或者，当使用 Mac 设备时， *Cmd* + *C* )来停止该命令。
2.  之后，让我们运行下面的命令，该命令利用`kubectl delete`删除资源:

    ```
    cd ~/environment/ch10/kubeflow-manifests/
    ```

    ```
    cd deployments/vanilla/
    ```

    ```
    kustomize build . | kubectl delete -f -
    ```

3.  让我们通过运行以下命令来删除EKS 集群:

    ```
    eksctl delete cluster --region $CLUSTER_REGION --name $CLUSTER_NAME
    ```

运行命令前，确保`CLUSTER_REGION`和`CLUSTER_NAME`变量设置为适当的值。例如，如果您正在俄勒冈地区运行 Kubernetes 集群，那么`CLUSTER_REGION`应该被设置为`us-west-2`，而`CLUSTER_NAME`应该被设置为`kubeflow-eks-000`(这类似于`eks.yaml`文件中指定的内容)

重要说明

确保验证由`eksctl`命令创建的云形成堆栈已被完全删除。您可以通过导航到 CloudFormation 控制台并检查是否有状态为 **DELETE_FAILED** 的堆栈来完成此操作。如果是这种情况，只需重新尝试删除这些堆栈，直到所有资源都被成功删除。

1.  最后，分离附加到运行 Cloud9 环境的 EC2 实例的 IAM 角色。我们将把这个留给您作为练习！

在继续下一部分之前，请确保检查所有删除操作是否都已成功。

# 推荐的策略和最佳实践

在我们结束这一章之前，我们将快速讨论一些在 EKS 与 Kubeflow 合作时推荐的策略和最佳实践。

让我们首先确定我们可以改进如何设计和实现我们的 ML 管道的方法。我们可以对初始版本的管道做哪些改进？下面是我们可以实施的一些可能的升级:

*   通过允许管道的第一步接受数据集输入路径作为输入参数(而不是像现在这样硬编码)，使管道更具可重用性
*   使用管道组件时，构建和使用自定义容器映像，而不是使用`packages_to_install`参数
*   将模型工件保存到存储服务中，比如**亚马逊 S3** (这将帮助我们确保即使 Kubernetes 集群被删除，我们也能够保留工件)
*   使用`ContainerOp`对象的`set_memory_limit()`和`set_cpu_limit()`向流水线中的特定步骤添加资源限制(如 CPU 和内存限制)
*   利用用于 Kubeflow 管道的 SageMaker 组件将一些数据处理和训练工作转移到 SageMaker

注意

如果您有兴趣在准备 **Kubeflow 管道的组件**时学习和应用最佳实践，请随时查看https://www . kube flow . org/docs/components/Pipelines/SDK/best-practices/。

接下来，让我们讨论一些策略和解决方案，我们可以实施这些策略和解决方案来升级我们的 EKS 集群和 Kubeflow 设置:

*   在亚马逊 EKS 集群上设置cloud watch Container Insights 来监控集群性能
*   设置和部署 **Kubernetes Dashboard** 和/或 **Rancher** 来管理和控制亚马逊 EKS 集群资源
*   设置设置**普罗米修斯**和**格拉夫纳**用于监控库伯内特星团
*   访问 **Kubeflow 中央仪表盘**时，更改默认的用户密码
*   部署 Kubeflow 时使用 **AWS Cognito** 作为身份提供者(用于 Kubeflow 用户验证)
*   使用亚马逊**关系数据库服务** ( **RDS** )和亚马逊**简单存储服务** ( **S3** )部署 Kubeflow，用于存储元数据和管道工件
*   通过和**应用负载均衡器**公开和访问 Kubeflow
*   使用**亚马逊弹性文件系统** ( **EFS** )和 Kubeflow 进行持久存储
*   减少附属于运行 Cloud9 环境的 EC2 实例的 IAM 角色的权限(到最小的特权集)
*   审核和升级所使用的每个资源的安全配置
*   设置 EKS 集群的自动缩放(例如，使用**集群自动缩放器**)
*   为了管理运行 EKS 集群的长期成本，我们可以利用**成本节约计划**，其中涉及在做出长期承诺(例如，1 年或 3 年承诺)后降低运行资源的总体成本

还有更多的我们可以添加到这个列表，但这些应该做了！请务必查看并检查在第 9 章 、*安全、治理和合规性策略*中分享的推荐解决方案和策略。

# 总结

在本章中，我们使用 **Kubeflow** 、 **Kubernetes** 和**亚马逊 EKS** 来设置和配置我们的容器化 ML 环境。设置好环境后，我们使用 **Kubeflow Pipelines SDK** 准备并运行一个定制的 ML 管道。在完成所有需要动手的工作之后，我们继续清理我们创建的资源。在结束本章之前，我们讨论了相关的最佳实践和策略，以使用我们在本章实践部分使用的技术堆栈来保护、扩展和管理 ML 管道。

在下一章中，我们将使用**sage maker Pipelines**—**Amazon sage maker 的**专用解决方案来构建和设置一个 ML 管道，以使用相关的 MLOps 实践来自动化 ML 工作流。

# 延伸阅读

有关本章主题的更多信息，请随时查阅以下资源:

*   *Kubernetes 概念【https://kubernetes.io/docs/concepts/[T21](https://kubernetes.io/docs/concepts/)*
*   *亚马逊 EKS 入门*([https://docs . AWS . Amazon . com/eks/latest/user guide/Getting-started . XHTML](https://docs.aws.amazon.com/eks/latest/userguide/getting-started.xhtml))
*   *eks CTL——亚马逊 EKS*([https://eksctl.io/](https://eksctl.io/))的官方 CLI
*   *亚马逊 EKS 故障排除*([https://docs . AWS . Amazon . com/eks/latest/user guide/trouble shooting . XHTML](https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.xhtml))
*   *kube flow on AWS–Deployment*([https://aw slabs . github . io/kube flow-manifests/docs/Deployment/](https://awslabs.github.io/kubeflow-manifests/docs/deployment/))
*   *kube flow on AWS Security*([https://aw slabs . github . io/kube flow-manifests/docs/about/Security/](https://awslabs.github.io/kubeflow-manifests/docs/about/security/))