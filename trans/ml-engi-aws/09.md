<title>Chapter 6: SageMaker Training and Debugging Solutions</title>

# 6

# SageMaker 培训和调试解决方案

在 [*第二章*](B18638_02.xhtml#_idTextAnchor041) 、*深度学习 AMIs* 和 [*第三章*](B18638_03.xhtml#_idTextAnchor060) 、*深度学习容器*中，我们在 EC2 实例内部执行了我们的初始 ML 训练实验。我们注意到了运行这些 EC2 实例的每小时成本，因为在某些情况下，我们需要使用更昂贵的实例类型(例如大约每小时*$ 7.20*的`p2.8xlarge`实例)来运行我们的 ML 培训作业和工作负载。为了管理和降低使用这些 EC2 实例运行 ML 工作负载的总成本，我们讨论了一些成本优化策略，包括在培训工作完成后手动关闭这些实例。

此时，您可能想知道是否有可能自动化以下过程:

*   *启动将运行 ML 培训作业的 EC2 实例*
*   *在模型训练之后，将训练的 ML 模型的模型工件上传到存储位置(例如 S3 桶)*
*   *培训工作完成后删除 EC2 实例*

好消息是使用自动化脚本这是可能的！一旦这个过程的主要部分实现了自动化，我们就可以更加专注于准备用于训练我们的 ML 模型的脚本。我们可以编写自己的自动化脚本集；然而，我会建议你做*而不是*重新发明轮子，因为 AWS 已经在 **Amazon SageMaker** 中为我们自动化了这个过程！

SageMaker 有许多功能和特性，可以帮助数据科学家和 ML 实践者轻松地在 AWS 云中执行 ML 实验和部署。在前面的章节中，我们能够快速浏览其中的一些功能，包括 **SageMaker Canvas** 、 **SageMaker Autopilot** 和 **SageMaker Data Wrangler** 。在本章中，我们将深入探讨它的功能和特性，重点是在 AWS 的托管基础设施资源内培训 ML 模型。你会惊讶地发现，只需要几个额外的配置参数就可以启用某些训练技术和解决方案，例如**网络隔离**、**分布式训练**、**管理点训练**、**检查点训练**和**增量训练**。如果这是你第一次遇到这些概念和技术，不要担心，因为我们将在本章中更详细地讨论它们。

在本章中，我们将讨论以下主题:

*   SageMaker Python SDK 入门
*   准备必要的先决条件
*   使用 SageMaker Python SDK 训练影像分类模型
*   使用调试器洞察仪表板
*   利用有管理的现场培训和检查站
*   清理

在我们继续本章的动手解决方案之前，我们将首先快速讨论如何使用 **SageMaker Python SDK** 来帮助我们利用和处理 SageMaker 服务的不同功能和特性。

# 技术要求

开始之前，我们必须准备好以下内容:

*   网络浏览器(最好是 Chrome 或 Firefox)
*   访问本书前几章中使用的 AWS 帐户

Jupyter 笔记本、源代码和其他用于每章的文件可以在本书的 GitHub 资源库中找到:https://GitHub . com/packt publishing/Machine-Learning-Engineering-on-AWS。

重要说明

运行本书中的示例时，建议使用具有有限权限的 IAM 用户，而不是 root 帐户。我们将在第 9 章 、*安全、治理和遵从性策略*的 [*中详细讨论这一点以及其他安全最佳实践。如果您刚刚开始使用 AWS，您可以同时继续使用 root 帐户。*](B18638_09.xhtml#_idTextAnchor187)

# SageMaker Python SDK 入门

SageMaker Python SDK 是一个库，它允许 ML 从业者使用 SageMaker 的不同特性和功能来训练和部署 ML 模型。它提供了几个高级抽象，如**估算器**、**模型**、**预测器**、**会话**、**转换器**和**处理器**，所有这些封装了并映射到具体的 ML 流程和实体。这些抽象允许数据科学家和 ML 工程师只用几行代码就能管理 ML 实验和部署。与此同时，基础设施管理已经由 SageMaker 处理，所以我们需要做的就是用正确的参数集配置这些高层抽象。

注意，使用 **boto3** 库也可以使用 SageMaker 的不同功能和特性。与使用 SageMaker Python SDK 相比，我们将使用 boto3 处理更多的代码行，因为在使用该库中可用的低级客户端和函数时，我们必须注意一些小细节。建议尽可能使用 SageMaker Python SDK，对于 SageMaker Python SDK 不直接支持的更高级的场景，只使用 boto3 库。

注意

如果您有兴趣了解如何在处理更高级的用例时一起使用这两个库，请查看第 8 章[](B18638_08.xhtml#_idTextAnchor172)*、*模型监控和管理解决方案*。*

 *下图显示了使用 SageMaker Python SDK 训练和部署 ML 模型仅涉及几行代码:

![Figure 6.1 – SageMaker Python SDK

](img/B18638_06_001.jpg)

图 6.1–SageMaker Python SDK

这里，我们使用 **SageMaker Python SDK** 来完成以下工作:

1.  我们通过初始化一个`Estimator`对象来开始，然后使用它的`set_hyperparameters()`方法来指定所需的超参数值的组合。在这里，我们可以通过在初始化`Estimator`对象时提供相应的配置参数值来指定是使用内置算法还是自定义算法(使用脚本和自定义 Docker 容器映像)。
2.  接下来，我们调用`fit()`方法，该方法使用期望的属性集运行一个训练作业，正如在`Estimator`对象配置中定义的那样。该训练作业将在专用实例中运行，一旦训练作业完成，这些实例将自动终止。
3.  最后，我们使用`deploy()`方法将训练好的模型部署到 SageMaker 自动为我们准备的专用实时推理端点。然后，我们使用`predict()`方法对推理端点执行样本预测。

当在 AWS 云中训练和部署我们的 ML 模型时，这只是使用 **SageMaker Python SDK** 的方法之一。如果我们已经有一个预先训练好的模型可供使用(例如，在从模型库中下载一个预先构建的 ML 模型之后)，我们可以完全跳过训练步骤，并使用下面的代码块立即部署模型:

```
from sagemaker.model import Model 

model = Model(model_data=model_data, ...)

model.deploy(<insert configuration parameters>)
```

当然，前面的代码块假设模型工件已经被上传到 S3 桶中，并且`model_data`变量指向这些模型工件或者文件被存储的位置。

注意

如果您有兴趣了解更多关于如何使用预先训练的模型在 SageMaker 中直接执行部署的信息，请查看 [*第 7 章*](B18638_07.xhtml#_idTextAnchor151) ， *SageMaker 部署解决方案*。

如果我们想要利用 SageMaker 的**自动模型调整**功能，并在寻找“最佳模型”时使用不同的超参数组合自动运行多个训练作业，那么我们只需要运行几行代码，类似于下面的代码块:

```
estimator = Estimator(...)

estimator.set_hyperparameters(...)

hyperparameter_ranges = {...}

objective_metric_name = "<insert target metric>"

hyperparameter_tuner = HyperparameterTuner(

    estimator, 

    objective_metric_name, 

    hyperparameter_ranges, 

    max_jobs=20, 

    max_parallel_jobs=3

)

hyperparameter_tuner.fit(...)
```

在这里，SageMaker 为我们做了所有繁重的工作，我们需要担心的只是运行超参数调优工作所需的配置参数。这将花费我们几个星期(或者甚至几个月！)如果我们自己使用定制的自动化脚本来构建它。

注意

如果你有兴趣通过 **SageMaker Python SDK** 进一步了解如何利用 SageMaker 的自动模型调优功能，那么请查看 [*第 6 章*](B18638_06.xhtml#_idTextAnchor132) 、 *SageMaker 培训和调试解决方案、*一书的*机器学习与亚马逊 SageMaker 食谱*。

使用 Amazon SageMaker 训练模型时，有几个选项和功能可用。这些包括网络隔离、分布式培训、管理点培训、检查点、增量培训等等。与前面讨论的自动模型调整功能类似，利用和启用这些功能只需要几行额外的代码。如果您想知道这些是什么，请不要担心，我们将在本章的动手解决方案中详细讨论每一个。

现在我们已经更好地理解了 **SageMaker Python SDK** 如何帮助我们在云中训练和部署 ML 模型，让我们继续创建一个服务限制请求！

# 准备必要的先决条件

在本节中，我们将确保在继续学习本章的动手解决方案之前，满足以下先决条件:

*   我们增加了使用`ml.p2.xlarge`实例运行 SageMaker 培训任务的服务限制(SageMaker 培训)
*   我们增加了使用`ml.p2.xlarge`实例运行 SageMaker 培训作业的服务限制(SageMaker 管理的现场培训)

如果你想知道为什么我们在本章中使用`ml.p2.xlarge`实例，那是因为我们需要使用**图像分类算法**支持的实例类型之一，如下面的截图所示:

![Figure 6.2 – EC2 Instance Recommendation for the image classification algorithm

](img/B18638_06_002.jpg)

图 6.2–图像分类算法的 EC2 实例建议

如我们所见，当使用图像分类算法运行训练作业时，我们可以使用`ml.p2.xlarge`、`ml.p2.8xlarge`、`ml.p2.16xlarge`、`ml.p3.2xlarge`、`ml.p3.8xlarge`和`ml.p3.16xlarge`(在撰写本文时)。

注意

查看出[https://docs . AWS . Amazon . com/sagemaker/latest/DG/image-classification . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.xhtml)了解更多关于这个话题的信息。

## 创建服务限额增加请求

在这一章中，我们将使用多个`ml.p2.xlarge`实例训练一个图像分类模型。在我们可以使用这种类型的实例来训练 ML 模型之前，我们需要通过`0`请求增加服务配额(或服务限制)；如果我们使用`ml.p2.xlarge`实例运行训练作业，我们将会遇到`ResourceLimitExceeded`错误。

重要说明

本章假设我们在使用服务管理和创建不同类型的资源时使用了`us-west-2`区域。您可以使用不同的区域，但请确保进行必要的调整，以防某些资源需要转移到所选的区域。

按照以下步骤创建支持案例，并请求增加 SageMaker 培训实例数量限制:

1.  导航到 AWS 管理控制台搜索栏中的`support`。
2.  从**服务**下的结果列表中选择**支持**。

*   找到并点击**创建案例**按钮。*   在**创建案例**页面，从选项列表中选择**服务限制增加**。*   在`SageMaker Training Jobs`下指定以下配置*   在`US West (Oregon)`下*   `SageMaker Training`*   `ml.p2.xlarge`*   `2`

注意

请注意，增加 SageMaker 培训资源类型的服务限制不会自动增加 SageMaker 管理的现场培训资源类型的服务限制。

1.  点击**添加另一个请求**。
2.  在`US West (Oregon)`下
3.  `SageMaker Managed Spot Training`
4.  `ml.p2.xlarge`
5.  `2`
6.  在**用例描述**下，在提供的文本区域中指定以下用例描述:

    ```
    Good day, 
    ```

    ```
    I am planning to run a SageMaker training job using 2 x ml.p2.xlarge instances to train an Image Classification model. After this I am planning to use Managed Spot Training to run a similar example and will need 2 x ml.p2.xlarge (spot) instances. Hope these 2 limit increase requests can be processed as soon as possible in the Oregon (us-west-2) region.
    ```

    ```
    You can find the relevant notebooks here: https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS
    ```

如果您计划在另一个区域运行您的 ML 实验，请确保用适当的区域替换`Oregon (us-west-2)`。

1.  向下滚动到**联系选项**，并从**联系方式**下的选项列表中选择**网页**(或**聊天**。
2.  最后，点击**提交**按钮。

请注意，限额增加请求可能需要大约 24 到 48 小时才能获得 **AWS 支持团队**的批准。在等待时，您可以浏览本章中解释的内容和概念。这将有助于您在动手解决方案之前对 SageMaker 的功能有一个更好的了解。您也可以跳过本章，继续阅读第 7 章 、 *SageMaker 部署解决方案*，同时等待限额增加获得批准。

# 用 SageMaker Python SDK 训练图像分类模型

如*SageMaker Python SDK*一节所述，在 SageMaker 中进行训练实验时，我们可以使用内置算法或自定义算法(使用脚本和自定义 Docker 容器映像)。

数据科学家和 ML 从业者可以使用 AWS 团队准备的一个或多个内置算法，在 SageMaker 中快速开始训练和部署模型。有多种内置算法可供选择，每种算法都是为了帮助 ML 从业者解决特定的业务和 ML 问题而提供的。以下是一些可用的内置算法，以及这些算法可以解决的一些使用案例和问题:

*   **深度预测**:时间序列预测
*   **主成分分析**:降维
*   **IP 洞察** : IP 异常检测
*   **潜在狄利克雷分配(LDA)** :主题建模
*   **序列对序列**:文本摘要
*   **语义分割**:计算机视觉

第二个选项涉及使用 SageMaker **脚本模式**，在这里我们导入一个定制的训练脚本，它利用一个深度学习框架(比如 **TensorFlow** 、 **PyTorch** 或者 **MXNet** )来训练一个模型。这里，定制训练脚本将在其中一个预构建的容器内运行，其中包括 **AWS 深度学习容器**，如 [*第 3 章*](B18638_03.xhtml#_idTextAnchor060) 、*深度学习容器*中所述。也就是说，当选择这个选项时，我们需要担心的是准备训练脚本，因为大多数依赖项已经安装在这些脚本将运行的容器环境中。

第三个选项涉及到在 SageMaker 中构建和使用定制的容器映像来训练 ML 模型。该选项为我们提供了最高级别的灵活性，因为我们可以完全控制自定义培训脚本的运行环境。

注意

哪种选择对我们最有利？如果我们想继续训练一个 ML 模型，而不必准备一个定制脚本和一个定制容器图像，最好的选择是使用 SageMaker 的内置算法。如果我们试图将我们的自定义脚本移植到 SageMaker，它利用开源 ML 库和框架(如 scikit-learn、PyTorch 和 TensorFlow)来训练模型，那么最好的选择是使用 SageMaker 的脚本模式。如果我们需要更多的灵活性，那么我们可以选择使用我们自己的定制容器映像。

现在我们对在 SageMaker 中训练 ML 模型时有哪些选项有了更好的了解，让我们继续讨论我们将在本部分的实践部分做些什么。在这个部分，我们将使用内置的`ml.p2.xlarge`实例。为了测试我们训练的模型，我们将部署该模型，并且在`ml.m5.xlarge`实例中启动一个推理端点。然后，使用几幅测试图像，将该推断终点用于执行样本预测。

如下图所示，在执行训练步骤时，我们可以利用**分布式训练**:

![Figure 6.3 – Training and deploying an image classification model

](img/B18638_06_003.jpg)

图 6.3–训练和部署图像分类模型

通过使用多个实例而不是一个实例，分布式培训有助于减少培训时间。因为我们使用的是内置算法，所以我们需要做的就是配置训练作业，使用两个或更多实例来支持分布式训练。

考虑到这些方面，让我们继续在 **SageMaker Studio** 中创建一个新的笔记本。我们将使用它来运行代码块，以训练我们的图像分类模型。

## 在 SageMaker Studio 中创建新笔记本

首先打开 SageMaker Studio，创建一个名为`CH06`的新目录。然后，创建一个新的 **Jupyter 笔记本**并保存在这个目录下。

注意

在继续之前，请确保您已经完成了第 1 章 、*AWS 上的 ML 工程介绍*的*sage maker 和 SageMaker Studio* 部分中的动手解决方案。

按照这些步骤启动 SageMaker Studio 并创建新的笔记本，用于运行本章中的 Python 脚本:

1.  通过执行以下操作导航到 SageMaker Studio:
    1.  在 AWS 管理控制台的搜索栏中键入`sagemaker studio`。
    2.  从**功能**下的结果列表中选择 **SageMaker Studio** 。

重要说明

本章假设我们在使用服务管理和创建不同类型的资源时使用了`us-west-2`区域。您可以使用不同的区域，但如果某些资源需要转移到所选的区域，请确保进行任何必要的调整。

1.  接下来，点击侧边栏中 **SageMaker 域**下的 **Studio** 。
2.  点击**启动 app** ，如下图截图所示。从下拉选项列表中选择**工作室**:

![Figure 6.4 – Opening SageMaker Studio

](img/B18638_06_004.jpg)

图 6.4–打开 SageMaker Studio

这将把你重定向到 SageMaker 工作室。等待几秒钟，让界面加载。

1.  在**文件浏览器**侧边栏窗格的空白处右击，打开类似如下的上下文菜单:

![Figure 6.5 – Creating a new folder

](img/B18638_06_005.jpg)

图 6.5–创建新文件夹

选择`CH06`。

1.  双击侧边栏中相应的文件夹名称，导航到`CH06`目录。
2.  通过点击**文件**菜单并从**新建**子菜单下的选项列表中选择**笔记本**来创建一个新笔记本:

![Figure 6.6 – Creating a new Notebook

](img/B18638_06_006.jpg)

图 6.6–创建新笔记本

在这里，我们还可以看到其他选项，包括创建一个新的**控制台**、**数据牧马人流**、**终端**、**文本文件**等等。

1.  在`Data Science`(sage maker 图像下的选项)
2.  `Python 3`
3.  `No script`
4.  点击**选择**按钮。

注意

等待内核启动。在配置 ML 实例以运行 Jupyter 笔记本单元时，此步骤可能需要大约 3 到 5 分钟。

1.  右键单击选项卡的名称，如下图所示:

![Figure 6.7 – Renaming a notebook

](img/B18638_06_007.jpg)

图 6.7–重命名笔记本

从上下文菜单的选项列表中选择**重命名笔记本…** 。

1.  在`PART01.ipynb`下**新名称**。然后，点击**重命名**按钮。
2.  在笔记本的第一个单元格中输入如下:

    ```
    print('Hello')
    ```

3.  点击**运行所选单元格并前进**按钮，如下图所示。或者，您可以按住 **SHIFT** 并按 **ENTER** 来运行所选单元格并自动创建一个新单元格:

![Figure 6.8 – Running a selected cell

](img/B18638_06_008.jpg)

图 6.8–运行选定的单元

这将使产生一个`Hello`的输出，该输出将显示在单元格下方。

注意

如果没有显示输出，这意味着没有内核在运行，或者内核仍在启动。一旦内核准备就绪，您就可以再次运行细胞了。

现在我们的笔记本已经准备好了，我们将在随后的部分中为每个代码块创建一个新的单元格。

## 下载训练、验证和测试数据集

此时，你可能想知道我们将使用什么数据集来训练我们的 ML 模型。为了回答你的问题，我们将使用 **MNIST 数据集**，该数据集是手写数字图像的大型集合。下图中可以看到一个的例子:

![Figure 6.9 – MNIST dataset

](img/B18638_06_009.jpg)

图 6.9-MNIST 数据集

在这里，我们可以看到 MNIST 数据集中的每个图像都有一个对应于`0`和`9`之间的数字的类。也就是说，总共有 10 个类，并且该数据集中的每个图像恰好属于一个类。

注意

MNIST 数据集包含数以千计的手写数字图像。通常的挑战包括正确识别 0 到 9 中的哪个数字映射到显示的手写数字(在图像中)。对我们人类来说，正确分类这些手写数字可能是微不足道的。然而，这对于机器来说并不简单，因为它们必须处理图像的像素数据，并建立数字在图像中的表示模式。为了让机器正确分类这些图像，我们将使用深度学习(使用 SageMaker 的图像分类算法)！

为了让我们的生活更轻松，我们已经准备好了训练、验证和测试集，并将它们存储在一个 ZIP 文件中。按照这些步骤下载这个 ZIP 文件并解压到指定的目录下:

1.  运行以下语句以确保您准备好了一个空的`tmp`目录:

    ```
    !rm -rf tmp && mkdir -p tmp
    ```

这里，我们在命令前使用一个感叹号(`!`)，这样我们就可以在 Jupyter 笔记本中运行终端命令。

1.  使用`wget`命令:

    ```
    !wget -O tmp/batch1.zip https://bit.ly/37zmQeb
    ```

    下载`batch1.zip`文件
2.  接下来，运行下面的代码块来提取`tmp`目录中`batch1.zip`文件的内容:

    ```
    %%time
    ```

    ```
    !cd tmp && unzip batch1.zip && rm batch1.zip
    ```

这将产生一组日志，显示从 ZIP 文件中提取的文件:

![Figure 6.10 – Enabling scrolling for the output logs

](img/B18638_06_010.jpg)

图 6.10–启用输出日志的滚动

右键单击生成的日志消息附近的空白区域。这将打开一个上下文菜单，类似于前面截图中的。从上下文弹出菜单的可用选项列表中选择**启用输出滚动**。

1.  使用`ls`命令检查当前目录下的解压文件:

    ```
    !ls -RF
    ```

使用`ls`命令时，我们设置了两个标志。第一个是`-R`标志，它递归地列出了目录树。第二个标志是`-F`标志，它根据文件的类型添加一个特定的字符:`/`表示目录，`*`表示可执行文件，`@`表示符号链接，`|`表示 FIFO 特殊文件。

运行`ls`命令应该会给我们一组日志，如下所示:

![Figure 6.11 – Listing the extracted files and folders

](img/B18638_06_011.jpg)

图 6.11–列出提取的文件和文件夹

你应该在`tmp`目录下找到五个目录—`test`、`train`、`train_lst`、`validation`和`validation_lst`:

![Figure 6.12 – Files and directories extracted from the batch1.zip file

](img/B18638_06_012.jpg)

图 6.12–从 batch1.zip 文件中提取的文件和目录

如上图所示，我们应该在`train`目录中找到 10 个目录。这些目录中的每一个都包含几个 *PNG* 文件，标签对应于存储这些文件的目录名称。例如，存储在`0`目录中的 PNG 文件的标签为`0`。在`train_lst`目录中是`train.lst`文件，它包含来自`train`目录的标签和图像的映射(给定指定的路径和文件名)。我们应该在`validation`和`validation_lst`中找到一组相似的目录和文件。

1.  接下来，让我们安装`IPyPlot`，我们将使用它来检查我们从 ZIP 文件中提取的图像:

    ```
    !pip3 install ipyplot
    ```

2.  安装了`IPyPlot`之后，让我们快速看一下我们标记的图像集是什么样子的:

    ```
    import ipyplot
    ```

    ```
    import glob
    ```

    ```
    for i in range(0,10):    
    ```

    ```
        image_files = glob.glob(f"tmp/train/{i}/*.png")
    ```

    ```
        print(f'---{i}---')
    ```

    ```
        ipyplot.plot_images(image_files, 
    ```

    ```
                            max_images=5, 
    ```

    ```
                            img_width=128)
    ```

这将绘制一系列图像，如下所示:

![Figure 6.13 – Using IPyPlot to display a selected number of images

](img/B18638_06_013.jpg)

图 6.13–使用 IPyPlot 显示选定数量的图像

这里我们可以看到同组图像的差异和变化。首先，零看起来不一样！

在进入下一部分之前，调用`plot_images()`功能时，请随意调整和更改`max_images`的参数值。

现在我们已经准备好了训练、验证和测试数据集，让我们继续将它们上传到一个**亚马逊 S3** 桶。

## 上传数据到 S3

注意在本章中，我们将使用两种不同的 S3 桶，如下图所示:

![Figure 6.14 – S3 buckets

](img/B18638_06_014.jpg)

图 6.14-S3 铲斗

正如我们所看到的，第一个 S3 存储桶将包含这个部分中培训作业的输入和输出文件。类似地，第二个 S3 存储桶将包含训练作业的输入和输出文件，我们将在本章末尾的*利用受管理的现场训练和检查点*部分运行该作业。除此之外，我们将使用一种称为增量训练的技术，其中我们将使用本节中生成的模型作为起点来训练更精确的模型。现在，让我们关注第一个 S3 桶，并上传将用于训练我们的 ML 模型的数据。

按照以下步骤创建一个 S3 存储桶，然后将所有文件和文件夹从`tmp`目录上传到新的 S3 存储桶:

1.  指定唯一的 S3 时段名称和前缀。确保在运行下面的代码块之前，用一个惟一的 S3 存储桶名替换了`<INSERT S3 BUCKET NAME HERE>`的值:

    ```
    s3_bucket = "<INSERT S3 BUCKET NAME HERE>"
    ```

    ```
    prefix = "ch06"
    ```

建议不要使用在前面章节中创建的任何 S3 存储桶。因此，这里的 S3 存储桶名称应该是一个尚不存在的存储桶。

1.  让我们使用`glob()`函数来准备一个包含`tmp/train`目录中所有图像的列表。然后，使用`len()`函数统计生成的列表中的项目数:

    ```
    training_samples = glob.glob(f"tmp/train/*/*.png")
    ```

    ```
    len(training_samples)
    ```

这应该给我们一个值`4000`，这个值是`tmp/train`目录中`.png`文件的总数。

1.  使用`aws s3 mb`命令创建一个新的亚马逊 S3 桶。在这里，`{s3_bucket}`自动被用 Python:

    ```
    !aws s3 mb s3://{s3_bucket}
    ```

    编写的先前代码单元格中的`s3_bucket`的值替换

如果 S3 存储桶创建步骤成功，您应该会看到类似于`make_bucket: <S3 bucket name>`的成功日志消息。请注意，如果在使用此命令之前存储桶已经存在，此步骤可能会失败。

1.  接下来，使用 AWS CLI 将`tmp`目录的内容上传到目标 S3 路径:

    ```
    %%time
    ```

    ```
    !aws s3 cp tmp/.  s3://{s3_bucket}/{prefix}/ --recursive
    ```

`aws s3 cp`命令的第一个参数是源(`tmp/.`)，而第二个参数是目标目的地(S3 路径)。这里，我们使用`--recursive`标志递归地将所有文件从源文件复制到目标文件:

![Figure 6.15 – Copying the files and directories from the tmp directory to the S3 bucket

](img/B18638_06_015.jpg)

图 6.15–将文件和目录从 tmp 目录复制到 S3 存储桶

如上图所示，`aws s3 cp`命令会将 SageMaker Studio 笔记本的`tmp`目录下的所有内容复制到新的 S3 桶中。这包括`train`、`train_lst`、`validation`、`validation_lst`和`test`目录中的所有文件和目录。

注意

完成此步骤大约需要 1 到 2 分钟。在等待的时候，请随意喝杯咖啡或茶！

一旦上传操作完成，我们就可以开始训练 ML 模型了！

## 使用 SageMaker Python SDK 训练一个 ML 模型

在前面的部分，我们将训练和验证数据集上传到亚马逊 S3 桶。运行本节中的培训作业时，这些数据集将用作输入。当然，在配置和运行 SageMaker 培训作业之前，我们还需要准备一些输入参数:

![Figure 6.16 – Requirements when initializing an Estimator object

](img/B18638_06_016.jpg)

图 6.16-初始化评估对象时的要求

如上图所示，在初始化和配置一个`Estimator`对象时，我们需要准备一些配置参数值和超参数配置值。当调用`Estimator`对象的`fit()`方法时，SageMaker 在运行训练作业时使用用于配置`Estimator`对象的参数值。例如，在初始化估计器时，用于训练 ML 模型的实例类型取决于`instance_type`的参数值。

按照以下步骤使用 **SageMaker Python SDK** 训练图像分类模型:

1.  导入 SageMaker Python SDK 和**Boto AWS Python SDK**:

    ```
    import sagemaker
    ```

    ```
    import boto3
    ```

2.  初始化一些先决条件，如`session`、`role`和`region_name` :

    ```
    session = sagemaker.Session()
    ```

    ```
    role = sagemaker.get_execution_role()
    ```

    ```
    region_name = boto3.Session().region_name
    ```

3.  使用`retrieve()`功能为图像分类算法准备图像 URI。注意`retrieve()`函数返回内置算法的亚马逊 ECR URI:

    ```
    image = sagemaker.image_uris.retrieve(
    ```

    ```
        "image-classification", 
    ```

    ```
        region_name, 
    ```

    ```
        "1"
    ```

    ```
    )
    ```

    ```
    image
    ```

这应该给我们一个类似于`'433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:1'`的值。

1.  定义`map_path()`和`map_input()`功能:

    ```
    def map_path(source):
    ```

    ```
        return 's3://{}/{}/{}'.format(
    ```

    ```
            s3_bucket, 
    ```

    ```
            prefix, 
    ```

    ```
            source
    ```

    ```
        )
    ```

    ```
    def map_input(source):
    ```

    ```
        path = map_path(source)
    ```

    ```
        return sagemaker.inputs.TrainingInput(
    ```

    ```
            path, 
    ```

    ```
            distribution='FullyReplicated', 
    ```

    ```
            content_type='application/x-image', 
    ```

    ```
            s3_data_type='S3Prefix'
    ```

    ```
        )
    ```

2.  通过运行以下代码块来准备`data_channels`字典:

    ```
    data_channels = {}
    ```

    ```
    channels = ["train", 
    ```

    ```
                "validation",
    ```

    ```
                "train_lst",
    ```

    ```
                "validation_lst"]
    ```

    ```
    for channel in channels:
    ```

    ```
        data_channels[channel] = map_input(channel)
    ```

这些数据通道对应于我们上传到亚马逊 S3 桶的每个目录(除了`test`目录)。

1.  使用我们之前定义的`map_path()`函数为输出路径生成 S3 URL:

    ```
    output_path = map_path("output")
    ```

    ```
    output_path
    ```

这应该给我们一个类似于`'s3://<S3 BUCKET NAME>/ch06/output'`的 S3 路径。

在我们初始化`Estimator`对象之前，让我们快速回顾一下到目前为止我们所拥有的:

![Figure 6.17 – Data channels and the output path

](img/B18638_06_017.jpg)

图 6.17–数据通道和输出路径

在这里，我们可以看到，我们在前面步骤中准备的数据通道将在稍后运行培训作业时用作输入。一旦培训工作完成，输出文件将存储在`output_path`中指定的 S3 位置。

1.  一切准备就绪后，让我们初始化`Estimator`对象。当初始化一个`Estimator`对象时，我们传递几个参数，比如容器图像 URI、IAM 角色 ARN 和 SageMaker `session`对象。我们还指定了执行训练作业时使用的 ML 实例的数量和类型，以及`output_path`和`enable_network_isolation`的参数值:

    ```
    estimator = sagemaker.estimator.Estimator(
    ```

    ```
        image,
    ```

    ```
        role, 
    ```

    ```
        instance_count=2, 
    ```

    ```
        instance_type='ml.p2.xlarge',
    ```

    ```
        output_path=output_path,
    ```

    ```
        sagemaker_session=session,
    ```

    ```
        enable_network_isolation=True
    ```

    ```
    )
    ```

请注意，初始化`Estimator`对象并不会运行培训作业。当我们在后面的步骤中使用`fit()`方法运行训练作业时，SageMaker 将启动并提供两个`ml.p2.xlarge`实例来运行图像分类算法以训练模型。然后，结果在`output_path`中上传到 S3 位置。因为我们将`enable_network_isolation`设置为`True`，所以我们已经在 SageMaker ML 实例中配置了容器，这样当训练作业运行时，它们就不能访问外部网络。这有助于保护设置，因为这种配置可以防止正在运行的容器下载恶意代码或访问外部服务。

注意

我们应该没问题，因为我们使用的是 AWS 准备的容器映像。如果我们使用一个定制的容器映像，我们可以将`enable_network_isolation`设置为`True`，特别是当我们不希望容器访问外部服务或下载资源的时候。这将有助于保护我们的 ML 环境和资源免受需要网络连接的攻击。有关此主题的更多信息，请查看第 9 章 、*安全、治理和遵从性策略*。

1.  使用以下代码块初始化超参数配置值:

    ```
    hyperparameters = {
    ```

    ```
        'num_training_samples': len(training_samples),
    ```

    ```
        'num_layers': 18,
    ```

    ```
        'image_shape': "1,28,28",
    ```

    ```
        'num_classes': 10,
    ```

    ```
        'mini_batch_size': 100,
    ```

    ```
        'epochs': 3,
    ```

    ```
        'learning_rate': 0.01,
    ```

    ```
        'top_k': 5,
    ```

    ```
        'precision_dtype': 'float32'    
    ```

    ```
    }
    ```

可配置的超参数值取决于所使用的算法。这些只是我们可以用图像分类算法配置的一些超参数。

1.  使用`set_hyperparameters()`方法用上一步准备好的超参数配置`Estimator`对象:

    ```
    estimator.set_hyperparameters(**hyperparameters)
    ```

在这里，我们可以看到我们使用了`**`来直接使用字典向函数或方法传递多个参数。注意，这相当于调用`set_hyperparameters()`方法，类似于我们在下面的代码块中所做的:

```
estimator.set_hyperparameters(

    num_training_samples=len(training_samples),

    num_layers=18,

    image_shape="1,28,28",

    ...

)
```

注意

或者，我们可以使用`__dict__`属性检查`Estimator`对象的属性。在继续下一步之前，请在单独的单元中运行`estimator.__dict__`。

1.  使用`fit()`方法启动培训工作:

    ```
    %%time
    ```

    ```
    estimator.fit(inputs=data_channels, logs=True)
    ```

一旦培训工作完成，我们应该会看到如下所示的一组日志:

![Figure 6.18 – Logs generated after the training job has been completed

](img/B18638_06_018.jpg)

图 6.18-培训工作完成后生成的日志

1.  当调用`fit()`方法时，在后台执行几个操作和步骤。在 SageMaker 提供了所需数量的 ML 实例之后，输入数据和训练容器映像被下载到每个实例中。从下载的容器映像运行容器，并使用输入数据训练 ML 模型。生成的模型文件存储在一个`model.tar.gz`文件中。该`model.tar.gz`文件随后被上传到已配置的输出 S3 位置。最后，SageMaker 在训练作业完成后终止实例:

![Figure 6.19 – What happens after calling the fit() method

](img/B18638_06_019.jpg)

图 6.19–调用 fit()方法后会发生什么

如前面的图中的所示，在 ML 实例中执行的每个相关步骤都会生成日志，这些日志会自动存储在 **CloudWatch 日志**中。这包括度量值，以及培训作业运行时生成的不同类型的日志消息。

重要说明

完成此步骤可能需要大约 5 到 10 分钟。如果您遇到了**resourcelimitexceed**错误，这意味着您在运行培训作业时使用某种类型的 ML 实例时已经超出了配额。确保你已经完成了本章*准备必要的先决条件*一节中指定的步骤。有关这个主题的更多信息，请查看[https://AWS . Amazon . com/premium support/knowledge-center/resourcelimitexceed-sage maker/](https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/)。

我们可以从存储在 CloudWatch 日志中的日志中获得很多信息。如果在运行培训作业时遇到错误，可以检查存储在 CloudWatch 日志中的日志(例如，`/aws/sagemaker/TrainingJob`)来解决问题。

## 使用%store 魔法存储数据

在我们部署和测试我们的模型之前，让我们快速存储第一个笔记本中使用的一些变量值的备份副本(例如，`PART01.ipynb`):

![Figure 6.20 – %store magic

](img/B18638_06_020.jpg)

图 6.20–商店魔术百分比

我们将使用 IPython 的`%store`魔法来实现这一点，并使这些变量值在其他笔记本中也可用。我们将在稍后的*利用受管理的现场培训和检查点*部分加载这些变量值，在这里我们将创建一个名为`PART02.ipynb`的新笔记本。

按照以下步骤使用`%store`魔法保存`PART01.ipynb`中使用的一些变量值的副本:

1.  检查`model_data`的值:

    ```
    estimator.model_data
    ```

这将返回存储培训作业输出文件(`model.tar.gz`)的 S3 路径。

1.  将`estimator.model_data`的值复制到名为`model_data`的新变量中。类似地，将最新培训作业名称的值复制到名为`job_name` :

    ```
    model_data = estimator.model_data
    ```

    ```
    job_name = estimator.latest_training_job.name
    ```

    的变量中
2.  使用`%store`魔法将数据存储在内存中:

    ```
    %store model_data
    ```

    ```
    %store job_name
    ```

    ```
    %store role
    ```

    ```
    %store region_name
    ```

    ```
    %store image
    ```

如你所见，魔法帮助我们将一个长的 Jupyter 笔记本分成几个更小的笔记本。稍后，在*利用管理点训练和检查点*部分，我们将使用`%store -r <variable name>`加载存储在该部分的变量值。

## 使用 SageMaker Python SDK 部署 ML 模型

现在是我们将模型部署到推理端点的时候了。使用 SageMaker Python SDK 部署 ML 模型非常简单。我们需要做的就是调用`deploy()`方法；推理端点将在几分钟内自动为我们提供和配置。

按照以下步骤使用 SageMaker Python SDK 部署我们的 ML 模型，然后执行一些测试预测:

1.  使用`deploy()`方法将训练好的图像分类模型部署到实时推理端点。模型部署大约需要 5 到 10 分钟完成:

    ```
    endpoint = estimator.deploy(
    ```

    ```
        initial_instance_count = 1,
    ```

    ```
        instance_type = 'ml.m5.xlarge'
    ```

    ```
    )
    ```

这里，我们指定使用一个`ml.m5.xlarge`实例来托管训练好的 ML 模型。在这一点上，您可能想知道为什么在训练或部署一个模型时会涉及到几个不同的实例类型。您需要知道的第一件事是，运行 Jupyter 笔记本脚本的 SageMaker Studio 笔记本实例是不同的，并且与培训或部署模型时使用的实例完全分离:

![Figure 6.21 – Different instances used to train and deploy a model

](img/B18638_06_021.jpg)

图 6.21–用于训练和部署模型的不同实例

在这里，我们可以看到用于训练模型的实例也不同于部署期间使用的实例。在大多数情况下，与部署训练模型时使用的实例相比，用于训练模型的 ML 实例更强大(并且每小时更昂贵)。在我们的例子中，我们在训练期间使用了两个`ml.p2.xlarge`实例( *GPU 驱动的| 4 vCPU | 61 GiB | $1.125 每小时每个实例*)和一个`ml.m5.xlarge`实例( *4 vCPU | 16 GiB | $0.23 每小时每个实例*)来托管我们的实时推理端点。

重要说明

单看这些数字，我们可能会错误地认为运行`ml.p2.xlarge`训练实例的总成本高于运行用于托管已部署模型的`ml.m5.xlarge`实例的总成本。实际上，如果我们不立即删除推理实例，运行`ml.m5.xlarge`推理实例的总成本将超过运行`ml.p2.xlarge`训练实例的总成本。训练作业完成后，训练期间使用的 ML 实例将自动终止。因为我们只为我们使用的东西付费，如果我们要运行两个各 6 分钟的`ml.p2.xlarge`训练实例，我们将支付大约`$1.125 x 2 x 0.1 = $0.225`的费用。另一方面，如果我们让一个`ml.m5.xlarge`推理实例运行 24 小时，那么它的成本大约是`$0.23 x 24 = $5.52`。为了管理成本，请确保在不活动期间删除用于实时推理的实例。如果推理端点接收的预期流量不可预测或断断续续，您可能需要检查 **SageMaker 无服务器推理**选项。更多信息请查看[https://AWS . Amazon . com/about-AWS/whats-new/2021/12/Amazon-sage maker-server less-inference/](https://aws.amazon.com/about-aws/whats-new/2021/12/amazon-sagemaker-serverless-inference/)。

1.  在我们使用推断端点来执行测试预测之前，让我们快速更新端点的`serializer`属性来接受指定的内容类型:

    ```
    from sagemaker.serializers import IdentitySerializer
    ```

    ```
    endpoint.serializer = IdentitySerializer(
    ```

    ```
        content_type="application/x-image"
    ```

    ```
    )
    ```

2.  让我们定义一下`get_class_from_results()`函数，它接受来自 SageMaker 实时推理端点的原始输出数据，并以字符串形式返回相应的类(例如，`"ONE",``"TWO",``"THREE"`):

    ```
    import json
    ```

    ```
    def get_class_from_results(results):
    ```

    ```
        results_prob_list = json.loads(results)
    ```

    ```
        best_index = results_prob_list.index(
    ```

    ```
            max(results_prob_list)
    ```

    ```
        )
    ```

    ```
        return {
    ```

    ```
            0: "ZERO",
    ```

    ```
            1: "ONE",
    ```

    ```
            2: "TWO",
    ```

    ```
            3: "THREE",
    ```

    ```
            4: "FOUR",
    ```

    ```
            5: "FIVE",
    ```

    ```
            6: "SIX",
    ```

    ```
            7: "SEVEN",
    ```

    ```
            8: "EIGHT",
    ```

    ```
            9: "NINE"
    ```

    ```
        }[best_index]
    ```

3.  让我们定义一个自定义的`predict()`函数:

    ```
    from IPython.display import Image, display
    ```

    ```
    def predict(filename, endpoint=endpoint):
    ```

    ```
        byte_array_input = None
    ```

    ```
        with open(filename, 'rb') as image:
    ```

    ```
            f = image.read()
    ```

    ```
            byte_array_input = bytearray(f)
    ```

    ```
        display(Image(filename))
    ```

    ```
        results = endpoint.predict(byte_array_input)
    ```

    ```
        return get_class_from_results(results)
    ```

该自定义`predict()`功能执行以下操作:

1.  给定文件名，打开测试图像。
2.  在 Jupyter 笔记本中显示测试图像。
3.  使用端点对象的`predict()`方法获得预测的类值。
4.  在渲染图像后立即打印预测的类值:

![Figure 6.22 – Performing test predictions

](img/B18638_06_022.jpg)

图 6.22–执行测试预测

请注意，在调用方法之后还有一个额外的处理步骤。如前面的图所示，定制的`predict()`函数使用`get_class_from_results()`函数将推理端点的原始输出数据转换成预测类的友好字符串表示。

1.  现在，让我们使用我们在上一步中定义的自定义`predict()`函数:

    ```
    results = !ls -1 tmp/test
    ```

    ```
    for filename in results:
    ```

    ```
        print(predict(f"tmp/test/{filename}"))
    ```

这将产生一组类似如下的结果:

![Figure 6.23 – Performing test predictions

](img/B18638_06_023.jpg)

图 6.23–执行测试预测

这里，我们可以看到三个样本图像，以及它们对应的预测类值。我们的 ML 模型似乎做得很好！

1.  最后，让我们使用`delete_endpoint()`方法删除推理端点:

    ```
    endpoint.delete_endpoint()
    ```

那不是很容易吗？我们在本节中执行的部署只是在 AWS 上执行模型部署时许多可能场景中的一个。我们将在第 7 章 、 *SageMaker 部署解决方案*中了解其他部署策略和技术。

在下一节中，我们将进一步了解如何使用**调试器洞察仪表板**来检查用于训练我们的图像分类模型的资源的利用率。

# 使用调试器洞察仪表板

当在 ML 需求上工作时，ML 实践者在提出一个高性能的 ML 模型之前可能会遇到各种各样的问题。像软件开发和编程一样，构建 ML 模型需要一点反复试验。开发人员通常利用各种调试工具来帮助他们在编写软件应用程序时解决问题和实现错误。类似地，在构建 ML 模型时，ML 从业者需要一种方法来监控和调试培训工作。幸运的是，亚马逊 SageMaker 有一个名为 **SageMaker 调试器**的功能，允许我们在训练 ML 模型时解决不同的问题和瓶颈:

![Figure 6.24 – SageMaker Debugger features

](img/B18638_06_024.jpg)

图 6.24–sage maker 调试器功能

前面的图显示了当我们使用 SageMaker 调试器来监控、调试和排除影响 ML 模型性能的各种问题时可用的特性。这包括跨各种 ML 框架的**数据捕获**功能、**调试器交互报告**、 **SMDebug 客户端库**、带有**调试器内置规则的自动错误检测**和**自定义规则**，以及**调试器洞察仪表板**。

在本章中，我们将重点关注使用**调试器洞察仪表板**来检查和监控用于训练我们的 ML 模型的实例的硬件系统资源利用率。

重要说明

注意，每当我们使用 Debugger Insights 仪表板时，都会提供一个`ml.m5.4xlarge`实例。这个`ml.m5.4xlarge`实例需要手动关闭，因为它在不活动期间不会自动关闭。我们将确保在本节末尾关闭这个实例。

也就是说，让我们使用 Debugger Insights 仪表板来监控我们在前面部分中使用的实例的硬件系统资源利用率:

1.  点击下图所示的左侧边栏图标，导航至 **SageMaker resources** :

![Figure 6.25 – Navigating to SageMaker resources

](img/B18638_06_025.jpg)

图 6.25-导航至 SageMaker 资源

从第一个下拉菜单的可用选项列表中选择**实验和试验**。双击**未分配的试验组件**。

1.  右键单击列表中的第一个结果。它应该有一个以`image-classification`开头的名字，后面跟着一个时间戳。这将打开一个上下文菜单，如下所示。从选项列表中选择**打开洞察调试器**:

![Figure 6.26 – Open Debugger for insights

](img/B18638_06_026.jpg)

图 6.26–打开调试器以获得更多信息

在这里，我们可以看到另一个名为**的选项在试验细节**中打开。如果您选择此选项，您将看到几个图表，帮助您分析培训作业的指标和结果。

重要说明

确保在使用 Debugger Insights 仪表板后关闭`ml.m5.4xlarge`实例。

1.  在的**概述**选项卡上，向下滚动找到**资源利用汇总**报告，如下图所示:

![Figure 6.27 – Resource utilization summary

](img/B18638_06_027.jpg)

图 6.27–资源利用摘要

在这里，我们可以看到硬件系统资源利用率统计数据，如总 CPU 和 GPU 利用率、总 CPU 和 GPU 内存利用率等。

1.  导航到**节点**选项卡。
2.  向下滚动并找到不同的报告和图表，如下所示:

![Figure 6.28 – Debugger insights – nodes

](img/B18638_06_028.jpg)

图 6.28–调试器洞察–节点

在这里，我们可以看到帮助我们查看和分析不同利用率指标的图表。这包括随时间变化的 **CPU 利用率**、**网络利用率**、 **GPU 利用率**等报告。

注意

这些报告可以帮助 ML 工程师确定用于训练模型的资源是否“大小合适”这有助于优化成本，并在培训步骤中发现性能瓶颈。

1.  点击侧边栏中的**运行实例和内核**图标，如下图所示:

![Figure 6.29 – Turning off the running instances

](img/B18638_06_029.jpg)

图 6.29–关闭正在运行的实例

点击**运行实例和内核**图标将会打开，并在 SageMaker Studio 中显示运行实例、应用和终端。

1.  点击**关闭**按钮，关闭**运行实例**下的`ml.m5.4xlarge`运行实例，如前面截图中突出显示。点击**关闭**按钮将打开一个弹出窗口，验证实例关闭操作。点击**关闭所有**按钮继续。

至此，我们应该对如何在 Amazon SageMaker 中训练和部署 ML 模型有了更好的整体理解。请注意，我们只是触及了表面，因为有更多的特性和功能可供我们用来管理、分析和排除 ML 实验故障。

注意

如果你有兴趣了解更多关于 **SageMaker 调试器**的其他特性，那么可以随时查阅亚马逊 SageMaker Cookbook 的《机器学习》一书*第五章[](B18638_05.xhtml#_idTextAnchor105)*、*实用数据处理与分析*。**

 *在下一节中，我们将讨论在训练 ML 模型时 SageMaker 中可用的更多功能和特性。

# 利用受管理的现场培训和检查站

既然我们已经更好地理解了如何使用 SageMaker Python SDK 来训练和部署 ML 模型，那么让我们继续使用一些额外的选项，这些选项允许我们在运行训练作业时显著降低成本。在本节中，我们将在训练第二个影像分类模型时利用以下 SageMaker 特性和功能:

*   管理现场培训
*   检查点
*   增量训练

在 [*第二章*](B18638_02.xhtml#_idTextAnchor041) 、*深度学习 AMIs* 中，我们提到了可以使用 spot 实例来降低运行训练作业的成本。使用即时实例而不是按需实例可以帮助降低高达 70%到 90%的总体成本。那么，为什么现货实例更便宜呢？使用 spot 实例的缺点是这些实例可能会被中断，这将从头重新开始训练作业。如果我们要在 SageMaker 之外训练我们的模型，我们将不得不准备我们自己的一套定制自动化脚本，这些脚本将利用和管理 spot 实例来训练我们的模型。同样，我们不需要准备定制的解决方案，因为 SageMaker 已经通过其**托管 spot 培训**功能支持自动管理 Spot 实例的能力！除此之外，如果我们配置我们的 SageMaker 训练作业来使用**检查点**，我们将能够从最后保存的检查点恢复训练，即使在我们使用 spot 实例时出现了中断。

在本节中，我们还将使用一种称为**增量训练**的技术，其中我们将使用在*使用 SageMaker Python SDK* 部分训练图像分类模型中生成的模型，作为训练更精确模型的起点。这里，我们将使用我们提供的预训练模型，而不是从头开始训练新模型。

注意

注意增量训练只能在使用**图像分类算法****物体检测算法**和**语义分割算法**内置算法时使用。

按照这些步骤使用 **SageMaker Python SDK** 来运行一个利用检查点、管理点训练和增量训练的训练作业:

1.  点击**文件**菜单，从**新建**子菜单下的选项列表中选择**笔记本**，创建一个新笔记本。
2.  在`Data Science`(sage maker 图像下的选项)
3.  `Python 3`
4.  `No script`
5.  点击**选择**按钮。
6.  重命名笔记本`PART02.ipynb`。现在我们已经准备好了新的 Jupyter 笔记本，让我们在这个 Jupyter 笔记本中运行后续步骤中的代码块。
7.  指定 S3 时段名称和前缀。确保在运行下面的代码块之前，用一个唯一的 S3 桶名替换了`<INSERT S3 BUCKET NAME HERE>`的值:

    ```
    s3_bucket = "<INSERT S3 BUCKET NAME HERE>"
    ```

    ```
    prefix = "ch06"
    ```

注意，这应该不同于您在*使用 SageMaker Python SDK* 部分训练图像分类模型中创建的 S3 桶的名称。在本章中，我们将使用两种不同的 S3 存储桶，类似于下图所示:

![Figure 6.30 – Working with two S3 buckets

](img/B18638_06_030.jpg)

图 6.30–使用两个 S3 铲斗

运行第一个培训作业后，第一个桶应包含存储在`model.tar.gz`文件中的模型输出文件。在这一部分的后面，我们将使用这个`model.tar.gz`文件作为一个新的训练任务的输入参数，当构建一个新的模型时，这个新的训练任务使用增量训练。此培训作业的输出将存储在第二个 S3 存储桶内的输出文件夹中。

1.  使用 IPython 的`%store`魔术加载来自*的存储变量的值，使用 SageMaker Python SDK 的*部分:

    ```
    %store -r role
    ```

    ```
    %store -r region_name
    ```

    ```
    %store -r job_name
    ```

    ```
    %store -r image
    ```

2.  检查加载的`job_name`变量的值:

    ```
    job_name
    ```

这将返回一个类似于`'image-classification-2022-04-11-16-22-24-589'`的值。

1.  初始化并导入一些培训必备:

    ```
    import sagemaker
    ```

    ```
    from sagemaker.estimator import Estimator
    ```

    ```
    session = sagemaker.Session()
    ```

2.  接下来，使用`Estimator.attach()` :

    ```
    previous = Estimator.attach(job_name)
    ```

    加载一个使用先前培训作业名称的`Estimator`对象
3.  使用中的`logs()`方法检查我们在上一步加载的作业的日志:

    ```
    previous.logs()
    ```

请注意，这将生成一组日志，类似于我们在*使用 SageMaker Python SDK* 部分训练图像分类模型中运行训练作业时生成的日志。

1.  获取前一个培训作业的 ML 模型 ZIP 文件的存储位置。将该值存储在`model_data`变量中:

    ```
    model_data = previous.model_data
    ```

    ```
    model_data
    ```

`model_data`变量应该有一个类似于`'s3://<S3 BUCKET NAME>/ch06/output/image-classification-<DATETIME>/output/model.tar.gz'`格式的值。我们将在以后初始化和配置新的`Estimator`对象时使用这个值。

1.  定义`generate_random_string()`函数，用于为培训作业生成唯一的基础作业名称:

    ```
    import string 
    ```

    ```
    import random
    ```

    ```
    def generate_random_string():
    ```

    ```
        return ''.join(
    ```

    ```
            random.sample(
    ```

    ```
            string.ascii_uppercase,12)
    ```

    ```
        )
    ```

2.  使用`generate_random_string()`生成一个唯一的基础作业名，并将其存储在`base_job_name`变量:

    ```
    base_job_name = generate_random_string()
    ```

    ```
    base_job_name
    ```

使用`generate_random_string()`函数后，您应该会得到一个类似于`'FTMHLGKYVOAC'`的 12 个字符的字符串。

注意

我们将在哪里使用这个？在后面的步骤中，我们将在初始化一个新的`Estimator`对象时指定一个我们选择的基本作业名。如果在初始化`Estimator`对象时没有指定基本作业名称，SageMaker 通常在运行训练作业时使用算法图像名称(例如`image-classification`)作为默认基本作业名称。然后，在基本作业名后面附加一个表示当前时间戳的字符串，以生成完整的培训作业名。

1.  启用检查点支持时准备不同的配置参数:

    ```
    checkpoint_folder="checkpoints"
    ```

    ```
    checkpoint_s3_bucket="s3://{}/{}/{}".format(s3_bucket, base_job_name, checkpoint_folder)
    ```

    ```
    checkpoint_local_path="/opt/ml/checkpoints"
    ```

2.  运行下面的代码块，确保存在一个空的`tmp2`目录:

    ```
    !rm -rf tmp2 && mkdir -p tmp2
    ```

3.  使用`wget`命令下载`batch2.zip`:

    ```
    %%time
    ```

    ```
    !wget -O tmp2/batch2.zip https://bit.ly/3KyonQE
    ```

4.  接下来，运行下面的代码块来提取`tmp`目录中`batch1.zip`文件的内容:

    ```
    %%time
    ```

    ```
    !cd tmp2 && unzip batch2.zip && rm batch2.zip
    ```

5.  让我们使用`glob()`函数获得一个包含`tmp2/train`目录中所有图像的列表。之后，我们将使用`len()`函数来计算生成的列表中的项目数:

    ```
    import glob
    ```

    ```
    training_samples = glob.glob(f"tmp2/train/*/*.png")
    ```

    ```
    len(training_samples)
    ```

这应该给我们一个值`7200`，它是`tmp2/train`目录中`.png`文件的总数。

1.  使用`aws s3 mb`命令:

    ```
    !aws s3 mb s3://{s3_bucket}
    ```

    创建一个新的 S3 桶
2.  使用`aws s3 cp`命令将`tmp2`目录的内容复制到

    ```
    %%time
    ```

    ```
    !aws s3 cp tmp2/.  s3://{s3_bucket}/{prefix}/ --recursive
    ```

    S3 桶中
3.  定义`map_path()`和`map_input()`功能:

    ```
    def map_path(source):
    ```

    ```
        return 's3://{}/{}/{}'.format(
    ```

    ```
            s3_bucket, 
    ```

    ```
            prefix, 
    ```

    ```
            source
    ```

    ```
        )
    ```

    ```
    def map_input(source):
    ```

    ```
        path = map_path(source)
    ```

    ```
        return sagemaker.inputs.TrainingInput(
    ```

    ```
            path, 
    ```

    ```
            distribution='FullyReplicated', 
    ```

    ```
            s3_data_type='S3Prefix'
    ```

    ```
        )
    ```

4.  通过运行以下代码块准备`data_channels`字典:

    ```
    data_channels = {}
    ```

    ```
    channels = ["train", 
    ```

    ```
                "validation",
    ```

    ```
                "train_lst",
    ```

    ```
                "validation_lst"]
    ```

    ```
    for channel in channels:
    ```

    ```
        data_channels[channel] = map_input(channel)
    ```

5.  使用的`map_path()`功能:

    ```
    output_path = map_path("output")
    ```

    设置S3 输出路径
6.  初始化`Estimator`对象:

    ```
    estimator = sagemaker.estimator.Estimator(
    ```

    ```
        image,
    ```

    ```
        role, 
    ```

    ```
        instance_count=2, 
    ```

    ```
        instance_type='ml.p2.xlarge',
    ```

    ```
        output_path=output_path,
    ```

    ```
        sagemaker_session=session,
    ```

    ```
        enable_network_isolation=True,
    ```

    ```
        model_uri=model_data,
    ```

    ```
        use_spot_instances=True,
    ```

    ```
        max_run=1800,
    ```

    ```
        max_wait=3600,
    ```

    ```
        base_job_name=base_job_name,
    ```

    ```
        checkpoint_s3_uri=checkpoint_s3_bucket,
    ```

    ```
        checkpoint_local_path=checkpoint_local_path
    ```

    ```
    )
    ```

这个初始化步骤应该类似于我们在*使用 SageMaker Python SDK* 部分训练图像分类模型中所做的。在中，除了我们在初始化`Estimator`对象时设置的原始参数值之外，我们还设置了一些额外的参数，包括`model_uri`、`use_spot_instances`、`max_run`、`max_wait`、`checkpoint_s3_uri`和`checkpoint_local_path`。

![Figure 6.31 – Initializing the Estimator object with Checkpointing and Managed Spot Training

](img/B18638_06_031.jpg)

图 6.31–用检查点和管理点训练初始化评估器对象

如上图所示，启用检查点和托管点训练简单明了。当运行 SageMaker 培训作业时，默认情况下这些是禁用的，因此我们需要做的就是用适当的值更新`use_spot_instances`、`max_run`、`max_wait`、`checkpoint_s3_uri`和`checkpoint_local_path`的参数值。

注意

当使用内置算法时，可以使用的`Estimator`类如`RandomCutForest`、`FactorizationMachines`和`PCA`来代替“泛型”`Estimator`类。使用这些参数有它自己的好处，并且很多配置参数在初始化时已经有了很好的缺省初始值(这也使得代码更短)。在本章中，我们将在执行训练实验时使用" generic" `Estimator`类，但是如果您有兴趣了解更多关于 SageMaker Python SDK 中可用的其他类的信息，请随时查看[https://sage maker . readthedocs . io/en/stable/algorithms/index . XHTML](https://sagemaker.readthedocs.io/en/stable/algorithms/index.xhtml)。

1.  准备超参数配置和存储在`hyperparameters`变量:

    ```
    hyperparameters = {
    ```

    ```
        'num_training_samples': len(training_samples),
    ```

    ```
        'num_layers': 18,
    ```

    ```
        'image_shape': "1,28,28",
    ```

    ```
        'num_classes': 10,
    ```

    ```
        'mini_batch_size': 100,
    ```

    ```
        'epochs': 3,
    ```

    ```
        'learning_rate': 0.01,
    ```

    ```
        'top_k': 5,
    ```

    ```
        'precision_dtype': 'float32'    
    ```

    ```
    }
    ```

这应该类似于我们在*使用 SageMaker Python SDK* 部分训练图像分类模型中所做的超参数配置，除了`num_training_samples`的值。

注意

这里没有什么可以阻止我们改变一些配置参数的值，比如`mini_batch_size`、`epochs`和`learning_rate`。一旦您对超参数值的不同组合测试得心应手，您也可以尝试配置和使用其他超参数，如`optimizer`、`num_layers`和`momentum`。关于这个话题的更多细节，请查看[https://docs . AWS . Amazon . com/sagemaker/latest/DG/IC-hyperparameter . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.xhtml)。

1.  使用和`set_hyperparameters()`方法指定训练作业

    ```
    estimator.set_hyperparameters(**hyperparameters)
    ```

    的超参数配置值
2.  使用`fit()`方法开始增量训练作业:

    ```
    %%time
    ```

    ```
    estimator.fit(inputs=data_channels, logs=True)
    ```

这应该会生成一组日志，如下所示:

![Figure 6.32 – A portion of the logs after running the training job

](img/B18638_06_032.jpg)

图 6.32–运行培训作业后的部分日志

在这里，我们可以看到使用托管现场培训所节省的成本，大约节省了`70%`美元！注意，我们所做的只是在`Estimator`对象的配置上做了一些额外的调整。通过这样做，我们能够显著降低运行培训工作的成本。

重要说明

如果你遇到一个`fit()`方法，你可以停止当前的训练工作，一个小时左右再试一次。或者，你可以在另一个地区进行实验。如果您遇到一个**resourcelimitexceed**错误，这意味着您在运行培训作业时使用某种类型的 ML spot 培训实例时已经超出了配额。确保您已经完成了本章*准备基本先决条件*一节中指定的步骤。有关这个主题的更多信息，请查看[https://AWS . Amazon . com/premium support/knowledge-center/resourcelimitexceed-sage maker/](https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/)。

1.  使用的`model_data`属性:

    ```
    estimator.model_data
    ```

    检查被训练模型的输出位置

我们应该得到一个类似于`'s3://<S3 BUCKET NAME>/ch06/output/<BASE JOB NAME>-<DATE AND TIME>/output/model.tar.gz'.`的值

注意

如果我们决定在 SageMaker 之外部署模型(例如，在`estimator.model_data`中指向。

1.  使用`aws s3 ls`命令检查生成的检查点文件:

    ```
    !aws s3 ls {estimator.checkpoint_s3_uri} --recursive
    ```

这应该会产生一组类似于下面的结果:

![Figure 6.33 – Generated checkpoint files

](img/B18638_06_033.jpg)

图 6.33–生成的检查点文件

这些保存的检查点文件可用于从最后保存的检查点重新启动和继续训练作业。

注意

如果您想使用最后保存的检查点并继续先前的训练作业，您只需在初始化`Estimator`对象时指定相同的`checkpoint_s3_uri`。这将自动将检查点文件从 S3 下载到培训实例，并从那里继续培训作业。

检查点与 SageMaker 的**管理的现场培训**功能配合得很好，因为我们可以轻松地恢复模型培训，即使培训实例或培训工作出现意外的中断。除此之外，我们可以在训练步骤的不同阶段使用检查点来分析我们的模型(因为我们在不同的中间阶段有模型的多个*快照*)。

重要说明

让我们讨论一下在 SageMaker 中训练和调优 ML 模型时可以使用的其他一些策略。第一个是**提前停止**，涉及到配置一个超参数调优作业，如果目标度量值在指定的时间内没有显著改善，则提前停止训练作业。这有助于降低成本(因为培训工作结束得更早)，并防止模型过度拟合。第二种，**本地模式**，包括在 SageMaker notebook 实例中运行和测试定制脚本，然后在专用 ML 实例中运行它们。这有助于加快定制培训(和部署)脚本的开发和调试，因为使用本地模式时的反馈循环要快得多。第三种，**异构集群训练**，涉及在几个不同的实例组上运行训练作业。这有助于在处理 ML 工作负载时，通过结合使用 GPU 和 CPU 实例来提高资源的可扩展性和利用率。第四种，**快速文件模式**，通过支持从亚马逊 S3 进行高性能数据访问(下载培训数据时)，有助于显著加快培训作业的速度。在这个列表之外还有更多的最佳实践和策略，但是现在这些应该已经足够了！

现在我们已经完成了本章的动手解决方案，是时候清理并关闭我们不再使用的任何资源了。

# 清理

按照这些步骤，在 SageMaker Studio 中找到并关闭任何剩余的运行实例:

1.  点击 **Amazon SageMaker Studio** 侧边栏中的**运行实例和内核**图标，如下图所示:

![Figure 6.34 – Turning off any remaining running instances

](img/B18638_06_034.jpg)

图 6.34–关闭任何剩余的运行实例

点击**运行实例和内核**图标将打开并显示 SageMaker Studio 中的运行实例、应用和终端。

1.  通过单击前面屏幕截图中突出显示的每个实例的**关闭**按钮，关闭**运行实例**下任何剩余的运行实例。点击**关闭**按钮将打开一个弹出窗口，确认实例关闭操作。点击**关闭所有**按钮继续。

注意，这个清理操作需要在使用 SageMaker Studio 之后执行。SageMaker 不会自动关闭这些资源，即使在不活动期间也是如此。关闭未使用的资源并执行定期清理操作将有助于降低和管理成本。

在这一点上，当在 AWS 云中执行 ML 实验时，我们应该可以轻松地使用 **SageMaker Python SDK** 。我们只是触及了表面，因为 SageMaker 有更多的功能和特性，我们将在接下来的几章中讨论。

# 总结

在这一章中，我们使用 **SageMaker Python SDK** 来训练和部署 ML 模型。我们首先使用 MNIST 数据集(训练数据集)和 SageMaker 的内置**图像分类算法**来训练图像分类器模型。之后，我们通过使用 SageMaker Studio 中可用的**调试器洞察仪表板**仔细查看了培训步骤中使用的资源。最后，我们执行了第二个训练实验，该实验利用了 SageMaker 中可用的几个特性和选项，例如**管理点训练**、**检查点训练**和**增量训练**。

在下一章中，当使用 SageMaker 执行模型部署时，我们将更深入地研究不同的部署选项和策略。我们将把预先训练好的模型部署到各种推理端点类型中，包括**实时**、**无服务器**和**异步**推理端点。

# 延伸阅读

有关本章涵盖的主题的更多信息，请随时查阅以下资源:

*   *亚马逊 SageMaker 调试器*([https://docs . AWS . Amazon . com/SageMaker/latest/DG/train-Debugger . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.xhtml))
*   *使用亚马逊 SageMaker* 中的检查点([https://docs . AWS . Amazon . com/SageMaker/latest/DG/model-check points . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.xhtml))
*   *亚马逊 SageMaker* 中的增量培训([https://docs . AWS . Amazon . com/SageMaker/latest/DG/Incremental-Training . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/incremental-training.xhtml))
*   *在亚马逊 SageMaker*([https://docs . AWS . Amazon . com/SageMaker/latest/DG/model-Managed-Spot-Training . XHTML](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.xhtml)**