# 八、TPOT 模型部署

在这一章中，你将学习如何部署任何自动化的机器学习模型，包括本地主机和云。如果你的目标是制造机器学习驱动的软件，你将了解为什么部署步骤是必要的。假设你知道如何用 TPOT 训练基本的回归和分类模型。不需要了解最后几章的主题(Dask 和神经网络),因为我们在这里不会涉及这些。

在本章中，您将了解到将您的模型包装在 API 中并向其他不一定是数据科学家的用户展示其预测能力是多么容易。您还将了解哪些云提供商是让您完全免费入门的最佳选择。

本章将涵盖以下主题:

*   为什么我们需要模型部署？
*   介绍`Flask`和`Flask-RESTful`
*   部署自动化模型的最佳实践
*   将机器学习模型部署到本地主机
*   将机器学习模型部署到云中

# 技术要求

如前所述，你需要知道如何用 TPOT 建立基本的机器学习模型。如果您对这个库还不太适应，请不要担心，因为我们将从头开始开发这个模型。如果你对 TPOT 完全陌生，请参考 [*第二章*](B16954_02_Final_SK_ePub.xhtml#_idTextAnchor036)*深入 TPOT*[*第三章*](B16954_03_Final_SK_ePub.xhtml#_idTextAnchor051)*探索回归与 TPOT*[*第四章*](B16954_04_Final_SK_ePub.xhtml#_idTextAnchor058)*探索分类与 TPOT* 。

这一章代码会相当多，如果卡住了可以参考官方的 GitHub 资源库:[https://GitHub . com/packt publishing/Machine-Learning-Automation-with-TPOT/tree/main/chapter 08](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter08)。

# 为什么我们需要模型部署？

如果你已经在经历训练和优化机器学习模型的麻烦，为什么不更进一步，部署它，让每个人都可以使用它？

也许你想在 web 应用中使用模型的预测能力。也许你是一名移动应用开发人员，想要将机器学习引入 Android 和 iOS。选项层出不穷且各不相同，但所有选项都有一个共同点，即需要部署。

现在，机器学习模型部署与机器学习无关。目标是编写一个简单的 REST API(最好用 Python，因为这是整本书使用的语言),并向外界公开任何形式的调用`predict()`函数的端点。您希望将参数以 JSON 格式发送到您的应用，然后将它们用作模型的输入。一旦做出预测，您可以简单地将它返回给用户。

是的，这就是机器学习模型部署的全部内容。当然，事情可能会变得更加技术化，但是保持事情的简单性将会让我们达到 95%的目标，并且你总是可以进一步探索来挤压那额外的 5%。

当涉及到模型部署的技术方面时，Python 为您提供了许多选择。您可以使用`Flask`和`Flask-RESTful`、`FastAPI`、`Django`或`Pyramid`。当然，还有其他选择，但它们的“市场份额”或多或少可以忽略不计。从下一节开始，您将使用本章中的第一个选项。

接下来的部分旨在通过几个基本的实践示例向您介绍这些库。之后我们将深入研究机器学习。

# 引入烧瓶和烧瓶-RESTful

`Flask`是一个用于构建 web 应用的轻量级框架。它使您能够在需要时开始简单和规模。`Flask-RESTful`是对`Flask`的扩展，它允许你立刻构建 REST APIs。

要开始使用这两个软件，你需要安装它们。您可以从终端执行以下行:

```py
> pip install flask flask-restful
```

这就是你开始工作所需要的一切。让我们先来探索一下`Flask`的基础知识:

1.  Believe it or not, you'll need only seven lines of code to create your first web application with `Flask`. It won't do anything useful, but it's still a step in the right direction.

    首先，您需要导入库并创建一个应用实例。然后你必须创建一个函数，返回你想要在网站上显示的内容，并用一个`@app.route(route_url)`装饰器来装饰这个函数。请记住，您应该用函数应该显示结果的 URL 字符串替换`route_url`。如果您传入一个正斜杠(`/`)，结果将显示在根页面上——但稍后会详细介绍。

    最后，您将使用通过`if __name__ == '__main__'`检查使 Python 文件可运行。应用将在本地主机的端口`8000`上运行。

    请参考您的第一个`Flask`应用的以下代码片段:

    ```py
    from flask import Flask 
    app = Flask(__name__)
    @app.route('/')
    def root():
        return 'Your first Flask app!'
    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=8000)
    ```

    要运行应用，您必须从终端执行 Python 文件。这个文件在我的机器上被命名为`flask_basics.py`，所以要运行它，请执行以下命令:

    ```py
    Running on http://0.0.0.0:8000/ message, you can see where the application is running, ergo which URL you need to visit to see your application. Just so you know, the 0.0.0.0 part can be replaced with localhost.在那里，您将看到显示以下内容，表明一切工作正常:![Figure 8.2 – Your first Flask application
    ](img/B16954_08_2.jpg)图 8.2–您的第一个烧瓶应用这就是用`Flask`构建你的第一个 web 应用有多容易。接下来，您将学习如何让事情变得更复杂。
    ```

2.  By now, you know how to build the simplest application with `Flask` – but that's not why you're here. We want to make APIs instead of apps, and that's a bit of a different story. The difference between them is quite obvious – APIs don't come with a user interface (except for the documentation page), whereas web apps do. APIs are just a service. As it turns out, you can build APIs with `Flask` out of the box. We'll explore how to do so and explain why it isn't the best option.

    首先，创建一个新的 Python 文件。该文件将被称为`flask_basics2.py`。在其中，我们将为两种可能的 API 调用类型提供一个单一的路由。两者都有将两个数相加并返回结果的任务，但它们的方式不同。让我们列出不同之处:

    a) `/adding` (GET)依赖于前面实现的逻辑。更准确地说，GET 请求是在端点被调用时发出的。唯一不同的是这一次，参数是在 URL 中传递的。例如，调用`/adding?num1=3&num2=5`应该在屏幕上显示`8`。参数值直接从 URL 中提取。您将看到这一点在起作用，因此一切将立即变得清晰。

    b) `/adding` (POST)与第一个端点非常相似，但是发出 POST 请求。这是一种更安全的通信方法，因为参数值不是直接在 URL 中传递，而是在请求正文中传递。这个端点将总和作为 JSON 返回，所以您需要将结果包装在`flask.jsonify()`函数中。

    两个函数都旨在完成相同的任务——将两个数相加并返回结果。下面是一个如何实现这种逻辑的例子:

    ```py
    from flask import Flask, request, jsonify
    app = Flask(__name__)
    @app.route('/adding')
    def add_get():
        num1 = int(request.args.get('num1'))
        num2 = int(request.args.get('num2'))
        return f'<h3>{num1} + {num2} = {num1 + num2}</h3>'
    @app.route('/adding', methods=['POST'])
    def add_post():
        data = request.get_json()
        num1 = data['num1']
        num2 = data['num2']
        return jsonify({'result': num1 + num2})
    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=8000)
    ```

    如您所见，`add_get()`函数返回一个 HTML 格式的字符串。如果你想的话，你可以返回整个 HTML 文档，但是这不是我们现在感兴趣的事情，所以我们不会深入研究。

    要运行应用，您必须从终端执行 Python 文件。这个文件在我的机器上被命名为`flask_basics2.py`，所以要运行它，请执行以下命令:

    ```py
    /adding for GET first:![Figure 8.3 – The GET endpoint without parameter values
    ](img/B16954_08_3.jpg)

    ```
    import requests
    req = requests.post(
        url='http://localhost:8000/adding',
        json={'num1': 3, 'num2': 5}
    )
    res = req.content
    print(res)
    ```py

    如果您现在运行这段代码，您会看到以下输出:![Figure 8.6 – The POST endpoint with parameters (Python)
    ](img/B16954_08_6.jpg)图 8.6–带参数的 POST 端点(Python)这本质上是一个字符串，所以在您可以处理返回值之前，到 JSON 的一些转换将是强制性的。稍后，在第九章*的 [*中，将部署的 TPOT 模型用于生产*。](B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102)*到目前为止，您已经看到了如何使用`Flask`库来开发 web 应用和 web 服务(API)。这是很好的第一个选择，但是如果您只对构建 API 感兴趣，还有一个更好的方法。接下来就来探索一下。
    ```

3.  You already have `Flask-RESTful` installed. The syntax when using it is a bit different. It uses the `get()`, `post()`, and `put()`, which represent what happens when a request of a particular type is made.

    所有 API 类都继承自`Flask-RESTful.Resource`类，每个端点必须通过`add_resource()`方法手动绑定到特定的 URL 字符串。

    总而言之，我们将拥有`Add`类，它有两个方法:`get()`和`post()`。这些方法中的所有逻辑都与我们之前的相同，只有一个例外——我们不会在任何地方返回 HTML。

    下面是整个代码片段:

    ```py
    from flask import Flask, request, jsonify
    from flask_restful import Resource, Api 
    app = Flask(__name__)
    api = Api(app)
    class Adding(Resource):
        @staticmethod
        def get():
            num1 = int(request.args.get('num1'))
            num2 = int(request.args.get('num2'))
            return num1 + num2
        @staticmethod
        def post():
            data = request.get_json()
            num1 = data['num1']
            num2 = data['num2']
            return jsonify({'result': num1 + num2})
    api.add_resource(Adding, '/adding')
    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=8000)
    ```

    在`/adding`端点上可以获得`Adding`类中的所有内容。

    正如你所看到的，这个 API 将运行在不同的端口上，只是为了让容易区分这个 API 和之前的那个。

    如果你现在打开`http://localhost:8000/adding`，你会看到下面的消息:

![Figure 8.7 – Flask-RESTful GET without parameters
](img/B16954_08_7.jpg)

图 8.7–不带参数的 Flask-RESTful GET

我们现在有了与默认的`Flask` API 相同的错误，原因是 URL 中没有给出参数值。如果您要更改它并调用`http://localhost:8000/adding?num1=5&num2=10`，您将在浏览器窗口中看到以下内容:

![Figure 8.8 – Flask-RESTful GET with parameters
](img/B16954_08_8.jpg)

图 8.8–带参数的 Flask-RESTful GET

正如前面提到的，直接从浏览器与 API 通信被认为不是一个好的实践，但是你仍然可以用 GET 请求类型来做。你最好使用诸如 Postman 这样的工具，而且你已经知道怎么做了。

至于 POST 方法，可以调用与前面相同的 URL，`http://localhost:8000/adding`，并在请求体中以 JSON 的形式传递参数。以下是使用 Postman 的方法:

![Figure 8.9 – Flask-RESTful POST with Postman
](img/B16954_08_9.jpg)

图 8.9–带邮递员的 Flask-RESTful 帖子

您可以通过 Python 做同样的事情，但是现在您应该已经知道如何做了。

现在你已经知道了用 Python、`Flask`和`Flask-RESTful`开发 REST API 的基础。这是一个相对快速的动手部分，为接下来的内容做了铺垫。在下一节中，我们将回顾一些部署机器学习模型的最佳实践，在最后两节中，我们将探索如何分别训练和部署模型到本地主机和云中。

# 部署自动化模型的最佳实践

自动化模型的部署或多或少与普通机器学习模型的部署相同。归结起来就是首先训练模型，然后以某种格式保存模型。在正常机器学习模型的情况下，你可以很容易地将模型保存到一个`.model`或`.h5`文件中。没有理由不对 TPOT 模型做同样的事情。

如果你还记得前面的章节，TPOT 可以将最好的管道导出到 Python 文件中，这样如果这个管道还没有被训练过，它就可以被用来训练这个模型，并且这个模型可以在以后被保存。如果模型已经定型，则只获得预测。

通过检查文件是否存在，可以检查模型是否被训练过。如果模型文件存在，我们可以假设该模型已经过训练，因此我们可以加载它并进行预测。否则要先对模型进行训练和保存，然后才能进行预测。

在连接到机器学习 API 时，使用 POST 请求类型也是一个好主意。这是一个比 GET 更好的选择，因为参数值不直接在 URL 中传递。您可能知道，参数值可能很敏感，因此尽可能隐藏它们是个好主意。

例如，在进行预测之前，您可能需要使用 API 进行身份验证。很容易理解为什么在 URL 中直接发送您的用户名和密码凭证不是一个好主意。POST 已经覆盖了你，这一章的其余部分将很好地利用它。

简而言之，在进行预测之前，您应该始终检查模型是否经过训练，并在需要时对其进行训练。另一个要点是，在我们的情况下，POST 比 GET 更好。现在，您已经知道了一些部署机器学习模型的基本最佳实践。在下一节中，我们将训练模型并将其部署到本地主机。

# 将机器学习模型部署到本地主机

在部署之前，我们必须训练一个模型。你已经知道了和 TPOT 一起训练的一切，所以我们不会在这里花太多时间。目标是训练一个简单的虹膜分类器，并以某种方式输出预测功能。让我们一步一步地完成这个过程:

1.  As always, the first step is to load in the libraries and the dataset. You can use the following piece of code to do so:

    ```py
    import pandas as pd
    df = pd.read_csv('data/iris.csv')
    df.head()
    ```

    这是前几行的样子:

    ![Figure 8.10 – The first few rows of the Iris dataset
    ](img/B16954_08_10.jpg)

    图 8.10–Iris 数据集的前几行

2.  The next step is to separate the features from the target variable. This time, we won't split the dataset into training and testing subsets, as we don't intend to evaluate the model's performance. In other words, we know the model performs well, and now we want to retrain it on the entire dataset. Also, string values in the target variables will be remapped to their integer representation as follows:

    a)Setosa–0

    b)Virginica–1

    c)变色–2

    下面几行代码完成了描述的所有工作:

    ```py
    X = df.drop('species', axis=1)
    y = df['species']
    y = y.replace({'setosa': 0, 'virginica': 1, 'versicolor': 2})
    y
    ```

    下面是目标变量现在的样子:

    ![Figure 8.11 – The target variable after value remapping
    ](img/B16954_08_11.jpg)

    图 8.11-值重新映射后的目标变量

3.  Next stop – model training. We'll train the model with TPOT for 15 minutes. This part should be familiar to you, as we're not using any parameters that weren't used or described in previous chapters.

    以下代码将在整个数据集上训练模型:

    ```py
    from tpot import TPOTClassifier
    clf = TPOTClassifier(
        scoring='accuracy',
        max_time_mins=15,
        random_state=42,
        verbosity=2
    )
    clf.fit(X, y)
    ```

    在训练过程中，您会看到许多输出，但达到 100%的准确率应该不会花太长时间，如下图所示:

    ![Figure 8.12 – TPOT training process
    ](img/B16954_08_12.jpg)

    图 8.12-TPOT 训练流程

    在 15 分钟的时间框架内，会经过多少代取决于您的硬件，但是一旦完成，您应该会看到类似下面的内容:

    ![Figure 8.13 – TPOT output after training
    ](img/B16954_08_13.jpg)

    图 8.13-训练后的 TPOT 输出

4.  Once the training process is complete, you'll have access to the `fitted_pipeline_` property:

    ```py
    clf.fitted_pipeline_
    ```

    它是一个管道对象，可以导出供以后使用。它应该是这样的(请记住，您可能会在您的机器上看到一些不同的东西):

    ![Figure 8.14 – TPOT fitted pipeline
    ](img/B16954_08_14.jpg)

    图 8.14-TPOT 装配管道

5.  To demonstrate how this pipeline works, please take a look at the following code snippet. It calls the `predict()` function of the `fitted_pipeline_` property with a 2D array of input data, representing a single flower species:

    ```py
    clf.fitted_pipeline_.predict([[5.1, 3.5, 0.2, 3.4]])
    ```

    结果显示在下图中:

    ![Figure 8.15 – TPOT prediction
    ](img/B16954_08_15.jpg)

    图 8.15-TPOT 预测

    还记得几页前我们的重新映射策略吗？`0`表示该物种被归为`setosa`。

6.  The final step we have to do is save the predictive capabilities of this model to a file. The `joblib` library makes this step easy to do, as you just have to call the `dump()` function to save the model and the `load()` function to load the model.

    这里有一个快速演示。目标是将`fitted_pipeline_`属性保存到一个名为`iris.model`的文件中。您可以使用以下代码来实现这一点:

    ```py
    import joblib
    joblib.dump(clf.fitted_pipeline_, 'iris.model')
    ```

    这就是全部了！一旦模型保存到文件中，您将看到以下输出:

![Figure 8.16 – Saving TPOT models
](img/B16954_08_16.jpg)

图 8.16–保存 TPOT 模型

仅仅为了验证模型是否仍然有效，您可以使用`load()`函数将模型加载到一个新变量中:

```py
loaded_model = joblib.load('iris.model')
loaded_model.predict([[5.1, 3.5, 0.2, 3.4]])
```

上述代码的输出如下图所示:

![Figure 8.17 – Prediction of a saved model
](img/B16954_08_17.jpg)

图 8.17–已保存模型的预测

这就是保存机器学习模型以备后用是多么容易。我们现在已经具备了部署该模型所需的一切，接下来让我们开始吧。

模型部署过程将与我们之前用`Flask`和`Flask-RESTful`所做的非常相似。在进入分步指南之前，您应该使用以下目录/文件结构为您的 API 创建一个目录:

![Figure 8.18 – API directory structure
](img/B16954_08_18.jpg)

图 8.18–API 目录结构

如你所见，根文件夹叫做`api`，里面有两个 Python 文件——`app.py`和`helpers.py`。该文件夹还具有用于存储先前训练的模型的另一个文件夹。

接下来让我们一步一步地构建 API:

1.  Let's start with the `helpers.py` file. The goal of this Python file is to remove all calculations and data operations from `app.py`. The ladder is used only to declare and manage the API itself, and everything else is performed elsewhere.

    `helpers.py`文件将有两个功能——`int_to_species(in_species)`和`predict_single(model, X)`。

    第一个函数的目标是反转我们之前声明的映射，并返回给定整数表示的实际花卉种类名称。下面是给定整数输入时返回的字符串的具体列表:

    a)0—`setosa`

    b)1—`virginica`

    c)2—`versicolor`

    如果传递了其他数字，则返回一个空字符串。您可以找到该函数的代码，如下所示:

    ```py
    def int_to_species(in_species):
        if in_species == 0:
            return 'setosa'
        if in_species == 1:
            return 'virginica'
        if in_species == 2:
            return 'versicolor'
    ```

    现在转到`predict_single(model, X)`功能。它的目的是在给定模型和输入值列表的情况下，返回预测及其概率。该函数还进行以下检查:

    a)`X`是列表吗？如果不是，则引发一个异常。

    b)`X`是否有四项(萼片长度、萼片宽度、花瓣长度、花瓣宽度)？如果不是，则引发一个异常。

    这些检查是必需的,因为我们不希望坏的或格式错误的数据进入我们的模型并使 API 崩溃。

    如果所有检查都通过，预测和概率将作为一个字典返回给用户，旁边是为每个参数输入的数据。下面是实现这个函数的方法:

    ```py
    def predict_single(model, X):
        if type(X) is not list:
            raise Exception('X must be of list data type!')
        if len(X) != 4:
            raise Exception('X must contain 4 values - \
    sepal_length, sepal_width, petal_length, petal_width')
        prediction = model.predict([X])[0]
        prediction_probability =\
    model.predict_proba([X])[0][prediction]
        return {
            'In_SepalLength': X[0],
            'In_SepalWidth': X[1],
            'In_PetalLength': X[2],
            'In_PetalWidth': X[3],
            'Prediction': int_to_species(prediction),
            'Probability': prediction_probability
        }
    ```

    这里有一个调用`predict_single()`函数的例子:

    ```py
    predict_single(
        model=joblib.load('api/model/iris.model'), 
        X=[5.1, 3.5, 0.2, 3.4]
    )
    ```

    结果如下图所示:

    ![Figure 8.19 – Results of calling the predict_single() function
    ](img/B16954_08_19.jpg)

    图 8.19–调用 predict_single()函数的结果

2.  On to `app.py` now. If you have been following along from the beginning of this chapter, coding out this file will be a piece of cake. The goal is to have the model loaded at all times and to trigger the `post()` method of the `PredictSpecies` class when a `/predict` endpoint is called. You'll have to implement both the class and the method yourself.

    用户必须以 JSON 的形式传递输入数据。更准确地说，每个 flower 测量值都是单独传递的，因此用户必须指定总共四个参数的值。

    如果一切顺利，调用`helpers.py`中的`predict_single()`函数，并将结果返回给用户。

    让我们来看看`app.py`的实现:

    ```py
    import joblib 
    import warnings
    from flask import Flask, request, jsonify
    from flask_restful import Resource, Api
    from helpers import predict_single
    warnings.filterwarnings('ignore')
    app = Flask(__name__)
    api = Api(app)
    model = joblib.load('model/iris.model')
    class PredictSpecies(Resource):
        @staticmethod
        def post():
            user_input = request.get_json()
            sl = user_input['SepalLength']
            sw = user_input['SepalWidth']
            pl = user_input['PetalLength']
            pw = user_input['PetalWidth']
            prediction =\
    predict_single(model=model, X=[sl, sw, pl, pw])
            return jsonify(prediction)
    api.add_resource(PredictSpecies, '/predict')
    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=8000)
    ```

3.  You now have everything needed to run the API. You can do so the same way that you did with the previous APIs, and that is by executing the following line in the terminal:

    ```py
    > python app.py
    ```

    如果一切顺利，您将得到以下消息:

    ![Figure 8.20 – Running the API
    ](img/B16954_08_20.jpg)

    图 8.20–运行 API

4.  The API is now running on `http://localhost:8000`. We'll use the Postman application to test the API.

    下面是第一个例子:

![Figure 8.21 – API testing example 1
](img/B16954_08_21.jpg)

图 8.21–API 测试示例 1

正如你所看到的，这个模型 100%确信这个物种属于`setosa`类。让我们试试另一个:

![Figure 8.22 – API testing example 2
](img/B16954_08_22.jpg)

图 8.22–API 测试示例 2

这具有相同的置信水平，但是不同的预测类别。让我们将事情混在一起，传递与训练集中的任何内容稍有不同的值:

![Figure 8.23 – API testing example 3
](img/B16954_08_23.jpg)

图 8.23–API 测试示例 3

如您所见，该模型这次不是 100%有信心，因为输入数据与训练时看到的数据有很大不同。

现在您已经有了——部署到本地主机的 TPOT 模型!本章剩下要做的唯一一件事是将模型带到云中，并使它可以从任何地方访问。让我们接下来做那件事。

# 将机器学习模型部署到云

云机器学习模型的部署就是创建一个云虚拟机，把我们的 API 转移给它，然后运行它。这是一个乏味的过程，随着重复变得容易，因为涉及到许多步骤。如果你完全按照这一部分的每一步来做，一切都会好的。请确保不要错过任何小细节:

1.  To start, head over to [https://portal.aws.amazon.com/billing/signup#/start](https://portal.aws.amazon.com/billing/signup#/start) and create an account (assuming you don't already have one). Here's what the website currently looks like (as of February 2021):![Figure 8.24 – AWS registration website
    ](img/B16954_08_24.jpg)

    图 8.24–AWS 注册网站

    注册过程将花费一些时间，你必须输入你的信用卡信息。不用担心；我们将创建完全免费的虚拟机实例，因此不会向您收取任何费用。

2.  Once the registration process is complete, click on the `ubuntu` in the search bar:![Figure 8.26 – Ubuntu Server 20.04
    ](img/B16954_08_26.jpg)

    图 8.26–Ubuntu Server 20.04

    一旦点击**选择**，你将必须指定类型。如果您不想付费，请确保选择免费版本:

    ![Figure 2.27 – Ubuntu instance type
    ](img/B16954_08_27.jpg)

    图 2.27–Ubuntu 实例类型

    接下来，点击**查看并启动**按钮。您将进入以下屏幕:

    ![Figure 2.28 – Ubuntu instance confirmation
    ](img/B16954_08_28.jpg)

    图 2.28-Ubuntu 实例确认

    一旦你点击**发射**，下面的窗口就会出现。确保选择相同的选项，但密钥对名称由您决定:

    ![Figure 8.29 – Ubuntu key pair
    ](img/B16954_08_29.jpg)

    图 8.29-Ubuntu 密钥对

    输入详细信息后，点击**下载密钥对**按钮。下载完成后，您可以点击**启动实例**按钮:

    ![Figure 8.30 – Launching the Ubuntu instance
    ](img/B16954_08_30.jpg)

    图 8.30-启动 Ubuntu 实例

    最后，在一切完成后，您可以点击**查看实例**按钮:

    ![Figure 8.31 – View Instances
    ](img/B16954_08_31.jpg)

    图 8.31–查看实例

    您将立即看到您创建的实例。可能需要一些时间才能看到实例正在运行，所以请耐心等待:

    ![Figure 8.32 – Running instance
    ](img/B16954_08_32.jpg)

    图 8.32–运行实例

3.  To obtain the connection parameter, click on the instance row and select the `.ppk` file in the **Key file** option. After the **Connect** button is pressed, you'll see the following:![Figure 8.36 – FileZilla host key
    ](img/B16954_08_36.jpg)

    图 8.36–FileZilla 主机密钥

    只需按下 **OK** 即可运行。连接成功，如下图所示:

    ![Figure 8.37 – FileZilla successful connection
    ](img/B16954_08_37.jpg)

    图 8.37–FileZilla 成功连接

    现在您可以将 **api** 文件夹拖到远程虚拟机上的 **ubuntu** 文件夹中，如下所示:

    ![Figure 8.38 – Transferring API data to a remote virtual machine
    ](img/B16954_08_38.jpg)

    图 8.38–将 API 数据传输到远程虚拟机

    在进一步配置和启动 API 之前，让我们探索一下如何通过终端获得连接。

4.  打开一个新的终端窗口就在你的`.pem`文件存储的地方。在那里，执行下面的命令来改变权限:

    ```py
    TPOT_Book_KeyPair.pem with your filename and also make sure to write your instance name after ubuntu@. If you did everything correctly, you should see the following in your terminal:![Figure 8.39 – Accessing the Ubuntu virtual machine through the terminal
    ](img/B16954_08_39.jpg)

    ```
    > sudo apt-get update && sudo apt-get install python3-pip
    ```py

     最后，让我们安装每个需要的库。下面是在虚拟环境中这样做的命令: 

    ```
    > pip3 install virtualenv > virtualenv tpotapi_env > source tpotapi_env/bin/activate > pip3 install joblib flask flask-restful sklearn tpot
    ```py

     在启动 API 之前，您还需要完成一些步骤，比如管理安全性。
    ```

5.  If you were to run the API now, no errors would be raised, but you wouldn't be able to access the API in any way. That's because we need to "fix" a couple of permissions first. Put simply, our API needs to be accessible from anywhere, and it isn't by default.

    首先，导航到边栏上的**网络&安全** | **安全组**:

    ![Figure 8.40 – Security Groups
    ](img/B16954_08_40.jpg)

    图 8.40-安全组

    您应该会在浏览器窗口的右上角看到**创建安全组**按钮:

    ![Figure 8.41 – The Create security group button
    ](img/B16954_08_41.jpg)

    图 8.41–创建安全组按钮

    一旦新窗口弹出，你将必须指定几样东西。**安全组名称**和**描述**字段完全是任意的。另一方面，**入站规则**组不是任意的。您必须添加一个具有以下选项的新规则:

    a) **类型** : **所有流量**

    b) **来源** : **任何地方**

    请参考下图了解更多信息:

    ![Figure 8.42 – Creating a security group
    ](img/B16954_08_42.jpg)

    图 8.42–创建安全组

    指定正确的值后，您必须向下滚动到屏幕的末尾，并单击**创建安全组**选项:

    ![Figure 8.43 – Verifying a security group
    ](img/B16954_08_43.jpg)

    图 8.43–验证安全组

    我们还没完呢。下一步是去侧边栏上的**网络&安全** | **网络接口**选项:

    ![Figure 8.44 – The Network Interfaces option
    ](img/B16954_08_44.jpg)

    图 8.44–网络接口选项

    一旦出现，右键单击唯一可用的网络接口(假设这是您第一次进入 AWS 控制台)并选择**更改安全组**选项:

    ![Figure 8.45 – Changing security groups
    ](img/B16954_08_45.jpg)

    图 8.45–更改安全组

    这样做的目的是将“从任何地方访问”规则分配给我们的虚拟机。弹出窗口后，从下拉选项中选择之前声明的安全组:

    ![Figure 8.46 – Selecting the security group
    ](img/B16954_08_46.jpg)

    图 8.46–选择安全组

    添加后，点击**保存**按钮保存该关联:

    ![Figure 8.47 – Saving security associations
    ](img/B16954_08_47.jpg)

    图 8.47–保存安全关联

6.  Configuring our virtual machine was quite a lengthy process, but you can now finally start the `Flask` application (REST API). To do so, navigate to the `/api` folder and execute the following:

    ```py
    > python3 app.py
    ```

    您应该会看到下面这条熟悉的消息:

    ![Figure 8.48 – Starting the REST API through the terminal
    ](img/B16954_08_48.jpg)

    图 8.48–通过终端启动 REST API

    就是这样！API 现在正在运行，我们可以测试它是否正常工作。

7.  在通过 Postman 发出请求之前，我们首先需要找到远程虚拟机的完整 URL。你可以通过右击**实例**下的实例并点击**连接**选项来找到你的实例。在那里，您将看到 **SSH 客户端**选项卡:

![Figure 8.49 – Virtual machine URL
](img/B16954_08_49.jpg)

图 8.49–虚拟机 URL

现在我们知道了完整的网址:`http://ec2-18-220-113-224.us-east-2.compute.amazonaws.com:8000/predict`。从现在开始的过程与在 localhost 上的过程相同，如下图所示:

![Figure 8.50 – Testing our deployed API
](img/B16954_08_50.jpg)

图 8.50–测试我们部署的 API

正如您所看到的，连接通过了，API 返回了一个响应，就像对待本地部署的版本一样。

这就是将机器学习模型部署到 AWS 虚拟机的完整过程。如果这是你的第一次，这个过程会很乏味，甚至很棘手。随着你部署越来越多的机器学习模型，这将变得更容易，因为程序是相同的。

如果你不希望你的 API 被任何人从任何地方访问，你可以考虑权限，但是这超出了本书的范围。这一章差不多结束了——伟大的作品！接下来是对所学内容的总结，以及另一个有趣的动手操作章节。

# 总结

这一章是迄今为止最长的一章，包含了大量的实践任务。你很有希望能够继续学习，并了解如何在本地和云端部署用 TPOT 构建的机器学习模型。

现在，您可以部署任何用 Python 构建的机器学习模型。此外，如果您对前端技术(如 HTML、CSS 和 JavaScript)有必要的了解，您还知道如何部署基本的 Python web 应用。我们没有深入这个领域，因为它超出了本书的范围。

在接下来的章节中， [*第 9 章*](B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102) ，*在生产中使用部署的 TPOT 模型*，您将学习如何围绕这个 REST API 构建一个基本的应用。更准确地说，您将学习如何创建一个简单、美观的 web 界面，根据输入数据预测花卉种类。但在此之前，您将练习用 Python 向我们的 API 发出请求。

和往常一样，请随意更详细地研究模型部署，因为 AWS 不是唯一的选择。有许多云提供商提供某种形式的免费层，而 AWS 只是池塘中的一条鱼。

# 提问

1.  为什么我们需要(并且想要)模型部署？
2.  REST APIs 在模型部署中的作用是什么？
3.  列举几个可以用来部署机器学习模型的 Python 库。
4.  GET 和 POST 请求类型之间有什么区别？
5.  Python 中的`joblib`库背后的大致思路是什么？
6.  用自己的话解释什么是虚拟机。
7.  哪个免费工具可以用来测试 REST APIs？