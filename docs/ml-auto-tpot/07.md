# 五、使用 TPOT 和Dask并行训练

在这一章中，你将深入到一个更高级的话题；也就是自动机器学习。通过在 Dask 集群上分配工作，您将学习如何以并行方式处理机器学习任务。这一章将比前两章更理论化，但是你仍然会学到很多有用的东西。

我们将讨论 Python 中并行性背后的基本主题和思想，并且您将了解如何以几种不同的方式实现并行性。然后，我们将深入 Dask 库，探索它的基本功能，看看如何将它与 TPOT 联系起来。

本章将涵盖以下主题:

*   Python 中的并行性介绍
*   Dask 库简介
*   用 TPOT 和Dask训练机器学习模型

我们开始吧！

# 技术要求

阅读和理解这一章不需要事先接触 Dask 甚至并行编程。以前的经验是有帮助的，因为把这么大的一个概念装进几页纸几乎是不可能的。你应该仍然能够跟上并完全理解这里写的一切，因为所有的概念都将被解释。

你可以在这里下载本章的源代码和数据集:[https://github . com/packt publishing/Machine-Learning-Automation-with-TPOT/tree/main/chapter 05](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter05)。

# Python 中的并行性介绍

在某些情况下需要顺序执行任务(第一个任务完成后第二个任务开始)。例如，第二个函数的输入可能依赖于第一个函数的输出。如果是那样的话，这两个函数(进程)就不能同时执行了。

但更多时候，情况并非如此。想象一下，在显示仪表板之前，您的程序连接到三个不同的 API 端点。第一个 API 返回当前的天气状况，第二个返回股票价格，最后一个返回今天的汇率。一个接一个地调用 API 是没有意义的。它们互不依赖，因此按顺序运行它们会浪费大量时间。

不仅如此，它还会浪费 CPU 内核。大多数现代电脑至少有四个 CPU 核心。如果你按顺序运行，你只使用一个核心。如果可以的话，为什么不全部使用呢？

在 Python 中实现并行性的一种方法是多处理。这是一种基于进程的并行技术。正如您所想象的，Python 内置了一个`multiprocessing`库，本节将教您如何使用它。在 Python 3.2 及更高版本中，这个库不再是在应用中实现多处理的推荐方式。这个街区出现了一个新人，他的名字叫`concurrent.futures`。这是另一个内置库，您将在本节中学习如何使用。

解释和理解多处理最简单的方法是使用 Python 的内置`time`库。你可以用它来跟踪时差，有意识地暂停程序执行，等等。这正是我们所需要的，因为我们可以放入许多打印语句，它们之间有一些时间间隔，然后查看程序在顺序运行时的行为，以及在并行运行时的行为。

通过几个动手操作的例子，您将了解 Python 中的多重处理是如何工作的。

首先，请看看下面的代码片段。其中已经声明了`sleep_func()`函数。它的任务是打印一条消息，暂停程序执行 1 秒钟，然后在函数完成时打印另一条消息。我们可以监视这个函数运行任意次数(比如说五次)所花费的时间，然后打印出执行持续时间。片段如下:

```py
import time 
def sleep_func():
    print('Sleeping for a 1 second')
    time.sleep(1)
    print('Done.')
if __name__ == '__main__':
    time_start = time.time()
    # Run the function 5 times
    sleep_func()
    sleep_func()
    sleep_func()
    sleep_func()
    sleep_func()
    time_stop = time.time()
    print(f'Took {round(time_stop - time_start, 2)} seconds to execute!')
```

这里显示的是对应的输出:

```py
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Took 5.02 seconds to execute!
```

这里发生了什么？退一步说，没什么意外。`sleep_func()`功能连续执行五次。执行时间大约为 5 秒。您还可以用以下方式简化前面的代码片段:

```py
import time 
def sleep_func():
    print('Sleeping for a 1 second')
    time.sleep(1)
    print('Done.')
if __name__ == '__main__':
    time_start = time.time()
    # Run the function 5 times in loop
    for _ in range(5):
        sleep_func()
    time_stop = time.time()
    print(f'Took {round(time_stop - time_start, 2)} seconds to execute!')
```

如您所料，结果与完全相同:

```py
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Sleeping for a 1 second
Done.
Took 5.01 seconds to execute!
```

这种方法有问题吗？嗯，是的。我们在浪费时间和 CPU 内核。这些函数没有任何依赖关系，所以我们为什么不并行运行它们呢？正如我们前面提到的，有两种方法可以做到这一点。让我们首先通过`multiprocessing`库来检查旧的方法。

这是一个有点冗长的方法，因为它需要声明一个过程，启动它，并加入它。如果你只有几个进程就没那么繁琐了，但是如果你的程序里有几十个进程呢？它会很快变得乏味。

下面的代码片段演示了如何并行运行三次`sleep_func()`函数:

```py
import time 
from multiprocessing import Process
def sleep_func():
    print('Sleeping for a 1 second')
    time.sleep(1)
    print('Done.')
if __name__ == '__main__':
    time_start = time.time()
    process_1 = Process(target=sleep_func)
    process_2 = Process(target=sleep_func)
    process_3 = Process(target=sleep_func)
    process_1.start()
    process_2.start()
    process_3.start()
    process_1.join()
    process_2.join()
    process_3.join()
    time_stop = time.time()
    print(f'Took {round(time_stop - time_start, 2)} seconds to  execute!')
```

这里显示的是输出:

```py
Sleeping for a 1 second
Sleeping for a 1 second
Sleeping for a 1 second
Done.
Done.
Done.
Took 1.07 seconds to execute!
```

如您所见，这三个进程都是独立并行启动的，因此它们都设法在一秒钟内完成。

`Process()`和`start()`都是不言自明的，但是`join()`函数在做什么呢？简单地说，它告诉 Python 要等到过程完成。如果你在所有的进程上调用`join()`，最后两行代码直到所有的进程完成后才会执行。为了好玩，尽量去掉`join()`通话；你马上就会明白要点。

你现在对多处理有了一个基本的直觉，但是故事并没有就此结束。Python 3.2 引入了一种新的、改进的并行执行任务的方式。迄今为止,`concurrent.futures`库是最好的，接下来您将学习如何使用它。

有了它，您不必手动管理流程。每个被执行的函数都会返回一些东西，在我们的`sleep_func()`函数中是`None`。您可以通过返回最后一条语句而不是打印它来更改它。此外，这种新方法使用`ProcessPoolExecutor()`来运行。你不需要知道任何关于它的事情；只要记住它是用来同时执行多个进程的。就代码而言，只需将您想要并行运行的所有内容放入其中。这种方法开启了两个新功能:

*   `submit()`:用于并行运行功能。返回的结果将被附加到一个列表中，这样我们就可以用下一个函数打印它们(或者做其他任何事情)。
*   `result()`:用于获取函数返回值。我们将简单地打印结果，但是您可以自由地做任何其他事情。

概括地说，我们将把结果附加到一个列表中，然后在函数执行完毕时打印出来。下面的代码片段向您展示了如何用最新的 Python 方法实现多处理:

```py
import time 
import concurrent.futures
def sleep_func():
    print('Sleeping for a 1 second')
    time.sleep(1)
    return 'Done.'
if __name__ == '__main__':
    time_start = time.time()
    with concurrent.futures.ProcessPoolExecutor() as ppe:
        out = []
        for _ in range(5):
            out.append(ppe.submit(sleep_func))
        for curr in concurrent.futures.as_completed(out):
            print(curr.result())
    time_stop = time.time()
    print(f'Took {round(time_stop - time_start, 2)} seconds to execute!')
```

结果如下所示:

```py
Sleeping for a 1 second
Sleeping for a 1 second
Sleeping for a 1 second
Sleeping for a 1 second
Sleeping for a 1 second
Done.
Done.
Done.
Done.
Done.
Took 1.17 seconds to execute!
```

如您所见，该程序的行为与我们之前的类似，但有一些额外的好处——您不必自己管理流程，语法也更加清晰。

到目前为止，我们的一个问题是缺少函数参数。目前，我们只是调用一个不接受任何参数的函数。大多数情况下不会是这样的，所以尽早学习如何处理函数参数很重要。

我们将为我们的`sleep_func()`函数引入一个参数，允许我们指定执行将暂停多长时间。函数中的 print 语句会相应地更新。睡眠时间在`sleep_seconds`列表中定义，并且该值在每次迭代时作为第二个参数传递给`append()`。

完整的片段如下所示:

```py
import time 
import concurrent.futures
def sleep_func(how_long: int):
    print(f'Sleeping for a {how_long} seconds')
    time.sleep(how_long)
    return f'Finished sleeping for {how_long} seconds.'
if __name__ == '__main__':
    time_start = time.time()
    sleep_seconds = [1, 2, 3, 1, 2, 3]
    with concurrent.futures.ProcessPoolExecutor() as ppe:
        out = []
        for sleep_second in sleep_seconds:
            out.append(ppe.submit(sleep_func, sleep_second))
        for curr in concurrent.futures.as_completed(out):
            print(curr.result())
    time_stop = time.time()
    print(f'Took {round(time_stop - time_start, 2)} seconds to execute!')
```

这里显示了结果:

```py
Sleeping for 1 seconds
Sleeping for 2 seconds
Sleeping for 3 seconds
Sleeping for 1 seconds
Sleeping for 2 seconds
Sleeping for 3 seconds
Finished sleeping for 1 seconds.
Finished sleeping for 1 seconds.
Finished sleeping for 2 seconds.
Finished sleeping for 2 seconds.
Finished sleeping for 3 seconds.
Finished sleeping for 3 seconds.
Took 3.24 seconds to execute!
```

这就是你在并行处理中处理函数参数的方式。请记住，每台机器上的执行时间不会完全相同，因为运行时间将取决于您的硬件。一般来说，与脚本的非并行版本相比，您肯定会看到速度的提高。现在，您已经了解了并行处理的基础知识。在下一节中，您将了解 Python 的 Dask 库是如何发挥作用的，在随后的一节中，您将结合并行编程、Dask 和 TPOT 来构建机器学习模型。

# Dask 库简介

您可以将 Dask 视为最具革命性的大规模数据处理 Python 库之一。如果你是一个普通的熊猫和 NumPy 用户，你会喜欢 Dask 的。这个库允许你处理 NumPy 和 pandas 不允许的数据，因为它们不适合内存。

Dask 支持 NumPy 数组和 pandas DataFrame 数据结构，因此您可以很快熟悉它。它既可以在您的计算机上运行，也可以在集群上运行，这样更容易扩展。您只需要编写一次代码，然后选择运行它的环境。就这么简单。

另一件需要注意的事情是，Dask 允许您以最小的改动并行运行代码。正如您之前看到的，并行处理意味着执行时间减少，这通常是我们想要的行为。稍后，您将了解 Dask 中的并行性如何与`dask.delayed`一起工作。

要开始，您必须安装库。确保激活了正确的环境。然后，从终端执行以下命令:

```py
pipenv install "dask[complete]"
```

还有其他安装选项。例如，您可以只安装 arrays 或 DataFrames 模块，但最好从一开始就安装所有组件。不要忘记在库名两边加上引号，否则会导致错误。

如果您已经安装了所有的东西，您将可以访问三个 Dask 集合——数组、数据帧和包。所有这些都可以存储大于 RAM 大小的数据集，并且它们都可以在 RAM 和硬盘驱动器之间划分数据。

让我们从 Dask 数组开始，并将它们与 NumPy 替代数组进行比较。通过在笔记本环境中执行以下代码单元，您可以创建 1，000x1，000x1，000 维的  a NumPy 数组。`%%time` magic 命令用于测量单元完成执行所需的时间:

```py
%%time
import numpy as np
np_ones = np.ones((1000, 1000, 1000))
```

构造比这个更大的数组会导致我机器上的内存错误，但是这对于比较来说很好。相应的输出如下所示:

```py
CPU times: user 1.86 s, sys: 2.21 s, total: 4.07 s
Wall time: 4.35 s
```

如您所见，创建这个数组花了 4.35 秒。现在，让我们对 Dask 做同样的事情:

```py
%%time
import dask.array as da
da_ones = da.ones((1000, 1000, 1000))
```

如您所见，惟一的变化是库导入名称。如果这是您第一次接触 Dask 库，执行时间的结果可能会让您大吃一惊。它们如下所示:

```py
CPU times: user 677 µs, sys: 12 µs, total: 689 µs
Wall time: 696 µs 
```

是的，你没看错。Dask 花了 696 微秒创建了一个相同维数的数组，速度快了 6250 倍。当然，您不应该期望在现实世界中执行时间会有如此大的减少，但是差别应该还是很大的。

接下来，我们来看一下 Dask DataFrames。语法应该是非常相似的，所以学习这个库应该不会花你太多时间。为了充分展示 Dask 的能力，我们将创建一些无法在一台笔记本电脑的内存中容纳的大型数据集。更准确地说，我们将创建 10 个基于时间序列的 CSV 文件，每个文件呈现一年的数据，这些数据以秒为单位进行聚合，并通过五个不同的特性进行测量。这是一个很大的数目，创建它肯定需要一些时间，但是您最终应该得到 10 个数据集，每个数据集的大小大约为 1 GB。如果你像我一样有一台 8 GB 内存的笔记本电脑，你不可能把它放在内存里。

以下代码片段创建了这些数据集:

```py
import pandas as pd
from datetime import datetime
for year in np.arange(2010, 2020):
    dates = pd.date_range(
        start=datetime(year=year, month=1, day=1),
        end=datetime(year=year, month=12, day=31),
        freq='S'
    )
    df = pd.DataFrame()
    df['Date'] = dates
    for i in range(5):
        df[f'X{i}'] = np.random.randint(low=0, high=100, size=len(df))

    df.to_csv(f'data/{year}.csv', index=False)
!ls data/
```

只要确保有这个`/data`文件夹，你的笔记本就可以了。此外，如果你继续下去，确保你有 10 GB 的磁盘空间。最后一行`!ls data/`，列出了位于`data`文件夹中的所有文件。以下是您应该看到的内容:

```py
2010.csv 2012.csv 2014.csv 2016.csv 2018.csv
2011.csv 2013.csv 2015.csv 2017.csv 2019.csv
```

现在，让我们看看 pandas 读取一个 CSV 文件并执行一个简单的聚合需要多少时间。更准确地说，数据集按月分组，并提取总和。下面的代码片段演示了如何做到这一点:

```py
%%time
df = pd.read_csv('data/2010.csv', parse_dates=['Date'])
avg = df.groupby(by=df['Date'].dt.month).sum()
```

结果如下所示:

```py
CPU times: user 26.5 s, sys: 9.7 s, total: 36.2 s
Wall time: 42 s
```

正如你所看到的，熊猫花了 42 秒来完成这个计算。还不算太糟，但是如果您绝对需要加载所有数据集并执行计算，该怎么办呢？接下来让我们来探索一下。

您可以使用`glob`库获取指定文件夹中所需文件的路径。然后你可以单独读取它们，并使用 pandas 的`concat()`功能将它们堆叠在一起。聚合以相同的方式执行:

```py
%%time
import glob
all_files = glob.glob('data/*.csv')
dfs = []
for fname in all_files:
    dfs.append(pd.read_csv(fname, parse_dates=['Date']))

df = pd.concat(dfs, axis=0)
agg = df.groupby(by=df['Date'].dt.year).sum()
```

这里没什么可说的——笔记本就这么碎了。对于 8 GB RAM 的机器来说，将 10 GB 以上的数据存储到 RAM 中是不可行的。解决这个问题的一个方法是成块加载数据，但这本身就令人头疼。

Dask 能帮上什么忙？让我们学习如何用 Dask 加载这些 CSV 并执行相同的聚合。您可以使用下面的代码片段来实现这一点:

```py
%%time
import dask.dataframe as dd
df = dd.read_csv('data/*.csv', parse_dates=['Date'])
agg = df.groupby(by=df['Date'].dt.year).sum().compute()
```

结果会再次让你大吃一惊:

```py
CPU times: user 5min 3s, sys: 1min 11s, total: 6min 15s
Wall time: 3min 41s
```

没错，在不到 4 分钟的时间里，Dask 设法将超过 10 GB 的数据读取到一台 8 GB RAM 的机器上。仅此一点就应该让你重新考虑 NumPy 和 pandas，特别是如果你正在处理大量的数据或者你期望在不久的将来处理它。

最后还有 Dask 包。它们用于存储和处理不适合内存的一般 Python 数据类型——例如日志数据。我们不会探究这种数据结构，但是知道它的存在是很好的。

另一方面，我们将用 Dask 探索并行处理的概念。您在前面的章节中了解到，没有有效的理由按顺序处理数据或执行任何其他操作，因为一个的输入不依赖于另一个的输出。

*Dask 延迟*允许并行执行。当然，您仍然可以只依赖于我们之前学到的多处理概念，但是为什么呢？这可能是一个乏味的方法，Dask 有更好的东西提供。使用 Dask，不需要像纯 Python 那样改变编程语法。你只需要用`@dask.delayed` decorator 注释一个你想要并行化的函数，你就可以开始了！

您可以并行化多个函数，然后将它们放入计算图中。这就是我们接下来要做的。

下面的代码片段声明了两个函数:

*   `cube()`:返回一个数字的立方
*   `multiply()`:将列表中的所有数字相乘并返回乘积

以下是您需要的库导入:

```py
import time
import dask
import math
from dask import delayed, compute
```

让我们对五个数字运行第一个函数，对结果调用第二个函数，看看会发生什么。注意在`cube()`函数中对`time.sleep()`的调用。这将使发现并行化和非并行化函数之间的差异变得更加容易:

```py
%%time
def cube(number: int) -> int:
    print(f'cube({number}) called!')
    time.sleep(1)
    return number ** 3
def multiply(items: list) -> int:
    print(f'multiply([{items}]) called!')
    return math.prod(items)
numbers = [1, 2, 3, 4, 5]
graph = multiply([cube(num) for num in numbers])
print(f'Total = {graph}')
```

这是您的常规(顺序)数据处理。没什么不好，尤其是这么少这么简单的操作。相应的输出如下所示:

```py
cube(1) called!
cube(2) called!
cube(3) called!
cube(4) called!
cube(5) called!
multiply([[1, 8, 27, 64, 125]]) called!
Total = 1728000
CPU times: user 8.04 ms, sys: 4 ms, total: 12 ms
Wall time: 5.02 s
```

正如所料，由于顺序执行，代码单元运行了大约 5 秒钟。现在，让我们来看看为了并行化这些功能，您必须做哪些修改:

```py
%%time
@delayed
def cube(number: int) -> int:
    print(f'cube({number}) called!')
    time.sleep(1)
    return number ** 3
@delayed
def multiply(items: list) -> int:
    print(f'multiply([{items}]) called!')
    return math.prod(items)
numbers = [1, 2, 3, 4, 5]
graph = multiply([cube(num) for num in numbers])
print(f'Total = {graph.compute()}')
```

因此，图中只有装饰器和对`compute()`的调用。结果显示在这里:

```py
cube(3) called!cube(2) called!cube(4) called!
cube(1) called!
cube(5) called!
multiply([[1, 8, 27, 64, 125]]) called!
Total = 1728000
CPU times: user 6.37 ms, sys: 5.4 ms, total: 11.8 ms
Wall time: 1.01 s
```

正如所料，由于并行执行，整个过程只花了一秒多一点的时间。之前宣布的计算图有一个更方便的特性——很容易可视化。你需要在你的机器上安装 GraphViz 并作为一个 Python 库。每个操作系统的步骤都不一样，所以我们在这里就不赘述了。快速的谷歌搜索会告诉你如何安装。完成后，您可以执行以下代码行:

```py
graph.visualize()
```

相应的可视化显示如下:

![Figure 5.1 – Visualization of a Dask computational graph
](img/B16954_05_001.jpg)

图 5.1-Dask 计算图的可视化

从图中可以看到，`cube()`函数被并行调用了五次，其结果被存储在它上面的桶中。然后，使用这些值调用`multiply()`函数，并将产品存储在顶部存储桶中。

这就是你需要了解的关于 Dask 的基础知识。您已经学习了如何使用 Dask 数组和数据帧，以及如何使用 Dask 并行处理操作。不仅如此，你还学到了 Dask 在现代数据科学和机器学习中扮演的重要角色。数据集大小经常超过可用内存，因此需要现代解决方案。

在下一节中，您将学习如何使用 Dask 训练 TPOT 自动机器学习模型。

# 用 TPOT 和Dask训练机器学习模型

首先，优化机器学习管道是一个耗时的过程。我们可以通过并行运行来显著缩短时间。Dask 和 TPOT 结合使用效果很好，本节将教您如何在 Dask 集群上训练 TPOT 模型。不要让“集群”这个词吓到你，因为你的笔记本电脑或个人电脑就足够了。

你必须再安装一个库才能继续，它叫做`dask-ml`。顾名思义，它是用来和 Dask 一起执行机器学习的。从终端执行以下命令进行安装:

```py
pipenv install dask-ml
```

一旦完成，你就可以打开 Jupyter 实验室或者你最喜欢的 Python 代码编辑器，开始编码。让我们开始吧:

1.  Let's start with library imports. We'll also make a dataset decision here. This time, we won't spend any time on data cleaning, preparation, or examination. The goal is to have a dataset ready as soon as possible. The `load_digits()` function from scikit-learn comes in handy because it is designed to fetch many 8x8 pixel digit images for classification.

    由于一些库经常用不必要的警告填满你的屏幕，我们将使用`warnings`库来忽略它们。请参考以下所有库导入的代码片段:

    ```py
    import tpot
    from tpot import TPOTClassifier
    from sklearn.datasets import load_digits
    from sklearn.model_selection import train_test_split
    from dask.distributed import Client
    import warnings
    warnings.filterwarnings('ignore')
    ```

    这里唯一的新东西是来自`dask.distributed`的`Client`类。它用于建立与 Dask 集群(本例中是您的计算机)的连接。

2.  You'll now make an instance of the client. This will immediately start the Dask cluster and use all the CPU cores you have available. Here's the code for instance creation and checking where the cluster runs:

    ```py
    client = Client()
    client
    ```

    执行后，您应该会看到以下输出:

    ![Figure 5.2 – Information on the Dask cluster
    ](img/B16954_05_002.jpg)

    图 5.2–关于 Dask 集群的信息

    你可以点击仪表盘链接，会带你去 http://127.0.0.1:8787/status。下面的截图显示了仪表板第一次打开时的样子(没有任务运行):

    ![Figure 5.3 – Dask cluster dashboard (no running tasks)
    ](img/B16954_05_003.jpg)

    图 5.3–Dask 集群仪表板(无运行任务)

    一旦你开始训练模型，仪表盘会变得更加丰富多彩。接下来我们会做必要的准备。

3.  You can call the `load_digits()` function to get the image data and then use the `train_test_split()` function to split the images into subsets for training and testing. The train/test ratio is 50:50 for this example, as we don't want to spend too much time on the training. The ratio should be higher for the training set in almost any scenario, so make sure to remember that.

    一旦分割完成，您可以在子集上调用`.shape`来检查它们的维度。以下是完整的代码片段:

    ```py
    digits = load_digits()
    X_train, X_test, y_train, y_test = train_test_split(
        digits.data,
        digits.target,
        test_size=0.5,
    )
    X_train.shape, X_test.shape
    ```

    对应的输出如下图所示:

    ![Figure 5.4 – Dimensionality of training and testing subsets
    ](img/B16954_05_004.jpg)

    图 5.4–训练和测试子集的维度

    下一站——模特训练。

4.  You now have everything needed to train models with TPOT and Dask. You can do so in a very similar fashion to what you did previously. The key parameter here is `use_dask`. You should set it to `True` if you want to use Dask for training. The other parameters are well known:

    ```py
    estimator = TPOTClassifier(
        n_jobs=-1,
        random_state=42,
        use_dask=True,
        verbosity=2,
        max_time_mins=10
    )
    ```

    现在，您已经准备好调用`fit()`函数，并在训练子集上训练模型。下面是这样做的一行代码:

    ```py
    estimator.fit(X_train, y_train)
    ```

    在你开始训练模型后，Dask 仪表盘的外观会立即改变。这是这个过程开始几分钟后的样子:

![Figure 5.5 – Dask dashboard during training
](img/B16954_05_005.jpg)

图 5.5–训练期间的 Dask 仪表板

10 分钟后，TPOT 将完成管道优化，您将在笔记本上看到以下输出:

![Figure 5.6 – TPOT optimization outputs
](img/B16954_05_006.jpg)

图 5.6-TPOT 优化输出

这就是你要把 TPOT 和Dask结合起来所要做的。

您现在知道如何在 Dask 集群上训练模型，这是处理更大数据集和更具挑战性问题的推荐方式。

# 总结

这一章不仅包含了关于 TPOT 和并行训练模型的信息，还包含了关于并行性的一般信息。你已经学到了很多东西——从如何并行化除了休眠一会儿什么也不做的基本函数，到并行化带有参数和 Dask 基础的函数，到在 Dask 集群上用 TPOT 和 Dask 训练机器学习模型。

到目前为止，您已经知道如何以自动化的方式解决回归和分类任务，以及如何并行化训练过程。接下来的章节 [*第六章*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073) *《深度学习入门——神经网络速成课*》将为你提供所需的关于神经网络的知识。它将为第 7 章*[和 TPOT](B16954_07_Final_SK_ePub.xhtml#_idTextAnchor086)* 的神经网络分类器奠定基础，在那里我们将深入研究用最先进的神经网络算法训练自动化机器学习模型。

和往常一样，请随意练习用 TPOT 解决回归和分类任务，但是这一次，尝试用 Dask 并行化这个过程。

# 问&答

1.  定义术语“并行”
2.  解释哪些类型的任务可以并行化，哪些不可以并行化。
3.  列出并解释在您的应用中实现并行性的三个选项(所有选项都在本章中列出)。
4.  Dask 是什么，是什么让它在较大数据集上优于 NumPy 和 pandas？
5.  说出并解释在 Dask 中实现的三种基本数据结构。
6.  什么是 Dask 集群？
7.  你要怎么做才能告诉 TPOT 应该用 Dask 来训练？