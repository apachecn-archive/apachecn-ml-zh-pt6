

# 零、前言

从这本书的书名可以推断出这本书讲的是三件事:**解读**、**机器学习**、 **Python** 。而它们恰恰是按重要性排序的！

“为什么？”，你可能会问。

**可解释的机器学习**，也被称为**可解释的人工智能** ( **XAI** )，是一个不断增长的方法家族，我们可以利用它从模型中学习，并使它们安全、公平和可靠，我希望，这是我们所有人都希望我们的模型具备的。

然而，由于人工智能正在取代软件(和人类)，机器学习模型被视为更“智能”的软件形式。是的，它们是 1 和 0，但它们不是软件，因为它们的逻辑是由人编程的，并按照设计的意图运行。所以，解释是我们如何理解他们和他们的错误，然后纠正他们的错误，希望在他们造成任何伤害之前。因此，解释是使模型可信和合乎道德的关键。而且，很快，我们甚至不会用代码训练模型，而是用拖放界面！所以，虽然我们都热爱 Python，但经得起时间考验的技能是机器学习解释。

目前，仍然需要大量的代码来准备和探索数据，然后训练和生产模型，所以本书的每一章都涉及详细的 Python 代码示例。然而，这本书并没有被设计成脱离用例以及任何目的感的编程“食谱”。相反，这本书颠覆了这一模式。原因很简单:为了使**可解释的机器学习**有效，为什么？“得先于”**如何？**”。毕竟，解释就是回答“为什么”这个问题。

出于这个原因，大多数章节都以一个任务开始(“为什么？”)之后是一种方法(即“如何？”).之后，目标是使用方法完成任务(更多“如何？”)在整个章节中讲授，重点是解释结果(更多“为什么？”).最后，它将反映在完成任务的过程中学到了哪些可行的见解。

这本书本身也是结构化的。它从基础到更高级的话题。使用的工具都是开源的，由最先进的研究实验室构建，如微软、谷歌和 IBM。这是一个非常广泛的研究领域，其中大部分甚至还没有离开实验室就被广泛使用。本书无意涵盖所有内容。相反，我们的目标是以足够的深度呈现许多可解释性工具，以便对从业者和机器学习领域的许多专业人士有用。

这本书的第一部分是可解释性的初学者指南，涵盖了它在商业中的相关性，并探讨了它的关键方面和挑战。第二部分将向您介绍全面的解释方法，以及如何将它们应用于不同的用例，无论是分类或回归，还是表格数据、时间序列、图像或文本。在第三部分中，您将通过降低复杂性、减少偏差、设置防护栏和增强可靠性来实际操作调整模型和训练数据的可解释性。

到本书结束时，你将使用解释方法来更好地理解机器学习模型，并通过可解释性调整来改进它们。

# 这本书是给谁的

本书面向以下人群:

*   具有机器学习和 Python 编程语言基础知识的数据科学初学者和学生。
*   数据专业人员越来越有责任解释他们开发和维护的人工智能系统如何工作，以及如何改进它们。
*   机器学习工程师和数据科学家，他们希望扩展他们的技能组合，以包括最新的解释方法和偏差减轻技术。
*   艾道德干事，以加深他们的理解，执行方面的工作，以指导这些努力更好地进行。
*   人工智能项目经理和商业领袖，他们希望将可解释的机器学习引入他们的业务，以遵守公平，问责和透明的原则。

# 这本书涵盖了什么

[*第一章*](B16383_01_ePub_RK.xhtml#_idTextAnchor015) *，解释、可解释性、可说明性*；为什么这些都很重要？，介绍机器学习解释和相关概念，如可解释性、可解释性、黑盒模型和透明性，为这些术语提供定义以避免歧义。然后，我们强调机器学习可解释性对企业的价值。

[*第二章*](B16383_02_ePub_RK.xhtml#_idTextAnchor031) *，可解释性的关键概念*，用一个心血管疾病预测的例子介绍了两个基本概念(**特征重要性**和**决策区域)**以及用于对解释方法进行分类的最重要的分类法。我们还详细说明了哪些因素阻碍了机器学习的可解释性，作为未来发展的基础。

[*第 3 章*](B16383_03_ePub_RK.xhtml#_idTextAnchor051) *，解释挑战*，讨论了用于回归和分类的机器学习解释的传统方法与航班延误预测问题。然后，我们将检查这些传统方法的局限性，并解释是什么使“白盒”模型具有内在的可解释性，以及为什么我们不能总是使用白盒模型。为了回答这个问题，我们考虑预测性能和模型可解释性之间的权衡。最后，我们将发现一些新的“玻璃盒子”模型，它们试图在这种权衡中不妥协。

[*第 4 章*](B16383_04_ePub_RK.xhtml#_idTextAnchor081) *，特征重要性和影响*的基础，采用出生顺序分类示例来讨论获得特征重要性的不同方法，例如那些使用模型固有参数的方法，以及一种更可靠的模型无关方法，称为**置换特征重要性**。然后，为了传达单个特征对预测的边际影响，我们将研究如何渲染和解释**部分依赖图** ( **PDP** )和**个体条件期望** ( **ICE)** 图。

[*第 5 章*](B16383_05_ePub_RK.xhtml#_idTextAnchor106) *，全局模型不可知的解释方法*，用燃料效率回归模型非常详细地探索了博弈论启发的**沙普利加法解释** ( **SHAP** )，然后可视化条件边际分布**累积局部效应** ( **ALE** )图。最后，我们谈到了**全局代理**，如果选择正确，它可以是非常准确和高效的解释工具。

[*第 6 章*](B16383_06_ePub_RK.xhtml#_idTextAnchor125) *，局部模型不可知解释方法*，涵盖局部解释方法，解释单个或一组预测。为此，本章介绍了如何利用 **SHAP** 和**本地可解释的与模型无关的解释** ( **LIME** )进行本地解释，并给出了一个巧克力棒评级示例，其中包含表格和文本数据。

[*第 7 章*](B16383_07_ePub_RK.xhtml#_idTextAnchor143) *，锚点和反事实解释*，继续局部模型解释，但仅针对分类问题。我们用一个累犯风险预测的例子来理解我们如何以人类可理解的方式解释不公平的预测。本章涵盖了**锚**、**反事实**和**对比解释方法** ( **CEM** )，以及**假设工具** ( **WIT** )。

[*第 8 章*](B16383_08_ePub_RK.xhtml#_idTextAnchor162) *“可视化卷积神经网络*”专门探讨了使用水果分类器模型的**卷积神经网络(CNN)** 模型的解释方法。一旦我们掌握了 CNN 如何使用**激活**进行学习，我们将研究几种基于梯度的归属方法，如**显著图**、 **Grad-CAM** 和**集成梯度**来调试类别归属。最后，我们将使用基于扰动的归因方法扩展我们的归因调试技术，例如**遮挡敏感度**、**时间**和 **CEM** 。

[*第 9 章*](B16383_09_ePub_RK.xhtml#_idTextAnchor188) *，多变量预测和敏感性分析的解释方法*，使用一个交通预测问题和**长短期记忆(LSTM)** 模型来看如何在这个用例中使用**综合梯度**和 **SHAP** 。最后，本章着眼于预测和不确定性之间的内在联系，以及敏感性分析——一系列旨在衡量模型输出相对于输入的不确定性的方法。我们研究了两种这样的方法: **Morris** 用于因子优先级排序，以及 **Sobol** 用于因子固定。

[*第 10 章*](B16383_10_ePub_RK.xhtml#_idTextAnchor205) *，可解释性的特征选择和工程*，使用一个具有挑战性的非营利直接邮寄优化问题来回顾基于过滤器的特征选择方法，如 **Spearman** 的相关性，并了解嵌入式方法，如 **Lasso** 。然后，您会发现包装器方法，如**顺序特征选择**和混合方法，如**递归特征消除**，以及更高级的方法，如**遗传算法**。最后，尽管特征工程通常在选择之前进行，但在尘埃落定之后，出于多种原因，探索**特征工程**还是有价值的。

[*第 11 章*](B16383_11_ePub_RK.xhtml#_idTextAnchor231) *，偏差减轻和因果推断方法*，以一个信用卡违约问题为例，演示了利用公平性指标和可视化来检测不希望的偏差。然后，本章着眼于如何通过**预处理**方法来减少它，例如对处理中的**进行重新加权和不同冲击消除器**和对后处理的**进行均衡赔率**。然后，我们测试降低信用卡违约的处理方法，并利用因果建模来确定它们的**平均处理效果** ( **ATE** )，以及**条件平均处理效果** ( **CATE** )。最后，我们测试因果假设和估计的稳健性。

[*第十二章*](B16383_12_ePub_RK.xhtml#_idTextAnchor261) *，针对可解释性的单调约束和模型调优*，继续讲述来自 [*第七章*](B16383_07_ePub_RK.xhtml#_idTextAnchor143) 的累犯风险预测问题。我们将学习如何在数据端放置具有**特征工程**的护栏，在模型上放置**单调性和交互约束**以确保公平性，同时还将学习如何在有多个目标时调整模型。

[*第十三章*](B16383_13_ePub_RK.xhtml#_idTextAnchor284) *，对抗性鲁棒性*，用一个人脸面具检测问题来覆盖一个端到端的对抗性解决方案。对手可以通过多种方式故意阻挠模型，但我们重点关注规避攻击，如 **Carlini 和 Wagner Infinity-Norm** 和**对抗性补丁**，并简要解释其他形式的攻击。我们解释两种防御方法:**空间平滑预处理**和**对抗性训练**。最后，我们演示了一个**健壮性评估**方法和一个认证方法。

[*第十四章*](B16383_14_ePub_RK.xhtml#_idTextAnchor304) *，机器学习的下一步可解释性是什么？*，总结了在机器学习可解释性方法的生态系统背景下所学到的东西。然后推测接下来会发生什么！

# 为了充分利用这本书

您将需要一个 Python 3.6+的 Jupyter 环境。您可以执行以下任一操作:

*   通过 **Anaconda Navigator** 或者使用 **pip 从头开始在您的机器上安装一个。**
*   使用基于云的产品，例如**谷歌合作实验室**、 **Kaggle 笔记本**、 **Azure 笔记本**或**亚马逊 Sagemaker。**

关于如何开始的说明会有所不同，因此我们强烈建议您在网上搜索最新的设置说明。

关于安装贯穿全书的许多软件包的说明，请访问 Git 资源库，在**自述文件**中有更新的说明。考虑到软件包变化的频率，我们预计这些会不时地变化。我们还测试了在**自述文件**中详细描述的特定版本的代码，因此如果在以后的版本中出现任何问题，请安装特定的版本。

个别章节以如何以这种形式安装软件包的说明开始:

```
!pip install --upgrade nltk lightgbm lime
```

但是根据 **Jupyter** 的设置方式，安装包可能最好是通过**命令行**或者使用 **conda** 来完成，所以我们建议你修改这些安装说明来满足你的需求。

**如果你正在使用这本书的数字版本，我们建议你自己键入代码或者通过 GitHub 库访问代码(下一节提供链接)。这样做将帮助您避免任何与复制和粘贴代码相关的潜在错误。**

如果你不是机器学习的实践者或者是初学者，建议你按顺序阅读这本书，因为许多概念只有在前面的章节中才会详细解释。对于精通机器学习但不熟悉可解释性的从业者的建议是，他们可以略读前三章，以获得理解其余部分所需的伦理背景和概念定义，但要按顺序阅读其余部分。对于具有可解释性基础的高级实践者来说，以任何顺序阅读都可以。

至于代码，可以不同时运行代码，或者严格为了理论而运行代码，就可以看书。但是如果你计划运行代码，最好以这本书为指南来帮助解释结果，并加强你对理论的理解。

当你读这本书的时候，想一想你可以使用学到的工具的方法，希望在它结束的时候，你会受到启发，把新学到的知识付诸行动！

# 下载示例代码文件

您可以从 GitHub 下载本书的示例代码文件，网址为[https://GitHub . com/packt publishing/Interpretable-Machine-Learning-with-Python/](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python/)。如果代码有更新，它将在现有的 GitHub 库中更新。您还可以在`README.MD`文件中找到存储库的硬件和软件需求列表。

我们在 https://github.com/PacktPublishing/也有丰富的书籍和视频目录中的其他代码包。看看他们！

# 下载彩色图片

我们还提供了一个 PDF 文件，其中有本书中使用的截图/图表的彩色图像。可以在这里下载:[https://static . packt-cdn . com/downloads/9781800203907 _ color images . pdf](https://static.packt-cdn.com/downloads/9781800203907_ColorImages.pdf)。

# 习惯用法

本书通篇使用了许多文本约定。

`Code in text`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄。下面是一个例子:“接下来，我们可以通过用`robust_model.`初始化一个新的`KerasClassifier`来对抗训练模型。”

代码块设置如下:

```
base_classifier = KerasClassifier(model=base_model,\                                  clip_values=(min_, max_))y_test_mdsample_prob = np.max(y_test_prob[sampl_md_idxs],\                                                       axis=1)y_test_smsample_prob = np.max(y_test_prob[sampl_sm_idxs],\                                                       axis=1)
```

当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:

```
robust_classifier = KerasClassifier(model=robust_model,\                                    clip_values=(min_, max_))attacks = BasicIterativeMethod(robust_classifier, eps=0.3,\                               eps_step=0.01, max_iter=20)trainer = AdversarialTrainer(robust_classifier, attacks, ratio=0.5)trainer.fit(X_train, ohe.transform(y_train), nb_epochs=30,\            batch_size=128)
```

任何命令行输入或输出都按如下方式编写:

```
$ mkdir css
$ cd css
```

**粗体**:表示一个新的术语、一个重要的单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词出现在文本中，如下所示。下面是一个例子:“从**管理**面板中选择**系统信息**”

提示或重要注意事项

像这样出现。

# 取得联系

我们随时欢迎读者的反馈。

**总体反馈**:如果您对这本书的任何方面有疑问，请在邮件主题中提及书名，并发电子邮件至[customercare@packtpub.com](mailto:customercare@packtpub.com)。

**勘误表**:虽然我们已经尽力确保内容的准确性，但错误还是会发生。如果你在这本书里发现了一个错误，请告诉我们，我们将不胜感激。请访问 www.packtpub.com/support/errata,选择您的书，点击勘误表提交表格链接，并输入详细信息。

**盗版**:如果您在互联网上遇到我们作品的任何形式的非法拷贝，如果您能提供我们的地址或网站名称，我们将不胜感激。请通过 copyright@packt.com 的[联系我们，并提供材料链接。](mailto:copyright@packt.com)

**如果你有兴趣成为一名作家**:如果有一个你擅长的主题，你有兴趣写书或投稿，请访问 authors.packtpub.com。

# 评论

请留下评论。一旦你阅读并使用了这本书，为什么不在你购买它的网站上留下评论呢？潜在的读者可以看到并使用您不带偏见的意见来做出购买决定，我们 Packt 可以了解您对我们产品的看法，我们的作者可以看到您对他们的书的反馈。谢谢大家！

欲了解更多关于 Packt 的信息，请访问 packt.com。