# *第六章*:在云上处理和消费数据

边缘计算的价值主张是在更接近源的地方处理数据，并为不同用例中的不同类型的应用提供智能的近实时响应。此外，边缘计算减少了需要传输到云的数据量，从而节省了网络带宽成本。通常，高性能边缘应用需要本地计算、本地存储、网络、数据分析和机器学习能力，以低延迟处理高保真数据。虽然 AWS 物联网 Greengrass 允许您在设备和网关上运行复杂的边缘应用程序，但与云的马力相比，它将受到资源的限制。因此，对于不同的用例，利用云计算的规模来满足大量复杂数据处理需求是很常见的。

在前一章中，您了解了围绕边缘数据转换策略的不同设计模式。本章将重点解释如何基于从运行 Greengrass 实例的 HBS 中心收集的数据速度、数据种类和数据量，在云上构建不同的数据工作流。具体来说，您将学习如何在事务性数据存储中持久化数据，开发 API 驱动的访问，以及构建无服务器数据仓库来为最终用户提供数据。因此，本章分为以下主题:

*   为物联网工作负载定义大数据
*   **领域驱动设计** ( **DDD** )概念介绍
*   设计云上的数据流模式
*   记住边缘工作负载的数据流反模式

# 技术要求

本章的技术要求与 [*第二章*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032) *【边缘工作负载基础】中概述的技术要求相同。请参阅该章中的完整要求。*

# 为物联网工作负载定义大数据

**大数据**中的术语*大*是相对的，因为在过去的二十年里，由于企业和互联生态系统的数字化转型，数据的流入量从 TB 级大幅增长到 EB 级。大数据技术的出现使得人们(*认为社交媒体*)和企业(*认为数字化转型*)能够生成、存储和分析海量数据。要分析如此大规模的数据集，需要复杂的计算基础设施，能够根据输入数据量和所需结果进行弹性扩展。大数据工作负载的这一特征，以及云计算的可用性，推动了各种规模的公司对大数据技术的采用。即使随着边缘计算的发展，云上的大数据处理在物联网工作负载中也发挥着关键作用，因为当数据与其他数据系统相邻并丰富时，数据更有价值。在本章中，我们将了解大数据生态系统如何支持对从边缘收集的大量原始测量或事件进行高级处理和分析，从而支持不同角色消费可操作的信息。

物联网与大数据生态系统的集成开辟了一套多样化的分析能力，从而可以产生更多的业务见解。其中包括以下内容:

*   **描述性分析 e 分析**:这种类型的分析有助于用户回答*发生了什么，为什么？*这方面的例子包括传统的查询和报告仪表板。
*   **预测分析**:这种形式的分析帮助用户根据历史事件或检测到的异常预测未来给定事件的概率。这方面的例子包括银行交易中的早期欺诈检测和不同系统的预防性维护。
*   **规定性分析**:这种分析帮助用户提供具体(清晰)的建议。他们提出了一个问题*如果 x 发生了，我该怎么办？*这方面的例子包括接触目标选民的竞选活动或财富管理中的统计建模，以实现回报最大化。

这些流程的结果使组织能够更好地了解新信息、新兴趋势或隐藏的数据关联，从而提高效率或创造新的收入来源。在本章中，您将了解对从边缘收集的数据进行描述性和预测性分析的方法。除此之外，您还将学习如何实现设计模式，例如流式传输到云上的数据湖或事务性数据存储，以及利用 API 驱动的访问，这被认为是边缘的反模式。因此，让我们从与物联网工作负载相关的大数据设计方法开始。

## 什么是大数据处理？

大数据处理通常根据三个 v 进行分类:数据量(例如，1tb、Pb 或更多)、数据种类(即结构化、半结构化或非结构化)和数据速度(即数据产生或消费的速度)。然而，随着越来越多的组织开始采用大数据技术，虚拟化列表中又增加了一些内容，例如:

*   **粘度**:这个强调数据的易用性；例如，可能会从边缘收集到不容易解析的噪声数据。
*   **易失性**:这指的是数据变化发生的频率，以及数据有用的时间；例如，捕捉家中的特定事件可能比其他任何活动都更有用。
*   **准确性**:这指的是数据的可信度，例如，如果从室外摄像机捕获的图像质量很差，则不能信任它们来识别入侵。

对于边缘计算和**物联网** ( **IoT** )来说，这六个 v 都是相关的。下图直观总结了随着物联网和大数据技术的出现而变得可用的数据范围。这要求您根据数据各自的特征考虑组织大规模数据的不同方式:

![Figure 6.1 – The evolution of big data
](img/B17595_06_01.jpg)

图 6.1—大数据的演变

因此，您已经在 [*第 5 章*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090) *中了解了数据建模概念，从边缘*摄取和流式传输数据，这是一种基于数据类型和关系将数据组织成有意义的结构并从中提取价值的标准方式。然而，收集数据、将数据存储在流或持久层中，并快速处理数据以采取智能行动只是事情的一个方面。下一个挑战是找出如何在数据的整个生命周期中保持高质量的数据，以便它在不一致或风险的情况下继续为下游应用程序产生商业价值。对于物联网工作负载，这一方面至关重要，因为设备或网关驻留在物理世界中，连接时断时续，有时容易受到不同形式的干扰。这就是领域驱动设计(DDD)方法可以发挥作用的地方。

## 什么是领域驱动设计？

为了更好地管理数据质量，我们需要学习如何按内容(如数据域或主题区域)组织数据。最常见的方法之一是通过 Eric Evans 在 2003 年推出的 DDD。在他的书中，Eric 指出软件的核心是为用户解决领域相关问题的能力。所有其他的功能，尽管可能很重要，也支持这个基本目的。因此，DDD 是一种以业务领域的需求、规则和过程为中心的软件开发方法。

DDD 方法包括两个核心概念:有界语境和无处不在的语言。让我们更深入地了解每一个问题:

*   **Bounded context**: Bounded contexts help you to define the logical boundaries of a solution. They can be implemented on the application or business layer, as per the requirements of the organization. However, the core concept is that a bounded context should have its own application, data, and process. This allows the respective teams to clearly define the components they own in a specific domain. These boundaries are important in managing data quality and minimizing data silos, as they grow with different Vs and get redistributed with different consumers within or outside an organization. For example, with a connected HBS solution, there can be different business capabilities required by the internal business functions of HBS and their end consumers. This could include the following:
    *   内部能力(针对组织实体):
        *   产品工程:不同服务或特征的利用
        *   *车队运行*:监控车队健康状况
        *   *信息安全*:监控对不同监管要求的遵守情况，如 GDPR
        *   更多，如客户关系管理、企业资源规划和营销
    *   外部功能(针对最终消费者):
        *   *车队遥测*:近乎实时地处理来自设备的数据馈送，如恒温器或 HVAC 读数
        *   *车队监控*:捕捉车队健康信息或传感器故障等关键事件
        *   *车队分析*:用其他元数据丰富遥测数据，以执行分析，将时间、位置和高度等不同环境因素考虑在内

    下面的图展示了一个有界的上下文:

![Figure 6.2 – A bounded context 
](img/B17595_06_02.jpg)

图 6.2–一个有界的上下文

所有这些不同的业务能力都可以定义为一个有界的上下文。因此，现在已经确定了业务能力，我们可以在这个有限的上下文中定义技术需求，以交付所需的业务成果。一般的经验法则是，应用程序、数据或流程应该是内聚的，而不是供其他上下文使用。在这一章中，我们将主要关注为使用不同技术的最终消费者所需要的外部功能构建有界的上下文。

注意

然而，在现实世界中，在定义有界上下文时，还需要记住许多其他因素，比如组织结构、产品所有权等等。我们不会深究这些因素，因为它们与这里讨论的主题无关。

*   **Ubiquitous language**: The second concept in DDD is ubiquitous language. Each bounded context is supposed to have its own ubiquitous language. Applications that belong together within a bounded context should all follow the same language. If the bounded context changes, the ubiquitous language is also expected to be different. This allows the bounded context to be developed and managed by one team and, therefore, aligns with the DevOps methodology as well. This operating model makes it easier for a single team, familiar with the ubiquitous language, to own and resolve different applications or data dependencies quicker.Later in this chapter, you will discover how the different bounded contexts (or workflows) are implemented using a diverse set of languages.

    注意

    DDD 模型没有规定如何确定应用程序或数据管理中的有界上下文。因此，建议您从用例向后工作，并确定适当的内聚性。

因此，在此基础上，让我们定义一些云数据管理的设计原则——其中一些将用于本章的剩余部分。

## 使用 DDD 设计数据工作流的原则是什么？

我们将概述一组护栏(即原则),以了解如何使用 DDD 设计数据工作负载:

*   *原则 1:通过域管理数据所有权*–数据的质量和易用性是使用域的优势。最了解数据的团队拥有并管理数据。因此，数据所有权是分布式的，而不是集中式的。
*   *原则 2:使用有界的上下文定义域*——一个域实现了一个有界的上下文，它反过来又链接到一个业务能力。
*   *原则 3:将一个有界上下文链接到一个或多个应用程序工作负载*–一个有界上下文可以包含一个或多个应用程序。如果有多个应用程序，所有的应用程序都应该为相同的业务功能提供价值。
*   \ *原则 4:在有界上下文中共享通用语言*–负责在其有界上下文中分发数据的应用程序使用相同的通用语言，以确保不同的术语和数据语义不会冲突。每个有界上下文都与概念数据模型有一对一的关系。
*   *原则 5:保留原始来源的数据*——在集中式解决方案中，需要保留摄取的原始数据作为真实的来源。这通常被称为黄金数据集。这将允许不同的有界上下文在失败的情况下重复处理数据。
*   *原则 6:将数据与元数据相关联*–随着数据种类和数量的增长，任何数据集都需要易于发现和分类。这简化了不同下游应用程序对数据的重用，并建立了数据谱系。
*   *原则 7:为正确的工作使用正确的工具*–基于数据工作流，如速度层或批处理层，持久性和计算工具会有所不同。
*   *原则 8:分层数据存储*–根据数据的访问模式为其选择最佳存储层。通过将数据集分布到不同的存储服务中，您可以构建成本优化的存储基础架构。
*   *原则 9:保护和管理数据管道*—实施控制以保护和管理所有静态和传输中的数据。需要一种机制来只允许授权的实体可视化、访问、处理和修改数据资产。这有助于我们保护数据机密性和数据安全性。
*   *原则 10:为规模而设计*–最后但同样重要的是，云完全是关于规模经济的。因此，利用托管服务进行弹性扩展，并可靠地处理任何数量的数据。

在本章的剩余部分，当我们深入研究不同的设计模式、数据流和动手实验时，我们将触及这些设计原则中的大多数(如果不是全部的话)。

# 在云上设计数据模式

当数据通过不同的通道(例如通过速度层或批处理层)从边缘安全地流向云时，通常的做法是根据数据速度或数据种类将数据存储在不同的暂存区域或集中位置。这些数据源充当真实的单一来源，并有助于确保它们各自的有界上下文的数据质量。因此，在本节中，我们将讨论云上不同的数据存储选项、数据流模式和反模式。让我们从数据存储开始。

## 数据存储

正如我们在前面的章节中了解到的，由于边缘解决方案在计算资源方面受到限制，因此根据使用案例优化应用数量或本地持久存储的数据量非常重要。另一方面，云没有这种限制，因为它具有不同计算和存储选项的几乎无限的资源。这使得它非常适合大数据应用程序根据需求增长和收缩。除此之外，它还提供了对全球基础设施的轻松访问，以编排不同下游或邻近地区的最终消费者所需的数据。最后，当数据增加了其他数据或元数据时，它更有价值；因此，最近，像数据湖这样的模式变得非常流行。那么，什么是数据湖呢？

数据湖是一个集中、安全、耐用的存储平台，允许您接收、存储结构化和非结构化数据，并根据需要转换原始数据。您可以将数据湖视为第 5 章 *、* *中介绍的数据池概念的超集，从边缘*摄取和流式传输数据。由于物联网设备或网关的存储量相对较低，因此只有与边缘操作相关的高价值数据才能在本地持久存储在数据池中:

![Figure 6.3 – The data lake architecture
](img/B17595_06_03.jpg)

图 6.3–数据湖架构

这里解释了数据湖架构的一些基本特征:

*   有一个中央存储器，用于安全地存储原始数据，只需很少的转换或不需要转换。这是数据真实性的单一来源。计算、存储层、模式、接收频率和数据质量的选择由数据生产者决定。亚马逊 S3 通常被选为中央存储，因为它是一种高度可扩展、高度耐用且经济高效的服务，允许计算层和存储层分离。AWS 在亚马逊 S3 提供不同的分层选项，以及一项名为 Amazon Glacier 的成熟存档服务。
*   有一个持久层，用于以列格式(如 Parquet、ORC 或 Avro)存储特定于领域的数据集市或转换后的数据，以实现通过有界上下文的隔离、更快的性能或更低的成本。AWS 提供不同的服务，如用于数据转换和数据目录的 AWS Glue，用于数据仓库和数据集市的 Amazon Athena 或 Amazon Redshift，以及用于管理大数据处理的 Amazon EMR 或 EMR 上的 Spark。
*   有一个持久层，用于安全地存储从边缘获取的事务数据。这一层通常被称为**操作数据存储** ( **ODS** )。AWS 提供了不同的服务，可以根据给定的数据结构和访问模式来利用这些服务，比如 Amazon DynamoDB、Amazon RDS 和 Amazon Timestream。

您一定想知道如何将数据湖中的数据提供给数据仓库或 ODS。这就是数据集成模式发挥关键作用的地方。

## 数据集成模式

**数据集成和互操作性** ( **DII** )通过批处理、速度和服务层发生。大数据世界中一种将所有这些层交织在一起的常见方法是**提取、转换和加载** ( **ETL** )或**提取、加载和转换** ( **ELT** )。我们已经在 [*第 5 章*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090) 、*从边缘*摄取和流式传输数据中详细解释了这些概念，并讨论了它们如何随着时间演变成不同的数据流模式，如事件驱动、批处理、lambda 和复杂事件处理。因此，我们将不在这里重复这些概念。但是在下一节中，我们将解释它们如何与云中的数据工作流相关联。

## 数据流模式

在本章早些时候，我们讨论了如何使用有界上下文来为最终用户隔离不同的外部功能，例如*车队遥测*、*车队监控*或*车队分析*。现在，是时候学习如何使用不同的数据流模式实现这些概念了。

### 批处理(或聚集处理)

让我们考虑一个场景；您发现在过去的六个月中，您收到了更高的电费账单，并且您想要比较不同设备在该时间段的利用率。或者，您想要更精细的信息的可见性，例如在过去的六个月中洗衣机在一天中运行了多少次？多长时间？这导致了多少 X 瓦的消耗？

这就是批处理发挥作用的地方。在事件驱动架构流行之前，它已经是事实上的行业标准，并且仍然大量用于不同的用例，例如订单管理、计费、工资、财务报表等等。在这种处理模式下，大量的数据，例如数千或数十万条(或更多)记录，通常以文件格式(例如`TXT`或`CSV`)传输、清理、转换并加载到关系数据库或数据仓库中。此后，该数据用于数据协调或分析目的。典型的批处理环境还包括一个作业调度器，它可以根据进料可用性或业务所需的时间表触发分析工作流。

为了设计*车队分析*有界上下文，我们设计了一个批处理工作流，如下所示:

![Figure 6.4 – The batch architecture 
](img/B17595_06_04.jpg)

图 6.4–批处理架构

在这种模式下，会发生以下活动:

*   从边缘流出的事件通过流服务(即亚马逊 Kinesis)路由到数据湖(即亚马逊 S3)。
*   Amazon Kinesis 允许在将数据保存到数据湖之前，用额外的元数据对数据进行预处理或丰富(如果需要的话)。
*   可以通过 ETL 引擎(即 AWS Glue)抓取或转换数据，并使用无服务器分析服务(即 Amazon Athena)轻松查询数据。亚马逊 Athena 在引擎盖下使用了 Presto 引擎，并且兼容 ANSI SQL。
*   不同的服务，如亚马逊 S3 和亚马逊雅典娜，通过 JDBC 和 ODBC 连接器提供与亚马逊 QuickSight 和不同的第三方**商业智能** ( **BI** )工具的集成。
*   Amazon S3 is highly available and durable object storage that integrates with other big data services such as a fully managed Hadoop cluster (that is, Amazon EMR) or a data warehouse (that is, Amazon Redshift).

    有趣的事实

    Amazon EMR 和 Amazon Redshift 通过计算层和存储层的解耦来支持大数据处理，这意味着无需将所有数据从数据湖复制到本地存储。因此，加工变得更具成本效益和操作优化。

在这个有限的上下文中使用的通用语言包括:

*   用于亚马逊 Kinesis 上的流处理、亚马逊 S3 桶上的数据处理和 AWS Glue 上的 ETL 处理的 REST API
*   用于 Amazon Athena 和 Amazon Redshift 数据分析的 SQL
*   MapReduce 或 Spark 用于 Amazon EMR 上的数据处理
*   Rest APIs、JDBC 或 ODBC 连接器与 Amazon QuickSight 或第三方 BI 工具

批处理是强大的，因为它没有任何窗口限制。在如何将单个数据点与整个数据集相关联方面有很大的灵活性，无论是 TB 级还是 EB 级，都可以获得所需的分析结果。

### 事件驱动处理

让我们考虑一下下面的场景:你冲出家门，在登上通勤车后，你收到通知说你忘了关炉子。因为你有一个连接的炉子，你可以立即从应用程序远程关闭它，以避免火灾危险。答对了。

这看起来很容易，但在本地枢纽(如 HBS 枢纽)需要一定程度的智能和一系列事件来促进这一工作流程。这些可能包括以下内容:

*   从运动传感器、占用传感器或摄像机检测到没有人在家。
*   在一段时间内从炉子传感器获取多个测量值。
*   使用边缘的本地流程将事件关联起来，以确定这是一个危险场景。
*   将事件流式传输到消息代理，并将其保存在 ODS 中。
*   触发微服务将此事件通知给最终用户。
*   根据用户反应修复问题。

因此，正如你所观察到的，在几秒钟之内，在边缘、云以及终端用户之间发生了很多事情来帮助减轻危害。在过去十年左右的时间里，这就是诸如事件驱动架构之类的模式变得非常流行的地方。

在 EDA 之前，轮询和 Webhooks 是在不同组件之间传递事件的常用机制。轮询是低效的，因为在如何从数据源获取新的更新并将它们与下游服务同步方面总是存在滞后。Webhooks 并不总是首选，因为它们可能需要定制的授权和认证配置。简而言之，这两种方法都需要额外的工作来集成，或者存在缩放问题。因此，您有了事件的概念，因为数据是作为小事件或数据集的流传输的，所以可以对事件进行过滤、路由，并将其推送到其他不同的服务或系统，从而减少带宽和资源的使用。与 edge 类似，流允许数据在到达时被处理，而不会产生任何延迟。

通常，事件驱动的架构有两种拓扑结构，中介拓扑结构和代理拓扑结构。我们在这里解释了它们:

*   **中介拓扑**:需要一个中央控制器或协调器来处理事件。当有一系列处理事件的步骤时，这通常是有用的。
*   **代理拓扑**:没有中介，因为事件通过代理传播给不同的后端消费者。

代理拓扑在边缘工作负载中非常常见，因为它将边缘与云分离，并允许整体解决方案更好地扩展。因此，对于车队遥测绑定上下文，我们使用代理拓扑设计了一个事件驱动的架构，如下图所示。

在下面的数据流中，从连接的 HBS 中心(即边缘)流出的事件通过 MQTT 路由到物联网网关(即 AWS 物联网核心)，该网关允许通过内置的规则引擎过滤数据(如果需要)，并将数据持久化到 ODS(即 Amazon DynamoDB)。Amazon DynamoDB 是一种高性能的非关系数据库服务，可以根据数百万台边缘设备的数据流量自动扩展。通过上一章，您应该已经熟悉了如何为时间序列数据建模和优化 NoSQL 数据库。一旦数据在 Amazon DynamoDB 中持久化，**创建、读取、更新和删除** ( **CRUD** )操作可以使用无服务器函数(即 AWS Lambda)在数据之上执行。最后，数据通过 API 访问层(即 Amazon API 网关)以同步或异步方式提供:

![Figure 6.5 – Streaming architecture
](img/B17595_06_05.jpg)

图 6.5–流式架构

在这个有限的上下文中使用的通用语言包括:

*   用于 DynamoDB 表访问的 SQL
*   Python 开发 lambda 函数
*   用于 API 网关和 DynamoDB 访问的 REST API

流处理和 EDA 对于许多需要近实时关注的物联网用例来说非常强大，例如警报、异常检测等，因为它会在数据到达时立即进行分析。然而，每种架构都有一个权衡，EDA 也不例外。对于流，由于处理后的结果立即可用，因此特定数据点的分析无法考虑未来值。即使对于过去的值，它也被限制在一个较短的时间间隔内，这通常是通过不同的窗口机制(如滑动、翻转等)指定的。这就是批处理发挥关键作用的地方。

### 复杂事件处理

让我们考虑下面的场景，你计划在家里减少食物浪费。因此，每当你在杂货店登记入住时，你都会收到一份通知，上面列有你冰箱(或食品架)中易腐物品的清单，因为它们甚至没有被打开或没有得到充分利用，并且即将过期。

这听起来像是一个容易解决的问题，但是在本地中心(例如 HBS 中心)需要一定的智能，并且在云上有一个复杂的事件处理工作流来促进这一点。它可能包括以下内容:

*   基于位置共享和用户行为，识别用户计划购物的模式(或特殊事件)的能力。
*   通过安装在冰箱或食品架上的摄像头传感器检测到一些易腐物品即将过期。或者，使用来自气味传感器的事件来检测腐烂食物的模式。
*   通过状态机将所有这些模式(即用户、位置和食品过期日期)关联起来，并应用业务规则来识别需要注意的项目列表。
*   触发微服务将此信息通知给最终用户。

由于易腐物品的数量和它们的经营规模，这个问题对于餐馆来说可能变得更加复杂。在这种情况下，拥有基于当前实践的近乎实时的可见性来识别浪费，可以帮助企业优化其供应链并节省大量成本。所以，你可以想象，边缘和物联网与大数据处理能力(如 CEP)的融合有助于消除具有挑战性的用例。

与通过关联事件来识别模式相比，处理和查询以小块或批量形式到达的事件相对容易。这就是 CEP 有用的地方。它被视为流处理的一个子集，重点是通过关联来自多个来源的事件或通过长时间监听遥测数据来识别特殊(或复杂)事件。实现 CEP 的一种常见模式是构建状态机。

在下面的流程中，从连接的 HBS 中心(即边缘)流出的事件通过 MQTT 路由到物联网网关(即 AWS 物联网核心)，该网关根据设定的标准过滤复杂事件，并将它们推送到复杂事件处理引擎中定义的不同状态机(即 AWS 物联网事件)。AWS IoT events 是一项全面管理的 CEP 服务，允许您监控设备或设备群的故障或操作变化，然后根据定义的事件触发操作:

![Figure 6.6 – CEP architecture
](img/B17595_06_06.jpg)

图 6.6–中心平台架构

在车队监控受限环境中使用的通用语言包括:

*   复杂事件处理的状态机
*   通过**亚马逊简单通知服务** ( **SNS** )进行通知或订阅的 REST API

CEP 对于许多需要根据来自多个传感器、时间线或其他环境因素的事件进行关注的物联网用例非常有用。

为了设计现实生活中的物联网工作负载，您可能需要考虑许多其他设计模式。这些可能是功能性或非功能性需求，例如用于法规要求的数据归档、用于冗余的数据复制以及用于实现所需 RTO 或 RPO 的灾难恢复；然而，这超出了本书的范围，因为这些是一般原则，不一定与边缘计算或物联网工作负载相关。如果您对这些主题感兴趣，还有许多其他书籍或资源可供参考。

## 云的数据流反模式

使用三个定律可以更好地解释在云上处理来自边缘设备的数据的反模式，这三个定律是物理定律、经济定律和土地定律:

*   **物理定律**:对于延迟至关重要的用例，让数据处理更靠近事件源通常是最好的方法，因为我们无法超越光速，因此往返延迟可能无法承受。让我们考虑一个场景，自动驾驶汽车在检测到行人后需要施加硬制动；它无法承受来自云的往返延迟。这一因素也与物理位置偏远的环境相关，例如网络覆盖不良或时断时续的采矿、石油和天然气设施。即使对于我们这里的用例，在连接了 HBS 的情况下，如果停电或网络中断，集线器仍然需要足够智能，以通过分析本地事件来检测入侵。
*   **经济法则**:与联网成本相比，计算和存储成本在过去几十年中已经呈指数级下降，但联网成本在大规模使用时仍会变得令人望而却步。尽管数字化转型导致不同行业的数据激增，但许多数据质量低下。因此，本地聚合和边缘数据过滤将允许您将高价值数据发布到云，从而降低网络带宽成本。
*   **国家法律**:大多数行业需要遵守与数据主权相关的法规或合规性要求。因此，在特定设施、地区或国家本地保留数据可能会成为数据处理中的一个关键因素。即使对于我们这里连接 HBS 的用例，工作负载也可能需要符合 GDPR 的要求。

AWS 提供不同的边缘服务来支持需要遵守前述法律的用例，而不仅限于物联网服务。例如，考虑以下情况:

*   **基础设施**:自动气象站本地区域、自动气象站前哨和自动气象站波长
*   **网络**:亚马逊 CloudFront 和 POP 位置
*   **存储** : AWS 存储网关
*   **坚固和断开的边缘装置** : AWS 雪球边缘和 AWS 雪锥
*   **机器人** : AWS 机器人制造商
*   **视频分析**:亚马逊 Kinesis 视频流
*   **机器学习**:亚马逊 Sagemaker Neo、亚马逊 Sagemaker Edge Manager、亚马逊 Monitron、AWS Panorama

上述服务超出了本书的范围，提供这些信息只是为了让您充分了解 AWS edge 服务的广度和深度。

# 实验室实践方法

在本节中，您将学习如何利用您在本章中学到的概念来设计一个云架构。具体来说，您将继续使用在 [*第 5 章*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090) 、*中介绍的 lambda 架构模式从边缘*接收和流式传输数据，以处理云上的数据:

![Figure 6.7 – Hands-on architecture
](img/B17595_06_07.jpg)

图 6.7–实践架构

在上一章中，您已经完成了步骤 1 和 4。本章将帮助您完成步骤 2、3、5、6 和 7，其中包括使用遥测数据和构建用于执行 BI 的分析管道:

![Figure 6.8 – Hands-on lab components 
](img/B17595_06_08.jpg)

图 6.8–动手实验组件

在这一动手操作部分，您的目标包括以下内容:

1.  查询混乱办。
2.  构建一个 API 接口层来支持数据消费。
3.  构建一个 ETL 层来处理数据湖中的遥测数据。
4.  通过 BI 工具可视化数据。

## 构建云资源

本实验基于您已经在第 5 章 、*中部署的云资源，从边缘*获取和传输数据。因此，请确保您已经完成了动手操作部分，然后再继续下面的步骤。此外，请继续从`chapter 6/cfn`文件夹部署 CloudFormation 模板，以创建本实验所需的资源，如 AWS API 网关、lambda 函数和 AWS Glue crawler。

注意

请从 [*第 5 章*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090) 、*从边缘*摄取和流式传输数据的已部署云形成堆栈的*输出*部分检索该云形成模板所需的参数(如 S3 桶)。

除此之外，您总是可以从部署的 CloudFormation 堆栈的*资源*或*输出*部分找到本实验所需的特定资源名称(如 lambda 函数)。将它们复制到本地的记事本中是一个很好的习惯，这样你就可以快速地引用它们。

一旦云编队部署成功，请继续以下步骤。

## 查询 ODS

导航到 AWS 控制台，并尝试从操作(或事务)数据存储中持久化的数据中生成洞察。正如您在前一章中了解到的，所有处理的接近实时的数据都保存在 DynamoDB 表中(`packt_sensordata`):

1.  要查询数据，导航到 **DynamoDB 控制台**，选择**表格**(从左侧窗格)，点击表格，然后点击**查看项目**。
2.  点击`1`进入`device_id`分区键，点击**运行**。这将返回一组包含所有属性的数据点。
3.  Expand the filters section, and add filters to the following attributes:  
    *   `temperature`。
    *   `humidity`。
    *   **型号**–**编号**。
    *   **条件**–**大于等于**。
    *   **值**–**35**。
    *   点击**运行**。

    在这里，查询界面允许您根据不同的标准快速过滤数据。如果您熟悉 SQL，还可以尝试 PartiQL 编辑器，它位于 DynamoDB 控制台上。

4.  此外，DynamoDB 允许您扫描整个表或索引，但这通常是一个开销很大的操作，尤其是对于大型数据集。要扫描表格，点击**扫描**选项卡(与**查询**相邻)，然后点击**运行**。

为了获得更好的性能和更快的响应时间，我们建议您使用**查询**而不是**扫描**。

### 自动气象站λ

除了对数据进行交互式查询之外，您通常还需要构建表示层和业务逻辑，以便其他各种角色(比如消费者、车队运营商等等)访问数据。您可以使用 Lambda 定义业务逻辑层:

1.  导航到**AWSλ**控制台。点击 **Functions** (从左侧窗格)，选择之前使用 CloudFormation 模板创建的函数。
2.  还记得我们在 [*第 5 章*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090) 、*从 Edge* 获取和流式传输数据的数据建模练习中创建了两个 facet(`getItems`和`putItems`)来访问数据吗？以下是嵌入在 lambda 函数中的逻辑，用于实现等效的函数构造。请查看代码以了解`get`和`put`功能是如何工作的:

    ```
      try {     switch (event.routeKey) {       case "GET /items/{device_id}":         var nid = String(event.pathParameters.id);         body = await dynamo           .query({             TableName: "<table-name>",             KeyConditionExpression: "id = :nid",             ExpressionAttributeValues: {               ":nid" : nid             }           })           .promise();         break;       case "GET /items":         body = await dynamo.scan({ TableName: "<table-name>" }).promise();         break;       case "PUT /items":         let requestJSON = JSON.parse(event.body);         await dynamo           .put({             TableName: "<table-name>",             Item: {               device_id: requestJSON.id,               temperature: requestJSON.temperature,               humidity: requestJSON.humidity,               device_name: requestJSON.device_name             }           })           .promise();         body = `Put item ${requestJSON.id}`;         break;       default:         throw new Error(`Unsupported route: "${event.routeKey}"`);     }   } catch (err) {     statusCode = 400;     body = err.message;   } finally {     body = JSON.stringify(body);   }   return {     statusCode,     body,     headers   };};
    ```

请注意这里，我们使用的是 lambda 函数。这是因为无服务器函数已经成为近实时处理事件驱动数据的常见模式。由于它减轻了您在应用程序的整个生命周期中管理或操作任何服务器的需要，您唯一的责任就是用支持的语言编写代码并将其上传到 Lambda 控制台。

有趣的事实

AWS IoT Greengrass 为 edge 提供了 Lambda 运行时环境，以及 Python、Java、Node.js 和 C++等不同的语言。这意味着你不需要管理两个不同的代码库(比如嵌入式和云)或者多个开发团队。这将减少您的开发时间，实现从边缘到云的统一开发堆栈，并加快您的上市时间。

### 亚马逊 API 网关

现在已经使用 lambda 函数开发了业务逻辑，让我们使用 Amazon API gateway 创建 HTTP 接口(也称为表示层)。这是一项托管服务，用于大规模创建、管理和部署 API:

1.  导航到使用 CloudFormation 模板创建的`MyPacktAPI`。
2.  展开`REST`方法。
3.  您应该观察以下操作:

    ```
    /items GET – allows accessing all the items on the DynamoDB table (can be an expensive operation)
    ```

4.  继续进入**开发**下拉菜单。点击**授权**并检查各自的操作。在这个实验室中，我们没有附加任何授权者，但是建议在实际工作负载中使用。API gateway 提供了不同形式的授权器，包括内置的 IAM 集成、 **JSON Web 令牌** ( **JWT** )或者使用 lambda 函数的定制逻辑。
5.  接下来，点击`/items GET`。在右边的窗格中，您将看到相关的 lambda 函数。为了简单起见，我们在这里对所有操作使用相同的 lambda 函数，但是您可以选择其他函数或目标，例如亚马逊 SQS、亚马逊 Kinesis、您的 VPC 中的私有资源，或者任何其他 HTTP URI，如果您的真实世界用例需要的话。
6.  API gateway 提供了许多与 CORS、重新导入/导出和限制相关的附加选项，但它们不在本实验的考虑范围内。相反，我们将专注于执行 HTTP APIs 和检索传感器数据。
7.  Click on the `GET`) items from your device Terminal:

    ```
    a. Query all items from the table 
    curl https://xxxxxxxx.executeapi.<region>.amazonaws.com/items
    ```

    您应该会在我们的终端上看到一个从`dynamodb`表中检索出来的长列表。

Amazon API gateway 允许您创建不同类型的 API，前面配置的 API 属于 HTTP API 类别，允许访问 lambda 函数和其他 HTTP 端点。此外，我们可以在这里使用 REST APIs，但选择 HTTP 选项是因为它使用简单，因为它可以自动准备和部署所需的 API，而无需任何额外的工作，并且更具成本效益。总之，现在您已经通过查询或 API 接口完成了 ODS 的有界上下文的实现。

## 构建分析工作流程

在下一节中，您将在亚马逊 S3 上持久化的批量数据(即数据湖)上构建一个分析管道。为此，您可以使用 AWS Glue 来抓取数据并生成数据目录。此后，您将使用 Athena 进行交互式查询，并使用 QuickSight 通过图表/仪表板可视化数据。

### AWS 胶水

AWS Glue 是一个托管服务，它提供了许多 ETL 功能，比如数据爬虫、数据目录、批处理作业、与 CI/CD 管道的集成、Jupyter 笔记本集成等等。在本实验中，您将主要使用数据爬行器和编目功能。我们认为这对物联网专业人员来说可能已经足够了，因为数据工程师将主要负责现实世界中的这些活动。但是，如果您相信学习并有好奇心，请随意使用其他功能:

1.  导航到 **AWS Glue** 控制台，点击**爬虫**(从左侧窗格)，并选择之前使用 CloudFormation 模板创建的爬虫。
2.  查看 crawler 定义的一些关键属性，例如:
    *   状态:爬虫准备好运行了吗？
    *   时间表:爬虫的频率设置是否正确？
    *   数据仓库:S3。
    *   包含路径:数据集的位置是否正确？这应该指向原始传感器数据桶。
    *   配置选项:目录中的表定义是否基于上游更改进行更新？
3.  此外，Glue 允许您通过其分类器功能处理不同的数据格式。您可以使用内置的分类器处理最常见的数据格式，如 Grok、XML、JSON 和 CSV，如果您有专有格式的数据，还可以指定自定义模式。
4.  这里，爬虫应该按照通过 CloudFormation 配置的指定时间表运行；但是，您也可以通过点击**运行爬虫**按需运行它。如果你也这样做，请等待爬虫完成从**开始** - > **运行** - > **停止** - > **就绪**状态的转换。
5.  现在数据抓取已经完成，导航到`*packt*`已经创建。如果您已经创建了许多表格，另一个快捷的选择是使用搜索按钮和`packt_gluedb`上的过滤器。
6.  Click on the table to verify the properties, such as the database, the location, the input/output formats, and the table schema. Confirm the schema is showing the attributes that you are interested in retaining. If not, you can click on **Edit** schema and make the necessary changes:![Figure 6.9 – The table schema in Glue
    ](img/B17595_06_09.jpg)

    图 6.9–胶水中的表格模式

7.  记下数据库和表名，因为在接下来的两个部分中会用到它们。

在这个实验中，您使用了一个只有单一数据源的爬虫；但是，如果您的用例需要，您可以添加多个数据源。一旦数据目录被更新并且数据(或元数据)可用，您就可以通过不同的 AWS 服务来使用它。您可能还需要经常清理、过滤或转换您的数据。然而，这些职责通常不由物联网从业者来履行，主要由数据分析师或数据科学家来承担。

### 亚马逊雅典娜

Amazon Athena 充当一个无服务器的数据仓库，您可以在其中对由 ETL 引擎(如 Glue)管理的数据运行分析查询。Athena 使用一种读取模式的方法；因此，当您运行查询时，一个模式被投射到您的数据上。由于 Athena 支持计算层和存储层的分离，您可以连接到不同的数据湖服务(如 S3)来运行这些查询。Athena 使用 Apache Hive 进行 DDL 操作，例如定义表和创建数据库。对于通过查询支持的不同功能，Presto 在幕后使用。Hive 和 Presto 都是开源的 SQL 引擎:

1.  导航到 **AWS Athena** 控制台，并从左侧窗格中选择**数据源**。
2.  保持数据源为`packt_gluedb`:
    *   这是在前面的部分中由 Glue crawler 在扫描 S3 目的地存储桶之后自动创建的，该存储桶存储了成批的传感器数据。
3.  这将填充在该数据库下创建的表列表。
4.  点击类似`*mysensordatabucket*`名称的表格旁边的三个点，选择**预览表格**。这应该会自动构建和执行 SQL 查询。

这应该显示只有 10 条记录的数据结果。如果您想查看整个数据集，请从查询末尾删除 10 个参数的限制。如果您熟悉 SQL，请随意调整查询并使用不同的属性或连接条件。

注意

在这里，您处理了来自 HBS 中心设备的 JSON 数据流。但是，如果您的组织想要利用更轻量级的数据格式，该怎么办呢？Athena 通过使用**串行器-解串器** ( **SerDe** )库，为各种数据格式提供本地支持，如`CSV`、`AVRO`、`Parquet`和`ORC`。正则表达式甚至支持复杂的模式。

到目前为止，您已经从数据湖中抓取了数据，创建了表，并成功地查询了数据。现在，在最后一步，让我们学习如何构建能够基于这些数据实现 BI 的仪表板和图表。

### 快速瞄准

作为一名物联网从业者，构建业务仪表盘可能不是你核心职责的一部分。但是，一些基础知识总是有用的。如果考虑传统的 BI 解决方案，数据工程师可能需要几周或几个月的时间来构建复杂的交互式专用数据浏览和可视化功能。因此，业务用户只能使用预先准备好的报告和预先选择的查询。此外，这些传统的 BI 解决方案需要大量的前期投资，并且随着数据源规模的增长，在规模上表现不佳。这就是亚马逊 QuickSight 的用处。这是一项易于使用、高度可扩展的托管服务，支持业务所需的复杂功能:

1.  导航到 Amazon QuickSight 控制台，完成一次性设置，如下所述:
    *   注册标准版(如果您以前没有使用过)。
    *   为实验室购买 SPICE 容量
    *   *请注意，这有 60 天的试用期，因此请务必在研讨会结束后取消订阅，以免被收取费用*。
    *   点击您的登录用户(在右上角)，选择**管理快速查看** | **安全&权限** | **添加和删除** | **查看亚马逊雅典娜** | **应用**。
    *   单击 QuickSight 徽标(位于左上角)导航至主页。
    *   单击您的登录用户(在右上角)，您会发现您的区域首选项列在您的语言首选项下面。
    *   确认或更新区域，使其与您的工作区域相匹配。
2.  点击**新建分析**，然后**新建数据集**，选择**雅典娜**。
3.  输入数据源名称`packt-data-visualization`，保持工作组为默认设置，点击**创建数据源**。
4.  保持目录为**默认**，选择**数据库**，然后选择在 *AWS 胶水*部分的*步骤 5* 中创建的表格。
5.  点击**选择**，选择直接查询您的数据，然后再次点击**可视化**。
6.  现在构建仪表板:
    *   选择 *X* 轴的时间戳(从**值**下拉菜单中选择**分钟**)。
    *   为 *Y* 轴选择其他读数，如 **device_id** 、**温度**和**湿度**(从**值**下拉菜单中选择**平均值**以获得每个读数)。

随意使用不同的字段或视觉类型来可视化其他智能家居相关信息。正如您可能已经观察到的，在创建数据集时，QuickSight 本身支持不同的 AWS 和第三方数据源，如 Salesforce、ServiceNow、Adobe Analytics、Twitter、吉拉等。此外，它允许业务用户或运营人员通过移动应用程序(如 iOS 和 Android)即时访问数据，以快速推断特定工作负载的数据洞察力，以及与机器学习增强的集成。

恭喜你！您已经使用不同的 AWS 应用程序和数据服务完成了云上数据处理和数据消费的整个生命周期。现在，让我们用总结和知识检查问题来结束这一章。

挑战区(可选)

在 *Amazon API gateway* 部分，您构建了一个从`dynamodb`表中检索所有商品的接口。但是，如果您需要为特定的设备(如 HVAC)提取特定的项目(或一组项目)该怎么办呢？与扫描所有数据相比，这是一种成本较低的操作。

`GET /items {device_id}`。检查 lambda 函数，以更好地理解它如何映射到后端逻辑。

# 总结

在本章中，您了解了与物联网工作负载相关的大数据概念。您学习了如何使用 DDD 方法以及物联网工作负载常见的不同数据存储和数据集成模式来设计数据流。您实现了一个 lambda 架构来处理舰队遥测数据和一个分析管道。最后，您通过 API 使用数据并通过业务仪表板可视化数据来验证工作流。在下一章中，您将了解如何使用所有这些数据来构建、训练和部署机器学习模型。

# 知识检查

在进入下一章之前，通过回答这些问题来测试你的知识。答案可以在书的结尾找到:

1.  从边缘工作负载的角度来看，您能想到域驱动设计的至少两个好处吗？
2.  判断题:有界语境和无处不在的语言是一样的。
3.  您认为拥有一个可运行的数据存储库或数据湖/数据仓库需要什么？
4.  您还记得将流和批处理工作流结合在一起的设计模式名称吗？
5.  您可以采用什么策略来转换云中的原始数据？
6.  是非判断:您不能通过 API 访问 NoSQL 数据存储中的数据。
7.  对于事件驱动的工作负载，您何时会使用中介与代理拓扑？
8.  您能想到使用无服务器功能处理物联网数据的至少一个好处吗？
9.  您可以使用哪些**商业智能** ( **BI** )服务向最终消费者公开数据？
10.  是非判断:JSON 是云上大数据处理的最佳数据格式。
11.  如何在运营数据存储(或数据湖)之上构建 API 接口？

# 参考文献

有关本章中讨论的概念的更多信息，请查看以下资源:

*   *数据管理–知识体系*:[https://www.dama.org/cpages/body-of-knowledge](https://www.dama.org/cpages/body-of-knowledge)
*   *领域驱动设计*作者 Eric Evans:[https://www . Amazon . com/Domain-Driven-Design-charging-Complexity-Software-ebook/DP/b 00794 taug](https://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software-ebook/dp/B00794TAUG)
*   *领域语言*:【https://www.domainlanguage.com/ddd 
*   *AWS 上的大数据*:[https://aws.amazon.com/big-data/use-cases/](https://aws.amazon.com/big-data/use-cases/)
*   *AWS 无服务器数据分析管道*:[https://D1 . AWS static . com/whites/AWS-server less-Data-Analytics-Pipeline . pdf](https://d1.awsstatic.com/whitepapers/aws-serverless-data-analytics-pipeline.pdf)
*   AWS 上的现代无服务器架构:[https://D1 . AWS static . com/architecture-diagrams/architecture diagrams/mobile-we B- server less-ra . pdf？did = WP _ card&trk = WP _ card](https://d1.awsstatic.com/architecture-diagrams/ArchitectureDiagrams/mobile-web-serverless-RA.pdf?did=wp_card&trk=wp_card)
*   *BI 工具*:[https://aws.amazon.com/blogs/big-data/tag/bi-tools/](https://aws.amazon.com/blogs/big-data/tag/bi-tools/)