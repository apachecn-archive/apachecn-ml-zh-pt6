

# 7

# 探索谷歌云顶点 AI

在上一章中，我们讨论了 Google Cloud BQML，它用于从结构化数据开发 ML 模型，以及 Google 的 TensorFlow 和 Keras 框架，它们为 ML 模型开发提供了高级 API 接口。在本章中，我们将讨论 Cloud Vertex AI，它是 Google 用于 ML 模型开发的集成云服务套件。我们将研究 Vertex AI 套件及其所有产品和服务。

**Google Vertex AI** 是一套集成的谷歌云产品、功能和管理界面，简化了 ML 服务的管理。它为用户提供了一个完整的平台，可以在 Google Cloud 中端到端地构建、训练和部署 ML 应用程序。Vertex AI 为数据科学家构建机器学习应用提供了一站式服务。

在本章中，我们将讨论以下 Vertex AI 产品和服务:

*   顶点人工智能数据标注和数据集
*   顶点人工智能特征库
*   顶点人工智能工作台和笔记本
*   顶点 AI 训练
*   顶点人工智能模型和预测
*   顶点人工智能管道
*   顶点人工智能元数据
*   顶点人工智能实验和张量板

先说 Vertex AI 套件中的数据标注和数据集。

# 顶点 AI 数据标注和数据集

数据集在机器学习过程中扮演着如此重要的角色，以至于数据集的质量对 ML 模型的性能有着巨大的影响。正如我们在 [*第 4 章*](B18333_04.xhtml#_idTextAnchor094) 、*开发和部署 ML 模型*中所讨论的，数据准备是任何机器学习过程中的第一步也是最重要的一步。

**Vertex AI 数据标记**是一项谷歌云服务，让最终用户与人类工人一起审查和标记用户上传的数据集。在数据集被标记后，它们可以用于训练机器学习模型。人类工人受雇于谷歌，用户需要向人类工人提供数据集、标签和标签说明。

最终用户也可以直接上传带标签的数据集。**顶点人工智能数据集**是谷歌云服务的一部分，为用户提供上传各种类型数据的能力，用于构建、训练和验证机器学习模型。目前，Vertex AI 支持四种类型的数据集(图像、表格、文本和视频):

*   **图像数据集**:您可以在 Vertex AI 中创建图像数据集，并使用它们来训练图像分类、图像分割和对象检测的模型。通过 Vertex AI，你可以直接上传图像数据集，也可以使用谷歌云存储桶中存储的图像。
*   **表格数据集**:你可以直接从本地电脑上传一个 CSV 文件，使用一个来自谷歌云存储，或者从 BigQuery 服务选择一个表格。一旦生成了表格数据集，这些数据就可以在顶点 AI 数据集中用于模型训练。
*   **视频数据集** : Vertex AI 允许你直接从本地电脑上传视频，或者使用谷歌云桶中的视频。一旦有了视频数据集，就可以用它们来进行视频分类或动作识别。
*   **文本数据集**:在 Vertex AI 中，你创建一个文本数据集，将 CSV 从 Google 云存储桶导入到数据集中。然后，您可以将数据集用于文本文档分类、自定义文本实体识别、情感分析等。

Vertex AI datasets 让你可以直接在 Vertex AI 套件内创建和管理数据集，通过 Vertex AI 上传的数据集自动存储在云存储桶中，由 Vertex AI 创建和管理。

# 顶点人工智能特征库

在 ML/DL 模型训练中，特征是建立模型和进行未来推理的属性。GoogleVertex AI Feature Store 是一个完全托管的云服务，它提供了一个集中的存储库来存储、组织和提供 ML 功能。你可以创建并管理一个**顶点 AI 特征库**，其中包含所有的模型特征及其值。有了中央功能库，谷歌云组织中的用户可以共享和重用这些功能，用于不同 ML/DL 项目中的模型训练或服务任务，以加快机器学习应用程序开发和模型部署。

Vertex AI 特征存储使用户能够管理 ML 模型中的特征。要素存储可为新数据提供实时、在线预测或批量预测。例如，在加载关于电影观看习惯的信息之后，特征存储可以用于基于新用户的特征来预测他们可能观看什么电影。

在传统的 ML 框架中，您可能已经计算了特征值并将它们保存在不同的位置，包括云存储桶或 BQ 表，并且您可能有单独的解决方案来存储和管理特征值。使用 Vertex AI Feature Store，您可以获得一个统一的解决方案，在整个组织中保持一致，以存储和提供可以在不同项目或用例的不同团队之间共享的功能。

# 顶点 AI 工作台和笔记本

**Vertex AI Workbench** 服务为整个数据科学工作流程提供单一开发平台；您可以使用它来启动云虚拟机实例/笔记本，以查询和探索数据，并开发和培训用于部署的模型。

正如我们之前在*准备平台*部分所解释的，Jupyter Notebook 是一个广泛用于 ML 模型开发的平台。Vertex AI Workbench 为您的数据科学家、托管笔记本和用户托管笔记本提供了两种基于 Jupyter-Notebook 的选项:

*   **托管笔记本电脑**是 Google 托管的、基于 Jupyter 的、可扩展的、企业就绪的计算实例，可帮助您在端到端的 ML 生产环境中设置和工作。
*   **用户管理的笔记本电脑**是高度可定制的实例，因此适合需要对其环境进行大量控制的用户。有了用户管理的笔记本实例，你就预装了一套深度学习包，包括 TensorFlow 和 PyTorch 框架。

Vertex AI Workbench 提供灵活的笔记本选项。它为数据科学家训练和开发模型提供了一个很好的 ML 模型训练平台。

# 顶点 AI 训练

在 ML 模型开发过程中，培训工作是生成 ML 模型的离散任务。在 Vertex AI 中，可以根据模型和数据的来源选择不同的训练方法； **Vertex AI AutoML** ，由 Google 管理，使用 Google 的模型和你的数据进行训练， **Vertex AI 平台**，使用自定义代码或自定义容器，利用你的模型和你的数据进行模型训练。

## 顶点人工智能汽车

**Vertex AI AutoML** 是一项受管理的谷歌云服务，它使用户能够在不编写任何代码的情况下跨多种用例建立模型。目标是为不同水平的人工智能专家开发 ML 模型。

Vertex AutoML 支持的车型类型如*表 7.1* 所示:

![Table 7.1 – Vertex AI AutoML models

](img/Figure_7.1.jpg)

表 7.1–顶点人工智能汽车模型

创建 AutoML 培训管道作业时，您有以下选项:

*   **数据集**:顶点 AI 管理，用户上传
*   **型号类型**:从支持的型号中选择(如上所述)
*   **数据分割**(可选):使用自定义参数在训练、验证和测试数据之间分割数据集
*   **加密**(可选):选择**客户管理的加密密钥** ( **CMEK** )用于进程内加密的选项

Vertex AI AutoML 帮助你基于你的训练数据建立一个无代码模型。使用 Vertex AI AutoML，您可以使用自己的数据定制谷歌的模型。

## 顶点 AI 平台

带有定制容器的 **Vertex AI 平台**，可以让你用自己的数据从开始构建自己的模型。**自定义容器**是用户创建的 Docker 图像，在创建管道时选择。自定义容器环境的典型工作流程如图*图 7.2* 所示，包括以下步骤:

1.  **代码开发**:你可以用自己选择的编程语言构建一个应用，可以在本地，也可以在笔记本内，默认情况下，依赖项可以来自任何互联网位置。
2.  **Build** :您可以将代码构建到打包的工件中，或者编写一个配置来将代码和各种依赖项自动打包到容器运行时工件中。
3.  **工件存储**:您可以将新构建的定制工件推送到云存储或容器注册表中。
4.  **启动训练管道**:创建训练管道时可以选择*自定义容器*来构建 ML 模型。

![Figure 7.1 – Vertex AI platform custom container

](img/Figure_7.2.jpg)

图 7.1–顶点人工智能平台定制容器

在顶点人工智能中训练了模型之后，您可以使用 AutoML 或自定义容器，在顶点人工智能模型中访问/管理，并部署在顶点人工智能端点中进行单独预测或批量预测。

# 顶点人工智能模型和预测

**顶点 AI 模型**为提供了管理 ML 模型的平台。有了顶点 AI 模型，你可以用多种方式开发和管理 ML 模型:

*   **创建模型**:用户可以选择创建一个新模型，并被重定向到**培训管道**屏幕。
*   **上传模型**:用户可以上传一个在其他地方训练过的模型，用于他们的 Vertex AI 项目。
*   **部署模型**:用户可以将选择的模型部署到一个端点，通过 REST API 使其可用。
*   **导出模型**:用户可以将一个训练好的模型导出到一个 GCS 存储桶中，在那里它可以被存储或者在另一个项目中使用。

模型经过训练后，可以公开或私下导出或部署，以预测生产案例。当您将模型部署到端点资源以进行联机预测时，或者当您请求批量预测时，您总是可以自定义预测服务使用的 VM 类型，并且您还可以将预测节点配置为使用 GPU。我们将在接下来的章节中讨论模型部署。

## 顶点 AI 端点预测

**顶点 AI 端点**允许用户基于顶点 AI 模型创建 REST API 端点，以预测新数据的结果。使用 Vertex AI，模型可以部署到公共端点或私有端点:

*   **公共端点**:模型被部署到一个互联网可路由的、由 Google 托管的端点，该端点位于一个选定的区域。
*   **私有端点**:该模型被部署到位于所选 VPC 私有 IP 地址上的所选区域的 Google 管理的端点。

顶点人工智能端点用于部署在线预测的训练模型。创建新端点时，用户可以配置以下内容:

*   **端点名称**
*   **GCP 地区**
*   **私人或公共访问**
*   **加密(可选)**
*   **模型**:由新端点服务的一个或多个模型。

与顶点人工智能训练和顶点人工智能模型集成，顶点人工智能端点允许用户交互式地预测个人结果。

## 顶点 AI 批量预测

与顶点人工智能端点不同，**顶点人工智能批量预测**作业是离散任务，根据预测模型运行批量输入数据集。如图*图 7.3* 所示，可以在 Google 云存储中输入文件，并将结果输出到指定的 GCS 位置。

![Figure 7.2 – Vertex AI batch prediction

](img/Figure_7.3.jpg)

图 7.2–顶点人工智能批量预测

当创建一个批量预测任务时，你有以下选项:

*   **区域**:存放模型的地方
*   **型号**:指向 ML 型号
*   **输入数据**:存储输入数据的云存储桶
*   **输出目录**:存储预测的云存储桶
*   计算相关信息，包括机器类型和节点数量

从前面的服务中我们可以看到，Vertex AI 提供了一个 ML 开发和管理套件，供你创建和管理数据集，创建和管理笔记本进行模型训练，开发和管理批量预测终点的模型。有了 Vertex AI，你可以从头到尾执行 ML 工作流中的所有任务。这将我们带到顶点人工智能管道的讨论:自动化 ML 工作流程。

# 顶点 AI 管道

**顶点 AI 管道**允许你使用**tensor flow Extended**(**TFX**)或 **Kubeflow** 以无服务器的方式自动编排你的 ML 工作流。每个顶点 AI 流水线作业都是从一个概述了一系列步骤的配置文件中生成的。典型的顶点 AI 管道将数据导入数据集，使用**训练管道**训练模型，并将模型部署到新的端点进行预测。管道作业使用计算资源运行，具有以下选项:

*   您可以使用 **Kubeflow DSL** 为管道作业编写定制的配置。
*   您可以创建、运行和计划管道作业。
*   您可以指定**服务帐户**或使用**计算默认服务帐户**(如果未指定)。

谷歌顶点人工智能管道编排你的 ML 工作流程，基于你对工作流程的描述。ML 管道是基于容器的可移植和可扩展的 ML 工作流。ML 管道由一组输入参数和一系列步骤组成——每一步都是管道的一个实例。

# 顶点人工智能元数据

**顶点人工智能元数据**是跨各种顶点人工智能组件生成的元数据的储存库。当在 ML 工作流管道中开发模型时，会生成并存储元数据，您可以将这些元数据合并到一个元数据存储中，这允许用户查询和回答如下问题:

*   经过训练的模型的哪个版本达到了一定的质量阈值？
*   哪个管道运行/使用某个数据集？

在 Vertex AI 管道中，用户还可以配置写入元数据存储的数据对象。从那里，用户可以创建*上下文*对象，将这些数据对象组织成逻辑分组，并获得更多的洞察力。

使用 Vertex AI 元数据 API，用户可以构建模式、组织数据对象或查询存储在 Vertex AI 元数据中的数据。

# 顶点 AI 实验和张量板

**TensorBoard** 是用于机器学习实验可视化的 Google open 源码项目。顶点 AI 实验是 TensorBoard 的一个实现。通过 Vertex AI 实验，用户可以创建 TensorBoard 实例，并上传从 Vertex AI 模型生成的 TensorBoard 日志来运行实验——各种指标的可视化表示，如不同运行时间不同模型参数的损失函数和准确性。*图 7.4* 显示了顶点人工智能实验和张量板的示例工作流程:

![Figure 7.3 – Vertex AI experiments and TensorBoard

](img/Figure_7.4.jpg)

图 7.3–顶点人工智能实验和张量板

这些 TensorBoard 可视化可通过一个 web 应用程序获得，通过设置 GCP IAM 权限，该应用程序可与其他用户共享。使用顶点 AI 实验，您可以配置以下选项:

*   **管理 TensorBoard 实例**:用户可以创建、更新或删除 TensorBoard 实例；实例用于实验。
*   **创建实验**:通过上传管道日志数据，用户可以生成实验和可视化。
*   **查看 TensorBoard Web 应用**:用户可以通过为每个 TensorBoard 实例生成的 Web 应用查看 TensorBoard。
*   **导出数据**:用户可以使用 API 导出管道元数据和张量板数据点。

顶点 AI 实验为用户提供了一个实验和调优模型参数的平台。通过 Vertex AI 实验，我们可以在 TensorBoard web 上进行交互并检查结果。它是 Google Vertex AI 套件的重要组成部分。

# 总结

在这一章中，我们介绍了 Google Vertex AI 套件，包括它的服务、平台和用于 ML 模型开发和部署的工具。使用 Vertex AI，您可以轻松灵活地管理数据集、模型和管道。毫无疑问，掌握 Vertex AI 需要对套件中的每个服务进行动手练习，我们已经在 [*附录 4*](B18333_14.xhtml#_idTextAnchor218) 、*用 Google Vertex AI 练习*中提供了示例动手练习步骤。请遵循这些实践并理解附录中的步骤。在下一章，我们将讨论另一个 Google Cloud ML 服务:Google Cloud ML APIs。

# 延伸阅读

要进一步了解本章的学习内容，您可以参考以下链接:

*   *顶点 AI 文档*

https://cloud.google.com/vertex-ai/docs

*   *所有数据集文档|顶点 AI*

[https://cloud.google.com/vertex-ai/docs/datasets/datasets](https://cloud.google.com/vertex-ai/docs/datasets/datasets)

*   *顶点 AI 特征库介绍*

[https://cloud . Google . com/vertex-ai/docs/featurestore/overview](https://cloud.google.com/vertex-ai/docs/featurestore/overview)

*   *顶点 AI 工作台介绍*

[https://cloud . Google . com/vertex-ai/docs/work bench/introduction](https://cloud.google.com/vertex-ai/docs/workbench/introduction)

*   *选择笔记本解决方案|顶点 AI 工作台*

[https://cloud . Google . com/vertex-ai/docs/work bench/notebook-solution](https://cloud.google.com/vertex-ai/docs/workbench/notebook-solution)

*   *顶点 AI 模型监控简介*

[https://cloud . Google . com/vertex-ai/docs/model-monitoring/overview](https://cloud.google.com/vertex-ai/docs/model-monitoring/overview)

*   *顶点 AI 流水线介绍*

[https://cloud . Google . com/vertex-ai/docs/pipelines/introduction](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)

*   *顶点可解释 AI |顶点 AI*

[https://cloud.google.com/vertex-ai/docs/explainable-ai](https://cloud.google.com/vertex-ai/docs/explainable-ai)

*   *使用云控制台| Vertex AI 部署模型*

[https://cloud . Google . com/vertex-ai/docs/predictions/deploy-model-console](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-console)

*   [*附录 4*](B18333_14.xhtml#_idTextAnchor218) ，*用谷歌顶点 AI 练习*