<html><head/><body>





<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}</style>
<div><div><h1 id="_idParaDest-207"><a id="_idTextAnchor206"/>第十章:高级训练技术</h1>
			<p>在前一章中，您学习了何时以及如何使用<strong class="bold">管道模式</strong>和<strong class="bold">分布式培训</strong>等功能，以及用于数据集存储的<strong class="bold"> S3 </strong>的替代方案来扩展培训作业。</p>
			<p>在这一章中，我们将总结我们对训练技巧的探索。在本章的第一部分，你将学习如何使用<strong class="bold">管理的现场训练</strong>削减你的训练成本，如何使用<strong class="bold">自动模型调整</strong>从你的模型中挤出每一滴准确性，以及如何使用<strong class="bold"> SageMaker 调试器</strong>打开模型。</p>
			<p>在本章的第二部分，我们将介绍两个新的 SageMaker 功能，帮助您构建更高效的工作流和更高质量的模型:<strong class="bold"> SageMaker 特征库</strong>和<strong class="bold"> SageMaker Clarify </strong>。</p>
			<p>本章涵盖以下主题:</p>
			<ul>
				<li>通过管理现场培训优化培训成本</li>
				<li>利用自动模型调整优化超参数</li>
				<li>使用 SageMaker 调试器探索模型</li>
				<li>使用 SageMaker 要素库管理要素和构建数据集</li>
				<li>用 SageMaker Clarify 检测偏差和解释预测</li>
			</ul>
			<h1 id="_idParaDest-208"><a id="_idTextAnchor207"/>技术要求</h1>
			<p>您将需要一个 AWS 帐户来运行本章中包含的示例。如果你还没有，请将你的浏览器指向<a href="https://aws.amazon.com/getting-started/">https://aws.amazon.com/getting-started/</a>来创建它。您还应该熟悉 AWS 免费层(<a href="https://aws.amazon.com/free/">https://aws.amazon.com/free/</a>)，它允许您在一定的使用限制内免费使用许多 AWS 服务。</p>
			<p>您将需要<a id="_idIndexMarker1069"/>为您的帐户(<a href="https://aws.amazon.com/cli/">https://aws.amazon.com/cli/</a>)安装和配置 AWS <strong class="bold">命令行界面</strong> ( <strong class="bold"> CLI </strong>)。</p>
			<p>你将<a id="_idIndexMarker1070"/>需要一个工作的<code>pandas</code>、<code>numpy</code>等等)。</p>
			<p>本书中包含的代码示例可从 GitHub 上的<a href="https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition">https://GitHub . com/packt publishing/Learn-Amazon-sage maker-second-edition</a>获得。你需要安装一个 Git 客户端来访问它们(<a href="https://git-scm.com/">https://git-scm.com/</a>)。</p>
			<h1 id="_idParaDest-209"><a id="_idTextAnchor208"/>通过管理现场培训优化培训成本</h1>
			<p>在<a id="_idIndexMarker1072"/>上一章中，我们在<strong class="bold"> ImageNet </strong>数据集上训练了<strong class="bold">图像分类</strong>算法。这项工作持续了不到 4 个小时的<a id="_idIndexMarker1073"/>。这项工作每小时大约 290 美元，花费了我们大约 1160 美元。这是一大笔钱…但这是真的吗？</p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor209"/>比较成本</h2>
			<p>在你举起双臂大喊大叫之前，他在想什么？”，请考虑您的组织拥有和运行此培训集群的成本:</p>
			<ol>
				<li>粗略计算资本支出(服务器、存储、GPU、100 Gbit/s 网络设备)至少需要 150 万美元。就运营支出而言，托管成本并不便宜，因为每台同等的服务器需要 4-5 千瓦的电力。对于典型的托管公司来说，这足以填满一个机架，所以即使有高密度的机架，你也需要几个。增加带宽、交叉连接等等，我的直觉告诉我每月大约要花费 15K 美元(在世界的某些地方要多得多)。</li>
				<li>我们需要增加硬件支持合同(比如说，每年 10%，所以 15 万美元)。将该群集折旧超过 5 年，每月总成本将为(150 万美元+60 * 15000 美元+5 * 150000 美元)/60 = 525000 美元。我们将其四舍五入为 55000 美元，以计入服务器维护等方面的人工成本。</li>
			</ol>
			<p>保守估计，这一花费相当于我们在 ImageNet 示例中使用的每小时 290 美元的大型集群的 190 个小时的培训。正如我们将在本章后面看到的，有管理的现场培训通常可以节省 70%的成本。因此，现在的花费相当于每月 633 小时的 ImageNet 培训。</p>
			<p>这相当于每月 87%的使用率(633/720 ),你不太可能让你的培训集群一直这么忙。再加上停机时间、硬件创新导致的加速折旧、硬件保险成本、不在其他<a id="_idIndexMarker1075"/>项目中投资 150 万美元的机会成本等等，物理基础设施的业务案例每分钟都在变得更糟。</p>
			<p>财务状况很重要，但最糟糕的是你只有一个集群。如果一个潜在的商业机会需要另一个呢？你会再花 150 万美元吗？如果不是，您是否必须分时使用现有集群？当然，只有你能决定什么对你的组织最好。只要确保你着眼于大局。</p>
			<p>现在，让我们看看您如何轻松享受这 70%的成本削减。</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor210"/>了解亚马逊 EC2 Spot 实例</h2>
			<p>在任何时候，<strong class="bold">亚马逊</strong> <strong class="bold"> EC2 </strong>的产能都超过了需求。这允许客户在需要时按需向其平台添加<a id="_idIndexMarker1077"/>容量。按需实例可以使用 API 调用显式创建，或者如果配置了<strong class="bold">自动缩放</strong>，则可以自动创建。一旦客户获得了一个随需应变的实例，他们将保留它，直到他们决定释放它，无论是显式的还是自动的。</p>
			<p><strong class="bold"> Spot Instances </strong>是一种简单的<a id="_idIndexMarker1078"/>方法，可以利用这些未使用的容量并享受非常显著的折扣(通常为 50-70%)。你可以用同样的方式请求他们，他们的行为也是一样的。唯一的区别是，如果 AWS 需要构建按需实例的能力，您的 Spot 实例可能会被回收。它会在被强制终止前两分钟收到中断通知。</p>
			<p>这并不像听起来那么糟糕。根据地区和实例系列的不同，Spot 实例可能不会经常被回收，客户通常会保留它们几天，甚至更长时间。此外，您可以针对这一需求构建您的应用程序，例如，通过在 Spot 实例上运行无状态工作负载，并依靠托管服务进行数据存储。成本效益太好了，过不去！</p>
			<p>去过去三个月的<code>p3dn.24xlarge</code>，那里的现货价格比需求价格便宜 60-70%:</p>
			<div><div><img src="img/B17705_10_1.jpg" alt="Figure 10.1 – Viewing the spot price of p3dn.24xlarge&#13;&#10;" width="1273" height="759"/>
				</div>
			</div>
			<p class="figure-caption">图 10.1–查看 p3dn.24xlarge 的现货价格</p>
			<p>这些是 EC2 价格，但同样的折扣率也适用于 SageMaker 价格。折扣因实例类型、地区甚至可用性区域而异。您可以使用<code>describe-spot-price-history</code> API 以编程方式收集这些信息，并在您的工作流中使用它:</p>
			<p>https://docs . AWS . Amazon . com/CLI/latest/reference/ec2/describe-spot-price-history . html</p>
			<p>现在，让我们看看这对 SageMaker 意味着什么。</p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor211"/>了解受控现场培训</h2>
			<p>在所有 SageMaker 配置中都可以使用 Spot <a id="_idIndexMarker1080"/>实例进行训练:单实例训练、分布式训练、内置算法、框架和您自己的算法。</p>
			<p>只需设置几个估计器参数。你不需要担心处理通知和中断。SageMaker 会自动为您完成。</p>
			<p>如果培训作业中断，SageMaker 会重新获得足够的现场容量，并重新启动培训作业。如果算法使用检查点，则训练从最新的检查点恢复。否则，作业将从头重新开始。</p>
			<p>实现检查点需要多少工作量取决于您使用的算法:</p>
			<ul>
				<li>计算机视觉和<strong class="bold"> XGBoost </strong>的三个内置算法支持检查点。</li>
				<li>其他内置算法都没有。您仍然可以使用 Spot 实例训练它们。但是，最长运行时间限制为 60 分钟，以最大限度地减少潜在的浪费。如果你的培训工作超过 60 分钟，你应该试着扩大规模。如果这还不够，您将不得不使用按需实例。</li>
				<li>用于<strong class="bold"> TensorFlow </strong>、<strong class="bold"> PyTorch </strong>、<strong class="bold"> Apache </strong>、T29】 MXNet 和<strong class="bold">抱抱脸</strong>的<strong class="bold">深度学习容器</strong>自带检查点，无需修改训练脚本。</li>
				<li>如果您使用其他框架或您自己的定制代码，您需要实现检查点。</li>
			</ul>
			<p>在训练期间，检查点保存在训练容器中。默认路径是<code>/opt/ml/checkpoints</code>，您可以使用估计器参数对其进行定制。SageMaker 还会自动将这些检查点保存到用户定义的 S3 路径中。如果您的培训作业中断并重新启动，检查点会自动复制到容器中。您的代码可以检查它们是否存在，并加载适当的代码来恢复训练。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">请注意，即使在使用按需实例训练时，检查点也是可用的。如果您想在 S3 存储检查点以便进一步检查或进行增量训练，这可能会很方便。唯一的限制是在<strong class="bold">本地模式</strong>下检查点不可用。</p>
			<p>最后但同样重要的是，检查点的确会降低作业速度，尤其是对于大型模型。然而，为了避免从零开始重新启动长时间运行的作业，这是一个很小的代价。</p>
			<p>现在，让我们在第五章 、<em class="italic">训练计算机视觉模型</em>中运行的<strong class="bold">对象检测</strong>任务中添加管理点训练。</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor212"/>使用带有目标检测的管理点训练</h2>
			<p>从按需培训切换到受管理的现场培训非常简单。我们只需要设置培训工作的最大持续时间，包括等待 Spot 实例可用的时间。</p>
			<p>我们设定最长运行时间为 2 小时，加上任何现场延迟的 8 小时。如果超过其中任何一个界限，作业将自动终止。这有助于终止持续时间比预期长得多的失控作业，或者停止等待 spot 实例的作业:</p>
			<pre>od = sagemaker.estimator.Estimator(
     container,
     role,
     instance_count=2,                                 
     instance_type='ml.p3.2xlarge',                                 
     use_spot_instances=True,
     max_run=7200,                     # 2 hour
     max_wait=36000,                   # +8 hours
     output_path=s3_output_location)</pre>
			<p>我们用和以前一样的配置训练:管道模式和<code>dist_sync</code>模式。当第一个时期完成时，训练日志告诉我们检查点处于活动状态。每次验证指标提高时，都会自动保存新的检查点:</p>
			<pre><strong class="bold">Updating the best model with validation-mAP=1.615789635726003e-05</strong>
<strong class="bold">Saved checkpoint to "/opt/ml/model/model_algo_1-0000.params"</strong></pre>
			<p>培训工作完成后，培训日志会告诉我们节省了多少:</p>
			<pre><strong class="bold">Training seconds: 7794</strong>
<strong class="bold">Billable seconds: 2338</strong>
<strong class="bold">Managed Spot Training savings: 70.0%</strong></pre>
			<p>这项工作不仅比按需分配的工作便宜 70%,而且价格还不到我们原来单一实例工作的一半。这意味着我们可以使用更多的<a id="_idIndexMarker1086"/>实例，并以同样的预算加速我们的培训工作。事实上，有管理的现场培训可以让你优化工作的持续时间和成本。除了复杂的容量规划之外，您还可以设定适合您业务需求的培训预算，然后获取尽可能多的基础架构。</p>
			<p>让我们尝试另一个例子，我们在<strong class="bold"> Keras </strong>中实现检查点。</p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor213"/>使用 Keras 的管理点训练和检查点</h2>
			<p>在这个例子中，我们将<a id="_idIndexMarker1087"/>在 TensorFlow 2.1 中构建一个简单的<code>Sequential</code> API。</p>
			<h3>使用 Keras 设置检查点</h3>
			<p>我们先来看看 Keras 脚本本身。为了简洁起见，这里只介绍重要的步骤。你可以在 GitHub 资源库中找到这本书的完整代码:</p>
			<ol>
				<li value="1">使用脚本模式，我们存储数据集路径和超参数。</li>
				<li>然后，我们加载数据集并将像素值归一化到[0，1]范围。我们也一次性编码类标签。</li>
				<li>我们构建一个<code>Sequential</code>模型:两个卷积块(<code>Conv2D</code> / <code>BatchNormalization</code> / <code>ReLU</code> / <code>MaxPooling2D</code> / <code>Dropout</code>)，然后是两个完全连接的块(<code>Dense</code> / <code>BatchNormalization</code> / <code>ReLU</code> / <code>Dropout</code>)，最后是数据集中 10 个类的<code>softmax</code>输出层。</li>
				<li>我们使用<strong class="bold">分类交叉熵</strong>损失函数和<strong class="bold"> Adam </strong>优化器<pre>model.compile(     loss=tf.keras.losses.categorical_crossentropy,     optimizer=tf.keras.optimizers.Adam(),     metrics=['accuracy'])</pre>编译<a id="_idIndexMarker1089"/>模型</li>
				<li>我们定义了一个 Keras 回调函数，用于在每次验证准确性提高时检查模型:<pre>from tensorflow.keras.callbacks import ModelCheckpoint chk_dir = '/opt/ml/checkpoints' chk_name = 'fmnist-cnn-{epoch:04d}' checkpointer = ModelCheckpoint(     filepath=os.path.join(chk_dir, chk_name),     monitor='val_accuracy')</pre></li>
				<li>我们训练模型，添加我们刚刚创建的回调:<pre>model.fit(x=x_train, y=y_train,            validation_data=(x_val, y_val),           batch_size=batch_size, epochs=epochs,           callbacks=[checkpointer],           verbose=1)</pre></li>
				<li>训练完成后，我们将模型保存为<strong class="bold"> TensorFlow Serving </strong>格式，这是在 SageMaker: <pre>from tensorflow.keras.models import save_model save_model(model, os.path.join(model_dir, '1'),              save_format='tf')</pre>上部署所需的<a id="_idIndexMarker1090"/></li>
			</ol>
			<p>现在，让我们看看我们的培训笔记本。</p>
			<h3>使用管理点培训和检查点进行培训</h3>
			<p>我们使用与之前相同的工作流程:</p>
			<ol>
				<li value="1">我们下载时尚 MNIST 数据集，并将其保存到本地目录。我们将数据集上传到 S3，并定义 SageMaker 复制检查点的 S3 位置。</li>
				<li>我们配置了一个<code>TensorFlow</code>估计器，支持<a id="_idIndexMarker1092"/>管理的现场训练，并通过检查点的 S3 输出位置。这一次，我们使用一个<code>ml.g4dn.xlarge</code>实例。这个性价比非常高的 GPU 实例(<code>eu-west-1</code>0.822 美元)对于一个小型号来说绰绰有余:<pre>from sagemaker.tensorflow import TensorFlow tf_estimator = TensorFlow(     entry_point='fmnist-1.py',     role=sagemaker.get_execution_role(),     instance_count=1,     instance_type='ml.g4dn.xlarge',          framework_version='2.1.0',     py_version='py3',     hyperparameters={'epochs': 20},     output_path=output_path,     use_spot_instances=True,     max_run=3600,     max_wait=7200,     checkpoint_s3_uri=chk_path)</pre></li>
				<li>我们照常展开<a id="_idIndexMarker1093"/>训练，而<a id="_idIndexMarker1094"/>工作达到了 93.11%的准确率。训练持续 289 秒，由于 69.9%的折扣，我们只需支付 87 秒的费用。总费用 1.98 美分！谁说 GPU 培训一定要花钱的？</li>
				<li>In the training log, we see that a checkpoint is created every time validation accuracy improves:<pre><strong class="bold">INFO:tensorflow:Assets written to /opt/ml/checkpoints/fmnist-cnn-0001/assets</strong></pre><p>在作业运行时，我们还看到检查点被拷贝到 S3:</p><pre><strong class="bold">$ aws s3 ls s3://sagemaker-eu-west-1-123456789012/keras2</strong>
<strong class="bold">fashion-mnist/checkpoints/</strong>
<strong class="bold">PRE fmnist-cnn-0001/</strong>
<strong class="bold">PRE fmnist-cnn-0002/</strong>
<strong class="bold">PRE fmnist-cnn-0003/</strong>
<strong class="bold">PRE fmnist-cnn-0006/</strong>
<strong class="bold">. . .</strong></pre></li>
			</ol>
			<p>如果我们的 spot 作业被中断，SageMaker 将复制容器内部的检查点，以便我们可以使用它们来恢复训练。这需要我们的 Keras 脚本中的一些逻辑来加载最新的检查点。让我们看看如何做到这一点。</p>
			<h3>从检查站恢复训练</h3>
			<p>这是一个非常简单的过程——寻找检查点，并从最新的检查点开始恢复训练:</p>
			<ol>
				<li value="1">我们列出检查点目录:<pre>import glob checkpoints = sorted(     glob.glob(os.path.join(chk_dir,'fmnist-cnn-*')))</pre></li>
				<li>如果检查点存在，我们会找到最近的检查点及其纪元编号。然后，我们加载模型:<pre>from tensorflow.keras.models import load_model if checkpoints :     last_checkpoint = checkpoints[-1]     last_epoch = int(last_checkpoint.split('-')[-1])     model = load_model(last_checkpoint)     print('Loaded checkpoint for epoch ', last_epoch)</pre></li>
				<li>如果没有检查点，我们照常构建模型:<pre>else:     last_epoch = 0     model = Sequential()     . . .</pre></li>
				<li>我们编译模型，然后开始训练，通过最后一个纪元的编号:<pre>model.fit(x=x_train, y=y_train,            validation_data=(x_val, y_val),            batch_size=batch_size,           epochs=epochs,           initial_epoch=last_epoch,           callbacks=[checkpointer],           verbose=1)</pre></li>
			</ol>
			<p>我们如何测试这个？没有办法故意造成现场中断。</p>
			<p>这里有一个技巧:用<code>checkpoint_s3_uri</code>路径中现有的检查点开始一个新的训练任务，然后<a id="_idIndexMarker1096"/>增加历元的数量。这将模拟恢复中断的作业。</p>
			<p>将历元数设置为 25，并将检查点保持在<code>s3://sagemaker-eu-west-1-123456789012/keras2</code></p>
			<p><code>fashion-mnist/checkpoints</code>，我们再次启动培训工作。</p>
			<p>在训练日志中，我们看到加载了最新的检查点，训练在第 21:</p>
			<pre><strong class="bold">Loaded checkpoint for epoch 20</strong>
<strong class="bold">. . .</strong>
<strong class="bold">Epoch 21/25</strong></pre>
			<p>我们还看到，随着验证准确性的提高，会创建新的检查点，并将它们复制到 S3:</p>
			<pre><strong class="bold">INFO:tensorflow:Assets written to: /opt/ml/checkpoints/fmnist-cnn-0021/assets</strong></pre>
			<p>正如您所看到的，在 SageMaker 中设置检查点并不困难，您应该能够为其他框架做同样的事情。由于这一点，您可以享受由管理的现场培训提供的大折扣，而没有在中断发生时丢失任何工作的风险。当然，您可以单独使用检查点来检查中间训练结果，或者用于增量训练。</p>
			<p>在下一节中，我们将介绍另一个重要特性:自动模型调整。</p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor214"/>通过自动模型调整优化超参数</h1>
			<p>超参数对训练结果有很大的影响。就像在<strong class="bold">混沌理论</strong>中一样，单个超参数的微小<a id="_idIndexMarker1097"/>变化会<a id="_idIndexMarker1098"/>导致精确度的剧烈波动。在大多数情况下，“为什么？”避开我们，让我们不知下一步该做什么。</p>
			<p>多年来，已经设计了几种技术来试图解决选择最佳超参数的问题:</p>
			<ol>
				<li value="1"><strong class="bold">手动搜索</strong>:这意味着使用我们的最佳判断和经验来选择“最佳”超参数。让我们面对它:这真的不起作用，尤其是在深度学习及其大量训练和网络架构参数的情况下。</li>
				<li><strong class="bold">网格搜索</strong>:这需要系统地探索超参数空间，放大热点，<a id="_idIndexMarker1100"/>重复这个过程。这比手动搜索好得多。然而，这通常需要培训数百个职位。即使有了可扩展的基础设施，时间和资金预算也会很可观。</li>
				<li><strong class="bold">随机搜索</strong>:随机选择超参数<a id="_idIndexMarker1101"/>。虽然听起来很不直观，但詹姆斯·伯格斯特拉(James Bergstra)和 Yoshua Bengio(因图灵奖而出名)在 2012 年证明，这种技术在相同的计算预算下提供了比网格搜索更好的模型</li>
				<li><a href="http://www.jmlr.org/papers/v13/bergstra12a.html">http://www.jmlr.org/papers/v13/bergstra12a.html</a></li>
				<li><strong class="bold">超参数优化</strong> (HPO):这个<a id="_idIndexMarker1102"/>就是利用优化技术来选择超参数，比如<strong class="bold">贝叶斯优化</strong>和<strong class="bold">高斯过程回归</strong>。在<a id="_idIndexMarker1103"/>相同的计算预算下，HPO 通常比其他技术交付的结果少 10 倍的训练周期<a id="_idIndexMarker1104"/>。</li>
			</ol>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor215"/>了解自动模型调整</h2>
			<p>SageMaker 包括一个<strong class="bold">自动模型调整</strong>功能，让您可以轻松探索超参数<a id="_idIndexMarker1105"/>范围，并快速优化有限数量工作的任何训练指标。</p>
			<p>模型优化支持随机搜索和 HPO。前者是一个有趣的基线，可以帮助你检查后者是否真的表现过度。你可以在这篇精彩的博文中找到非常详细的对比:</p>
			<p>https://AWS . Amazon . com/blogs/machine-learning/Amazon-sage maker-automatic-model-tuning-now-supports-random-search-and-hyperparameter-scaling/</p>
			<p>模型调优与您使用的算法完全无关。它与内置算法一起工作，文档中列出了可以调优的超参数。它还适用于所有框架和定制容器，超参数也以同样的方式传递。</p>
			<p>对于我们想要优化的每个超参数，我们必须定义以下内容:</p>
			<ul>
				<li>一个名字</li>
				<li>类型(参数可以是整数、连续或分类)</li>
				<li>一系列值得探索的价值</li>
				<li>缩放类型(线性、对数、反对数或自动)—这让我们可以控制如何探索特定的参数范围</li>
			</ul>
			<p>我们还定义了我们想要优化的指标。它可以是任何数值，只要它在训练日志中可见，并且您可以传递一个正则表达式来提取它。</p>
			<p>然后，我们启动调优作业，传递所有这些参数以及要运行的训练作业的数量和它们的并行度。使用贝叶斯优化，您将获得顺序作业的最佳结果(无并行性)，因为优化可以在每个作业之后应用。话虽如此，并行运行少量作业是可以接受的。随机搜索对并行性没有限制，因为作业是完全不相关的。</p>
			<p>调用 tuner 对象上的<code>deploy()</code> API 部署最佳模型。如果调优仍在进行中，它将部署目前为止最好的<a id="_idIndexMarker1106"/>模型，这对早期测试很有用。</p>
			<p>让我们使用内置算法运行第一个示例，并了解模型调优 API。</p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor216"/>使用带有对象检测的自动模型调整</h2>
			<p>我们将优化我们的物体检测工作。查看文档，我们可以看到可调超参数的列表:</p>
			<p>https://docs . AWS . Amazon . com/sage maker/latest/DG/object-detection-tuning . html</p>
			<p>让我们尝试优化<a id="_idIndexMarker1108"/>学习率、动量和重量衰减:</p>
			<ol>
				<li value="1">我们使用管道模式设置输入通道。这里没有变化。</li>
				<li>我们还像往常一样配置估计器，设置管理现场培训以最小化成本。我们将针对单个实例进行训练，以获得最大的准确性:<pre>od = sagemaker.estimator.Estimator(      container,      role,                                              instance_count=1,                                              instance_type='ml.p3.2xlarge',                                             output_path=s3_output_location,                                              use_spot_instances=True,      max_run=7200,      max_wait=36000,      volume_size=1)       </pre></li>
				<li>我们使用和以前一样的超参数:<pre>od.set_hyperparameters(base_network='resnet-50',                        use_pretrained_model=1,                        num_classes=20,                        epochs=30,                        num_training_samples=16551,                        mini_batch_size=90)</pre></li>
				<li>我们定义了三个想要优化的额外超参数。我们为学习率明确设置了对数标度，以确保探索不同的数量级:<pre>from sagemaker.tuner import ContinuousParameter, hyperparameter_ranges = {     'learning_rate': ContinuousParameter(0.001, 0.1,                       scaling_type='Logarithmic'),      'momentum': ContinuousParameter(0.8, 0.999),      'weight_decay': ContinuousParameter(0.0001, 0.001) }</pre></li>
				<li>我们<a id="_idIndexMarker1109"/>将指标设置为<a id="_idIndexMarker1110"/>优化:<pre>objective_metric_name = 'validation:mAP' objective_type = 'Maximize'</pre></li>
				<li>我们使用<code>HyperparameterTuner</code>对象将所有东西放在一起。我们决定运行 30 个作业，其中两个作业并行运行。我们还可以提前停止工作，淘汰表现不佳的工作，为我们节省时间和金钱:<pre>from sagemaker.tuner import HyperparameterTuner tuner = HyperparameterTuner(od,             objective_metric_name,             hyperparameter_ranges,             objective_type=objective_type,             max_jobs=30,             max_parallel_jobs=2,             early_stopping_type='Auto')</pre></li>
				<li>我们在调谐器对象(而不是评估器)上启动训练，而不等待它完成:<pre>tuner.fit(inputs=data_channels, wait=False)</pre></li>
				<li>目前，<strong class="bold"> SageMaker Studio </strong>不提供调优作业的便捷视图。相反，我们可以在 SageMaker 控制台的<strong class="bold">超参数调优作业</strong>部分跟踪进度，如下图所示:</li>
			</ol>
			<div><div><img src="img/B17705_10_2.jpg" alt="Figure 10.2 – Viewing tuning jobs in the SageMaker console&#13;&#10;" width="1622" height="807"/>
				</div>
			</div>
			<p class="figure-caption">图 10.2–在 SageMaker 控制台中查看调优作业</p>
			<p>作业<a id="_idIndexMarker1111"/>运行 17 小时(墙时间)。22 项工作完成，8 项提前停止。总训练时间为 30 小时 15 分钟。应用 70%的现货折扣，总成本为 25.25 * 4.131 * 0.3 = 37.48 美元。</p>
			<p>这个调优工作做得怎么样？使用默认的超参数，我们的独立培训工作达到了<code>0.2453</code>。我们的调优工作点击了<code>0.6337</code>，如下面的截图所示:</p>
			<div><div><img src="img/B17705_10_3.jpg" alt="Figure 10.3 – Tuning job results&#13;&#10;" width="686" height="180"/>
				</div>
			</div>
			<p class="figure-caption">图 10.3-调优作业结果</p>
			<p>验证图的图形<a id="_idIndexMarker1113"/>如下图所示。这告诉我，我们也许可以训练得更久一点，并获得额外的准确性:</p>
			<div><div><img src="img/B17705_10_4.jpg" alt="Figure 10.4 – Viewing the mAP metric&#13;&#10;" width="963" height="276"/>
				</div>
			</div>
			<p class="figure-caption">图 10.4–查看地图度量</p>
			<p>一个想法是用最好的超参数启动一个单一的训练任务，并让它运行更多的时期。我们还可以使用 tuner 对象上的<code>deploy()</code>恢复调优工作，并像测试任何 SageMaker 模型一样测试我们的模型。</p>
			<p>如您所见，自动模型调整非常强大。通过运行少量作业，我们将指标提高了 158%！与您尝试其他技术所花费的时间相比，成本可以忽略不计。</p>
			<p>事实上，使用随机策略运行相同的调优作业可以达到 0.52 的最高精度。我们当然需要运行更多的训练工作，甚至希望达到 0.6315。</p>
			<p>现在让我们试着优化我们在本章前面使用的 Keras 例子。</p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor217"/>使用 Keras 的自动模型调整</h2>
			<p>自动模型调优可以很容易地用于 SageMaker 上的任何算法，这当然包括所有的<a id="_idIndexMarker1115"/>框架。让我们看看这是如何与 Keras 一起工作的。</p>
			<p>在本章早些时候，我们在时尚 MNIST 数据集上训练了我们的 Keras CNN 20 个时期，达到了 93.11%的验证准确率。让我们看看是否可以通过自动模型调整来改善它。在这个过程中，我们还将学习如何优化培训日志中的任何指标，而不仅仅是 SageMaker 中预定义的指标。</p>
			<h3>根据自定义指标进行优化</h3>
			<p>修改<a id="_idIndexMarker1117"/>我们的培训脚本，我们安装<code>keras-metrics</code>包(<a href="https://github.com/netrack/keras-metrics">https://github.com/netrack/keras-metrics</a>)并将<strong class="bold">精度</strong>、<strong class="bold">召回</strong>和<strong class="bold"> f1 得分</strong>指标添加到培训日志中:</p>
			<pre>import subprocess, sys
def install(package):
    subprocess.call([sys.executable, "-m", "pip",
                     "install", package])
install('keras-metrics')
import keras_metrics
. . . 
model.compile(
    loss=tf.keras.losses.categorical_crossentropy,
    optimizer=tf.keras.optimizers.Adam(),
    metrics=['accuracy',
              keras_metrics.precision(),
              keras_metrics.recall(),
              keras_metrics.f1_score()])</pre>
			<p>经过 20 个时期后，指标现在看起来像这样:</p>
			<pre><strong class="bold">loss: 0.0869 - accuracy: 0.9678 - precision: 0.9072 - recall: 0.8908 - f1_score: 0.8989 - val_loss: 0.2301 - val_accuracy: 0.9310 - val_precision: 0.9078 - val_recall: 0.8915 - val_f1_score: 0.8996</strong></pre>
			<p>如果我们想要<a id="_idIndexMarker1118"/>优化 f1 分数，我们将像这样定义调谐器指标:</p>
			<pre>objective_metric_name = 'val_f1'
objective_type = 'Maximize'
metric_definitions = [
    {'Name': 'val_f1',
     'Regex': 'val_f1_score: ([0-9\\.]+)'
    }]</pre>
			<p>这就够了。只要在训练日志中打印了一个指标，您就可以使用它来优化模型。</p>
			<h3>优化我们的 Keras 模型</h3>
			<p>现在，让我们<a id="_idIndexMarker1119"/>运行我们的调优工作:</p>
			<ol>
				<li value="1">我们像这样定义<code>HyperparameterTuner</code>的指标，优化准确性，并显示 f1 分数:<pre>objective_metric_name = 'val_acc' objective_type = 'Maximize' metric_definitions = [     {'Name': 'val_f1',       'Regex': 'val_f1_score: ([0-9\\.]+)'},     {'Name': 'val_acc',       'Regex': 'val_accuracy: ([0-9\\.]+)'} ]</pre></li>
				<li>我们定义<a id="_idIndexMarker1120"/>要探索的参数范围:<pre>from sagemaker.tuner import ContinuousParameter, IntegerParameter hyperparameter_ranges = {     'learning_rate': ContinuousParameter(0.001, 0.2,                       scaling_type='Logarithmic'),      'batch-size': IntegerParameter(32,512) }</pre></li>
				<li>我们使用相同的估计器(20 个具有 spot 实例的纪元)，并定义调谐器:<pre>tuner = HyperparameterTuner(     tf_estimator,     objective_metric_name,     hyperparameter_ranges,                               metric_definitions=metric_definitions,     objective_type=objective_type,     max_jobs=20,     max_parallel_jobs=2,     early_stopping_type='Auto')</pre></li>
				<li>We launch the tuning job. While it's running, we can use the <strong class="bold">SageMaker SDK</strong> to display the list of training jobs and their properties: <pre>from sagemaker.analytics import HyperparameterTuningJobAnalytics
exp = HyperparameterTuningJobAnalytics(
   hyperparameter_tuning_job_name=
   tuner.latest_tuning_job.name)
jobs = exp.dataframe()
jobs.sort_values('FinalObjectiveValue', ascending=0)</pre><p>这将打印出下一个屏幕截图中可见的表格:</p></li>
			</ol>
			<div><div><img src="img/B17705_10_5.jpg" alt="Figure 10.5 – Viewing information on a tuning job&#13;&#10;" width="1080" height="321"/>
				</div>
			</div>
			<p class="figure-caption">图 10.5–查看有关调整作业的信息</p>
			<p>调整作业将运行 2 小时 8 分钟(挂机时间)。最高验证准确率为 93.46%，比我们的基线有了长足的进步。</p>
			<p>我们当然可以通过更长时间的训练做得更好。然而，我们训练的时间越长，过度训练就越令人担忧。我们可以通过提前停止来缓解它，这可以通过 Keras 回调来实现。但是，我们应该确保作业报告的是最佳时期的度量，而不是最后一个时期的度量。我们如何在培训日志中显示？又一次回调！</p>
			<h3>为提前停止添加回调</h3>
			<p>添加<a id="_idIndexMarker1122"/>一个用于提前止损的 Keras 回调非常简单:</p>
			<ol>
				<li value="1">我们添加了一个内置回调，用于根据验证的准确性提前停止:<pre>from tensorflow.keras.callbacks import EarlyStopping early_stopping = EarlyStopping(     monitor='val_accuracy',     min_delta=0.0001,     patience=10,     verbose=1,     mode='auto')</pre></li>
				<li>我们添加了<a id="_idIndexMarker1123"/>一个自定义回调，以存储每个纪元结束时的验证精度，并在训练结束时显示最佳的一个:<pre>from tensorflow.keras.callbacks import Callback class LogBestMetric(Callback):     def on_train_begin(self, logs={}):         self.val_accuracy = []     def on_train_end(self, logs={}):         print("Best val_accuracy:",               max(self.val_accuracy))     def on_epoch_end(self, batch, logs={}):         self.val_accuracy.append(             logs.get('val_accuracy'))         best_val_metric = LogBestMetric()</pre></li>
				<li>We add these two callbacks to the training API:<pre>model.fit(. . . 
    callbacks=[checkpointer, early_stopping, 
               best_val_metric])</pre><p>通过测试一些单独的工作，培训日志的最后几行现在看起来像这样:</p><pre><strong class="bold">Epoch 00048: early stopping</strong>
<strong class="bold">Best val_accuracy: 0.9259</strong></pre></li>
				<li>在笔记本中，我们更新了我们的指标定义，以提取最佳验证准确度:<pre>objective_metric_name = 'val_acc' objective_type = 'Maximize' metric_definitions = [     {'Name': 'val_acc',       'Regex': 'Best val_accuracy: ([0-9\\.]+)'} ]</pre></li>
			</ol>
			<p>本次训练<a id="_idIndexMarker1124"/>60 个纪元(约 3 小时壁时)，最高验证准确率现为 93.78%。看起来，通过调整学习速度和批量，这已经很好了。</p>
			<h2 id="_idParaDest-219"><a id="_idTextAnchor218"/>使用自动模型调整进行架构搜索</h2>
			<p>我们的神经<a id="_idIndexMarker1125"/>网络有很多<a id="_idIndexMarker1126"/>更多的超参数:卷积滤波器的数量，脱落，等等。让我们也尝试优化这些:</p>
			<ol>
				<li value="1">We modify our training script to add command-line parameters for the following network parameters, which are used by Keras layers in our model:<pre>parser.add_argument(
    '--filters1', type=int, default=64)
parser.add_argument(
    '--filters2', type=int, default=64)
parser.add_argument(
    '--dropout-conv', type=float, default=0.2)
parser.add_argument(
    '--dropout-fc', type=float, default=0.2)</pre><p>如您所料，这些参数允许我们设置每个<a id="_idIndexMarker1128"/>层中卷积<a id="_idIndexMarker1127"/>滤波器的数量、卷积层的丢失值以及完全连接的层的丢失值。</p></li>
				<li>因此，在笔记本中，我们定义了这些超参数及其范围。对于学习率和批量，我们使用了以先前调优作业发现的最优值为中心的窄范围:<pre>from sagemaker.tuner import ContinuousParameter,                              IntegerParameter hyperparameter_ranges = {     learning-rate': ContinuousParameter(0.01, 0.14),      'batch-size': IntegerParameter(130,160),     'filters1': IntegerParameter(16,256),     'filters2': IntegerParameter(16,256),     'dropout-conv': ContinuousParameter(0.001,0.5,                      scaling_type='Logarithmic'),     'dropout-fc': ContinuousParameter(0.001,0.5,                    scaling_type='Logarithmic') }</pre></li>
				<li>我们启动了调优作业，在 100 个时期内一次运行 50 个作业两个。</li>
			</ol>
			<p>该调优工作运行约 12 小时，总成本约为 15 美元。顶级验证准确率达到 94.09%。与我们的基线相比，自动模型调整使我们的模型精度提高了近 1 个百分点，这是一个非常显著的增益。如果使用此模型每天预测 100 万个样本，这意味着将有超过 10，000 个额外的准确预测！</p>
			<p>总的来说，我们花在调整 Keras 模型上的费用不到 50 美元。无论<a id="_idIndexMarker1129"/>的商业指标会因<a id="_idIndexMarker1130"/>的额外准确性而得到改善，可以公平地说，这笔花费很快就会收回。正如许多客户告诉我的，自动模型调优是有回报的，而且有些是有回报的。</p>
			<p>我们对自动模型调整的探索到此结束，这是我在 SageMaker 中最喜欢的特性之一。您可以在<a href="https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning">https://github . com/aw plats/Amazon-sage maker-examples/tree/master/hyperparameter _ tuning</a>上找到更多示例。</p>
			<p>现在，让我们了解 SageMaker 调试器，以及它如何帮助我们理解模型内部发生的事情。</p>
			<h1 id="_idParaDest-220"><a id="_idTextAnchor219"/>使用 SageMaker 调试器探索模型</h1>
			<p>SageMaker 调试器允许您为您的培训工作配置<em class="italic">调试规则</em>。这些规则将<a id="_idIndexMarker1131"/>检查其内部状态，并<a id="_idIndexMarker1132"/>检查在训练期间可能出现的特定不良情况。SageMaker Debugger 包括一长串内置规则(<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html">https://docs . AWS . Amazon . com/sage maker/latest/DG/Debugger-built-in-rules . html</a>)，你还可以添加自己用 Python 编写的。</p>
			<p>此外，您可以保存和检查模型状态(梯度、权重等)以及训练状态(度量、优化器参数等)。在每个训练步骤中，存储这些值的<strong class="bold">张量</strong>可以近乎实时地保存在 S3 桶中，使得在模型训练时可以可视化它们。</p>
			<p>当然，您可以选择想要保存的张量<strong class="bold">集合</strong>，保存的频率等等。根据您使用的框架，可以使用不同的集合。你可以在<a href="https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md">https://github . com/aw slabs/sage maker-debugger/blob/master/docs/API . MD</a>找到更多信息。最后但同样重要的是，您可以保存原始张量数据或张量缩减以限制所涉及的数据量。减少量包括最小值、最大值、中间值等。</p>
			<p>如果您正在使用 TensorFlow、PyTorch、Apache MXNet 或内置 XGBoost 算法的受支持版本的内置容器，您可以使用现成的 SageMaker 调试器，而无需更改脚本中的一行代码。是的，你没看错。你所要做的就是给估计器添加额外的参数，就像我们在接下来的例子中要做的那样。</p>
			<p>对于其他<a id="_idIndexMarker1133"/>版本，或者你自己的容器，只需要很少的修改。你可以在 https://github.com/awslabs/sagemaker-debugger 找到最新的信息和例子。</p>
			<p>可以在同一个培训作业上配置调试规则和保存张量。为了清楚起见，我们将<a id="_idIndexMarker1134"/>运行两个单独的例子。首先，让我们使用第四章<em class="italic">中<a href="B17705_04_Final_JM_ePub.xhtml#_idTextAnchor069"> <em class="italic">的 XGBoost 和 Boston Housing 示例来训练机器学习模型</em>。</a></em></p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor220"/>调试 XGBoost 作业</h2>
			<p>首先，我们将配置<a id="_idIndexMarker1135"/>几个内置规则，训练我们的模型，<a id="_idIndexMarker1136"/>检查所有规则的状态:</p>
			<ol>
				<li value="1">看看内置规则列表，我们决定使用<code>overtraining</code>和<code>overfit</code>。每个规则都有我们可以调整的额外参数。我们坚持使用默认值，并相应地配置了<code>Estimator</code>:<pre>from sagemaker.debugger import rule_configs, Rule xgb_estimator = Estimator(container,   role=sagemaker.get_execution_role(),   instance_count=1,   instance_type='ml.m5.large',   output_path='s3://{}/{}/output'.format(bucket, prefix),   rules=[     Rule.sagemaker(rule_configs.overtraining()),     Rule.sagemaker(rule_configs.overfit())   ] )</pre></li>
				<li>我们设置超参数并启动培训，而不等待培训工作完成。训练日志在笔记本中看不到，但在<strong class="bold">云观察日志</strong> : <pre>xgb_estimator.set_hyperparameters(   objective='reg:linear', num_round=100) xgb_estimator.fit(xgb_data, wait=False)</pre>中仍然可以看到</li>
				<li>In addition to <a id="_idIndexMarker1137"/>the training job, one <a id="_idIndexMarker1138"/>debugging job per rule is running under the hood, and we can check their statuses:<pre>description = xgb_estimator.latest_training_job.rule_job_summary()
for rule in description:
  rule.pop('LastModifiedTime')
  rule.pop('RuleEvaluationJobArn')
  print(rule)</pre><p>这告诉我们调试器作业正在运行:</p><pre><strong class="bold">{'RuleConfigurationName': 'Overtraining',  </strong>
<strong class="bold"> 'RuleEvaluationStatus': 'InProgress'}</strong>
<strong class="bold">{'RuleConfigurationName': 'Overfit', </strong>
<strong class="bold"> 'RuleEvaluationStatus': 'InProgress'}</strong></pre></li>
				<li>训练作业完成后运行同一个单元，我们看到没有触发任何规则:<pre><strong class="bold">{'RuleConfigurationName': 'Overtraining',</strong> <strong class="bold"> 'RuleEvaluationStatus': 'NoIssuesFound'}</strong> <strong class="bold">{'RuleConfigurationName': 'Overfit', </strong> <strong class="bold"> 'RuleEvaluationStatus': 'NoIssuesFound'}</strong></pre></li>
			</ol>
			<p>如果触发了一个规则，我们<a id="_idIndexMarker1139"/>将会得到一个错误消息，并且训练任务将会停止。检查存储在 S3 的张量会帮助我们了解哪里出了问题。</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor221"/>检查 XGBoost 作业</h2>
			<p>让我们配置一个新的<a id="_idIndexMarker1141"/>训练作业，保存所有可用于 XGBoost 的张量集合:</p>
			<ol>
				<li value="1">We configure the <a id="_idIndexMarker1142"/><code>Estimator</code>, passing a <code>DebuggerHookConfig</code> object. We save three tensor collections at each training step: metrics, feature importance, and average <strong class="bold">SHAP</strong> (<a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>) values. These help us understand how each feature in a data sample contributes to increasing or decreasing the predicted value.<p>对于较大的模型和数据集，这可能会生成大量数据，需要很长时间来加载和分析。我们要么增加保存间隔，要么保存张量缩减，而不是全张量:</p><pre>from sagemaker.debugger import DebuggerHookConfig, CollectionConfig
save_interval = '1'
xgb_estimator = Estimator(container,
    role=role,
    instance_count=1,
    instance_type='ml.m5.large',
    output_path='s3://{}/{}/output'.format(bucket,  
                                           prefix),
    
    debugger_hook_config=DebuggerHookConfig(                
        s3_output_path=
        's3://{}/{}/debug'.format(bucket,prefix),
      collection_configs=[
        CollectionConfig(name='metrics',
          parameters={"save_interval": 
                      save_interval}),
        CollectionConfig(name='average_shap',  
          parameters={"save_interval": 
                      save_interval}),
        CollectionConfig(name='feature_importance', 
          parameters={"save_interval": save_interval})
      ]
    )
)</pre></li>
				<li>一旦<a id="_idIndexMarker1143"/>培训工作开始，我们<a id="_idIndexMarker1144"/>可以创建一个试验并加载已经保存的数据。由于这项工作非常短，我们在一分钟左右看到所有数据:<pre>from smdebug.trials import create_trial s3_output_path = xgb_estimator.latest_job_debugger_artifacts_path() trial = create_trial(s3_output_path)</pre></li>
				<li>我们可以列出所有被保存的张量的名称:<pre>trial.tensor_names() <strong class="bold">['average_shap/f0','average_shap/f1','average_shap/f10', … </strong> <strong class="bold"> 'feature_importance/cover/f0','feature_importance/cover/f1',…</strong> <strong class="bold"> 'train-rmse','validation-rmse']</strong></pre></li>
				<li>我们还可以列出给定集合中所有张量的名称:<pre>trial.tensor_names(collection="metrics") <strong class="bold">['train-rmse', 'validation-rmse']</strong></pre></li>
				<li>对于<a id="_idIndexMarker1145"/>每个张量，我们可以访问训练<a id="_idIndexMarker1146"/>的步骤和值。让我们从<code>average_shap</code>和<code>feature_importance</code>系列中提取特征信息:<pre>def plot_features(tensor_prefix):     num_features = len(dataset.columns)-1     for i in range(0,num_features):     feature = tensor_prefix+'/f'+str(i)     steps = trial.tensor(feature).steps()     v = [trial.tensor(feature).value(s) for s in steps]     plt.plot(steps, v, label=dataset.columns[i+1])     plt.autoscale()     plt.title(tensor_prefix)     plt.legend(loc='upper left')     plt.show()</pre></li>
				<li>我们构建了<code>average_shap</code>图:<pre>plot_features('average_shap')</pre></li>
				<li>You can see it in the <a id="_idIndexMarker1147"/>following screenshot – <strong class="bold">dis</strong>, <strong class="bold">crim</strong>, and <strong class="bold">nox</strong> have the largest <a id="_idIndexMarker1148"/>average values:<div><img src="img/B17705_10_6.jpg" alt="Figure 10.6 – Plotting average SHAP values over time&#13;&#10;" width="383" height="264"/></div><p class="figure-caption">图 10.6–绘制一段时间内的平均 SHAP 值</p></li>
				<li>We build the <code>feature_importance/weight</code> plot:<pre>plot_features('feature_importance/weight')</pre><p>你可以在下面的截图中看到——<strong class="bold">crim</strong>、<strong class="bold"> age </strong>和<strong class="bold"> dis </strong>的权重最大:</p></li>
			</ol>
			<div><div><img src="img/B17705_10_7.jpg" alt="Figure 10.7 – Plotting feature weights over time&#13;&#10;" width="377" height="264"/>
				</div>
			</div>
			<p class="figure-caption">图 10.7-绘制随时间变化的要素权重</p>
			<p>现在，让我们在 Keras 和时尚 MNIST 的例子中使用 SageMaker 调试器。</p>
			<h2 id="_idParaDest-223"><a id="_idTextAnchor222"/>调试和检查 Keras 作业</h2>
			<p>我们可以使用以下步骤<a id="_idIndexMarker1149"/>检查和<a id="_idIndexMarker1150"/>调试 Keras 作业:</p>
			<ol>
				<li value="1">TensorFlow 2.x 中的默认<a id="_idIndexMarker1151"/>行为是渴望模式，在这种模式下渐变不可用。因此，我们<a id="_idIndexMarker1152"/>在我们的脚本中禁用渴望模式，这是唯一需要的修改:<pre>tf.compat.v1.disable_eager_execution()</pre></li>
				<li>我们从同一个估计量开始。该数据集有 70，000 个样本(60，000 个用于训练，10，000 个用于验证)。有了 30 个纪元和 128 个批量，我们的训练工作将有大约 16，400 个步骤(70，000 * 30 / 128)。每一步都省张量感觉有点矫枉过正。让我们改为每 100 步保存一次:<pre>from sagemaker.tensorflow import TensorFlow from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig, CollectionConfig save_interval = '100' tf_estimator = TensorFlow(entry_point='fmnist-5.py',     role=role,     instance_count=1,     instance_type='ml.p3.2xlarge',     framework_version='2.1.0',      py_version='py3',     hyperparameters={'epochs': 30},     output_path=output_path,     use_spot_instances=True,     max_run=3600,     max_wait=7200,</pre></li>
				<li>查看 TensorFlow 可用的内置规则，我们决定设置<code>poor_weight_initialization</code>、<code>dead_relu,</code>和<code>check_input_images</code>。我们<a id="_idIndexMarker1154"/>需要<a id="_idIndexMarker1155"/>指定输入张量中通道信息<a id="_idIndexMarker1156"/>的索引。TensorFlow 是 4(批量大小、高度、宽度和通道):<pre>    rules=[       Rule.sagemaker(     rule_configs.poor_weight_initialization()),  Rule.sagemaker(     rule_configs.dead_relu()), Rule.sagemaker(     rule_configs.check_input_images(),      rule_parameters={"channel": '3'})     ],</pre></li>
				<li>查看<a id="_idIndexMarker1157"/>可用于<a id="_idIndexMarker1159"/> TensorFlow 的集合<a id="_idIndexMarker1158"/>，我们<a id="_idIndexMarker1160"/>决定保存度量、损失、输出、权重和梯度:<pre>    debugger_hook_config=DebuggerHookConfig(                         s3_output_path='s3://{}/{}/debug'                .format(bucket, prefix),         collection_configs=[             CollectionConfig(name='metrics',                   parameters={"save_interval":                              save_interval}),             CollectionConfig(name='losses',                  parameters={"save_interval":                              save_interval}),             CollectionConfig(name='outputs',                  parameters={"save_interval":                              save_interval}),             CollectionConfig(name='weights',                  parameters={"save_interval":                              save_interval}),             CollectionConfig(name='gradients',                  parameters={"save_interval":                              save_interval})         ],     ) )</pre></li>
				<li>随着<a id="_idIndexMarker1161"/>训练开始，我们<a id="_idIndexMarker1162"/>在<a id="_idIndexMarker1164"/>训练日志:<pre><strong class="bold">********* Debugger Rule Status *********</strong> <strong class="bold">*</strong> <strong class="bold">* PoorWeightInitialization: InProgress        </strong> <strong class="bold">* DeadRelu: InProgress        </strong> <strong class="bold">* CheckInputImages: InProgress        </strong> <strong class="bold">*</strong> <strong class="bold">****************************************</strong></pre>中看到<a id="_idIndexMarker1163"/>规则被启动</li>
				<li>当训练完成时，我们检查调试规则的状态:<pre>description = tf_estimator.latest_training_job.rule_job_summary() for rule in description:     rule.pop('LastModifiedTime')     rule.pop('RuleEvaluationJobArn')     print(rule) <strong class="bold">{'RuleConfigurationName': 'PoorWeightInitialization', </strong> <strong class="bold"> 'RuleEvaluationStatus': 'NoIssuesFound'}</strong> <strong class="bold">{'RuleConfigurationName': 'DeadRelu',</strong> <strong class="bold"> 'RuleEvaluationStatus': 'NoIssuesFound'}</strong> <strong class="bold">{'RuleConfigurationName': 'CheckInputImages', </strong> <strong class="bold"> 'RuleEvaluationStatus': 'NoIssuesFound'}</strong></pre></li>
				<li>我们使用保存在 S3 的相同张量创建一个试验:<pre>from smdebug.trials import create_trial s3_output_path = tf_estimator.latest_job_debugger_artifacts_path() trial = create_trial(s3_output_path)</pre></li>
				<li>Let's inspect the filters in the first convolution layer:<pre>w = trial.tensor('conv2d/weights/conv2d/kernel:0')
g = trial.tensor(
'training/Adam/gradients/gradients/conv2d/Conv2D_grad/Conv2DBackpropFilter:0')
print(w.value(0).shape)
print(g.value(0).shape)
<strong class="bold">(3, 3, 1, 64)</strong>
<strong class="bold">(3, 3, 1, 64)</strong></pre><p>正如在<a id="_idIndexMarker1165"/>我们的训练<a id="_idIndexMarker1166"/>脚本中定义的，第一个卷积层<a id="_idIndexMarker1167"/>有 64 个过滤器。每个<a id="_idIndexMarker1168"/>都是 3x3 像素，单通道(2D)。因此，渐变具有相同的形状。</p></li>
				<li>We write a function to plot filter weights and gradients over time, and we plot weights in the last filter of the first convolution layer:<pre>plot_conv_filter('conv2d/weights/conv2d/kernel:0', 63)</pre><p>您可以在下面的截图中看到该图表:</p></li>
			</ol>
			<div><div><img src="img/B17705_10_8.jpg" alt="Figure 10.8 – Plotting the weights of a convolution filter over time&#13;&#10;" width="383" height="252"/>
				</div>
			</div>
			<p class="figure-caption">图 10.8–绘制卷积滤波器随时间变化的权重</p>
			<p>正如您<a id="_idIndexMarker1169"/>所见，SageMaker 调试器使检查<a id="_idIndexMarker1170"/>培训工作变得非常容易。如果你使用支持它的内置<a id="_idIndexMarker1171"/>容器，你就不需要修改你的代码。所有配置都发生在估计器中。</p>
			<p>你可以在 https://github.com/awslabs/amazon-sagemaker-examples 找到更多的例子，包括一些高级用例，比如实时可视化和模型修剪。</p>
			<p>本章的第一部分到此结束，在这里我们学习了如何使用托管现场培训优化培训作业的成本，使用自动模型调整优化其准确性，以及如何使用 SageMaker 调试器检查其内部状态。</p>
			<p>在第二部分中，我们将深入探讨两项高级功能，它们将帮助我们构建更好的培训工作流程——sage maker 功能商店和 SageMaker Clarify。</p>
			<h1 id="_idParaDest-224"><a id="_idTextAnchor223"/>使用 SageMaker 特征库管理特征和构建数据集</h1>
			<p>到目前为止，我们已经在笔记本或 SageMaker <a id="_idIndexMarker1173"/>处理脚本中设计了我们的训练和验证功能，然后<a id="_idIndexMarker1174"/>将它们存储为 S3 对象。然后，我们按原样使用这些对象来训练和评估模型。这是一个完全<a id="_idIndexMarker1175"/>合理的工作流程。然而，随着您的机器学习<a id="_idIndexMarker1176"/>工作流的增长和成熟，可能会出现以下问题:</p>
			<ul>
				<li>我们如何将定义良好的模式应用到我们的功能中？</li>
				<li>我们如何选择要素的子集来构建不同的数据集？</li>
				<li>我们如何存储和管理不同的功能版本？</li>
				<li>我们如何发现和重用其他团队的特征工程？</li>
				<li>我们如何在预测时访问工程特征？</li>
			</ul>
			<p>SageMaker 功能商店旨在回答这些问题。我们在<a href="B17705_06_Final_JM_ePub.xhtml#_idTextAnchor108"> <em class="italic">第六章</em></a><em class="italic">训练自然语言处理模型</em>中用 BlazingText 和 Amazon 评论构建的分类训练工作流程中加入吧。</p>
			<h2 id="_idParaDest-225"><a id="_idTextAnchor224"/>用 SageMaker 加工的工程特征</h2>
			<p>我们几乎可以原样重用我们以前的 SageMaker 处理作业。唯一的区别是工程数据的输出<a id="_idIndexMarker1177"/>格式。在最初的作业中，我们根据 BlazingText 期望的输入格式将其保存为纯文本文件。这种格式对 SageMaker 特性库不方便，因为我们需要方便地访问每一列。CSV 也不能工作，因为评论包含逗号，所以我们决定使用 TSV:</p>
			<ol>
				<li value="1">相应地，我们在处理脚本中添加了几行:<pre>fs_output_dir = '/opt/ml/processing/output/fs/' os.makedirs(fs_output_dir, exist_ok=True) fs_output_path = os.path.join(fs_output_dir, 'fs_data.tsv')   data.to_csv(fs_output_path, index=False,header=True, sep='\t')</pre></li>
				<li>像以前一样运行我们的 SageMaker 处理作业，我们现在看到两个输出:BlazingText 的纯文本输出(如果我们想直接在完整数据集上训练)和我们将在 SageMaker 特征存储中接收的 TSV 输出:<pre><strong class="bold">s3://sagemaker-us-east-1-123456789012/sagemaker-scikit-learn-2021-07-05-07-54-15-145/output/bt_data</strong> <strong class="bold">s3://sagemaker-us-east-1-123456789012/sagemaker-scikit-learn-2021-07-05-07-54-15-145/output/fs_data</strong></pre></li>
				<li>Let's load <a id="_idIndexMarker1178"/>the TSV file in a <code>pandas</code> dataframe and display the first few rows:<pre>fs_training_output_path = 's3://sagemaker-us-east-1-123456789012/sagemaker-scikit-learn-2021-07-05-07-54-15-145/output/fs_data/fs_data.tsv'
data = pd.read_csv(fs_training_output_path, sep='\t',
                   error_bad_lines=False, dtype='str')
data.head()</pre><p>这将打印出下图中可见的表格:</p></li>
			</ol>
			<div><div><img src="img/B17705_10_9.jpg" alt="Figure 10.9 – Viewing the first rows&#13;&#10;" width="700" height="163"/>
				</div>
			</div>
			<p class="figure-caption">图 10.9–查看第一行</p>
			<p>现在，让我们创建一个特征组，我们将在其中接收这些数据。</p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor225"/>创建特征组</h2>
			<p><strong class="bold">特性组</strong>是存储相关特性集合的资源。功能组<a id="_idIndexMarker1179"/>按行组织，有唯一的标识符和时间戳。每一行都包含键值对，每一对都代表一个特性名和一个特性值。</p>
			<ol>
				<li value="1">首先，让我们定义我们的特性组的名称:<pre>from sagemaker.feature_store.feature_group import FeatureGroup feature_group_name = 'amazon-reviews-feature-group-' + strftime('%d-%H-%M-%S', gmtime()) feature_group = FeatureGroup(     name=feature_group_name,         sagemaker_session=feature_store_session)</pre></li>
				<li>接下来，我们设置包含惟一标识符的特性的名称——<code>review_id</code>在这里非常适用，您可以使用数据源中存在的任何惟一值，比如主键:<pre>record_identifier_feature_name = 'review_id'</pre></li>
				<li>Then, we add a timestamp column to all rows in our <code>pandas</code> dataframe. If your data source already contains a timestamp, you can reuse that value, either in the <strong class="bold">float64</strong> format or in the <strong class="bold">UNIX</strong> date/time format:<pre>event_time_feature_name = 'event_time'
current_time_sec = int(round(time.time()))
data = data.assign(event_time=current_time_sec)</pre><p>我们的数据帧现在看起来如下图所示:</p><div><img src="img/B17705_10_10.jpg" alt="Figure 10.10 – Viewing timestamps&#13;&#10;" width="769" height="161"/></div><p class="figure-caption">图 10.10–查看时间戳</p></li>
				<li>The next step is to define a schema for the feature group. We can either provide it explicitly <a id="_idIndexMarker1180"/>in a JSON document or let SageMaker pick it up from the pandas dataframe. We use the second option:<pre>data['review_id'] = data['review_id']
    .astype('str').astype('string')
data['product_id'] = data['product_id']
    .astype('str').astype('string')
data['review_body'] = data['review_body']
    .astype('str').astype('string')
data['label'] = data['label']
    .astype('str').astype('string')
data['star_rating'] = data['star_rating']
    .astype('int64')
data['event_time'] = data['event_time']
    .astype('float64')</pre><p>然后，我们加载特征定义:</p><pre>feature_group.load_feature_definitions(
    data_frame=data)</pre></li>
				<li>最后，我们创建要素组，传递存储要素的 S3 位置。这是我们将查询它们以构建数据集的地方。我们启用了在线商店，这将使我们能够在预测时低延迟地访问功能。我们还<a id="_idIndexMarker1181"/>添加了一个描述和标签，这样更容易发现特性组:<pre>feature_group.create(   role_arn=role,   s3_uri='s3://{}/{}'.format(default_bucket, prefix),   enable_online_store=True,   record_identifier_name=       record_identifier_feature_name,   event_time_feature_name=       event_time_feature_name,   description="1.8M+ tokenized camera reviews from the                   Amazon Customer Reviews dataset",   tags=[       { 'Key': 'Dataset',          'Value': 'amazon customer reviews' },       { 'Key': 'Subset',         'Value': 'cameras' },       { 'Key': 'Owner',         'Value': 'Julien Simon' }   ])</pre></li>
			</ol>
			<p>几秒钟后，特性组就准备好了，并在 SageMaker Studio 中可见，位于<strong class="bold">组件和注册表</strong> / <strong class="bold">特性库</strong>下，如下面的截图所示:</p>
			<div><div><img src="img/B17705_10_11.jpg" alt="Figure 10.11 – Viewing a feature group&#13;&#10;" width="903" height="150"/>
				</div>
			</div>
			<p class="figure-caption">图 10.11–查看功能组</p>
			<p>现在，让我们接收数据。</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor226"/>摄取功能</h2>
			<p>SageMaker <a id="_idIndexMarker1182"/>功能商店让我们以三种方式获取数据:</p>
			<ul>
				<li>调用<code>PutRecord()</code> API 来摄取单个记录。</li>
				<li>调用<code>ingest()</code> API 上传<code>pandas</code>数据帧的内容。</li>
				<li>如果我们使用<strong class="bold"> SageMaker Data Wrangler </strong>进行特性工程，那么使用自动生成的<a id="_idIndexMarker1183"/>笔记本来创建特性组并接收数据。</li>
			</ul>
			<p>我们在这里使用第二个选项，如下所示:</p>
			<pre>feature_group.ingest(data_frame=data, max_workers=10, 
                     wait=True)</pre>
			<p>一旦接收完成，功能将存储在我们指定的 S3 位置，以及一个专用的低延迟后端。让我们使用前者来建立一个数据集。</p>
			<h2 id="_idParaDest-228"><a id="_idTextAnchor227"/>查询要素以构建数据集</h2>
			<p>当我们<a id="_idIndexMarker1184"/>创建特征<a id="_idIndexMarker1185"/>组时，SageMaker 自动在<strong class="bold"> AWS 粘合数据目录</strong>中为其添加一个新表。这使得使用<strong class="bold"> Amazon Athena </strong>查询<a id="_idIndexMarker1186"/>数据和按需构建数据集变得很容易。</p>
			<p>假设我们想要构建一个数据集，其中包含至少有 1，000 条评论的畅销相机:</p>
			<ol>
				<li value="1">首先，我们编写一个 SQL 查询，计算每台摄像机的平均评分，统计每台摄像机收到多少评论，只保留至少有 1000 条评论的摄像机，并按平均评分降序排列摄像机:<pre>query_string =  'SELECT label,review_body FROM  "'+ feature_group_table +'"' + ' INNER JOIN (       SELECT product_id FROM (           SELECT product_id, avg(star_rating) as                    avg_rating, count(*) as review_count           FROM "'+ feature_group_table+ '"' + '           GROUP BY product_id)        WHERE review_count &gt; 1000) tmp  ON "'+feature_group_table+'"' + '.product_id=tmp.product_id;'</pre></li>
				<li>然后，我们使用<a id="_idIndexMarker1187"/> Athena 查询我们的特性组，将选择的行存储在<code>pandas</code> dataframe 中，并显示前几行:<pre>dataset = pd.DataFrame() feature_group_query.run(query_string=query_string, output_location='s3://'+default_bucket+'/query_results/') feature_group_query.wait()dataset = feature_group_query.as_dataframe() dataset.head()</pre></li>
			</ol>
			<p>这将打印出下图中可见的表格:</p>
			<div><div><img src="img/B17705_10_12.jpg" alt="Figure 10.12 – Viewing query results&#13;&#10;" width="435" height="161"/>
				</div>
			</div>
			<p class="figure-caption">图 10.12–查看查询结果</p>
			<p>从那时起，一切照常。我们可以将这个数据帧保存到 CSV 文件中，并使用它来训练模型。您将在 GitHub 资源库中找到一个端到端的例子。</p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor228"/>探索 SageMaker 功能商店的其他功能</h2>
			<p>随着时间的推移，我们可以存储同一个特性的不同版本——也就是说，具有相同标识符但不同时间戳的几个记录。这将允许我们用一个简单的 SQL 查询检索数据集的早期版本——数据中的“时间旅行”。</p>
			<p>最后但并非最不重要的是，在线商店中也提供功能。我们可以用<code>GetRecord()</code> API 检索单个记录，并在需要时使用预测时的特性。</p>
			<p>同样，您可以在 GitHub 资源库中找到这两种功能的代码示例。</p>
			<p>为了结束这一章，让我们看看 Amazon SageMaker Clarify，这是一种通过检测数据集和模型中存在的潜在偏差来帮助我们建立更高质量模型的功能。</p>
			<h1 id="_idParaDest-230"><a id="_idTextAnchor229"/>检测数据集中的偏差并使用 SageMaker Clarify 解释预测</h1>
			<p>一个<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)模型<a id="_idIndexMarker1190"/>只能和构建它的数据集<a id="_idIndexMarker1191"/>一样好。如果数据集<a id="_idIndexMarker1192"/>在表示<a id="_idIndexMarker1193"/>它应该捕捉的现实时不准确或不公平，相应的模型很可能会学习这种有偏见的表示，并在预测中延续它。作为 ML 从业者，我们需要意识到这些问题，理解它们如何影响预测，并尽可能限制这种影响。</p>
			<p>在这个<a id="_idIndexMarker1194"/>例子中，我们将使用<strong class="bold">成人数据集</strong>，该数据集可从<strong class="bold"> UCI 机器学习库</strong>(<a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>，Dua，d .和 Graff，c .，2019)获得。这个数据集描述了一个二元<a id="_idIndexMarker1195"/>分类任务，我们试图<a id="_idIndexMarker1196"/>预测一个人的年收入是少于<a id="_idIndexMarker1197"/>还是多于 5 万美元。在这里，我们想要检查这个数据集是否引入了性别偏见。换句话说，它是否有助于我们建立对男性和女性同样有效的预测模型？</p>
			<p class="callout-heading">注意</p>
			<p class="callout">您将在 GitHub 存储库中找到的数据集已经过轻微处理。根据 XGBoost 的要求，标签列被移到了前面。分类变量已被一次性编码。</p>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor230"/>使用 SageMaker Clarify 配置偏倚分析</h2>
			<p>SageMaker Clarify 计算训练前和训练后的指标，帮助我们了解模型如何预测。</p>
			<p>训练后的<a id="_idIndexMarker1198"/>度量显然需要一个训练好的模型，所以我们先用 XGBoost 训练一个二元分类模型。我们已经看过很多次了，你可以在 GitHub 库中找到代码。该模型达到 92.75%的验证 AuC。</p>
			<p>培训完成后，我们可以继续进行偏差分析:</p>
			<ol>
				<li value="1">偏差分析作为 SageMaker 处理作业运行。相应地，我们根据我们的基础设施需求创建一个<code>SageMakerClarifyProcessor</code>对象。由于工作规模小，我们使用单个实例。对于较大的任务，我们可以使用增加的实例计数，分析将在<strong class="bold"> Spark </strong> : <pre>from sagemaker import clarify clarify_processor = clarify.SageMakerClarifyProcessor(     role=role,     instance_count=1,     instance_type='ml.m5.large',     sagemaker_session=session)</pre>上自动运行</li>
				<li>然后，我们创建一个<code>DataConfig</code>对象来描述要分析的数据集:<pre>bias_report_output_path = 's3://{}/{}/clarify-bias'.format(bucket, prefix) data_config = clarify.DataConfig(     s3_data_input_path=train_uri,     s3_output_path=bias_report_output_path,     label='Label',     headers=train_data.columns.to_list(),     dataset_type='text/csv')</pre></li>
				<li>同样，我们<a id="_idIndexMarker1199"/>创建一个<code>ModelConfig</code>对象来描述要分析的模型:<pre>model_config = clarify.ModelConfig(     model_name=xgb_predictor.endpoint_name,     instance_type='ml.t2.medium',     instance_count=1,     accept_type='text/csv')</pre></li>
				<li>最后，我们创建一个<code>BiasConfig</code>对象来描述要计算的指标。<code>label_values_or_threshold</code>定义了积极结果的标签值(1，表示收入高于 5 万美元)。<code>facet_name</code>定义了我们想要运行分析的特征(<code>Sex_</code>)，而<code>facet_values_or_threshold</code>定义了潜在弱势群体的特征值(1，表示女性)。<pre>bias_config = clarify.BiasConfig(     label_values_or_threshold=[1],     facet_name='Sex_',     facet_values_or_threshold=[1])</pre></li>
			</ol>
			<p>我们<a id="_idIndexMarker1200"/>现在准备运行分析。</p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor231"/>运行偏倚分析</h2>
			<p>将所有东西放在一起，我们用以下内容开始分析:</p>
			<pre>clarify_processor.run_bias(
    data_config=data_config,
    model_config=model_config,
    bias_config=bias_config)</pre>
			<p>一旦分析完成，就可以在 SageMaker Studio 中看到结果。还会生成一份报告，并以 HTML、PDF 和笔记本格式存储在 S3 中。</p>
			<p>在<strong class="bold">实验和试验</strong>中，我们找到我们的 SageMaker Clarify 作业，并右键单击<strong class="bold">打开试验详情</strong>。选择<strong class="bold">偏差报告</strong>，我们会看到偏差指标，如下图所示:</p>
			<div><div><img src="img/B17705_10_13.jpg" alt="Figure 10.13 – Viewing bias metrics&#13;&#10;" width="1030" height="715"/>
				</div>
			</div>
			<p class="figure-caption">图 10.13–查看偏差指标</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor232"/>分析偏差指标</h2>
			<p>如果你想了解更多关于偏差指标、它们的含义以及它们是如何计算的，我强烈推荐这些资源:</p>
			<ul>
				<li>【https://pages.awscloud.com/rs/112-TZM-766/images/Fairness. T21】Measures.for.Machine.Learning.in.Finance.pdf</li>
				<li><a href="https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf">https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf</a></li>
				<li><a href="https://github.com/aws/amazon-sagemaker-clarify">https://github.com/aws/amazon-sagemaker-clarify</a></li>
			</ul>
			<p>让我们来看两个训练前的指标，即<strong class="bold">类别不平衡</strong> ( <strong class="bold"> CI </strong>)和<strong class="bold">标签中的正比例差</strong> ( <strong class="bold"> DPL </strong>)，以及一个训练后的指标，即<strong class="bold">预测标签中的正比例差</strong> ( <strong class="bold"> DPPL </strong>)。</p>
			<p>CI 的非零<a id="_idIndexMarker1203"/>值表示数据集不平衡。这里，男性分数和女性分数之差为 0.35。事实上，男性群体约占数据集的三分之二，女性群体约占三分之一。这不是一个非常严重的不平衡，但我们也应该看看每个类的正面标签的比例。</p>
			<p>DPL <a id="_idIndexMarker1205"/>测量每个类别是否具有相同比例的阳性标签。换句话说，该数据集是否包含相同比例的收入为 5 万美元的男性和女性？DPL 不为零(0.20)，这告诉我们，男性在 5 万美元收入人群中的比例更高。</p>
			<p>DPPL 是<a id="_idIndexMarker1206"/>，一个类似于 DPL 的训练后指标。它的值(0.18)表明模型不幸地拾取了数据集中存在的偏差，只是轻微地减少了它。事实上，该模型预测了对男性更有利的结果(高估了 5 万美元的收入)和对女性不太有利的结果(低估了 5 万美元的收入)。</p>
			<p>这显然是个问题。尽管该模型具有相当好的验证 AuC (92.75%)，但它不能同样好地预测这两类。</p>
			<p>在我们深入研究数据并试图缓解这个问题之前，让我们进行一个可解释性分析。</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor233"/>运行可解释性分析</h2>
			<p>SageMaker <a id="_idIndexMarker1207"/> Clarify 可以计算本地和全局的 https://github.com/slundberg/shap(<a href="https://github.com/slundberg/shap">)值。它们有助于我们理解特性的重要性，以及单个特性值对积极或消极结果的贡献。</a></p>
			<p>偏差分析作为 SageMaker 处理作业运行，其过程类似:</p>
			<ol>
				<li value="1">我们创建一个<code>DataConfig</code>对象来描述要分析的数据集:<pre>explainability_output_path = 's3://{}/{}/clarify-explainability.format(bucket, prefix) data_config = clarify.DataConfig(     s3_data_input_path=train_uri,     s3_output_path= explainability_output_path,     label='Label',     headers=train_data.columns.to_list(),     dataset_type='text/csv')</pre></li>
				<li>我们创建一个<code>SHAPConfig</code>对象来描述我们想要如何计算 SHAP 值——也就是说，使用哪个基线(我使用的是我删除标签的测试集),如何使用<a id="_idIndexMarker1208"/>多个样本(两倍的特征数加上 2048，一个常见的默认值),以及如何聚合值:<pre>shap_config = clarify.SHAPConfig(     baseline=test_no_labels_uri,     num_samples=2*86+2048,     agg_method='mean_abs',     save_local_shap_values=True )</pre></li>
				<li>最后，我们运行分析:<pre>clarify_processor.run_explainability(     data_config=explainability_data_config,     model_config=model_config,     explainability_config=shap_config )</pre></li>
			</ol>
			<p>在 SageMaker Studio 中可用的结果中，<code>Sex</code>下的特征是迄今为止最重要的，这证实了偏倚分析。抛开道德考虑，从商业角度来看，这似乎没有太大意义。教育或资本收益等特征应该更重要。</p>
			<div><div><img src="img/B17705_10_14.jpg" alt="Figure 10.14 – Viewing feature importance&#13;&#10;" width="1235" height="941"/>
				</div>
			</div>
			<p class="figure-caption">图 10.14–查看特征重要性</p>
			<p>本地 SHAP <a id="_idIndexMarker1209"/>值也被计算并存储在 S3。我们可以用它们来理解特征值如何影响每个样本的预测。</p>
			<p>现在，让我们看看如何减轻我们在数据集中检测到的偏差。</p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor234"/>减轻偏见</h2>
			<p>这个数据集结合了两个问题。首先，它包含的男性多于女性。第二，男性<a id="_idIndexMarker1210"/>组有更高比例的积极成果。这两个问题的结合导致了这样一种情况，即数据集包含的收入超过 5 万美元的女性数量少得不成比例。这使得模型更难以公平的方式学习，并且它倾向于偏向多数阶级。</p>
			<p>偏差缓解技术包括以下内容:</p>
			<ul>
				<li>通过移除多数样本对多数类进行欠采样以重新平衡数据集</li>
				<li>通过复制现有样本来添加更多样本，从而对少数类进行过采样</li>
				<li>Adding synthetic samples to the minority class by generating new samples that have statistical properties similar to existing samples<p class="callout-heading">注意</p><p class="callout">改变数据不应该是轻而易举的事情，尤其是在受监管行业的组织中。这可能会带来严重的业务、合规性和法律后果。请确保在生产中这样做之前获得批准。</p></li>
			</ul>
			<p>让我们试试<a id="_idIndexMarker1211"/>基于<strong class="bold">不平衡学习</strong>开源库(https://unbalanced-learn . org)的组合方法。首先，我们将使用<strong class="bold">合成少数过采样技术</strong> ( <strong class="bold"> SMOTE </strong>)算法<a id="_idIndexMarker1212"/>将合成样本添加到少数类，以匹配多数样本中出现的 50K 美元收入者的比例。然后，我们将对多数类进行欠采样，以匹配少数类的样本数<a id="_idIndexMarker1213"/>。结果将是一个完美平衡的数据集，其中两个类具有相同的大小和相同的 5 万美元收入者比例。让我们开始吧:</p>
			<ol>
				<li value="1">First, we need to compute the ratios for both classes:<pre>female_male_not_50k_count = train_data['Sex_'].where(
    train_data['Label']==0).value_counts()
female_male_50k_count = train_data['Sex_'].where(
    train_data['Label']==1).value_counts()
ratios = female_male_50k_count / 
         female_male_not_50k_count
print(ratios)</pre><p>这给了我们以下结果，表明多数阶级(阶级 0)有一个大得多的 50k 收入者的比例:</p><pre><strong class="bold">0.0    0.457002</strong>
<strong class="bold">1.0    0.128281</strong></pre></li>
				<li>然后，我们生成合成的少数样本:<pre>from imblearn.over_sampling import SMOTE female_instances = train_data[train_data['Sex_']==1] female_X = female_instances.drop(['Label'], axis=1) female_Y = female_instances['Label'] oversample = SMOTE(sampling_strategy=ratios[0]) balanced_female_X, balanced_female_Y = oversample.fit_resample(female_X, female_Y) balanced_female=pd.concat([balanced_female_X, balanced_female_Y], axis=1)</pre></li>
				<li>接下来，我们<a id="_idIndexMarker1214"/>用原始多数类和重新平衡的少数类重建数据集:<pre>male_instances = train_data[train_data['Sex_']==0] balanced_train_data=pd.concat(     [male_instances, balanced_female], axis=0)</pre></li>
				<li>最后，我们对原始多数类进行欠采样以重新平衡比率:<pre>from imblearn.under_sampling import RandomUnderSampler X = balanced_train_data.drop(['Sex_'], axis=1) Y = balanced_train_data['Sex_'] undersample = RandomUnderSampler(     sampling_strategy='not minority') X,Y = undersample.fit_resample(X, Y) balanced_train_data=pd.concat([X, Y], axis=1)</pre></li>
				<li>We count both classes and compute their ratios again:<pre>female_male_count= balanced_train_data['Sex_']    
    .value_counts()
female_male_50k_count = balanced_train_data['Sex_']
    .where(balanced_train_data['Label']==1)
    .value_counts()
ratios = female_male_50k_count/female_male_count
print(female_male_count)
print(female_male_50k_count)
print(ratios)</pre><p>这将显示以下结果:</p><pre><strong class="bold">1.0    0.313620</strong>
<strong class="bold">0.0    0.312039</strong></pre></li>
			</ol>
			<p>使用<a id="_idIndexMarker1215"/>这个重新平衡的数据集进行训练，并使用相同的测试集，我们得到了 92.95%的验证 AuC，而原始模型为 92.75%。运行新的偏倚分析，CI 为零，DPL 和 DPPL 接近于零。</p>
			<p>我们不仅建立了一个预测更公平的模型，而且也更准确了一点。这一次，看起来我们得到了最好的两个世界！</p>
			<h1 id="_idParaDest-236"><a id="_idTextAnchor235"/>总结</h1>
			<p>本章总结了我们对训练技巧的探索。您了解了管理现场培训，这是一种将培训成本削减 70%或更多的简单方法。您还看到了检查点如何帮助恢复被中断的作业。然后，您学习了自动模型调整，这是一种通过探索超参数范围从模型中提取更多精度的好方法。您了解了 SageMaker Debugger，这是一种高级功能，可以自动检查训练作业中不需要的条件，并将张量集合保存到 S3 以便检查和可视化。最后，我们发现了两个可以帮助您构建更高质量的工作流和模型的功能，SageMaker Feature Store 和 SageMaker Clarify。</p>
			<p>在下一章，我们将详细研究模型部署。</p>
		</div>
	</div>
</body></html>