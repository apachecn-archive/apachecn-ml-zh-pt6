<html><head/><body>





<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}</style>
<div><div><h1 id="_idParaDest-261"><a id="_idTextAnchor260"/>第 12 章:自动化机器学习工作流程</h1>
			<p>在前一章中，您学习了如何在不同的配置中部署机器学习模型，使用了<code>boto3</code> SDK。我们在<strong class="bold"> Jupyter </strong> <strong class="bold">笔记本</strong>中使用了他们的 APIs 这是快速实验和迭代的首选方式。</p>
			<p>然而，运行笔记本来完成生产任务并不是一个好主意。即使您的代码已经过仔细测试，那么监控、日志记录、创建其他 AWS 资源、处理错误、回滚等等又如何呢？做好这一切将需要大量额外的工作和代码，从而有可能出现更多的错误。需要一种更加工业化的方法。</p>
			<p>在本章中，您将首先学习如何使用<strong class="bold">AWS</strong><strong class="bold">Cloud formation</strong>和<strong class="bold">AWS</strong><strong class="bold">Cloud Development Kit</strong>(<strong class="bold">CDK</strong>)——专门构建的两个 AWS 服务来提供可重复性、可预测性和健壮性。您将看到如何在应用更改之前预览它们，以避免不受控制的和潜在的破坏性操作。</p>
			<p>然后，您将学习如何使用另外两个服务来自动化端到端的机器学习工作流——<strong class="bold">AWS</strong><strong class="bold">步骤功能</strong>和<strong class="bold">亚马逊</strong> <strong class="bold"> SageMaker 管道</strong>。您将看到如何使用简单的 API 构建工作流，以及如何在<strong class="bold"> SageMaker Studio </strong>中可视化结果。</p>
			<p>在本章中，我们将讨论以下主题:</p>
			<ul>
				<li>通过 AWS 云形成实现自动化</li>
				<li>通过 AWS CDK 实现自动化</li>
				<li>使用 AWS 步骤功能构建端到端工作流</li>
				<li>使用 Amazon SageMaker 管道构建端到端工作流</li>
			</ul>
			<h1 id="_idParaDest-262"><a id="_idTextAnchor261"/>技术要求</h1>
			<p>您将需要一个 AWS 帐户来运行本章中包含的示例。如果您还没有，请将浏览器指向<a href="https://aws.amazon.com/getting-started/">https://aws.amazon.com/getting-started/</a>来创建一个。您还应该熟悉 AWS 免费层(<a href="https://aws.amazon.com/free/">https://aws.amazon.com/free/</a>)，它允许您在一定的使用限制内免费使用许多 AWS 服务。</p>
			<p>您需要为您的帐户(<a href="https://aws.amazon.com/cli/">https://aws.amazon.com/cli/</a>)安装并配置<strong class="bold"> AWS </strong> <strong class="bold">命令行接口</strong> ( <strong class="bold"> CLI </strong>)。</p>
			<p>你将需要一个工作的<code>pandas</code>、<code>numpy</code>等等)。</p>
			<p>本书中包含的代码示例可以在 GitHub 上的<a href="https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition">https://GitHub . com/packt publishing/Learn-Amazon-sage maker-second-edition</a>获得。你需要安装一个 Git 客户端来访问它们(<a href="https://git-scm.com/">https://git-scm.com/</a>)。</p>
			<h1 id="_idParaDest-263"><a id="_idTextAnchor262"/>自动气象站云形成自动化</h1>
			<p>AWS CloudFormation 长期以来一直是自动化 AWS 上的基础设施构建和操作的首选方式(<a href="https://aws.amazon.com/cloudformation">https://aws.amazon.com/cloudformation</a>)。你当然可以写一本关于这个主题的书<a id="_idIndexMarker1338"/>,但是我们将在这一部分坚持基础知识。</p>
			<p>使用 CloudFormation 的第一步是编写一个模板——即一个<strong class="bold"> JSON </strong>或<strong class="bold"> YAML </strong>文本文件，描述你想要构建的<strong class="bold">资源</strong>，比如一个<strong class="bold"> EC2 </strong>实例或一个<strong class="bold"> S3 </strong>桶。几乎所有的 AWS 服务都有资源可用，SageMaker 也不例外。如果我们查看<a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/AWS_SageMaker.html">https://docs . AWS . Amazon . com/AWS cloudformation/latest/user guide/AWS _ sage maker . html</a>，我们会看到我们可以创建 SageMaker Studio 应用程序、部署端点等等。</p>
			<p>模板可以(也应该)包括参数和输出。前者有助于使模板尽可能通用。后者提供下游应用程序可以使用的信息，比如端点 URL 或存储桶名称。</p>
			<p>一旦你写好了模板文件，你就把它传递给 CloudFormation 来创建一个<strong class="bold">栈</strong>——也就是 AWS 资源的集合。CloudFormation 将解析模板并自动创建所有资源。依赖关系也是自动管理的，资源将以正确的顺序创建。如果不能正确创建一个栈，CloudFormation 会回滚它，删除目前已经构建好的资源。</p>
			<p>可以通过应用较新的模板修订来更新堆栈。CloudFormation 将分析变化，并相应地创建、删除、更新或替换资源。由于有了<strong class="bold">变更集</strong>，您可以在执行<a id="_idIndexMarker1339"/>变更之前对其进行验证，然后决定是否继续。</p>
			<p>当然，栈可以被<a id="_idIndexMarker1340"/>删除，CloudFormation <a id="_idIndexMarker1341"/>会自动拆除它的所有资源，这是清理你的构建而不留下任何残迹的好方法。</p>
			<p>让我们运行第一个例子，其中我们将一个模型部署到一个实时端点。</p>
			<h2 id="_idParaDest-264"><a id="_idTextAnchor263"/>编写模板</h2>
			<p>这个堆栈将相当于<a id="_idIndexMarker1342"/>调用我们在<a href="B17705_11_Final_JM_ePub.xhtml#_idTextAnchor237"> <em class="italic">第十一章</em></a><em class="italic">中学习的<code>boto3</code> API，部署机器学习模型</em>:<code>create_model()</code><code>create_endpoint_configuration()</code><code>create_endpoint()</code>。相应地，我们将定义三个 CloudFormation 资源(一个模型、一个端点配置和一个端点)及其参数:</p>
			<ol>
				<li>创建一个名为<code>endpoint-one-model.yml</code>的新 YAML 文件，我们首先在<code>Parameters</code>部分定义堆栈的输入参数。每个参数都有名称、描述和类型。可选地，我们可以提供默认值:<pre>AWSTemplateFormatVersion: 2010-09-09 Parameters:     ModelName:         Description: Model name         Type: String     ModelDataUrl:         Description: Location of model artifact         Type: String     ContainerImage:         Description: Container used to deploy the model         Type: String     InstanceType:         Description: Instance type         Type: String         Default: ml.m5.large     InstanceCount:         Description: Instance count         Type: String         Default: 1     RoleArn:         Description: Execution Role ARN         Type: String</pre></li>
				<li>在<code>Resources</code>部分，我们定义了一个模型资源，使用<code>Ref</code>内置函数来引用<a id="_idIndexMarker1343"/>适当的输入参数:<pre>Resources:     Model:         Type: "AWS::SageMaker::Model"         Properties:             Containers:                 -                     Image: !Ref ContainerImage                     ModelDataUrl: !Ref ModelDataUrl             ExecutionRoleArn: !Ref RoleArn             ModelName: !Ref ModelName</pre></li>
				<li>然后，我们定义一个端点配置资源。我们使用<code>GetAtt</code>内置函数来获取模型资源的名称。当然，这要求模型资源已经存在，CloudFormation 将确保资源<a id="_idIndexMarker1344"/>以正确的顺序创建:<pre>    EndpointConfig:         Type: "AWS::SageMaker::EndpointConfig"         Properties:             ProductionVariants:                 -                  ModelName: !GetAtt Model.ModelName                  VariantName: variant-1                  InitialInstanceCount: !Ref InstanceCount                  InstanceType: !Ref InstanceType                  InitialVariantWeight: 1.0</pre></li>
				<li>最后，我们定义一个端点资源。同样，我们使用<code>GetAtt</code>来查找端点配置的名称:<pre>    Endpoint:         Type: "AWS::SageMaker::Endpoint"         Properties:             EndpointConfigName: !GetAtt              EndpointConfig.EndpointConfigName</pre></li>
				<li>在<code>Outputs</code>部分，我们<a id="_idIndexMarker1345"/>返回端点的云信息标识符，以及它的名字:<pre>Outputs:     EndpointId:         Value: !Ref Endpoint     EndpointName:         Value: !GetAtt Endpoint.EndpointName</pre></li>
			</ol>
			<p>现在模板完成了(<code>endpoint-one-model.yml</code>)，我们可以创建一个堆栈了。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">请确保您的 IAM 角色有权调用 CloudFormation APIs。如果没有，请<a id="_idIndexMarker1346"/>将<code>AWSCloudFormationFullAccess</code>托管策略添加到角色中。</p>
			<h2 id="_idParaDest-265"><a id="_idTextAnchor264"/>将模型部署到实时端点</h2>
			<p>让我们<a id="_idIndexMarker1347"/>使用<a id="_idIndexMarker1348"/>API<code>boto3</code>创建一个<a id="_idIndexMarker1349"/>栈，部署一个<strong class="bold"> TensorFlow </strong>模型。我们将在<strong class="bold">时尚 MNIST </strong>上重用一个用<strong class="bold"> Keras </strong>训练过的模特:</p>
			<p class="callout-heading">注意</p>
			<p class="callout">因为我们的模板是完全独立于区域的，所以您可以使用任何您想要的区域。只要确保您已经在那里训练了一个模型，并且您正在使用适当的容器映像。</p>
			<ol>
				<li value="1">我们需要 SageMaker 和 CloudFormation 的<code>boto3</code>客户端:<pre>import boto3 sm = boto3.client('sagemaker') cf = boto3.client('cloudformation')</pre></li>
				<li>我们描述训练作业，以找到它的工件的位置，以及它的执行角色:<pre>training_job =      'tensorflow-training-2021-05-28-14-25-57-394' job = sm.describe_training_job(       TrainingJobName=training_job) model_data_url =         job['ModelArtifacts']['S3ModelArtifacts'] role_arn = job['RoleArn']</pre></li>
				<li>我们<a id="_idIndexMarker1350"/>将容器<a id="_idIndexMarker1351"/>设置为<a id="_idIndexMarker1352"/>用于部署。在某些情况下，这是不必要的，因为相同的容器用于培训和部署。对于<strong class="bold"> TensorFlow </strong>和其他框架，SageMaker 使用了两种不同的容器。你可以在<a href="https://github.com/aws/deep-learning-containers/blob/master/available_images.md">https://github . com/AWS/deep-learning-containers/blob/master/available _ images . MD</a>:<pre>container_image = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1.0-cpu-py36-ubuntu18.04'</pre>找到更多信息</li>
				<li>然后，我们读取我们的模板，创建一个新的堆栈，并传递所需的参数:<pre>import time timestamp = time.strftime("%Y-%m-%d-%H-%M-%S", time.gmtime()) stack_name='endpoint-one-model-'+timestamp with open('endpoint-one-model.yml', 'r') as f:   response = cf.create_stack(       StackName=stack_name,       TemplateBody=f.read(),       Parameters=[            { "ParameterKey":"ModelName",                    "ParameterValue":training_job+                               '-'+timestamp },            { "ParameterKey":"ContainerImage",                "ParameterValue":container_image },            { "ParameterKey":"ModelDataUrl",                 "ParameterValue":model_data_url },            { "ParameterKey":"RoleArn",                     "ParameterValue":role_arn }       ] )</pre></li>
				<li>Jumping to the CloudFormation console, we see that the stack is being created, as shown in<a id="_idIndexMarker1353"/> the <a id="_idIndexMarker1354"/>following <a id="_idIndexMarker1355"/>screenshot. Notice that resources are created in the right order: model, endpoint configuration, and endpoint:<div><img src="img/B17705_12_1.jpg" alt="Figure 12.1 – Viewing stack creation&#13;&#10;" width="874" height="610"/></div><p class="figure-caption">图 12.1–查看堆栈创建</p><p>正如我们<a id="_idIndexMarker1356"/>所期望的那样，我们也在 SageMaker Studio 中看到了端点，如下面的截图所示:</p><div><img src="img/B17705_12_2.jpg" alt="Figure 12.2 – Viewing endpoint creation&#13;&#10;" width="853" height="368"/></div><p class="figure-caption">图 12.2–查看端点创建</p></li>
				<li>Once the<a id="_idIndexMarker1358"/> stack <a id="_idIndexMarker1359"/>creation is complete, we <a id="_idIndexMarker1360"/>can use its output to find the name of the endpoint:<pre>response = cf.describe_stacks(StackName=stack_name)
print(response['Stacks'][0]['StackStatus'])
for o in response['Stacks'][0]['Outputs']:
    if o['OutputKey']=='EndpointName':
         endpoint_name = o['OutputValue']
print(endpoint_name)</pre><p>这会打印出 CloudFormation 自动生成的堆栈状态和端点名称:</p><p><strong class="bold">创建 _ 完成</strong></p><p><strong class="bold">端点-MTaOIs4Vexpt </strong></p></li>
				<li>我们可以像往常一样测试端点。然后，我们可以删除堆栈及其资源:<pre>cf.delete_stack(StackName=stack_name)</pre></li>
			</ol>
			<p>不过，让我们<a id="_idIndexMarker1361"/>而不是<a id="_idIndexMarker1362"/>马上删除<a id="_idIndexMarker1363"/>堆栈。相反，我们将使用变更集来更新它。</p>
			<h2 id="_idParaDest-266"><a id="_idTextAnchor265"/>用变更集修改堆栈</h2>
			<p>这里，我们将<a id="_idIndexMarker1364"/>更新支持端点的实例数量:</p>
			<ol>
				<li value="1">我们使用相同的模板和参数创建一个新的变更集，除了<code>InstanceCount</code>，我们将其设置为<code>2</code> : <pre>response = cf.create_change_set(     StackName=stack_name,     ChangeSetName='add-instance',     UsePreviousTemplate=True,     Parameters=[       { "ParameterKey":"InstanceCount",          "ParameterValue": "2" },       { "ParameterKey":"ModelName",         "UsePreviousValue": True },       { "ParameterKey":"ContainerImage",         "UsePreviousValue": True },       { "ParameterKey":"ModelDataUrl",         "UsePreviousValue": True },       { "ParameterKey":"RoleArn",         "UsePreviousValue": True }     ] )</pre></li>
				<li>We see details <a id="_idIndexMarker1365"/>on the change set in the CloudFormation console, as shown in the next screenshot. We could also use the <code>describe_change_set()</code> API:<div><img src="img/B17705_12_3.jpg" alt="Figure 12.3 – Viewing a change set&#13;&#10;" width="979" height="425"/></div><p class="figure-caption">图 12.3–查看变更集</p><p>这告诉我们，端点配置和端点需要修改，并且可能被替换。正如我们从<a href="B17705_11_Final_JM_ePub.xhtml#_idTextAnchor237"> <em class="italic">第 11 章</em></a><em class="italic">部署机器学习模型</em>中已经知道的，一个新的端点将被创建并以非破坏性<a id="_idIndexMarker1366"/>方式应用到现有端点。</p><p class="callout-heading">注意</p><p class="callout">在使用 CloudFormation 时，理解针对您的资源的<strong class="bold">替换政策</strong>至关重要。每种资源类型的文档中都有详细信息。</p></li>
				<li>By clicking on the <code>execute_change_set()</code> API. As expected, the endpoint is immediately updated, as shown in the following screenshot:<div><img src="img/B17705_12_4.jpg" alt="Figure 12.4 – Updating the endpoint&#13;&#10;" width="849" height="386"/></div><p class="figure-caption">图 12.4–更新端点</p></li>
				<li>Once the update is complete, we<a id="_idIndexMarker1367"/> see the sequence of events in the CloudFormation console, as shown in the next screenshot. A new endpoint configuration has been created and applied to the endpoint. The previous endpoint configuration has been deleted:<div><img src="img/B17705_12_5.jpg" alt="Figure 12.5 – Updating the stack&#13;&#10;" width="951" height="604"/></div><p class="figure-caption">图 12.5–更新堆栈</p></li>
				<li>We can check that the endpoint is now backed by two instances:<pre>r = sm.describe_endpoint(EndpointName=endpoint_name)
print r(['ProductionVariants'][0]
        ['CurrentInstanceCount'])</pre><p>这将打印出支持生产变型的实例数量:</p><pre><strong class="bold">2</strong></pre></li>
			</ol>
			<p>让我们继续使用变更<a id="_idIndexMarker1368"/>集，并向端点添加第二个生产变量。</p>
			<h2 id="_idParaDest-267"><a id="_idTextAnchor266"/>向端点添加第二个生产变量</h2>
			<p>我们的初始模板仅定义了一个<a id="_idIndexMarker1369"/>单一生产变体。我们将更新它并添加另一个(<code>endpoint-two-models.yml</code>):</p>
			<ol>
				<li value="1">在<code>Parameters</code>部分，我们添加了第二个模型的条目:<pre>    ModelName2:        Description: Second model name        Type: String     ModelDataUrl2:        Description: Location of second model artifact        Type: String     VariantWeight2:        Description: Weight of second model        Type: String     Default: 0.0</pre></li>
				<li>我们在<code>Resources</code>部分做同样的事情:<pre>    Model2:        Type: "AWS::SageMaker::Model"        Properties:            Containers:                -                     Image: !Ref ContainerImage                    ModelDataUrl: !Ref ModelDataUrl2        ExecutionRoleArn: !Ref RoleArn        ModelName: !Ref ModelName2</pre></li>
				<li>回到我们的笔记本，我们获得了另一项培训工作的信息。然后我们创建一个变更集，读取更新的模板并传递所有必需的参数:<pre>training_job_2 = 'tensorflow-training-2020-06-08-07-32-18-734' job_2=sm.describe_training_job(       TrainingJobName=training_job_2) model_data_url_2=       job_2['ModelArtifacts']['S3ModelArtifacts'] with open('endpoint-two-models.yml', 'r') as f:     response = cf.create_change_set(         StackName=stack_name,         ChangeSetName='add-model',         TemplateBody=f.read(),         Parameters=[              { "ParameterKey":"ModelName",                      "UsePreviousValue": True },              { "ParameterKey":"ModelDataUrl",                  "UsePreviousValue": True },             { "ParameterKey":"ContainerImage",                "UsePreviousValue": True },             { "ParameterKey":"RoleArn",                       "UsePreviousValue": True },              { "ParameterKey":"ModelName2",                    "ParameterValue": training_job_2+'-                                 '+timestamp},             { "ParameterKey":"ModelDataUrl2",                  "ParameterValue": model_data_url_2 }         ]     )</pre></li>
				<li>Looking at the CloudFormation<a id="_idIndexMarker1370"/> console, we see the changes caused by the change set. Create a new model and modify the endpoint configuration and the endpoint:<div><img src="img/B17705_12_6.jpg" alt="Figure 12.6 – Viewing the change set&#13;&#10;" width="1064" height="405"/></div><p class="figure-caption">图 12.6–查看变更集</p></li>
				<li>我们执行<a id="_idIndexMarker1371"/>变更集。完成后，我们看到端点现在支持两种生产变体。请注意，实例计数回到了它的初始值，因为我们在更新的模板中将其定义为<code>1</code>:</li>
			</ol>
			<div><div><img src="img/B17705_12_7.jpg" alt="Figure 12.7 – Viewing production variants&#13;&#10;" width="1071" height="141"/>
				</div>
			</div>
			<p class="figure-caption">图 12.7–查看生产变量</p>
			<p>新的生产变量的权重为<code>0</code>，因此不会用于预测。让我们看看如何使用<strong class="bold">金丝雀部署</strong>逐步<a id="_idIndexMarker1372"/>引入<a id="_idIndexMarker1373"/> it。</p>
			<h2 id="_idParaDest-268"><a id="_idTextAnchor267"/>实施金丝雀部署</h2>
			<p>金丝雀部署是一种流行的<a id="_idIndexMarker1374"/>技术，用于渐进的应用程序部署(<a href="https://martinfowler.com/bliki/CanaryRelease.html">https://martinfowler.com/bliki/CanaryRelease.html</a>)，它也可以<a id="_idIndexMarker1375"/>用于机器学习模型。</p>
			<p>简单地说，我们将使用一系列的堆栈更新，以 10%的增量逐渐增加第二个生产变体的权重，直到它完全取代第一个生产变体。我们还将<a id="_idIndexMarker1377"/>创建一个 CloudWatch 警报来监控第二个生产变体的延迟——如果警报被触发，变更集将被回滚:</p>
			<ol>
				<li value="1">我们创建了一个 CloudWatch 警报来监控第二个生产变体的 60 秒平均延迟。我们将阈值设置为 500 毫秒:<pre>cw = boto3.client('cloudwatch') alarm_name = 'My_endpoint_latency' response = cw.put_metric_alarm(     AlarmName=alarm_name,     ComparisonOperator='GreaterThanThreshold',     EvaluationPeriods=1,     MetricName='ModelLatency',     Namespace='AWS/SageMaker',     Period=60,     Statistic='Average',     Threshold=500000.0,     AlarmDescription=         '1-minute average latency exceeds 500ms',     Dimensions=[         { 'Name': 'EndpointName',            'Value': endpoint_name },         { 'Name': 'VariantName',            'Value': 'variant-2' }     ],     Unit='Microseconds' )</pre></li>
				<li>我们找到报警的 ARN:<pre>response = cw.describe_alarms(AlarmNames=[alarm_name]) for a in response['MetricAlarms']:     if a['AlarmName'] == alarm_name:         alarm_arn = a['AlarmArn']</pre></li>
				<li>然后，我们在权重上循环<a id="_idIndexMarker1378"/>并更新堆栈<a id="_idIndexMarker1379"/>。这里不需要变更集，因为从资源的角度来看，我们确切地知道将会发生什么。我们将<a id="_idIndexMarker1380"/>我们的 CloudWatch 警报设置为<strong class="bold">回滚触发器</strong>，在每次更新后，在进入下一次更新之前，给它五分钟的时间</li>
			</ol>
			<p>这就够了。很酷，你不觉得吗？</p>
			<p>这个电池将运行几个小时，所以不要停止它。在另一个笔记本中，下一步是开始向端点发送一些流量。为了简洁起见，我将不包括代码，它与我们在<a href="B17705_07_Final_JM_ePub.xhtml#_idTextAnchor130"> <em class="italic">第 7 章</em></a><em class="italic">使用内置框架扩展机器学习服务</em>中使用的代码相同。你会在 GitHub 资源库中找到这本书的笔记本(<code>Chapter12/cloudformation/Predict Fashion MNIST images.ipynb</code>)。</p>
			<p>现在，我们要做的就是坐下来，喝杯茶，享受我们的模型被安全自动部署的事实。由于端点更新是无缝的，客户端应用程序不会注意到<a id="_idIndexMarker1382"/>的事情。</p>
			<p>几个小时后，部署完成。下一个屏幕截图显示了一段时间内对这两种变体的调用。正如我们所看到的，流量逐渐从第一种变型转移到第二种变型:</p>
			<p class="figure-caption"> </p>
			<div><div><img src="img/B17705_12_8.jpg" alt="Figure 12.8 – Monitoring canary deployment&#13;&#10;" width="1650" height="559"/>
				</div>
			</div>
			<p class="figure-caption">图 12.8–监控金丝雀部署</p>
			<p>延迟保持在我们的<a id="_idIndexMarker1383"/> 500 毫秒的限制之内，警报没有被触发，如下面的截图所示:</p>
			<p class="figure-caption"> </p>
			<div><div><img src="img/B17705_12_9.jpg" alt="Figure 12.9 – Viewing the CloudWatch alarm&#13;&#10;" width="1650" height="542"/>
				</div>
			</div>
			<p class="figure-caption">图 12.9–查看 CloudWatch 警报</p>
			<p>这个例子可以作为您自己部署的起点。例如，您可以添加一个监控<code>4xx</code>或<code>5xx</code> HTTP 错误的警报。您还可以监视受预测延迟和准确性直接影响的业务指标，例如点击率、转换率等。添加一个有用的东西<a id="_idIndexMarker1385"/>将是一个警报通知(电子邮件、SMS，或者甚至是 Lambda 函数),以便在模型部署失败时触发下游的<a id="_idIndexMarker1386"/>动作。可能性是无限的！</p>
			<p>当你完成后，<em class="italic">不要忘记删除堆栈</em>，无论是在云形成控制台还是用<code>delete_stack()</code> API。这将自动清理堆栈创建的所有 AWS 资源。</p>
			<p>蓝绿色展开是另一种流行的技术。让我们看看如何在 SageMaker 上实现它。</p>
			<h2 id="_idParaDest-269"><a id="_idTextAnchor268"/>实施蓝绿部署</h2>
			<p>蓝绿色<a id="_idIndexMarker1387"/>部署<a id="_idIndexMarker1388"/>需要两个<a id="_idIndexMarker1389"/>生产环境(<a href="https://martinfowler.com/bliki/BlueGreenDeployment.html">https://martinfowler.com/bliki/BlueGreenDeployment.html</a>):</p>
			<ul>
				<li>现场制作<a id="_idIndexMarker1390"/>环境(<code>blue</code>)运行版本<code>n</code></li>
				<li>这个环境的副本(<code>green</code>)运行版本<code>n+1</code></li>
			</ul>
			<p>让我们来看两个可能的场景，我们可以使用与<a id="_idIndexMarker1391"/>用于金丝雀部署的<a id="_idIndexMarker1392"/>相同的 API 来实现。</p>
			<h3>通过单个端点实施蓝绿色部署</h3>
			<p>从运行模型当前版本的<a id="_idIndexMarker1393"/>现有端点<a id="_idIndexMarker1394"/>开始，我们将执行以下步骤:</p>
			<ol>
				<li value="1">创建具有两个生产变量的新端点配置:一个用于当前模型，一个用于新模型。初始权重将被分别设置为<code>1</code>和<code>0</code>。</li>
				<li>将其应用于端点。</li>
				<li>对新的生产变体进行测试，用<code>invoke_endpoint()</code>中的<code>TargetVariant</code>参数明确选择它。</li>
				<li>当测试令人满意时，将重量更新到<code>0</code>和<code>1</code>。这将无缝地将流量切换到新模型。如果出现任何问题，将重量恢复到<code>1</code>和<code>0</code>。</li>
				<li>部署完成后，更新端点以删除第一个生产变量。</li>
			</ol>
			<p>这是一个简单而可靠的解决方案。然而，更新一个端点需要几分钟的时间，这使得整个过程没有你希望的那么快。让我们看看如何通过使用两个端点来解决这个问题。</p>
			<h3>使用两个端点实施蓝绿色部署</h3>
			<p>从运行模型当前版本的现有<a id="_idIndexMarker1396"/>端点<a id="_idIndexMarker1397"/>开始，我们将实现以下步骤:</p>
			<ol>
				<li value="1">创建运行新版本模型的第二个端点。</li>
				<li>在这个新端点上运行测试。</li>
				<li>当测试结果令人满意时，将所有流量切换到新的端点。这可以通过不同的方式实现；例如，更新业务应用程序中的参数，或者更新私有 DNS 条目。如果有任何问题，恢复到以前的设置。</li>
				<li>部署完成后，删除旧端点。</li>
			</ol>
			<p>这个设置稍微复杂一点，但是它让您可以立即从一个模型版本切换到下一个版本，无论是部署还是回滚。</p>
			<p>CloudFormation 是一个非常棒的自动化工具，花时间学习它会有回报的。然而一些 AWS 用户更喜欢写代码而不是写模板，这就是我们引入 CDK 的原因。</p>
			<h1 id="_idParaDest-270"><a id="_idTextAnchor269"/>通过自动气象站 CDK 实现自动化</h1>
			<p>AWS CDK 是一个多语言 SDK，让你编写代码来定义 AWS 基础设施(<a href="https://github.com/aws/aws-cdk">https://github.com/aws/aws-cdk</a>)。然后，使用 CDK CLI，您可以在幕后使用 CloudFormation 来配置该基础架构。</p>
			<h2 id="_idParaDest-271"><a id="_idTextAnchor270"/>安装 CDK</h2>
			<p>当<code>npm</code>工具安装在您的机器上(<a href="https://www.npmjs.com/get-npm">https://www.npmjs.com/get-npm</a>)时，CDK <a id="_idIndexMarker1399"/>被本地实现。</p>
			<p>安装 CDK 就像这样简单:</p>
			<pre>$ npm i -g aws-cdk
$ cdk --version
1.114.0 (build 7e41b6b)</pre>
			<p>让我们创建<a id="_idIndexMarker1401"/>一个 CDK 应用程序并部署一个端点。</p>
			<h2 id="_idParaDest-272"><a id="_idTextAnchor271"/>创建 CDK 应用程序</h2>
			<p>我们将部署与 CloudFormation 相同的模型。我会用 Python，你也可以用<strong class="bold"> JavaScript </strong>、<strong class="bold"> TypeScript </strong>、<strong class="bold"> Java </strong>，还有。<strong class="bold">网</strong>。API 文件可从 https://docs.aws.amazon.com/cdk/api/latest/python/<a href="https://docs.aws.amazon.com/cdk/api/latest/python/">获得</a>:</p>
			<ol>
				<li value="1">首先，我们创建名为<code>endpoint</code> : <pre><strong class="bold">$ mkdir cdk</strong> <strong class="bold">$ cd cdk</strong> <strong class="bold">$ cdk init --language python --app endpoint</strong></pre>的 Python 应用程序</li>
				<li>这将自动创建一个虚拟环境，我们需要激活它:<pre><strong class="bold">$ source .venv/bin/activate</strong></pre></li>
				<li>这也为我们的 CDK 代码创建了一个默认的<code>app.py</code>文件，为应用程序配置创建了一个<code>cdk.json</code>文件，为安装依赖项创建了一个<code>requirements.txt</code>文件。相反，我们将使用 GitHub 存储库中的文件:</li>
				<li>在<code>requirements.txt</code>文件中，我们为 S3 和 SageMaker 安装了 CDK 包。每种服务需要不同的包。例如，我们将为 S3 添加<code>aws_cdk.aws_s3</code>:<pre>-e . aws_cdk.aws_s3 aws_cdk.aws_sagemaker</pre></li>
				<li>然后我们照常安装需求:<pre><strong class="bold">$ pip install -r requirements.txt</strong></pre></li>
				<li>In the <code>cdk.json</code> file, we store the application context. Namely, key-value pairs that <a id="_idIndexMarker1403"/>can be read by the application for configuration (<a href="https://docs.aws.amazon.com/cdk/latest/guide/context.html">https://docs.aws.amazon.com/cdk/latest/guide/context.html</a>):<pre>{
  "app": "python3 app.py",
  "context": {
    "role_arn": "arn:aws:iam::123456789012:role/Sagemaker-fullaccess"
    "model_name": "tf2-fmnist",
    "epc_name": "tf2-fmnist-epc",
    "ep_name": "tf2-fmnist-ep",
    "image": "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1-cpu",
    "model_data_url": "s3://sagemaker-us-east-1-123456789012/keras2-fashion-mnist/output/tensorflow-training-2020-06-08-07-46-04-367/output/model.tar.gz"
    "instance_type": "ml.t2.xlarge",
    "instance_count": 1
  }
}</pre><p>这是向应用程序传递值的首选方式。您应该使用版本控制来管理这个文件，以便跟踪栈是如何构建的。</p></li>
				<li>我们可以使用<code>cdk context</code>命令查看应用程序的上下文:</li>
			</ol>
			<p class="figure-caption"> </p>
			<div><div><img src="img/B17705_12_10.jpg" alt="Figure 12.10 – Viewing CDK context&#13;&#10;" width="1650" height="572"/>
				</div>
			</div>
			<p class="figure-caption">图 12.10–查看 CDK 环境</p>
			<p>现在，我们需要<a id="_idIndexMarker1404"/>来编写实际的应用程序。</p>
			<h2 id="_idParaDest-273"><a id="_idTextAnchor272"/>编写 CDK 应用程序</h2>
			<p>所有代码进入<code>app.py</code>文件中的<a id="_idIndexMarker1405"/>，我们通过以下步骤实现:</p>
			<ol>
				<li value="1">我们导入所需的包:<pre>import time from aws_cdk import (     aws_sagemaker as sagemaker,     core )</pre></li>
				<li>我们扩展了<code>core.Stack</code>类来创建我们自己的栈:<pre>class SagemakerEndpoint(core.Stack):  def __init__(self, app: core.App, id: str, **kwargs) -&gt; None:      timestamp =           '-'+time.strftime(                  "%Y-%m-%d-%H-%M-%S",time.gmtime())      super().__init__(app, id, **kwargs)</pre></li>
				<li>我们添加<a id="_idIndexMarker1406"/>一个<code>CfnModel</code>对象，读取适当的上下文值:<pre>     model = sagemaker.CfnModel(          scope = self,          id="my_model",          execution_role_arn=               self.node.try_get_context("role_arn"),          containers=[{             "image":               self.node.try_get_context("image"),            "modelDataUrl":                                self.node.try_get_context("model_data_url")          }],                     model_name= self.node.try_get_context(                      "model_name")+timestamp      )</pre></li>
				<li>我们添加一个<code>CfnEndpointConfig</code>对象，使用内置的<code>get_att()</code>函数将它与模型关联起来。这创建了一个依赖关系，CloudFormation 将使用它来以正确的顺序构建资源:<pre>     epc = sagemaker.CfnEndpointConfig(           scope=self,           id="my_epc",           production_variants=[{               "modelName": core.Fn.get_att(                                model.logical_id,                                 'ModelName'                            ).to_string(),               "variantName": "variant-1",               "initialVariantWeight": 1.0,               "initialInstanceCount": 1,               "instanceType":                    self.node.try_get_context(                   "instance_type")           }],           endpoint_config_name=                                      self.node.try_get_context("epc_name")                   +timestamp     )</pre></li>
				<li>我们<a id="_idIndexMarker1407"/>添加一个<code>CfnEndpoint</code>对象，使用内置的<code>get_att()</code>函数将它关联到端点配置:<pre>     ep = sagemaker.CfnEndpoint(          scope=self,          id="my_ep",          endpoint_config_name=              core.Fn.get_att(                  epc.logical_id,                  'EndpointConfigName'              ).to_string(),          endpoint_name=              self.node.try_get_context("ep_name")              +timestamp      )</pre></li>
				<li>最后，我们<a id="_idIndexMarker1408"/>实例化应用程序:<pre>app = core.App() SagemakerEndpoint(     app,      "SagemakerEndpoint",      env={'region': 'eu-west-1'} ) app.synth()</pre></li>
			</ol>
			<p>我们的代码是完整的！</p>
			<h2 id="_idParaDest-274"><a id="_idTextAnchor273"/>部署 CDK 应用程序</h2>
			<p>我们现在可以<a id="_idIndexMarker1409"/>部署端点:</p>
			<ol>
				<li value="1">我们可以列出可用的堆栈:<pre><strong class="bold">$ cdk list</strong> <strong class="bold">SagemakerEndpointEU</strong></pre></li>
				<li>我们还可以看到实际的云形成模板。它应该与我们在上一节中编写的模板极其相似:<pre><strong class="bold">$ cdk synth SagemakerEndpointEU</strong></pre></li>
				<li>Deploying the stack is equally simple, as shown in the next screenshot:<div><img src="img/B17705_12_11.jpg" alt="Figure 12.11 – Deploying an endpoint&#13;&#10;" width="610" height="119"/></div><p class="figure-caption">图 12.11–部署端点</p></li>
				<li>查看 CloudFormation，我们看到堆栈是使用变更集创建的。几分钟后，端点开始服务。</li>
				<li>Editing <code>app.py</code>, we<a id="_idIndexMarker1410"/> set the initial instance count to <code>2</code>. We then ask CDK to deploy the stack, but without executing the change set, as shown in the next screenshot:<div><img src="img/B17705_12_12.jpg" alt="Figure 12.12 – Creating a change set&#13;&#10;" width="789" height="122"/></div><p class="figure-caption">图 12.12–创建变更集</p></li>
				<li>If we're happy with the change set, we can execute it in the CloudFormation console, or run the previous command again without <code>--no-execute</code>. As expected, and as shown in the next screenshot, the endpoint is updated:<div><img src="img/B17705_12_13.jpg" alt="Figure 12.13 – Updating the endpoint&#13;&#10;" width="608" height="119"/></div><p class="figure-caption">图 12.13–更新端点</p></li>
				<li>完成后，我们可以销毁堆栈:<pre><strong class="bold">$ cdk destroy SagemakerEndpointEU</strong></pre></li>
			</ol>
			<p>正如你所看到的，CDK 是直接编写模板的一种有趣的替代方式，同时仍然受益于 CloudFormation 的严格性和健壮性。</p>
			<p>我们还没有做的一件事是自动化端到端的工作流，从培训到部署。让我们用 AWS 步骤函数来做这件事。</p>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor274"/>使用 AWS 步骤功能构建端到端工作流</h1>
			<p>在<strong class="bold">状态机</strong>(<a href="https://aws.amazon.com/step-functions/">https://aws.amazon.com/step-functions/</a>)上<a id="_idIndexMarker1413"/>的基础上<strong class="bold"> AWS 步骤功能</strong>让您定义并运行<a id="_idIndexMarker1412"/>工作流。状态机是步骤的组合，可以是顺序的、并行的或有条件的。每个步骤<a id="_idIndexMarker1415"/>接收来自其前任的输入，执行操作，并将输出传递给其继任者。Step 函数集成了很多 AWS 服务，比如亚马逊 SageMaker、<strong class="bold"> AWS </strong> <strong class="bold"> Lambda </strong>、容器服务、<strong class="bold">亚马逊</strong> <strong class="bold"> DynamoDB </strong>、<strong class="bold">亚马逊</strong> <strong class="bold"> EMR </strong>、<strong class="bold"> AWS </strong> <strong class="bold"> Glue </strong>等等。</p>
			<p>可以使用 JSON 和<strong class="bold"> Amazon States Language </strong>来定义状态机，并且可以在服务控制台中可视化它们。状态机的执行是完全受管理的，因此您不需要提供任何基础设施来运行。</p>
			<p>说到<a id="_idIndexMarker1416"/> SageMaker，Step Functions 有一个专用的 Python SDK，奇怪的命名为<strong class="bold">数据科学 SDK</strong>(<a href="https://github.com/aws/aws-step-functions-data-science-sdk-python">https://github . com/AWS/AWS-Step-Functions-Data-Science-SDK-Python</a>)。</p>
			<p>让我们运行一个例子，其中我们为在<strong class="bold"> Boston Housing </strong>数据集上训练<a id="_idIndexMarker1420"/>的<strong class="bold"> scikit-learn </strong>模型<a id="_idIndexMarker1419"/>自动化训练<a id="_idIndexMarker1417"/>和部署<a id="_idIndexMarker1418"/>。</p>
			<h2 id="_idParaDest-276"><a id="_idTextAnchor275"/>设置权限</h2>
			<p>首先，请<a id="_idIndexMarker1421"/>确保您的用户或笔记本实例的 IAM 角色有权调用 Step 函数 API。如果不是，请将<code>AWSStepFunctionsFullAccess</code>托管策略添加到角色中。</p>
			<p>然后，我们需要为 Step 函数创建一个服务角色，允许它代表我们调用 AWS APIs:</p>
			<ol>
				<li value="1">从 IAM 控制台(<a href="https://console.aws.amazon.com/iam/home#/roles">https://console.aws.amazon.com/iam/home#/roles</a>)开始，我们点击<strong class="bold">创建角色</strong>。</li>
				<li>我们选择<strong class="bold"> AWS 服务</strong>和<strong class="bold">步骤功能</strong>。</li>
				<li>我们单击下一个屏幕，直到可以输入角色名称。姑且称之为<code>StepFunctionsWorkflowExecutionRole</code>，点击<strong class="bold">创建角色</strong>。</li>
				<li>选择该角色，我们单击其<strong class="bold">权限</strong>选项卡，然后单击<strong class="bold">添加内嵌策略</strong>。</li>
				<li>选择 JSON 选项卡，我们用<code>Chapter12/step_functions/service-role-policy.json</code>文件的内容替换空策略，并单击<strong class="bold">查看策略</strong>。</li>
				<li>我们将策略命名为<code>StepFunctionsWorkflowExecutionPolicy</code>，并点击<strong class="bold">创建策略</strong>。</li>
				<li>我们记下角色的 ARN，然后关闭 IAM 控制台。</li>
			</ol>
			<p>设置<a id="_idIndexMarker1422"/>现已完成。现在，让我们创建一个工作流。</p>
			<h2 id="_idParaDest-277"><a id="_idTextAnchor276"/>实施我们的第一个工作流程</h2>
			<p>在这个<a id="_idIndexMarker1423"/>工作流中，我们将经历以下步骤序列:训练模型、创建模型、将其用于批量转换、创建端点配置，以及将模型部署到端点:</p>
			<ol>
				<li value="1">我们将训练集和测试集上传到 S3，在测试集中我们删除了目标属性。我们将使用后者进行批量转换:<pre>import sagemaker import pandas as pd sess = sagemaker.Session() bucket = sess.default_bucket()    prefix = 'sklearn-boston-housing-stepfunc' training_data = sess.upload_data(     path='housing.csv',      key_prefix=prefix + "/training") data = pd.read_csv('housing.csv') data.drop(['medv'], axis=1, inplace=True) data.to_csv('test.csv', index=False, header=False) batch_data = sess.upload_data(     path='test.csv',      key_prefix=prefix + "/batch")</pre></li>
				<li>我们像往常一样配置我们的估计器:<pre>from sagemaker.sklearn import SKLearn output = 's3://{}/{}/output/'.format(bucket,prefix) sk = SKLearn(     entry_point='sklearn-boston-housing.py',     role=sagemaker.get_execution_role(),     framework_version='0.23-1',     train_instance_count=1,     train_instance_type='ml.m5.large',     output_path=output,     hyperparameters={         'normalize': True,         'test-size': 0.1     } )</pre></li>
				<li>我们<a id="_idIndexMarker1424"/>还定义了用于批量转换的转换器:<pre>sk_transformer = sk.transformer(     instance_count=1,     instance_type='ml.m5.large')</pre></li>
				<li>我们导入工作流所需的步骤函数对象。你可以在<a href="https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/">https://AWS-step-functions-data-science-SDK . readthedocs . io/en/latest/</a>:<pre>import stepfunctions from stepfunctions import steps from stepfunctions.steps import TrainingStep, ModelStep, TransformStep from stepfunctions.inputs import ExecutionInput from stepfunctions.workflow import Workflow</pre>找到 API 文档</li>
				<li>我们定义工作流的输入。我们将传递给它一个培训作业名、一个模型名和一个端点名:<pre>execution_input = ExecutionInput(schema={     'JobName': str,     'ModelName': str,     'EndpointName': str} )</pre></li>
				<li>工作流程的第一步<a id="_idIndexMarker1425"/>是培训步骤。我们向它传递估计量、数据集在 S3 的位置以及一个训练作业名称:<pre>from sagemaker.inputs import TrainingInput training_step = TrainingStep(   'Train Scikit-Learn on the Boston Housing dataset',   estimator=sk,   data={'training': TrainingInput(        training_data,content_type='text/csv')},   job_name=execution_input['JobName'] )</pre></li>
				<li>下一步是模型创建步骤。我们将在上一步中训练的模型的位置和模型名传递给它:<pre>model_step = ModelStep(     'Create the model in SageMaker',     model=training_step.get_expected_model(),     model_name=execution_input['ModelName'] )</pre></li>
				<li>下一步是对测试数据集运行批处理转换。我们通过<code>transformer</code> <a id="_idIndexMarker1426"/>对象，测试数据集在 S3 的位置，其内容类型:<pre>transform_step = TransformStep(     'Transform the dataset in batch mode',     transformer=sk_transformer,     job_name=execution_input['JobName'],         model_name=execution_input['ModelName'],     data=batch_data,     content_type='text/csv' )</pre></li>
				<li>下一步是创建端点配置:<pre>endpoint_config_step = EndpointConfigStep(     "Create an endpoint configuration for the model",     endpoint_config_name=execution_input['ModelName'],     model_name=execution_input['ModelName'],     initial_instance_count=1,     instance_type='ml.m5.large' )</pre></li>
				<li>最后一步是创建端点:<pre>endpoint_step = EndpointStep(     "Create an endpoint hosting the model",     endpoint_name=execution_input['EndpointName'],     endpoint_config_name=execution_input['ModelName'] )</pre></li>
				<li>既然已经定义了所有步骤，我们<a id="_idIndexMarker1427"/>按顺序将它们链接起来:<pre>workflow_definition = Chain([     training_step,     model_step,     transform_step,     endpoint_config_step,     endpoint_step ])</pre></li>
				<li>我们现在使用工作流定义和输入定义<pre>import time timestamp = time.strftime("%Y-%m-%d-%H-%M-%S", time.gmtime()) workflow_execution_role = "arn:aws:iam::0123456789012:role/ StepFunctionsWorkflowExecutionRole" workflow = Workflow(     name='sklearn-boston-housing-workflow1-{}'          .format(timestamp),     definition=workflow_definition,     role=workflow_execution_role,     execution_input=execution_input )</pre>构建我们的工作流</li>
				<li>We can visualize the state machine, an easy way to check that we built it as expected, as shown <a id="_idIndexMarker1428"/>in the next screenshot:<pre>workflow.render_graph(portrait=True)</pre><div><img src="img/B17705_12_14.jpg" alt="Figure 12.14 – Viewing the state machine&#13;&#10;" width="475" height="596"/></div><p class="figure-caption">图 12.14–查看状态机</p></li>
				<li>我们创建工作流程:<pre>workflow.create()</pre></li>
				<li>It's visible in the Step Functions console, as shown in the following screenshot. We can see both its graphical representation and its JSON definition based on the Amazon States Language. We could edit the workflow as well if needed:<div><img src="img/B17705_12_15.jpg" alt="Figure 12.15 – Viewing the state machine in the console&#13;&#10;" width="1365" height="649"/></div><p class="figure-caption">图 12.15–在控制台中查看状态机</p></li>
				<li>我们<a id="_idIndexMarker1429"/>运行工作流:<pre>execution = workflow.execute(  inputs={    'JobName': 'sklearn-boston-housing-{}'               .format(timestamp),    'ModelName': 'sklearn-boston-housing-{}'                 .format(timestamp),    'EndpointName': 'sklearn-boston-housing-{}'                    .format(timestamp)  } )</pre></li>
				<li>We can track its progress with <code>render_progress()</code> and the <code>list_events()</code> API. We can also see it in the console, as shown in the next screenshot. Note that we also see the input and output of each step, which is a great way to troubleshoot problems:<div><img src="img/B17705_12_16.jpg" alt="Figure 12.16 – Running the state machine&#13;&#10;" width="1265" height="564"/></div><p class="figure-caption">图 12.16–运行状态机</p></li>
				<li>工作流完成后，您可以像往常一样测试端点。<em class="italic">完成后不要忘记在 SageMaker 控制台中将其删除</em>。</li>
			</ol>
			<p>本示例<a id="_idIndexMarker1430"/>展示了使用该 SDK 构建 SageMaker 工作流是多么简单。尽管如此，我们仍然可以通过并行运行批处理转换和端点创建来改进它。</p>
			<h2 id="_idParaDest-278"><a id="_idTextAnchor277"/>为工作流增加并行执行</h2>
			<p>下一个<a id="_idIndexMarker1431"/>截图显示了我们将要构建的工作流程。步骤本身完全相同。我们只需要修改它们的链接方式:</p>
			<div><div><img src="img/B17705_12_17.jpg" alt="Figure 12.17 – Viewing the parallel state machine&#13;&#10;" width="1060" height="755"/>
				</div>
			</div>
			<p class="figure-caption">图 12.17–查看并行状态机</p>
			<p>我们将从以下步骤开始:</p>
			<ol>
				<li value="1">我们的<a id="_idIndexMarker1432"/>工作流有两个分支——一个用于批处理转换，一个用于端点:<pre>batch_branch = Chain([   transform_step ]) endpoint_branch = Chain([   endpoint_config_step,   endpoint_step ]) </pre></li>
				<li>我们创建了一个<code>Parallel</code>步骤，以允许这两个分支的并行执行:<pre>parallel_step = Parallel('Parallel execution') parallel_step.add_branch(batch_branch) parallel_step.add_branch(endpoint_branch)</pre></li>
				<li>我们把所有的东西放在一起:<pre>workflow_definition = Chain([     training_step,     model_step,     parallel_step ])</pre></li>
			</ol>
			<p>就这样！我们<a id="_idIndexMarker1433"/>现在可以像前面的例子一样创建并运行这个工作流。</p>
			<p>查看 Step Functions 控制台，我们可以看到工作流确实并行运行了两个分支。然而，还有一个小问题。端点创建步骤显示为已完成，尽管端点仍在创建中。您可以在 SageMaker 控制台中看到，端点被列为<code>Creating</code>。如果客户端应用程序试图在工作流完成后立即调用终结点，这可能会导致问题。</p>
			<p>让我们通过添加一个额外的步骤来改进这一点，等待端点投入使用。我们可以很容易地用 Lambda 函数做到这一点，允许我们在工作流中的任何地方运行我们自己的代码。</p>
			<h2 id="_idParaDest-279"><a id="_idTextAnchor278"/>向工作流添加 Lambda 函数</h2>
			<p>如果你从来没有看过 https://aws.amazon.com/lambda 的电影，那你就错过了！Lambda 是无服务器架构的核心，在这里你可以编写和部署运行在完全托管的基础设施上的简短函数。这些功能可以由各种 AWS 事件触发，也可以按需调用。</p>
			<h3>设置权限</h3>
			<p>创建一个λ<a id="_idIndexMarker1436"/>函数很简单。唯一的先决条件是<a id="_idIndexMarker1437"/>创建一个<code>DescribeEndpoint</code> API，以及在 CloudWatch 中创建日志的权限。让我们为此使用<code>boto3</code> API。您可以在<a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-permissions.html">https://docs . AWS . Amazon . com/lambda/latest/DG/lambda-permissions . html</a>找到更多信息:</p>
			<ol>
				<li value="1">我们首先为角色定义一个<strong class="bold">信任策略</strong>，允许<a id="_idIndexMarker1438"/>由 Lambda 服务:<pre>{   "Version": "2012-10-17",   "Statement": [{     "Effect": "Allow",     "Principal": {       "Service": "lambda.amazonaws.com"     },     "Action": "sts:AssumeRole"   }] }</pre>承担</li>
				<li>我们创建一个角色并<a id="_idIndexMarker1439"/>将信任策略附加到它:<pre>iam = boto3.client('iam') with open('trust-policy.json') as f:     policy = f.read()     role_name = 'lambda-role-sagemaker-describe-endpoint' response = iam.create_role(     RoleName=role_name,     AssumeRolePolicyDocument=policy,     Description='Allow function to invoke all SageMaker APIs' ) role_arn = response['Role']['Arn']</pre></li>
				<li>我们定义了一个策略，列出了允许的 API:<pre>{   "Version": "2012-10-17",   "Statement": [     {       "Effect": "Allow",       "Action": "sagemaker:DescribeEndpoint",       "Resource": "*"     },     {       "Effect": "Allow",       "Action": [           "logs:CreateLogGroup",           "logs:CreateLogStream",           "logs:PutLogEvents"       ],       "Resource": "*"      }   ] }</pre></li>
				<li>我们创建策略并将其添加到角色:<pre>with open('policy.json') as f:     policy = f.read() policy_name = 'Sagemaker-describe-endpoint' response = iam.create_policy(     PolicyName=policy_name,     PolicyDocument=policy,     Description='Allow the DescribeEndpoint API' ) policy_arn = response['Policy']['Arn'] response = iam.attach_role_policy(     RoleName=role_name,     PolicyArn=policy_arn )</pre></li>
			</ol>
			<p>IAM 设置<a id="_idIndexMarker1441"/>现已完成。</p>
			<h3>编写 Lambda 函数</h3>
			<p>我们现在可以写一个<a id="_idIndexMarker1442"/>短 Lambda 函数。它接收一个 JSON 事件作为输入，该事件存储了由<code>EndpointStep</code>步骤创建的端点的 ARN。它只是从 ARN 中提取端点名称，创建一个<code>boto3</code>等待程序，并一直等到端点投入使用。下面的屏幕截图显示了 Lambda 控制台中的代码:</p>
			<div><div><img src="img/B17705_12_18.jpg" alt="Figure 12.18 – Our Lambda function&#13;&#10;" width="1649" height="885"/>
				</div>
			</div>
			<p class="figure-caption">图 12.18–我们的 Lambda 函数</p>
			<p>让我们部署这个功能:</p>
			<ol>
				<li value="1">我们为 Lambda 函数创建一个<a id="_idIndexMarker1443"/>部署包，并将其上传到 S3: <pre><strong class="bold">$ zip -9 lambda.zip lambda.py</strong> <strong class="bold">$ aws s3 cp lambda.zip s3://my-bucket</strong></pre></li>
				<li>我们创建了超时 15 分钟的函数，这是 Lambda 函数可能的最长运行时间。终端部署通常不到 10 分钟，因此这应该绰绰有余:<pre>lambda_client = boto3.client('lambda') response = lambda_client.create_function(     FunctionName='sagemaker-wait-for-endpoint',     Role=role_arn,     Runtime='python3.6',     Handler='lambda.lambda_handler',     Code={         'S3Bucket': bucket_name,         'S3Key': 'lambda.zip'     },     Description='Wait for endpoint to be in service',     Timeout=900,     MemorySize=128 )</pre></li>
				<li>既然 Lambda <a id="_idIndexMarker1444"/>函数已经创建，我们可以很容易地将其添加到现有的工作流中。我们定义一个<code>LambdaStep</code>并将其添加到端点分支。它的有效载荷是端点 ARN，从<code>EndpointStep</code> : <pre>lambda_step = LambdaStep(     'Wait for endpoint to be in service',     parameters={         'FunctionName': 'sagemaker-wait-for-endpoint',         'Payload': {"EndpointArn.$": "$.EndpointArn"}     },     timeout_seconds=900 ) endpoint_branch = steps.Chain([     endpoint_config_step,     endpoint_step,     lambda_step ])</pre>的输出中提取</li>
				<li>再次运行工作流，我们在下面的屏幕截图中看到，这个新步骤接收端点 ARN 作为输入，并等待端点投入使用:</li>
			</ol>
			<div><div><img src="img/B17705_12_19.jpg" alt="Figure 12.19 – Running the state machine with Lambda&#13;&#10;" width="535" height="457"/>
				</div>
			</div>
			<p class="figure-caption">图 12.19–使用 Lambda 运行状态机</p>
			<p>有许多其他的方式可以让你在 SageMaker 中使用 Lambda 函数。您可以提取训练指标，预测端点上的测试集，等等。可能性是无限的。</p>
			<p>现在，让我们使用 Amazon SageMaker Pipelines 自动化端到端工作流。</p>
			<h1 id="_idParaDest-280"><a id="_idTextAnchor279"/>使用 Amazon SageMaker 管道构建端到端工作流</h1>
			<p><strong class="bold">亚马逊 SageMaker Pipelines </strong>让<a id="_idIndexMarker1446"/>美国创建<a id="_idIndexMarker1447"/>并运行端到端的机器学习<strong class="bold">工作流</strong>基于 SageMaker 步骤进行训练、调优、批量转换和处理脚本，使用的 SageMaker APIs SDK 与我们在 Step 函数中使用的非常相似。</p>
			<p>与阶跃函数相比，SageMaker Pipelines 增加了以下功能:</p>
			<ul>
				<li>能够直接在 SageMaker Studio 中编写、运行、可视化和管理您的工作流，而无需跳转到 AWS 控制台。</li>
				<li>一个<strong class="bold">模型注册中心</strong>，它<a id="_idIndexMarker1448"/>使得管理模型版本、只部署批准的版本以及跟踪<strong class="bold">血统</strong>变得更加容易。</li>
				<li><strong class="bold">MLOps templates</strong> – a collection of CloudFormation templates published via <strong class="bold">AWS Service Catalog</strong> that <a id="_idIndexMarker1449"/>help you automate the deployment of your models. Built-in templates are provided, and you can add your own. You (or your<a id="_idIndexMarker1450"/> Ops team) can <a id="_idIndexMarker1451"/>learn more at <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects.html">https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects.html</a>.<p class="callout-heading">注意</p><p class="callout">SageMaker Pipelines 缺乏的一点是与其他 AWS 服务的集成。在撰写本文时，SageMaker Pipelines 仅支持<strong class="bold"> SQS </strong>，而 Step Functions 支持许多计算和大数据服务。使用 SageMaker Pipelines，假设要么您的训练数据已经被处理，要么您将使用 SageMaker 处理步骤来处理它。</p></li>
			</ul>
			<p>现在我们知道了什么是 SageMaker Pipelines，让我们基于亚马逊评论数据集和我们在第 6 章 、<em class="italic">训练自然语言处理模型</em>、<a href="B17705_10_Final_JM_ePub.xhtml#_idTextAnchor206">T22)、第 10 章 </a>、<em class="italic">高级训练技术</em>中使用的 BlazingText 算法运行一个完整的示例，将我们到目前为止了解到的许多服务放在一起。我们的管道将包含以下步骤:</p>
			<ul>
				<li>处理步骤，其中<a id="_idIndexMarker1452"/>我们用<strong class="bold"> SageMaker 处理</strong>准备数据集。</li>
				<li>摄取<a id="_idIndexMarker1453"/>步骤，我们将处理过的数据集加载到<strong class="bold"> SageMaker 特征库</strong>中。</li>
				<li>数据集构建步骤，我们使用<strong class="bold"> Amazon Athena </strong>查询离线商店，并将数据集保存到 S3。</li>
				<li>训练步骤，我们在数据集上训练 BlazingText 模型。</li>
				<li>一个模型创建步骤，我们将训练好的模型保存为 SageMaker 模型。</li>
				<li>模型注册步骤，我们将模型添加到 SageMaker Pipelines 模型注册中心。</li>
			</ul>
			<p>在现实生活中，您最初不应该担心自动化。您应该首先使用 Jupyter 笔记本进行实验，并重复所有这些步骤。然后，随着项目的成熟，您应该开始自动化每个步骤，最终将它们组装成一个管道。</p>
			<p>我的建议是首先自动化每个处理步骤，由单独的 SageMaker 处理作业。这不仅会在开发阶段派上用场，而且还会创建一个简单的逐步实现完全自动化的路径。事实上，一旦 SageMaker 处理的步骤运行良好，将它们与 SageMaker 管道结合起来就不费吹灰之力了。事实上，您可以使用完全相同的 Python 脚本。您只需用 Pipelines SDK 编写代码。您马上就会看到，它与处理 SDK 非常相似。</p>
			<p>这是我在下面的例子中遵循的方法。在 GitHub 存储库中，您将找到用于数据处理、摄取和数据集构建步骤的<a id="_idIndexMarker1454"/> SageMaker <a id="_idIndexMarker1455"/>处理笔记本，以及用于端到端工作流的另一个笔记本。这里，我们将重点讨论后者。我们开始吧！</p>
			<h2 id="_idParaDest-281"><a id="_idTextAnchor280"/>定义工作流参数</h2>
			<p>就像<a id="_idIndexMarker1456"/> CloudFormation 模板一样，您可以(也应该)在您的工作流程中定义参数。这使得它们更容易在其他项目中重用。参数可以是字符串、整数和浮点数，有一个可选的默认值。</p>
			<ol>
				<li value="1">我们为 AWS 区域和我们希望用于处理和训练的实例创建参数:<pre>from sagemaker.workflow.parameters import ParameterInteger, ParameterString region = ParameterString(     name='Region',     default_value='eu-west-1') processing_instance_type = ParameterString(     name='ProcessingInstanceType',     default_value='ml.m5.4xlarge') processing_instance_count = ParameterInteger(     name='ProcessingInstanceCount',     default_value=1) training_instance_type = ParameterString(     name='TrainingInstanceType',     default_value='ml.p3.2xlarge') training_instance_count = ParameterInteger(     name='TrainingInstanceCount',     default_value=1)</pre></li>
				<li>我们还为输入数据的位置、模型名称和模型状态创建了<a id="_idIndexMarker1457"/>参数，以便在模型注册表中进行设置(稍后将详细介绍)。<pre>input_data = ParameterString(name='InputData') model_name = ParameterString(name='ModelName') model_approval_status = ParameterString(     name='ModelApprovalStatus',     default_value='PendingManualApproval')</pre></li>
			</ol>
			<p>现在，让我们定义数据处理步骤。</p>
			<h2 id="_idParaDest-282"><a id="_idTextAnchor281"/>使用 SageMaker 处理来处理数据集</h2>
			<p>我们重用<a id="_idIndexMarker1458"/>我们<a id="_idIndexMarker1459"/>在<a href="B17705_06_Final_JM_ePub.xhtml#_idTextAnchor108"> <em class="italic">第六章</em> </a> ( <code>preprocessing.py</code>)中写的处理脚本。</p>
			<ol>
				<li value="1">我们用刚刚定义的参数创建一个<code>SKLearnProcessor</code>对象:<pre>from sagemaker.sklearn.processing import SKLearnProcessor sklearn_processor = SKLearnProcessor(     framework_version='0.23-1',     role=role,     instance_type=processing_instance_type,     instance_count=processing_instance_count)</pre></li>
				<li>然后我们定义数据处理步骤。请记住，它创建了两个输出:一个是 BlazingText 格式，另一个是 SageMaker 特性存储中的摄取。如前所述，SageMaker 管道语法非常接近 SageMaker 处理语法(输入、输出和参数)。<pre>from sagemaker.workflow.steps import ProcessingStep from sagemaker.processing import ProcessingInput, ProcessingOutput step_process = ProcessingStep(     name='process-customer-reviews'     processor=sklearn_processor,     inputs=[         ProcessingInput(source=input_data,              destination="/opt/ml/processing/input")],     outputs=[         ProcessingOutput(output_name='bt_data',             source='/opt/ml/processing/output/bt'),         ProcessingOutput(output_name='fs_data',             source='/opt/ml/processing/output/fs')],     code='preprocessing.py',     job_arguments=[         '--filename',          'amazon_reviews_us_Camera_v1_00.tsv.gz',         '--library',          'spacy'] )</pre></li>
			</ol>
			<p>现在，让我们<a id="_idIndexMarker1460"/>定义<a id="_idIndexMarker1461"/>摄取步骤。</p>
			<h2 id="_idParaDest-283"><a id="_idTextAnchor282"/>通过 SageMaker 处理在 SageMaker 要素存储中获取数据集</h2>
			<p>我们<a id="_idIndexMarker1462"/>重用我们在<a href="B17705_10_Final_JM_ePub.xhtml#_idTextAnchor206"> <em class="italic">第十章</em> </a> ( <code>ingesting.py</code>)中写的<a id="_idIndexMarker1463"/>处理脚本。</p>
			<ol>
				<li value="1">我们首先为特性组定义一个名称:<pre>feature_group_name = 'amazon-reviews-feature-group-' + strftime('%d-%H-%M-%S', gmtime())</pre></li>
				<li>然后我们定义一个处理步骤，将数据输入设置为第一个处理作业的输出。为了说明步骤链接，我们定义一个指向脚本保存的文件的输出，该文件包含特性组的名称:<pre>step_ingest = ProcessingStep(     name='ingest-customer-reviews',     processor=sklearn_processor,     inputs=[        ProcessingInput(        source=         step_process.properties.ProcessingOutputConfig         .Outputs['fs_data'].S3Output.S3Uri,        destination="/opt/ml/processing/input")],     outputs = [        ProcessingOutput(        output_name='feature_group_name',        source='/opt/ml/processing/output/')],     code='ingesting.py',     job_arguments=[        '--region', region,        '--bucket', bucket,        '--role', role,        '--feature-group-name', feature_group_name,        '--max-workers', '32'] )</pre></li>
			</ol>
			<p>现在，让我们<a id="_idIndexMarker1464"/>关注<a id="_idIndexMarker1465"/>数据集构建步骤。</p>
			<h2 id="_idParaDest-284"><a id="_idTextAnchor283"/>使用 Amazon Athena 和 SageMaker 处理构建数据集</h2>
			<p>我们<a id="_idIndexMarker1466"/>重用<a id="_idIndexMarker1467"/>我们在<a href="B17705_10_Final_JM_ePub.xhtml#_idTextAnchor206"> <em class="italic">第十章</em> </a> ( <code>querying.py</code>)中编写的<a id="_idIndexMarker1468"/>处理脚本<a id="_idIndexMarker1469"/>。</p>
			<p>我们将输入设置为摄取步骤的输出，以便检索<a id="_idIndexMarker1470"/>特征<a id="_idIndexMarker1471"/>组的名称。我们<a id="_idIndexMarker1472"/>还为训练和验证数据集定义了两个<a id="_idIndexMarker1473"/>输出:</p>
			<pre>step_build_dataset = ProcessingStep(
    name='build-dataset',
    processor=sklearn_processor,
    inputs=[
      ProcessingInput(
        source=
          step_ingest.properties.ProcessingOutputConfig
          .Outputs['feature_group_name'].S3Output.S3Uri,
        destination='/opt/ml/processing/input')],
    outputs=[
      ProcessingOutput(
        output_name='training',
        source='/opt/ml/processing/output/training'),
      ProcessingOutput(
        output_name='validation',               
        source='/opt/ml/processing/output/validation')],
      code='querying.py',
      job_arguments=[
        '--region', region,
        '--bucket', bucket,]
)</pre>
			<p>现在，让我们进入培训阶段。</p>
			<h2 id="_idParaDest-285"><a id="_idTextAnchor284"/>训练一个模特</h2>
			<p>这里没有惊喜:</p>
			<ol>
				<li value="1">我们为这个作业定义了一个<code>Estimator</code>模块:<pre>container = image_uris.retrieve(     'blazingtext',      str(region))     # region is a ParameterString prefix = 'blazing-text-amazon-reviews' s3_output = 's3://{}/{}/output/'.format(bucket, prefix) bt = Estimator(container,                role,                instance_count=training_instance_count,                 instance_type=training_instance_type,                output_path=s3_output) bt.set_hyperparameters(mode='supervised')</pre></li>
				<li>然后我们定义训练步骤，传递训练和验证数据集作为输入:<pre>from sagemaker.workflow.steps import TrainingStep from sagemaker.inputs import TrainingInput step_train = TrainingStep(     name='train-blazing-text',     estimator=bt,     inputs={       'train': TrainingInput(s3_data= step_build_dataset.properties.ProcessingOutputConfig .Outputs['training'].S3Output.S3Uri,       content_type='text/plain'),        'validation': TrainingInput(s3_data= step_build_dataset.properties.ProcessingOutputConfig .Outputs['validation'].S3Output.S3Uri,       content_type='text/plain')     } )</pre></li>
			</ol>
			<p>现在，让我们来处理<a id="_idIndexMarker1475"/>模型创建和模型注册步骤(管道中的最后一步)。</p>
			<h2 id="_idParaDest-286"><a id="_idTextAnchor285"/>在 SageMaker 管道中创建和注册模型</h2>
			<p>一旦<a id="_idIndexMarker1476"/><a id="_idIndexMarker1477"/>模型<a id="_idIndexMarker1478"/>被训练，我们<a id="_idIndexMarker1479"/>需要将其创建为 SageMaker 模型，并在模型注册表中注册。</p>
			<ol>
				<li value="1">我们创建模型，传递训练容器和模型工件的位置:<pre>from sagemaker.model import Model from sagemaker.workflow.steps import CreateModelStep model = Model(     image_uri=container,     model_data=step_train.properties                .ModelArtifacts.S3ModelArtifacts,     sagemaker_session=session,     name=model_name,   # workflow parameter     role=role) step_create_model = CreateModelStep(     name='create-model',     model=model,     inputs=None)</pre></li>
				<li>然后，我们在模型注册中心注册模型，为<a id="_idIndexMarker1482"/>部署传递允许的实例<a id="_idIndexMarker1480"/>类型<a id="_idIndexMarker1481"/>列表，作为<a id="_idIndexMarker1483"/>以及批准状态。我们将它关联到一个模型包组，这个模型包组将保存这个模型，以及我们将来训练的进一步版本:<pre>from sagemaker.workflow.step_collections import RegisterModel step_register = RegisterModel(     name='register-model',     estimator=bt,     model_data=step_train.properties.ModelArtifacts                .S3ModelArtifacts,     content_types=['text/plain'],     response_types=['application/json'],     inference_instances=['ml.t2.medium'],     transform_instances=['ml.m5.xlarge'],     model_package_group_name='blazing-text-on-amazon-customer-reviews-package',     approval_status=model_approval_status )</pre></li>
			</ol>
			<p>现在所有的步骤都已经定义好了，所以让我们将它们组装到一个管道中。</p>
			<h2 id="_idParaDest-287"><a id="_idTextAnchor286"/>创建管道</h2>
			<p>我们简单地把<a id="_idIndexMarker1484"/>所有的步骤和它们的参数放在一起。然后，我们创建管道(或者更新它，如果它以前存在的话):</p>
			<pre>from sagemaker.workflow.pipeline import Pipeline
pipeline_name = 'blazing-text-amazon-customer-reviews'
pipeline = Pipeline(
    name=pipeline_name,
    parameters=[region, processing_instance_type, processing_instance_count, training_instance_type, training_instance_count, model_approval_status, input_data, model_name],
    steps=[step_process, step_ingest, step_build_dataset, step_train, step_create_model, step_register])
pipeline.upsert(role_arn=role)</pre>
			<p>我们都准备好了。让我们运行我们的管道！</p>
			<h2 id="_idParaDest-288"><a id="_idTextAnchor287"/>运行管道</h2>
			<p>启动一个管道执行只需要一行代码:</p>
			<ol>
				<li value="1">我们给数据位置和模型名称参数赋值(其他的有默认值):<pre>execution = pipeline.start(     parameters=dict(         InputData=input_data_uri,         ModelName='blazing-text-amazon-reviews') )</pre></li>
				<li>In SageMaker Studio, we go <strong class="bold">SageMaker resources</strong> / <strong class="bold">Pipelines</strong>, and we see the pipeline executing, as shown in the next screenshot:<div><img src="img/B17705_12_20.jpg" alt="Figure 12.20 – Executing a pipeline&#13;&#10;" width="1086" height="423"/></div><p class="figure-caption">图 12.20–执行管道</p><p>一个半小时后，管道完成了，如下图所示:</p><div><img src="img/B17705_12_21.jpg" alt="Figure 12.21 – Visualizing a pipeline&#13;&#10;" width="907" height="598"/></div><p class="figure-caption">图 12.21–可视化管道</p></li>
				<li>Finally, for each step of the pipeline, we can see the lineage of all artifacts: <pre>from sagemaker.lineage.visualizer import LineageTableVisualizer
viz = LineageTableVisualizer(session)
for execution_step in reversed(execution.list_steps()):
    print(execution_step)
display(viz.show(
    pipeline_execution_step=execution_step))</pre><p>例如，下图显示了训练步骤的<a id="_idIndexMarker1487"/>输出。我们可以准确地看到哪些数据集和哪个容器用于训练模型:</p></li>
			</ol>
			<div><div><img src="img/B17705_12_22.jpg" alt="Figure 12.22 – Viewing the lineage for the training step&#13;&#10;" width="901" height="261"/>
				</div>
			</div>
			<p class="figure-caption">图 12.22–查看培训步骤的沿袭</p>
			<p>让我们看看如何部署这个模型。</p>
			<h2 id="_idParaDest-289"><a id="_idTextAnchor288"/>从模型注册中心部署模型</h2>
			<p>进入<a id="_idIndexMarker1488"/>到<strong class="bold">sage maker resources</strong>/<strong class="bold">Model registry</strong>，我们<a id="_idIndexMarker1489"/>也看到该型号已经在 Model registry 注册，如下图截图所示。如果我们训练模型的进一步版本，它们也会出现在这里:</p>
			<div><div><img src="img/B17705_12_23.jpg" alt="Figure 12.23 – Viewing a model in the model registry&#13;&#10;" width="973" height="493"/>
				</div>
			</div>
			<p class="figure-caption">图 12.23–在模型注册表中查看模型</p>
			<p>由于它的状态是<code>Pending</code>，所以暂时不能部署。我们需要将其更改为<a id="_idIndexMarker1490"/>中的<code>Approved</code>，以便允许部署。这是一种安全的方式<a id="_idIndexMarker1491"/>来保证在所有适当的测试完成后，只部署好的模型。</p>
			<p>我们右键单击模型并选择<code>Approved</code>。我们还注意到型号 ARN，它在<strong class="bold">设置</strong>选项卡中可见。</p>
			<p>现在，我们可以部署和测试该模型:</p>
			<ol>
				<li value="1">回到我们的 Jupyter 笔记本，我们创建了一个<code>ModelPackage</code>对象，指向我们想要部署的模型版本:<pre>from sagemaker import ModelPackage model_package_arn = 'arn:aws:sagemaker:eu-west-1:123456789012:model-package/blazing-text-on-amazon-customer-reviews-package/1' model = sagemaker.ModelPackage(     role = role,     model_package_arn = model_package_arn)</pre></li>
				<li>我们照例称<code>deploy()</code>:<pre>model.deploy(     initial_instance_count = 1,     instance_type = 'ml.t2.medium',     endpoint_name='blazing-text-on-amazon-reviews')</pre></li>
				<li>We <a id="_idIndexMarker1492"/>create a <code>Predictor</code> and send a test <a id="_idIndexMarker1493"/>sample for prediction:<pre>from sagemaker.predictor import Predictor
bt_predictor = Predictor(
    endpoint_name='blazing-text-on-amazon-reviews',
    serializer=
        sagemaker.serializers.JSONSerializer(),       
    deserializer=
        sagemaker.deserializers.JSONDeserializer())
instances = [' I really love this camera , it takes amazing pictures . ']
payload = {'instances': instances, 
           'configuration': {'k': 3}}
response = bt_predictor.predict(payload)
print(response)</pre><p>这将打印出所有三个类别的概率:</p><pre><strong class="bold">[{'label': ['__label__positive__', '__label__neutral__', '__label__negative__'],</strong>
<strong class="bold">'prob': [0.9999945163726807, 2.51355941145448e-05, 1.0307396223652177e-05]},</strong></pre></li>
				<li>Once we're done, we can delete the endpoint. <p class="callout-heading">注意</p><p class="callout">对于完全清理，您还应该删除管道、特征存储和模型包组。你会在 GitHub 资源库中找到一个清理笔记本。</p></li>
			</ol>
			<p>如您所见，SageMaker Pipelines 为您提供了强大的工具来构建、运行和跟踪端到端的机器学习工作流。这些工具被很好地集成到了 SageMaker Studio 的<a id="_idIndexMarker1494"/>中，这将有助于你提高工作效率，更快地获得生产中的高质量模型</p>
			<h1 id="_idParaDest-290"><a id="_idTextAnchor289"/>总结</h1>
			<p>在本章中，您首先学习了如何使用 AWS CloudFormation 部署和更新端点。您还看到了如何使用它来实现金丝雀部署和蓝绿色部署。</p>
			<p>然后，您了解了 AWS CDK，这是一个专门构建的 SDK，用于使用各种编程语言轻松生成和部署 CloudFormation 模板。</p>
			<p>最后，您使用 AWS Step 函数和 Amazon SageMaker 管道构建了完整的端到端机器学习工作流。</p>
			<p>在下一章也是最后一章，您将了解 SageMaker 的其他功能，这些功能可以帮助您优化预测的成本和性能。</p>
		</div>
	</div>
</body></html>