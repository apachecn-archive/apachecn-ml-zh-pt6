<title>B18024_02_ePub</title>

# 第二章:功能商店解决什么问题？

在上一章中，我们讨论了**机器学习** ( **ML** )生命周期中的不同阶段，ML 的困难和耗时阶段，以及我们离理想世界有多远。在这一章中，我们将探索 ML 的一个领域，即 ML 特征管理。ML 特征管理是创建特征、将它们存储在持久存储器中、并大规模地用于模型训练和推理的过程。这是 ML 最重要的阶段之一，尽管它经常被忽视。在 ML 早期阶段的数据科学/工程团队中，特性管理的缺乏是将他们的 ML 模型投入生产的主要障碍。

作为一名数据科学家/ML 工程师，您可能已经找到了存储和检索 ML 模型特征的创新方法。但大多数情况下，我们构建的解决方案是不可重用的，并且每个解决方案都有局限性。例如，我们中的一些人可能使用 S3 存储桶来存储特性，而团队中的其他数据科学家可能使用事务数据库。一个人可能更喜欢使用 CSV 文件，而另一个人可能更喜欢使用 Avro 或 Parquet 文件。由于个人偏好和缺乏标准化，每个模型可能有不同的特性管理方式。另一方面，良好的特性管理应该做到以下几点:

*   使功能可被发现
*   导致模型易于再现
*   加速模型开发和生产
*   在团队内部和团队之间重用特性
*   简化功能监控

本章的目的是解释数据科学家和工程师如何努力实现更好的功能管理，但仍达不到预期。我们将回顾团队采用的将特性引入生产的不同方法，这些方法的常见问题，以及我们如何利用特性库做得更好。在本章结束时，你将理解一个特性库如何满足前面提到的目标，并提供跨团队的标准化。

在本章中，我们将讨论以下主题:

*   特性在生产中的重要性
*   将功能引入生产的方法
*   将功能引入生产的方法的常见问题
*   拯救特色商店
*   特色商店背后的理念

# 特性在生产中的重要性

在讨论如何将特性引入生产之前，让我们了解一下为什么生产中需要特性。我们来看一个例子。

我们经常使用出租车和送餐服务。这些服务的好处之一是，它们会告诉我们出租车或食物需要多长时间才能到达。此外，在大多数情况下，它是近似正确的。它是如何准确预测这一点的？它用的当然是 ML。ML 模型预测出租车或食物到达的时间。像这样的模型要想成功，不仅需要好的特征工程和 ML 算法，还需要最新的特征。虽然我们不知道模型使用的确切特性集，但是让我们来看几个动态变化并且非常重要的特性。

对于食品配送服务，影响配送时间的主要因素是餐馆、司机、交通和顾客。该模型可能使用一组定期更新(可能是每天或每周)的缓慢变化的特性，以及一组每隔几分钟就变化的动态特性。缓慢变化的功能可能包括餐厅在一天的不同时间从应用程序和亲自收到的平均订单数量，订单准备就绪的平均时间，等等。看起来这些功能变化并不缓慢，但是仔细想想，平均订单数量可能会因餐厅位置、季节性、一天中的时间、一周中的日期等因素而有所不同。动态特性包括最近五个订单花了多长时间，过去 30 分钟内取消的数量，以及餐馆的当前订单数量。类似地，司机特征可能包括相对于距离的平均订单交付时间、司机取消订单的频率以及司机是否接多个订单。除了这些特征之外，还会有交通特征，其变化更加动态。

随着许多动态特征的发挥，即使其中一个是一个小时前的，模型的预测也会超出图表。例如，如果配送路线上发生了交通事故，而交通特征没有捕捉到它并将其用于推断，则该模型将预测食物到达的速度会比实际速度更快。同样，如果模型无法获得餐馆的当前订单数，它将使用旧值，并预测一个可能与事实相差甚远的值。因此，一个模型的最新特征越多，预测就越准确。还有，另一件要记住的事情是，应用程序不会给出特性；该应用程序只能给出餐厅 ID 和客户 ID 等信息。该模型将不得不从不同的位置获取特性和事实，理想情况下是一个特性存储。无论从何处获取功能，为其提供服务的基础架构都必须根据流量进行扩展和缩小，以高效利用资源，并以极低的错误率(如果有)以低延迟满足请求。

就像食品配送服务一样，我们在第一章中建立的模型在推理过程中需要这些特征，这些特征越新，客户的**终身价值** ( **LTV** )预测就越好。好的预测会导致更好的行动，带来出色的客户体验，从而更好地吸引客户，并带来更好的业务。

# 将功能引入生产的方法

既然我们已经理解了生产中对特性的需求，那么让我们来看看将特性引入生产的一些传统方法。让我们考虑两种类型的管道:批处理模型管道和在线/事务模型管道:

*   **批处理模型**:这些是按计划运行的模型，比如每小时、每天、每周等等。两种常见的批处理模型是预测和客户细分。批量推理比它的对应物更容易，更简单，因为它没有任何延迟要求；推理可以持续几分钟或几小时。批处理模型可以使用分布式计算框架，如 Spark。此外，它们可以通过简单的基础设施运行。大多数 ML 模型开始是批处理模型，随着时间的推移，根据可用的基础设施和需求，它们会变成在线/事务模型。

尽管批量模型的基础设施易于构建和管理，但这些模型也有缺点，比如预测并不总是最新的。由于预测存在时滞，这可能会影响业务。例如，假设一家制造厂使用订单预测模型来获取原材料。根据批量预测模型的时间延迟，企业可能需要承担原材料短缺的成本，而不是仓库中原材料的积压。

*   **在线/交易模型**:在线模型遵循拉模式；预测将按需生成。在线模型利用当前的现实，并将其用于预测。在线模式是事务性的，需要低延迟服务，并且应该根据传入流量进行扩展。典型的在线模型是推荐模型，可以是产品推荐、设计推荐等等。

尽管实时预测听起来很新奇，但在线模型面临着一系列不同的挑战。构建延迟为 8 小时的应用程序比构建延迟为 100 毫秒的应用程序更容易。在线模型的延迟通常以毫秒计。这意味着模型有几毫秒的时间来计算出最新的值是什么(这意味着为模型生成或获取最新的功能)并预测结果。为了实现这一点，模型需要一个支持基础设施来提供预测所需的数据。在线模型通常作为 REST API 端点托管，这同样需要伸缩、监控等等。

既然我们已经理解了批处理模型和在线模型之间的区别，那么让我们来看看批处理模型管道是如何工作的。

## 批量模型流水线

如前所述，批处理模型流水线的延迟需求可能从几分钟到几小时不等。批处理模型通常按计划运行，因此它们将使用诸如 Airflow 或 AWS Step 函数等工具进行编排。让我们来看一个典型的批量模型流水线，以及特性是如何被引入生产的。

*图 2.1* 描绘了典型的批量模型管道:

![Figure 2.1 – Batch model pipelines
](img/B18024_02_01.jpg)

图 2.1–批量模型管道

正如在 [*第一章*](B18024_01_ePub.xhtml#_idTextAnchor014) *中所讨论的，机器学习生命周期概述*，一旦模型开发完成并准备好投入生产，笔记本将被重构以删除不需要的代码。一些数据工程师还将单个笔记本分解成多个逻辑步骤，例如特征工程、模型训练和模型预测。重构笔记本或从笔记本生成的重构 Python 脚本使用编排框架(如 Airflow)进行调度。在一个典型的管道中，第一阶段将从不同的数据源读取原始数据，执行数据清理，并执行特征工程，这些数据将被管道中的后续阶段使用。一旦模型预测阶段完成，预测输出将被写入持久性存储，可能是数据库或 S3 存储桶。当需要时，将从永久存储器中访问结果。如果管道中的某个阶段由于某种原因(如数据可访问性问题或代码中的错误)失败，管道将被设置为触发警报并停止进一步执行。

如果您还没有注意到，在批处理模型管线中，特征是在管线运行时生成的。在某些情况下，它还使用最新数据重新训练新模型，而在其他情况下，它使用以前训练的模型，并使用管道运行时可用数据生成的特征进行预测。正如您在*图 2.1* 中看到的，构建的每个新模型都从原始数据源开始，重复相同的步骤，并加入生产管道列表。我们将在后面的部分讨论这种方法中的问题。接下来，让我们看看在在线模型中将功能引入生产的不同方式。

## 在线模型管道

在线模型具有近实时服务特性的特殊要求，因为这些模型面向客户或者需要实时做出业务决策。在在线模型中，有不同的方法将特性引入生产。让我们在本节中逐一讨论它们。要记住的一点是，这些方法并不完全是每个人都这样做的；它们仅仅是群体方法的代表。不同的团队使用这些方法的不同版本。

### 将功能与模型一起打包

要部署一个在线模型，必须首先对其进行打包。同样，根据团队使用的工具，他们遵循不同的标准。有些可能使用 MLflow、joblib 或 ONNX 等打包库。其他人可能会将模型直接打包成 REST API Docker 映像。由于数据科学家和数据工程师拥有不同的技能，正如第 1 章 *的*图 1.1* 中提到的，机器学习生命周期概述*，理想的方法是为数据科学家提供工具，使用 MLflow、joblib 和 ONNX 等库打包模型，并将模型保存到模型注册表中。然后，数据工程师可以使用注册的模型来构建 REST APIs 并部署它。也有现成的支持，通过简单的**命令行界面** ( **CLI** )命令将 MLflow 打包的模型部署为 AWS SageMaker 端点。它还支持使用 CLI 命令构建 REST API Docker 映像，然后可以将其部署在任何容器环境中。

虽然 MLflow 和 joblib 等库提供了打包 Python 对象的方法，但它们也支持在需要时添加额外的依赖项。例如，MLflow 提供了一组内置的风格来支持使用 ML 库(如 scikit-learn、PyTorch、Keras 和 TensorFlow)对模型进行打包。它为 ML 库添加了所有必需的依赖项。使用内置风格打包模型就像使用下面的代码一样简单:

```
mlflow.<MLlib>.save_model(model_object)
```

```
## example scikit-learn
```

```
mlflow.sklearn.save_model(model_object)
```

连同所需的依赖项，您可以打包`features.csv`文件，并将其加载到模型的`predict`方法中。虽然这听起来像是一个简单的部署选项，但其结果离批处理模型不远了。因为特征是与模型一起打包的，所以它们是静态的。原始数据集中的任何更改都不会影响模型，除非使用根据最新数据生成的一组新要素构建新版本的模型，并与模型一起打包。然而，这可能是从批量模型到在线模型的第一步。我这样说的原因是，你现在已经把它变成了一个基于拉动的推理，而不是作为一个批处理模型来运行。此外，您已经为模型的消费者定义了 REST 端点输入和输出格式。唯一悬而未决的步骤是获得模型的最新特征，而不是打包的静态特征。一旦实现了这一点，模型的消费者将不必进行任何更改，消费者将获得使用最新可用数据的预测。

### 基于推送的推理

与基于拉的推理不同，在基于推的推理模式中，预测是主动运行的，并在事务数据库或键值存储中保持就绪，以便在请求到来时可以以低延迟提供服务。让我们看看使用基于推的推理的在线模型的典型架构:

![Figure 2.2 – Push-based inference
](img/B18024_02_02.jpg)

图 2.2-基于推送的推理

*图 2.2* 显示了基于推的推理的架构。这里的想法类似于批处理模型推理，但不同的是，管道还考虑了实时数据集，它是动态变化的。基于推的模型的操作如下:

*   实时数据(在本例中，用户与网站的交互)将被捕获并推送到一个队列，如 Kafka、Kinesis 或 Event Hubs。
*   特征工程管线根据生成模型特征所需的数据，订阅一组特定的主题或一组特定的队列。这也取决于工具和架构。根据应用程序的规模/多样性，可能有单个队列或多个队列。
*   Whenever an event of interest appears in the queue, the feature engineering pipeline will pick this event and regenerate the features of the model using other datasets.

    注意

    并非所有功能都是动态的。有些功能可能不会改变太多或太频繁。例如，客户的地理位置可能不会经常改变。

*   新生成的特征用于运行数据点的预测。
*   结果存储在事务数据库或键值存储中。
*   每当需要时，网站或应用程序将查询数据库以获得特定 ID 的新预测(例如在网站上为客户提供推荐时的`CustomerId`)。
*   每当一个新的感兴趣的事件出现在队列中时，就重复这个过程。
*   将为每个新的 ML 模型添加一个新的管道。

这种方法看起来简单明了，因为这里唯一的额外要求是实时流数据。然而，这有局限性；整个管道必须在几毫秒内运行，以便在应用程序进行下一次预测查询之前可以获得建议。这是可以实现的，但可能会涉及更高的运营成本，因为这不仅仅是一个管道:实时模型的每个管道都必须有类似的延迟要求。此外，这不是一个复制粘贴的基础设施，因为每个模型在传入流量方面都有不同的要求。例如，处理订单功能的模型可能需要较少的处理实例，而处理点击流数据的模型将需要更多的数据处理实例。需要记住的另一件事是，尽管看起来他们是在向同一个数据库写入数据，但大多数时候，这涉及到不同的数据库和不同的技术。

接下来让我们看看更好的解决方案。

### 基于拉动的推理

在中，与基于推的推理相反，在基于拉的推理中，预测在请求时运行。特定模型的功能集存储在事务数据库或键值存储中，而不是存储预测。在预测期间，可以低延迟地访问特征集。让我们来看看基于拉的推理模型的典型架构和涉及的组件:

![Figure 2.3 – Using transactional/key-value store for features
](img/B18024_02_03.jpg)

图 2.3–为特性使用事务/键值存储

*图 2.3* 显示了将功能引入生产的另一种方式:基于拉动的机制。一半管道的工作方式类似于我们刚刚讨论的基于推送的推理。这里的区别在于，在特性工程之后，特性被写入事务数据库或键值存储。这些功能将通过管道保持最新。一旦功能可用，模型的工作方式如下:

1.  模型的`predict` API 将有一个类似于这里提到的契约:

    ```
    def predict(entity_id: str) -> dict
    ```

2.  当应用程序需要查询模型时，它会用`entity_id`命中 REST 端点。
3.  模型将使用`entity_id`来查询键值存储，以获得对模型进行评分所需的特征。
4.  这些特征用于对模型进行评分并返回预测值。

如果您没有功能商店基础设施，这种方法是理想的。同样，我们将在下一章详细讨论这一点。同样，这种方法涉及到一些问题，包括重复工作、部署和扩展特性工程管道、管理多个键值存储基础设施等等。

### 按需计算要素

在我们继续讨论这些方法的问题之前，让我们讨论最后一种方法。在目前讨论的方法中，数据管道在数据到达时或管道运行时主动计算特征。然而，当有推理请求时，可以按需计算特征。这意味着当应用程序向模型查询预测时，模型将向另一个系统请求这些特性。该系统使用来自不同来源的原始数据，并按需计算特征。这可能是最难实现的架构，但我在 Sam Charrington 的 TWIML AI 播客中听说，网飞有一个系统可以在几秒钟的延迟内按需生成功能。

`predict` API 可能看起来类似于最后一种方法:

def predict(entity_id: str) ->字典

然后，它调用系统来获取给定实体的特性，使用这些特性运行预测，并返回结果。可以想象，所有这一切都将在几秒钟内发生。要实时执行的按需特征工程可能需要在不同存储系统之间具有多个缓存的巨大基础设施。保持这些系统同步不是一个简单的架构设计。对于我们大多数人来说，这只是一个梦想中的基础设施。目前为止我还没见过。希望我们能很快到达那里。

在这一节中，我们讨论了将特性引入生产进行推理的多种方法。可能有许多其他方法可以实现这一点，但是大多数解决方案都是围绕这些方法之一的变体。既然我们已经理解了为什么以及如何将特性引入到生产中，那么让我们来看看这些方法的共同问题以及如何克服它们。

# 将功能引入生产的方法的常见问题

上一节讨论的方法似乎是不错的解决方案。然而，不仅每种方法都有自己的技术难点，如基础设施规模、符合服务级别协议(SLA)以及与不同系统的交互，而且它们还有一些共同的问题。这在不断发展的技术领域中是可以预期的，直到它达到饱和水平。我想把这一节专门用来讨论这些方法中存在的常见问题。

## 重新发明轮子

工程中的一个常见问题是建造已经存在的东西。原因可能有很多；例如，开发解决方案的人可能不知道它已经存在，或者现有的解决方案效率低下，或者需要额外的功能。我们这里也有同样的问题。

在许多组织中，数据科学家在特定领域工作，并有一个团队支持他们，通常包括 ML 工程师、数据工程师和数据分析师。他们的目标是将模型投入生产。尽管并行工作的其他团队也有将他们的模型投入生产的目标，但是由于他们的时间表和交付时间表，他们很少相互协作。正如在第一章中所讨论的，团队中的每个角色都有不同的技能集，不同的可用工具经验水平，以及不同的偏好。此外，两个不同团队的数据工程师很少有相同的偏好。这导致每个团队找到生产他们的模型的解决方案，这包括构建特征工程管道、特征管理、模型管理和监控。

在想出一个成功的解决方案后，即使团队(姑且称之为团队 A)与其他团队分享他们的知识和成功，你得到的回应也会是*很高兴知道*、*有趣*、*对我们有用*。但它永远不会在其他团队的解决方案中实现。原因并不是其他团队对 A 队的成绩漠不关心。除了知识之外，团队 A 构建的东西在很多情况下都是不可重用的。留给其他团队的选择是复制代码，并根据他们的需要进行调整，希望它能够工作，或者实现一个类似的管道。因此，大多数团队最终都会为模型构建他们自己的解决方案。有趣的是，在大多数情况下，即使是团队 A 也会为他们正在开发的下一个模型重建相同的管道。

## 特征重新计算

先说一个问题。这样问自己:*你的手机有多少内存？很可能你已经记住了答案。如果你不确定，你可以在设置中检查内存并回答。无论哪种方式，如果我或其他人在一个小时内问你同样的问题，我很肯定你不会在回答之前回到手机的设置并再次检查，除非你已经换了手机。那么，为什么我们要在所有的 ML 管道中这样做呢？*

当你回头看前面讨论的方法时，它们都有这个共同的问题。假设团队 A 刚刚成功完成了一个客户 LTV 模型，并将其投入生产。现在，团队 A 被分配了另一个项目，即预测客户的下一个购买日。在客户 LTV 模型中有效的特性在这里也很有可能有效。尽管这些特征被周期性地计算以支持生产模型，但是 team-A 将从原始数据开始，从头开始计算这些特征，并将它们用于模型开发。不仅如此，他们复制了整个管道，尽管有重叠。

作为这种重新计算的结果，根据团队 A 使用的设置和工具，他们将浪费计算、存储和工时，而通过更好的特性管理，团队 A 可以在新项目上领先一步，这也是一种经济高效的解决方案。

## 功能可发现性和共享性

如前所述，问题之一是同一个团队内的重新计算。这个问题的另一部分甚至更大。这是跨团队和领域的重新计算。就像在*重新发明轮子*部分一样，团队试图找出如何将 ML 特性引入生产，数据科学家在这里重新发现数据和特性本身。

其中一个主要原因是缺乏信任和可发现性。先说可发现性。正如我们在第一章中所讨论的，每当数据科学家研究一个模型，并在数据挖掘、探索和特征工程方面做了大量工作时，共享它的方式非常有限。数据科学家可以使用电子邮件和演示文稿来做到这一点。然而，任何人都无法发现什么是可用的，并有选择地构建什么是不可用的，并在模型中使用这两者。即使有可能发现科学家工作的其他数据，如果不弄清楚数据访问和重新计算特征，也不可能使用它。

数据发现和特征工程的另一个驱动力是信任。尽管有明显的证据表明存在使用生成特征的生产模型，但数据科学家经常发现很难信任由其他人开发的生成特征的程序。由于原始数据是可信的，因为它有 SLA 和模式验证，所以数据科学家通常会重新发现和生成这些特性。

因此，这里需要的解决方案是一个可以使其他人生成的特性可被发现、可共享，最重要的是，可信任的应用程序，也就是说，一个人/团队拥有并管理他们生成的特性。

## 训练 vs 发球歪斜

ML 中的另一个常见问题是训练和服务的偏斜。当用于生成用于模型训练的特征的特征工程代码不同于用于生成用于模型预测/服务的特征的代码时，会发生这种情况。这可能有许多原因；例如，在模型培训期间，数据科学家可能使用 PySpark 来生成特征，而在生产管道时，接手的 ML/数据工程师使用了生产基础设施所需的不同技术。这个问题不大。一个是，有两个版本的特征工程代码，另一个问题是，这可能导致训练与服务的偏差，因为对于相同的原始数据输入，两个版本的管道生成的数据可能不相同。

## 模型再现性

模型再现性是 ML 中要解决的常见问题之一。我听说过一个故事，一个数据科学家辞职后，他正在研究的模型丢失了，他的团队无法多次重现该模型。其中一个主要原因是缺少特性管理工具。您可能会问，当您有原始数据的历史记录时，复制相同的模型有什么问题。让我们来看看。

假设有一个数据科学家，Ram，正在研究一个 ML 模型，向客户推荐产品。拉姆花了一个月的时间研究它，想出了一个绝妙的模型。在团队中数据工程师的帮助下，该模型被部署到生产中。但拉姆在这份工作中没有受到足够的挑战，所以他辞职了，去了另一家公司。不幸的是，生产系统崩溃了，Ram 没有遵循将模型保存到注册表中的 MLOps 标准，因此模型丢失了并且无法恢复。

现在，重建模型的责任交给了团队中的新数据科学家 Dee，他很聪明，使用 Ram 使用的相同数据集，并执行相同的数据清理和功能工程，就好像 Dee 是 Ram 的转世。不幸的是，迪伊的模型不能得到和拉姆一样的结果。无论迪伊尝试多少次，她都无法复制这个模型。

其中一个原因是数据随时间发生了变化，这反过来会影响特性值，进而影响模型。没有办法回到过去生产第一次使用的相同特征。由于模型再现性/可重复性是 ML 的一个重要方面，我们需要时间旅行。这意味着数据科学家应该能够回到过去，获取过去特定时间的特征，就像在*复仇者联盟 4：终局之战*中一样，这样模型就可以一致地重现。

## 低延迟

所有方法都试图解决的另一个问题是低延迟特性服务。以低延迟提供特性的能力决定了模型是可以作为在线模型还是批处理模型来托管。这存在一些问题，如构建和管理基础架构以及保持功能最新。因为将所有的模型都设置为事务性的是没有意义的，同时在一个批处理模型中使用的一个特性很有可能在一个不同的在线模型中非常有用。因此，开启和关闭低延迟服务的能力对数据科学家来说是一大优势。

到目前为止，在本节中，我们已经讨论了前一节中讨论的方法的一些常见问题。仍然没有答案的问题是，我们能做些什么来改善这种情况？现在有没有一个或一组工具可以帮助我们解决这些常见的问题？事实证明，答案是*是的*，有一个工具可以解决我们到目前为止谈到的所有问题。它被称为*特征库*。在下一部分，让我们看看什么是功能商店，它们如何解决这些问题，以及它们背后的哲学。

# 特色店来救场

让我们从特性库的定义开始这一部分。一个**特征库**是一个操作数据系统，用于管理和为生产中的模型提供 ML 特征。它可以从低延迟在线商店(用于实时预测)或离线商店(用于横向扩展批量评分或模型训练)向模型提供特征数据。正如定义所指出的，它是一个完整的包，帮助您创建和管理 ML 特性，并加速模型的可操作化。在我们深入特性库之前，让我们看看 ML pipelines 的架构如何随着特性库的引入而改变:

![Figure 2.4 – ML pipelines with a feature store
](img/B18024_02_04.jpg)

图 2.4–带功能库的 ML 管道

*图 2.4* 描述了包含特征库时的 ML 管道架构。你可能认为*图 2.4* 看起来和*图 2.3* 一样，我只是用一个更大的数据存储替换了一堆小数据存储，并称之为特性存储。是的，可能看起来是这样，但是还有更多。与传统的数据存储不同，功能存储具有一组特殊的功能；它不是一个数据存储，而是一个数据系统(如其定义所述)，它能做的不仅仅是存储和检索。

由于特性商店是 ML 管道的一部分，因此整个管道是这样工作的:

1.  一旦数据科学家有了问题陈述，出发点将不再是原始数据。这将是一个功能商店。
2.  数据科学家将连接到要素存储，浏览存储库，并使用感兴趣的要素。
3.  如果这是第一个模型，功能存储可能为空。从这里开始，数据科学家将进入发现阶段，找出数据集，构建要素工程管道，并将要素纳入要素存储。特征存储将特征工程管线与 ML 中的其余阶段分离。
4.  如果特征存储不为空，但是特征存储中没有足够的可用特征，则数据科学家将发现感兴趣的数据，并且将添加另一个特征工程管道，以将新的一组特征汇集到特征存储中。这种方法使这些功能可用于数据科学家正在处理的模型，以及发现这些功能在其模型中有用的其他数据科学家。
5.  一旦数据科学家对特性集感到满意，就会对模型进行训练、验证和测试。如果模型性能不好，数据科学家将返回去发现新的数据和特征。
6.  当模型准备好被部署时，模型的`predict`方法将包含代码来获取生成模型预测所需的特性。
7.  如果是在线模型，ready 模型将被部署为 REST 端点；否则，它将用于执行批量预测。

现在我们已经了解了管道是如何工作的，让我们仔细研究一下我们在上一节中讨论的问题，并了解特性存储是如何解决这些问题的。

## 用特征库标准化 ML

一旦功能存储在团队层面实现了标准化，尽管可能会有不同的读取数据和构建功能工程管道的方式，但在功能工程之外，管道的其余部分将成为标准实现。ML 工程师和数据科学家不需要想出新的方法来将特性引入生产。在特征工程之后，数据科学家和 ML 工程师将特征吸收到特征存储中。根据定义，特征存储可以以低延迟提供特征。在那之后，ML 工程师所要做的就是更新他们的`predict`方法，从特征库中获取所需的特征并返回预测。这不仅使 ML 工程师的生活变得容易，有时还减轻了管理特性管理基础设施的负担。

## 特征库避免重复处理数据

正如定义中提到的，一个特征店有一个线下店，线下店的数据可以检索出来进行模型训练或者批量推断。这里的模特训练不是指训练同一个模特。吸收到特征存储中的特征可以用于另一个模型的训练。

让我们以讨论这个问题时使用的同一个例子为例:团队 A 刚刚完成了客户 LTV 模型的生产部署。团队 A 开始工作的下一个模型是预测下一个购买日期。当数据科学家开始研究这个模型时，他们不必回到原始数据，重新计算用于构建客户 LTV 模型的特征。数据科学家可以连接到特征库，该特征库正在使用先前模型的最新特征进行更新，并获取训练新模型所需的特征。然而，数据科学家将不得不为他们从原始数据中发现的有用的附加特征建立数据清理和特征工程管道。同样，新添加的特性可以在下一个模型中重用。这使得模型开发高效且具有成本效益。

## 功能可被发现，并可与功能商店共享

在前面的段落中，我们讨论了在团队中特性的重用。要素存储有助于数据科学家实现这一目标。另一个主要问题是由于缺乏特性可发现性，跨团队重新计算和重新发现有用的数据和特性。你猜怎么着？特色商店也解决了这个问题。数据科学家可以连接到要素存储并浏览现有要素表和模式。如果他们发现任何现有的功能有用，数据科学家可以在模型中使用它们，而无需重新发现或重新计算它们。

分享的另一个问题是信任。虽然功能商店没有完全解决这个问题，但它们在一定程度上解决了这个问题。由于功能表是由一个团队创建和管理的，因此数据科学家可以随时联系所有者以获得访问权限并讨论其他方面，如 SLA 和监控。如果你还没有注意到，特性存储促进了团队之间的协作。这对两个团队都有好处，来自不同团队的数据科学家和 ML 工程师一起工作，分享彼此的专业知识。

没有更多的训练对发球歪斜

有了功能存储，培训与服务之间的偏差将永远不会发生。一旦特征工程完成，特征将被吸收到特征存储中，并且特征存储是模型训练的来源。因此，数据科学家将使用特征库中的特征来训练 ML 模型。一旦模型定型并投入生产，生产模型将再次获取在线商店或历史商店以进行模型预测。由于训练和预测都使用这些功能，所以服务是由相同的管道/代码生成的，我们在功能存储中永远不会遇到这个问题。

特征存储的模型再现性

之前讨论的架构的另一个主要问题是模型的可重复性。这是一个问题:数据经常变化，这反过来导致特征变化，从而导致模型变化，尽管使用相同的特征集来构建模型。解决这个问题的唯一方法是回到过去，获取产生旧模型的相同状态数据。这可能是一个非常复杂的问题，因为它将涉及多个数据存储。但是，以允许数据科学家进行时间旅行的方式存储生成的要素是可能的。

是的，这正是功能商店所做的。功能商店有一个离线商店，它存储历史数据，并允许用户及时返回并获取特定时间点的功能值。通过要素存储，数据科学家可以获取历史上特定时间的要素，因此可以一致地再现模型。模型再现性不再是特征存储的问题。

## 通过功能商店以低延迟提供功能

尽管所有的解决方案都能够以某种方式实现低延迟服务，但这些解决方案并不统一。ML 工程师必须想出一个解决方案来解决这个问题，同时还要构建和管理基础设施。然而，在 ML 管道中有一个特性存储使这变得简单，并且在平台团队管理特性存储的情况下，也将基础设施管理卸载给其他团队。即使没有这些，拥有运行一些命令和低延迟服务和运行的能力对 ML 工程师来说也是一个方便的工具。

# 特色商店背后的理念

在本章中，我们已经讨论了 ML 管道的不同问题，以及特征存储如何帮助数据科学家解决这些问题并加速 ML 开发。在这一节中，让我们试着理解特性存储背后的哲学，并试着理解为什么在 ML 管道中有一个特性存储可能是加速 ML 的理想方式。让我们从一个真实世界的例子开始，因为我们试图用 ML 构建真实世界的体验。你会得到两部手机的名字；你的工作是找出哪一个更好。名字分别是 iPhone 13 Pro 和谷歌 Pixel 6 Pro。你有无限的时间去寻找答案；一旦你有了答案，继续阅读。

正如拉尔夫·沃尔多·爱默生所说，*不是目的地，而是旅程。不管你的答案是什么，不管你花了多长时间得出这个答案，让我们看看你是如何得出这个答案的。你们中的一些人可能会马上得到答案，但是如果你没有使用过这两款手机，你可能会谷歌一下`iPhone 13 Pro vs Google Pixel 6 Pro`。你可能已经浏览了一些链接，这些链接会给你一个手机的比较:*

![Figure 2.5 – iPhone 13 Pro versus Google Pixel 6 Pro 
](img/B18024_02_05.jpg)

图 2.5–iPhone 13 Pro 与谷歌 Pixel 6 Pro 的对比

这是比较两款手机的好方法。你们中的一些人可能会做更多的工作来找到答案，但我相信我们没有人会去买下这两款手机，通读苹果和谷歌提供的规格，使用每款手机一个月，并在回答问题之前成为每款手机的专家。

在这项任务中，我们聪明地利用了其他人的专业知识和工作成果。虽然网上有很多比较，但我们选择了适合我们的那个。不仅在这个任务中，在大多数任务中，从买手机到买房，我们都试图用专家意见来做决定。如果你以某种方式看待它，这些是我们决策的特征。除了专家的意见，我们还包括我们自己的约束和功能，例如预算，如果是电话，内存，如果是汽车，座位数，如果是房子，房间数。我们综合运用这些因素来做出决定并采取行动。在大多数情况下，这种方法是可行的，在某些情况下，我们可能会做更多的研究并成为专家。

在 ML 中使用特色商店是为了达到类似的目的；这就像数据科学家的谷歌。数据科学家正在寻找特定的东西，而不是像谷歌那样的通用搜索，并且还与其他数据科学家分享他们的专业知识。如果功能商店中的可用功能对数据科学家不起作用，他们将去原始数据，探索、理解、成为这方面的专家，并得出关于特定实体(可能是产品、客户等)的显著特征。这种具有特征库的 ML 工作流不仅可以帮助数据科学家利用彼此的专业知识，还可以标准化和加速 ML 开发。

# 总结

在这一章中，我们讨论了 ML 特性管理中的常见问题，生产 ML 模型的不同架构，以及将特性引入生产的方法。我们还探讨了这些方法所涉及的问题，以及特性存储如何通过标准化实践和提供传统数据存储所不具备的附加特性来解决这些问题。

现在我们已经了解了特性存储必须提供什么，在下一章中，我们将接触特性存储，并探索特性存储的术语、特性、典型架构等等。

# 延伸阅读

*   *盛宴文档*:[https://docs.feast.dev/](https://docs.feast.dev/)