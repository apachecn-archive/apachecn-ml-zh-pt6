

# 一、Microsoft 认知服务入门

您刚刚开始了解 Microsoft 认知服务。这一章将作为对这些服务的简要介绍。最终目标是更多地了解这些认知 API 能为您做些什么。在本章结束时，我们将已经创建了一个易于使用的项目模板。你将学会如何检测图像中的人脸，并把人脸的数量反馈给你。

在本章中，我们将涵盖以下主题:

*   了解一些已经在使用 Microsoft 认知服务的应用
*   创建模板项目
*   使用人脸 API 检测图像中的人脸
*   发现微软认知服务可以提供什么
*   使用 Bing 语音 API 进行文本到语音转换



# 以娱乐和改变生活为目的的认知服务

介绍微软认知服务的最佳方式是看它如何被实际应用。微软和其他公司已经创建了许多示例应用来展示其能力。有几个可能看起来很傻，比如 How-Old.net([http://how-old.net/](http://how-old.net/))的图像分析和*如果我是那个人*的应用。这些应用引起了相当大的反响，它们以一种很好的方式展示了一些 API。

然而，一个真正鼓舞人心的演示是一个有视觉障碍的人。会说话的计算机启发他开发了一个应用，让盲人和视力受损的人能够理解他们周围发生的事情。该应用建立在微软认知服务的基础上。它很好地展示了如何使用 API 来改变世界，让世界变得更好。在继续之前，去 https://www.youtube.com/watch?v=R2mC-NUAmMk[看看微软认知服务的世界。](https://www.youtube.com/watch?v=R2mC-NUAmMk)



# 设置样板代码

在我们开始行动之前，我们将进行一些设置。更重要的是，我们将建立一些样板代码，我们将在本书中使用。

要开始，您需要安装一个版本的 Visual Studio，最好是 Visual Studio 2015 或更高版本。社区版可以很好地实现这个目的。除了默认安装所提供的，您不需要任何其他东西。

你可以在 https://www.microsoft.com/en-us/download/details.aspx?[找到 Visual Studio 2017id=48146](https://www.visualstudio.com/downloads/) 。

在本书中，我们将利用不同的 API 来构建智能房屋应用。该应用将被创建来看看一个人可以想象一个未来的房子。如果你看过钢铁侠电影，你可以认为这个应用在某些方面很像 Jarvis。

此外，我们将使用认知 API 来做更小的示例应用。这样做将允许我们覆盖每一个 API，甚至那些没有进入最终应用的 API。

我们将构建的所有应用的共同点是，它们将是 **Windows 演示基础** ( **WPF** )应用。这是众所周知的，它允许我们使用**模型视图视图模型** ( **MVVM** )模式来构建应用。走这条路的一个好处是，我们将能够非常清楚地看到 API 的用法。它还分离代码，以便您可以轻松地将 API 逻辑带到其他应用中。

以下步骤描述了创建新 WPF 项目的过程:

1.  打开 Visual Studio 并选择文件|新建|项目。
2.  在对话框中，从模板| Visual C#中选择 WPF 应用选项，如下图所示:

![](img/00005.jpeg)

3.  删除`MainWindow.xaml`文件，并创建与下图匹配的文件和文件夹:

![](img/00006.jpeg)

我们不会详细讨论 MVVM 模式，因为这超出了本书的范围。从图像中得到的关键是，我们已经将视图从逻辑中分离出来。然后，我们依靠视图模型来连接各个部分。

如果你想更多地了解 MVVM，我推荐你阅读 CodeProject 的一篇文章，网址是[http://www . code project . com/Articles/100175/Model-View-ViewModel-MVVM-解释](http://www.codeproject.com/Articles/100175/Model-View-ViewModel-MVVM-Explained)。

然而，为了能够运行它，我们需要涵盖项目中的一些细节:

1.  打开`App.xaml`文件，确保`StartupUri`被设置为正确的`View`，如以下代码所示(类名和命名空间可能因应用的名称而异):

```
        <Application x:Class="Chapter1.App"
            xmlns="http://schemas.microsoft.com/
winfx/2006/xaml/presentation" 
            xmlns:x = "http://schemas.microsoft.com/winfx/2006/xaml" 
            xmlns:local="clr-namespace:Chapter1" 
            StartupUri="View/MainView.xaml"> 
```

2.  打开`MainViewModel.cs`文件，并使其从`ObservableObject`类继承。

3.  打开`MainView.xaml`文件并将`MainViewModel`文件作为 datacontext 添加到其中，如以下代码所示(命名空间和类名可能因应用的名称而异):

```
        <Window x:Class="Chapter1.View.MainView" 

            xmlns="http://schemas.microsoft.com/
winfx/2006/xaml/presentation"
            xmlns:x="http://schemas.microsoft.com/winfx/2006/xaml" 
            xmlns:d="http://schemas.microsoft.com/
expression/blend/2008" 
            xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006" 
            xmlns:local="clr-namespace:Chapter1.View" 
            xmlns:viewmodel="clr-namespace:Chapter1.ViewModel" mc:Ignorable="d" 
            Title="Chapter 1" Height="300" Width="300"> 
            <Window.DataContext> 
                <viewmodel:MainViewModel /> 
            </Window.DataContext> 
```

接下来，我们需要填充`ObservableObject.cs`文件的内容。我们首先让它从`INotifyPropertyChanged`类继承，如下所示:

```
        public class ObservableObject : INotifyPropertyChanged 
```

这是一个相当小的类，应该包含以下内容:

```
        public event PropertyChangedEventHandlerPropertyChanged; 
        protected void RaisePropertyChangedEvent(string propertyName) 
        { 
            PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName)); 
        } 
```

我们声明一个属性更改事件，并创建一个函数来引发该事件。这将允许**用户界面** ( **UI** )在给定属性发生变化时更新其值。

我们还需要能够在按钮被按下时执行动作。这可以在我们将一些内容放入`DelegateCommand.cs`文件时实现。首先让该类继承`ICommand`类，并声明以下两个变量:

```
        public class DelegateCommand : ICommand 
        {
            private readonly Predicate<object> _canExecute; 
            private readonly Action<object> _execute; 
```

我们创建的两个变量将在构造函数中设置。您将会注意到，您不需要添加`_canExecute`参数，稍后您将会看到原因:

```
            public DelegateCommand(Action<object> execute, Predicate<object> canExecute = null) 
            { 
                _execute = execute; 
                _canExecute = canExecute; 
            } 
```

为了完成该类，我们添加两个公共函数和一个公共事件，如下所示:

```
        public bool CanExecute(object parameter) 
        { 
            if (_canExecute == null) return true; 
            return _canExecute(parameter); 
        } 

        public void Execute(object parameter) 
        { 
            _execute(parameter); 
        } 

        public event EventHandlerCanExecuteChanged 
        { 
            add 
            { 
                CommandManager.RequerySuggested += value; 
            } 
            remove 
            {
                CommandManager.RequerySuggested -= value; 
            } 
        } 
    } 
```

声明的函数将返回在构造函数中声明的相应谓词或动作。这将是我们在视图模型中声明的东西，而视图模型又将是执行一个动作或告诉应用它可以或不可以执行一个动作的东西。如果按钮处于禁用状态(`CanExecute`函数返回 false)并且`CanExecute`函数的状态发生变化，则声明的事件将通知按钮。

有了这些，您应该能够编译和运行应用了，所以继续尝试吧。您会注意到，该应用实际上并不做任何事情，也不提供任何数据，但是我们有一个很好的起点。

在我们对代码做任何事情之前，我们将把项目导出为一个模板。这样我们就不必为我们创建的每个小样本项目重复所有这些步骤:

1.  用替代参数替换命名空间名称:

1.在所有的`.cs`文件中，用`$safeprojectname$`替换名称空间名称。

2.在所有的`.xaml`文件中，用`$safeprojectname$`替换项目名称(通常是类名和名称空间声明)。

2.  导航到文件|导出模板。这将打开导出模板向导，如以下屏幕截图所示:

![](img/00007.jpeg)

3.  点击项目模板按钮。选择我们刚刚创建的项目，然后单击 Next 按钮。
4.  只需将图标和预览图像留空。输入可识别的名称和描述。点击完成按钮:

![](img/00008.jpeg)

5.  模板现在被导出为 zip 文件并存储在指定位置。

默认情况下，模板将再次导入 Visual Studio。我们将通过为本章创建一个项目来测试它是否能立即工作。因此，继续创建一个新项目，选择我们刚刚创建的模板。该模板应该列在已安装模板列表的 Visual C#部分中。如果你愿意的话，可以称这个项目为`Chapter1`或者其他什么。在我们进入下一步之前，确保它能够编译，并且您能够运行它。



# 使用人脸 API 检测人脸

对于新创建的项目，我们现在将尝试我们的第一个 API，Face API。我们不会做太多，但是我们会看到在图像中检测人脸是多么简单。

我们需要完成的步骤如下:

1.  在 Microsoft Azure 注册 Face API 预览订阅。
2.  将必要的 **NuGet** 包添加到我们的项目中。
3.  向应用添加一些 UI。
4.  根据命令检测人脸。

前往 https://portal.azure.com[开始注册免费订阅 Face API 的过程。您将被带到一个登录页面。使用您的 Microsoft 帐户登录，如果您没有，请注册一个。](https://portal.azure.com)

登录后，您需要通过单击右侧菜单上的+ New 来添加新资源。搜索 **Face API** 并选择第一个条目:

![](img/00009.jpeg)

输入名称并选择订阅、位置和定价层。在撰写本文时，有两种定价选择，一种是免费的，一种是付费的:

![](img/00010.jpeg)

创建后，您可以进入新创建的资源。您将需要两个可用 API 键中的一个。这些可以在资源菜单的键选项中找到:

![](img/00011.jpeg)

这就是我们将在本书中创建所有 API 资源的地方。您可以选择现在创建所有内容，或者在我们进入相应的章节时创建。

我们将要讨论的一些 API 创建了自己的 NuGet 包。在这种情况下，我们将利用这些包来执行我们想要执行的操作。所有 API 的共同点是它们都是 REST APIs，这意味着在实践中，您可以将它们用于任何语言。对于那些没有自己的 NuGet 包的 API，我们直接通过 HTTP 调用 API。

对于我们现在使用的 Face API，NuGet 包确实存在，所以我们需要将它添加到我们的项目中。转到我们之前创建的项目的 NuGet 包管理器选项。在浏览选项卡中，搜索`Microsoft.ProjectOxford.Face`包并安装来自微软的包:

![](img/00012.jpeg)

您会注意到，还将安装另一个包。这是`Newtonsoft.Json`包，是 Face API 所需要的。

下一步是向我们的应用添加一些 UI。我们将把这个添加到`MainView.xaml`文件中。打开我们之前创建的模板代码所在的文件。这意味着我们有了一个 datacontext，并且可以为我们的元素进行绑定，我们现在将对其进行定义。

首先，我们添加一个网格，并为网格定义一些行，如下所示:

```
    <Grid> 
        <Grid.RowDefinitions> 
            <RowDefinition Height="*" /> 
            <RowDefinition Height="20" /> 
            <RowDefinition Height="30" /> 
        </Grid.RowDefinitions> 
```

定义了三行。第一行是一幅图像。第二行是状态消息，最后一行是我们放置按钮的地方。

接下来，我们添加我们的图像元素如下:

```
        <Image x:Name="FaceImage" Stretch="Uniform" Source=
            "{Binding ImageSource}" Grid.Row="0" /> 
```

我们给它起了一个独特的名字。通过将`Stretch`参数设置为`Uniform`，我们确保图像保持其纵横比。接下来，我们将这个元素放在第一行。最后，我们将图像源绑定到 ViewModel 中的一个`BitmapImage`,稍后我们将对此进行介绍。

下一行将包含一个带有一些状态文本的文本块。`Text`属性将被绑定到 ViewModel 中的字符串属性，如下所示:

```
        <TextBlockx:Name="StatusTextBlock" Text=
            "{Binding StatusText}" Grid.Row="1" /> 
```

最后一行将包含一个浏览图像的按钮和一个能够检测人脸的按钮。两个按钮的`command`属性将被绑定到 ViewModel 中的`DelegateCommand`属性，如下所示:

```
        <Button x:Name = "BrowseButton" 
                  Content = "Browse" Height="20" Width="140"  
                  HorizontalAlignment = "Left" 
                  Command="{Binding BrowseButtonCommand}" 
                  Margin="5, 0, 0, 5"Grid.Row="2" /> 

        <Button x:Name="DetectFaceButton" 
                  Content="Detect face" Height="20" Width="140" 
                  HorizontalAlignment="Right" 
                  Command="{Binding DetectFaceCommand}" 
                  Margin="0, 0, 5, 5"Grid.Row="2"/> 
```

视图就绪后，确保代码编译并运行。这将为您呈现以下 UI:

![](img/00013.jpeg)

最后一部分是在我们的视图模型中创建绑定属性，并让按钮执行一些事情。打开`MainViewModel.cs`文件。该类应该已经继承了`ObservableObject`类。首先，我们定义两个变量如下:

```
    private string _filePath; 
    private IFaceServiceClient _faceServiceClient; 
```

string 变量将保存我们的图像的路径，而`IFaceServiceClient`变量将连接 Face API。接下来，我们定义两个属性如下:

```
    private BitmapImage _imageSource; 
    public BitmapImageImageSource 
    { 
        get { return _imageSource; } 
        set 
        { 
            _imageSource = value; 
            RaisePropertyChangedEvent("ImageSource"); 
        } 
    } 

    private string _statusText; 
    public string StatusText 
    { 
        get { return _statusText; } 
        set 
        { 
           _statusText = value; 
           RaisePropertyChangedEvent("StatusText"); 
        } 
    } 
```

这里我们有一个映射到视图中的`Image`元素的`BitmapImage`属性。我们还有一个状态文本的`string`属性，映射到视图中的文本块元素。您可能也注意到了，当设置了其中一个属性时，我们调用`RaisePropertyChangedEvent`事件。这将确保当任一属性有新值时，UI 会更新。

接下来，我们定义两个`DelegateCommand`对象，并通过构造函数进行一些初始化:

```
    public ICommandBrowseButtonCommand { get; private set; } 
    public ICommandDetectFaceCommand { get; private set; } 

    public MainViewModel() 
    { 
        StatusText = "Status: Waiting for image..."; 

        _faceServiceClient = new FaceServiceClient("YOUR_API_KEY_HERE", "ROOT_URI); 

        BrowseButtonCommand = new DelegateCommand(Browse); 
        DetectFaceCommand = new DelegateCommand(DetectFace, CanDetectFace); 
    } 
```

命令的属性都是要获取的`public`和要设置的`private`。这意味着我们只能在视图模型中设置它们。在我们的构造函数中，我们从设置状态文本开始。接下来我们创建一个 Face API 的对象，它需要用我们之前得到的 API 键来创建。此外，它需要指定根 URI，指向服务的位置。例如，如果服务位于西欧，则可以是 https://westeurope.api.cognitive.microsoft.com/face/v1.0。如果服务位于美国西部，您可以用`westus`替换`westeurope`。根 URI 可以在 Azure 门户的以下位置找到:

![](img/00014.jpeg)

最后，我们为命令属性创建了`DelegateCommand`构造函数。请注意 browse 命令没有指定谓词。这意味着总是可以点击相应的按钮。为了进行编译，我们需要创建在`DelegateCommand`构造函数中指定的函数:函数`Browse`、`DetectFace`和`CanDetectFace`。

我们通过创建一个`OpenFileDialog`对象来启动`Browse`函数。这个对话框被分配了一个 JPEG 图像的过滤器，并依次打开。当对话框关闭时，我们检查结果。如果对话框被取消，我们只需停止进一步的执行:

```
    private void Browse(object obj) 
    { 
        var openDialog = new Microsoft.Win32.OpenFileDialog(); 

        openDialog.Filter = "JPEG Image(*.jpg)|*.jpg"; 
        bool? result = openDialog.ShowDialog(); 

        if (!(bool)result) return; 
```

对话框关闭后，我们获取所选文件的文件名，并从中创建一个新的 URI:

```
        _filePath = openDialog.FileName; 
        Uri fileUri = new Uri(_filePath); 
```

有了新创建的 URI，我们想创建一个新的`BitmapImage`。我们指定它不使用缓存，并设置我们创建的 URI 的 URI 源:

```
        BitmapImage image = new BitmapImage(fileUri); 

        image.CacheOption = BitmapCacheOption.None; 
        image.UriSource = fileUri; 
```

我们采取的最后一步是将位图图像分配给我们的`BitmapImage`属性，这样图像就会显示在 UI 中。我们还更新了状态文本，让用户知道图像已经加载:

```
        ImageSource = image; 
        StatusText = "Status: Image loaded..."; 
    } 
```

`CanDetectFace`功能检查是否应启用`DetectFacesButton`按钮。在这种情况下，它检查我们的图像属性是否实际上有一个 URI。如果延伸开来，那就意味着我们有了图像，我们应该能够识别人脸:

```
    private boolCanDetectFace(object obj) 
    { 
        return !string.IsNullOrEmpty(ImageSource?.UriSource.ToString()); 
    } 
```

我们的`DetectFace`方法调用一个`async`方法来上传和检测人脸。返回值包含一个`FaceRectangles`变量数组。该数组包含给定图像中所有人脸位置的矩形区域。我们将会研究一下我们将要调用的函数。

执行完调用后，我们将带有面数的一行打印到调试控制台窗口，如下所示:

```
    private async void DetectFace(object obj) 
    { 
        FaceRectangle[] faceRects = await UploadAndDetectFacesAsync(); 

        string textToSpeak = "No faces detected"; 

        if (faceRects.Length == 1) 
            textToSpeak = "1 face detected"; 
        else if (faceRects.Length> 1) 
            textToSpeak = $"{faceRects.Length} faces detected"; 

        Debug.WriteLine(textToSpeak); 
    } 
```

在`UploadAndDetectFacesAsync`函数中，我们从图像中创建一个`Stream`。这个流将被用作对 Face API 服务的实际调用的输入:

```
    private async Task<FaceRectangle[]>UploadAndDetectFacesAsync() 
    { 
        StatusText = "Status: Detecting faces..."; 

        try 
        { 
            using (Stream imageFileStream = File.OpenRead(_filePath)) 
```

下面一行是对 Face API 的检测端点的实际调用:

```
            Face[] faces = await _faceServiceClient.DetectAsync(imageFileStream, true, true, new List<FaceAttributeType>() { FaceAttributeType.Age }); 
```

第一个参数是我们在上一步中创建的文件流。其余的参数都是可选的。如果您想获得一个 face ID，那么第二个参数应该为 true。下一个参数指定您是否想要接收面部标志。最后一个参数接受您可能希望接收的面部属性列表。在我们的例子中，我们希望返回年龄参数，所以我们需要指定它。

此函数调用的返回类型是一个面数组，包含您指定的所有参数:

```
            List<double> ages = faces.Select(face =>face.FaceAttributes.Age).ToList(); 
            FaceRectangle[] faceRects = faces.Select(face =>face.FaceRectangle).ToArray(); 

            StatusText = "Status: Finished detecting faces..."; 

            foreach(var age in ages) { 
                Console.WriteLine(age); 
            } 
            return faceRects; 
        } 
    } 
```

第一行遍历所有的脸，检索所有脸的大概年龄。这稍后在`foreach`循环中被打印到调试控制台窗口。

第二行遍历所有面并检索面矩形，以及所有面的矩形位置。这是我们返回给调用函数的数据。

添加一个`catch`子句来完成该方法。当我们的 API 调用中抛出异常时，我们会捕捉到它。你想显示错误信息并返回一个空的`FaceRectangle`数组。

有了这些代码，您现在应该能够运行完整的示例了。最终结果将类似于下面的截图:

![](img/00015.jpeg)

产生的调试控制台窗口将打印以下文本:

```
    1 face detected 
    23,7 
```



# 我们正在处理的事情的概述

既然你已经看到了如何检测人脸的基本示例，那么是时候了解一下认知服务还能为你做些什么了。当使用认知服务时，您手头有 21 个不同的 API。根据它们的用途，这些域名又被分成五个顶级域名。它们是视觉、言语、语言、知识和搜索。让我们在接下来的章节中了解更多。



# 视力

在 **Vision** 旗帜下的 API 允许你的应用理解图像和视频内容。它允许你检索关于脸、感觉和其他视觉内容的信息。可以稳定视频，识别名人。您可以读取图像中的文本，并从视频和图像中生成缩略图。

Vision 区域包含四个 API，我们现在来看看。



# 计算机视觉

使用**计算机视觉** API，您可以从图像中检索可操作的信息。这意味着您可以识别内容(如图像格式、图像大小、颜色、面孔等)。您可以检测图像是否成人/色情。这个 API 可以识别图像中的文本，并将其提取为机器可读的文字。它可以检测来自不同领域的名人。最后，它可以生成存储高效的缩略图与智能裁剪功能。

我们将在第二章、*中研究计算机视觉，分析图像以识别人脸*。



# 情绪

情感 API 允许你识别图像和视频中的情感。这可以在应用中提供更加个性化的体验。检测到的情绪是跨文化的情绪:愤怒、鄙视、厌恶、恐惧、快乐、中性、悲伤、惊讶。

我们将分两章介绍 Emotion API:第 2 章、*分析图像识别人脸*，用于基于图像的情感，以及第 3 章、*分析视频*，用于基于视频的情感。



# 脸

我们已经看到了一个非常基本的例子，展示了 **Face** API 可以做什么。API 的其余部分围绕着检测、识别、组织和标记照片中的人脸。除了人脸检测，你可以看到两张脸属于同一个人的可能性有多大。你可以识别人脸，也可以找到长相相似的人脸。

我们将在第 2 章、*分析图像以识别人脸*中进一步探究人脸 API。



# 录像

**视频** API 是关于在你的应用中分析、编辑和处理视频的。如果你有一个不稳定的视频，API 允许你稳定它。您可以检测和跟踪视频中的人脸。如果视频包含静止的背景，您可以检测到运动。该 API 允许您为视频生成缩略图摘要，这允许用户快速查看预览或快照。

视频将在第三章、*分析视频*中介绍。



# 视频索引器

使用**视频索引器** API，人们可以在上传后立即开始索引视频。这意味着您可以在不使用专家或自定义代码的情况下获得视频见解。利用这个 API 强大的人工智能，可以改进内容发现。这使您的内容更容易被发现。

视频索引器将在第 3 章、*分析视频*中介绍。



# 内容版主

**内容调节器** API 利用机器学习来自动调节内容。它可以检测 100 多种语言的潜在攻击性和不需要的图像、视频和文本。此外，它还允许您查看检测到的材料以改进服务。

内容主持人将在第 2 章、*分析图像识别人脸*中介绍。



# 定制视觉服务

**自定义视觉服务**允许您将自己的标签图像上传到视觉服务。这意味着您可以添加特定于您的域的图像，以允许使用计算机视觉 API 进行识别。

本书不涉及定制视觉服务。



# 演讲

添加一个**语音**API 允许您的应用听到并对您的用户说话。API 可以过滤噪音并识别说话者。基于识别出的意图，它们可以在您的应用中驱动进一步的动作。

Speech 包含三个 API，讨论如下。



# Bing 语音

将 Bing Speech API 添加到您的应用中可以让您将语音转换成文本，反之亦然。您可以通过利用麦克风或其他实时来源，或者通过从文件转换音频，将语音音频转换为文本。API 还提供语音意图识别，由**语言理解智能服务** ( **LUIS** )训练理解意图。



# 说话人识别

**说话者** **识别** API 赋予你的应用知道谁在说话的能力。通过使用这个 API，您可以验证说话的人就是他们所声称的那个人。您还可以根据一组选定的说话者来确定谁是未知的说话者。



# 自定义识别

为了改进语音识别，您可以使用**自定义识别** API。这使您可以随时随地为任何人微调语音识别操作。通过使用这个 API，语音识别模型可以根据用户的词汇和说话风格进行定制。此外，可以对模型进行定制，以匹配应用的预期环境。



# 翻译语音 API

**Translator Speech** API 是一个基于云的语音自动翻译服务。使用此 API，您可以在 web 应用、移动应用和桌面应用之间添加端到端翻译。根据您的使用情况，它可以为您提供部分翻译、全部翻译和翻译的抄本。

我们将在第 5 章、*与您的应用*对话中介绍所有与语音相关的 API。



# 语言

与语言相关的 API 允许你的应用处理自然语言，学习如何识别用户想要什么。您可以在应用中添加文本和语言分析，以及自然语言理解。

在语言区可以找到以下五个 API。



# Bing 拼写检查

Bing 拼写检查 API 允许你给你的应用添加高级拼写检查。

该 API 将在第 6 章、*理解文本*中介绍。



# 语言理解智能服务(LUIS)

LUIS 是一个 API，可以帮助您的应用理解来自用户的命令。使用这个 API，您可以创建理解意图的语言模型。通过使用来自 Bing 和 Cortana 的模型，您可以让这些模型识别常见的请求和实体(如地点、时间和数字)。您可以将对话智能添加到应用中。

LUIS 将在第 4 章中介绍，*让应用理解命令*。



# 语言分析

**语言分析** API 让您解析复杂的文本，探索文本的结构。通过使用这个 API，您可以在文本中找到名词、动词等等，这使得您的应用能够理解谁在对谁做什么。

我们将在第 6 章、*理解文本*中看到更多的语言分析。



# 文本分析

**文本分析** API 将帮助你从文本中提取信息。你可以找到一个文本的情绪(无论该文本是积极的还是消极的)。你将能够发现整篇文章中使用的语言、主题和关键短语。

我们还将在第六章、*理解文本*中涉及文本分析。



# 网络语言模型

通过使用 **Web 语言模型** ( **WebLM** ) API，您能够利用在 Web 规模数据上训练的语言模型的能力。您可以使用这个 API 来预测给定的序列或单词后面是哪些单词或序列。

Web 语言模型 API 将在第 6 章、*理解文本*中介绍。



# 翻译器文本 API

通过添加 **Translator Text** API，您可以获得超过 60 种语言的文本翻译。它可以自动检测语言，您可以根据自己的需要定制 API。此外，您可以通过创建用户组、利用众包的力量来改进翻译。

翻译器文本 API 将不在本书中讨论。



# 知识

当谈论**知识**API 时，我们谈论的是允许你挖掘丰富知识的 API。这可能是来自网络的知识。可能来自学术界，也可能是你自己的数据。使用这些 API，您将能够探索知识的不同细微差别。

知识 API 区域包含以下四个 API。



# 学术的

使用**学术** API，您可以探索学术论文、期刊和作者之间的关系。这个 API 允许您解释自然语言用户查询字符串，这允许您的应用预测用户正在键入的内容。它将评估所述表达式并返回学术知识实体。

这个 API 将在第 8 章、*以自然方式查询结构化数据*中详细介绍。



# 实体链接

**实体链接**是一个 API，你可以用它来扩展基于上下文的人、地点和事件的知识。你可能知道，一个单词可能会根据上下文有不同的用法。使用这个 API，您可以根据上下文来识别段落中的每个独立实体。

我们将在第 7 章、*中介绍实体链接 API，基于上下文扩展知识*。



# 知识探索

**Knowledge Exploration** API 将允许您在项目中添加使用交互式搜索结构化数据的可能性。它解释自然语言查询，并提供自动完成，以尽量减少用户的努力。基于收到的查询表达式，它将检索关于匹配对象的详细信息。

关于这个 API 的细节将在第八章、*以自然方式查询结构化数据*中介绍。



# 推荐

**推荐** API 允许您为客户提供个性化的产品推荐。您可以使用这个 API 向您的应用添加一个经常购买的功能。您可以添加的另一个功能是单品对单品推荐，它允许客户查看其他客户喜欢什么。该 API 还允许您根据客户之前的活动添加建议。

我们将在第 7 章、*基于上下文扩展知识*中介绍这个 API。



# QnA 制造商

QnA Maker 是一种为常见问题(FAQ)提取信息的服务。使用现有的 FAQ，无论是在线还是每个文档，您都可以创建问题和答案对。可以编辑、删除和修改问题对，并且可以添加几个相似的问题来匹配给定的问题对。

我们将在第 8 章、*中介绍 QnA Maker 以自然方式查询结构化数据*。



# 定制决策服务

**定制决策服务**是一项旨在使用强化学习来个性化内容的服务。该服务理解任何上下文，并可以提供基于上下文的内容。

这本书不包括自定义决策服务。



# 搜索

搜索 API 让你能够借助必应的力量让你的应用变得更加智能。使用这些 API，您可以使用一个调用来访问数十亿个网页、图像、视频和新闻中的数据。

以下五个 API 属于搜索领域。



# Bing 网络搜索

有了 Bing 网络搜索，你可以在 Bing 索引的数十亿网络文档中搜索细节。所有结果都可以根据您指定的布局进行排列和排序，并且结果可以根据最终用户的位置进行定制。



# 必应图片搜索

使用 **Bing 图像搜索** API，您可以将高级图像和元数据搜索添加到您的应用中。结果包括图像、缩略图和元数据的 URL。你也将能够获得机器生成的字幕，类似的图像，等等。这个 API 允许您根据图像类型、布局、新鲜度(图像有多新)和许可证来过滤结果。



# 必应视频搜索

Bing 视频搜索将允许你搜索视频并返回丰富的结果。结果包含来自视频、静态或基于运动的缩略图以及视频本身的元数据。您可以根据新鲜度、视频长度、分辨率和价格向结果添加过滤器。



# 必应新闻搜索

如果你把**必应新闻搜索**添加到你的应用中，你就可以搜索新闻文章了。搜索结果可以包括权威图片、相关新闻和类别、提供商信息、URL 等等。更具体地说，你可以根据主题过滤新闻。



# Bing 自动建议

Bing 自动建议 API 很小，但是很强大。它将允许您的用户通过搜索建议更快地进行搜索，允许您将强大的搜索连接到您的应用。

所有搜索 API 将在第 9 章、*添加专门搜索*中介绍。



# Bing 实体搜索

使用 Bing 实体搜索 API，你可以增强你的搜索。API 将根据您的搜索条件找到最相关的实体。它会找到名人、地点、电影等实体。

我们不会在本书中讨论 Bing 实体搜索。



# 获取关于检测到的人脸的反馈

既然我们已经看到了微软认知服务还能提供什么，我们将为我们的人脸检测应用添加一个 API。通过这一部分，我们将添加 Bing Speech API，让应用大声说出面数。

NuGet 包中没有提供 API 的这个特性，因此我们将使用 REST API。

为了达到我们的最终目标，我们将添加两个新的类，`TextToSpeak`和`Authentication`。第一个类将负责生成正确的头并调用我们的服务端点。后一个类将负责生成认证令牌。这将在我们的 ViewModel 中联系在一起，我们将让应用向我们反馈。

我们需要先拿到 API 密匙。前往微软 Azure 门户网站。为 Bing 语音创建新服务。

为了能够调用 Bing 语音 API，我们需要一个授权令牌。回到 Visual Studio，创建一个名为`Authentication.cs`的新文件。将它放在`Model`文件夹中。

我们需要向项目添加两个新的引用。在 Add References 窗口的 Assembly 选项卡中找到`System.Runtime.Serialization`和`System.Web`包并添加它们。

在我们的`Authentication`类中，如下定义四个私有变量和一个公共属性:

```
    private string _requestDetails; 
    private string _token; 
    private Timer _tokenRenewer; 

    private const int TokenRefreshInterval = 9; 

    public string Token { get { return _token; } } 
```

构造函数应该接受一个字符串参数`clientSecret`。`clientSecret`参数是您注册的 API 密钥。

在构造函数中，将`_clientSecret`变量赋值如下:

```
    _clientSecret = clientSecret; 
```

如下创建一个名为`Initialize`的新函数:

```
    public async Task Initialize()
    {
        _token = GetToken(); 

        _tokenRenewer = new Timer(new TimerCallback(OnTokenExpiredCallback), this, 
        TimeSpan.FromMinutes(TokenRefreshInterval), 
        TimeSpan.FromMilliseconds(-1));
    } 
```

然后，我们获取访问令牌，我们将很快创建一个方法。

最后，我们创建我们的`timer`类，它将在 9 分钟内调用`callback`函数。`callback`函数将需要再次获取访问令牌，并将其分配给`_token`变量。它还需要确保我们在 9 分钟后再次运行计时器。

接下来我们需要创建`GetToken`方法。这个方法应该返回一个`Task<string>`对象，并且应该声明为 private 并标记为 async。

在该方法中，我们首先创建一个`HttpClient`对象，指向将生成我们的令牌的端点。我们指定根端点并添加令牌发布路径，如下所示:

```
    using(var client = new HttpClient())
    {
        client.DefaultRequestHeaders.Add ("Opc-Apim-Subscription-Key", _clientSecret);
        UriBuilder uriBuilder = new UriBuilder (https://api.cognitive.microsoft.com/sts/v1.0”);
        uriBuilder.Path = “/issueToken”;
```

然后，我们继续进行 POST 调用来生成令牌，如下所示:

```
var result = await client.PostAsync(uriBuilder.Uri.AbsoluteUri, null);
```

当请求发出后，我们希望会有响应。我们想读取这个响应并返回响应字符串:

```
return await result.Content.ReadAsStringAsync();
```

添加一个名为`TextToSpeak.cs`的新文件，如果您还没有这样做的话。将该文件放在`Model`文件夹中。

在新创建的类下面(但是在名称空间内部)，我们想要添加两个事件参数类。这些将用于处理音频事件，我们将在后面看到。

`AudioEventArgs`类简单地采用了一个通用的`stream`，你可以想象它被用来发送音频流到我们的应用:

```
    public class AudioEventArgs : EventArgs 
    { 
        public AudioEventArgs(Stream eventData) 
        { 
            EventData = eventData; 
        } 

        public StreamEventData { get; private set; }  
    } 
```

下一个类允许我们发送一个带有特定错误消息的事件:

```
    public class AudioErrorEventArgs : EventArgs 
    { 
        public AudioErrorEventArgs(string message) 
        { 
            ErrorMessage = message; 
        } 

        public string ErrorMessage { get; private set; } 
    } 
```

我们继续从`TextToSpeak`类开始，首先声明一些事件和类成员，如下所示:

```
    public class TextToSpeak 
    { 
        public event EventHandler<AudioEventArgs>OnAudioAvailable; 
        public event EventHandler<AudioErrorEventArgs>OnError; 

        private string _gender; 
        private string _voiceName; 
        private string _outputFormat; 
        private string _authorizationToken; 
        private AccessTokenInfo _token;  

        private List<KeyValuePair<string, string>> _headers = new  List<KeyValuePair<string, string>>(); 
```

类中的前两行是使用我们之前创建的事件参数类的事件。如果对 API 的调用完成，并返回一些音频，或者如果任何事情失败，这些事件将被触发。接下来的几行是字符串变量，我们将使用它们作为输入参数。我们用一行来包含我们的访问令牌信息。最后一行创建了一个新的列表，我们将用它来保存我们的请求头。

我们向类中添加两个常量字符串，如下所示:

```
private const string RequestUri =  "https://speech.platform.bing.com/synthesize"; 

private const string SsmlTemplate = 
    "<speak version='1.0'xml:lang='en-US'>
        <voice xml:lang='en-US'xml:gender='{0}' 
        name='{1}'>{2}
        </voice>
    </speak>";
```

第一个字符串包含请求 URI。这就是我们需要调用来执行请求的 REST API 端点。接下来我们有一个字符串定义我们的**语音合成标记语言** ( **SSML** )模板。我们将在这里指定语音服务应该说什么，以及它应该如何说。

接下来，我们按如下方式创建构造函数:

```
        public TextToSpeak() 
        { 
            _gender = "Female"; 
            _outputFormat = "riff-16khz-16bit-mono-pcm"; 
            _voiceName = "Microsoft Server Speech Text to Speech Voice (en-US, ZiraRUS)"; 
        } 
```

这里我们只是初始化一些之前声明的变量。如你所见，我们将声音定义为女性，并定义为使用特定的声音。就性别而言，自然可以是女性也可以是男性。就语音名称而言，它可以是一长串选项中的一个。当我们在后面的章节中学习这个 API 的时候，我们将会更深入地研究这个列表的细节。

最后一行指定音频的输出格式。这将定义结果音频流使用的格式和编解码器。同样，这可以是许多种类，我们将在后面的章节中探讨。

在构造函数之后，我们将创建三个公共方法。这些将生成一个认证令牌，生成一些 HTTP 头，最后执行我们对 API 的调用。在我们创建这些之前，您应该添加两个助手方法来引发我们的事件。称它们为`RaiseOnAudioAvailable`和`RaiseOnError`方法。他们应该接受`AudioEventArgs`和`AudioErrorEventArgs`作为参数。

接下来，添加一个名为`GenerateHeaders`的新方法，如下所示:

```
        public void GenerateHeaders() 
        { 
            _headers.Add(new KeyValuePair<string, string>("Content-Type", "application/ssml+xml")); 
            _headers.Add(new KeyValuePair<string, string>("X-Microsoft-OutputFormat", _outputFormat)); 
            _headers.Add(new KeyValuePair<string, string>("Authorization", _authorizationToken)); 
            _headers.Add(new KeyValuePair<string, string>("X-Search-AppId", Guid.NewGuid().ToString("N"))); 
            _headers.Add(new KeyValuePair<string, string>("X-Search-ClientID", Guid.NewGuid().ToString("N"))); 
            _headers.Add(new KeyValuePair<string, string>("User-Agent", "Chapter1")); 
        } 
```

这里，我们将 HTTP 头添加到之前创建的列表中。这些头是服务响应所必需的，如果缺少任何头，它将产生一个 **HTTP/400** 响应。我们将在后面更详细地介绍我们所使用的标题。现在，只要确保他们在场就行了。

接下来，我们想添加一个名为`GenerateAuthenticationToken`的新方法，如下所示:

```
        public bool GenerateAuthenticationToken(string clientSecret) 
        { 
            Authentication auth = new Authentication(clientSecret); 
```

该方法接受一个字符串参数，即客户机机密(您的 API 密钥)。首先我们创建一个`Authentication`类的新对象，我们之前已经看过了，如下所示:

```
        try 
        { 
            _token = auth.Token; 

            if (_token != null) 
            { 
                _authorizationToken = $"Bearer {_token}"; 

                return true; 
            } 
            else 
            { 
                RaiseOnError(new AudioErrorEventArgs("Failed to generate authentication token.")); 
                return false; 
            } 
        } 
```

我们使用身份验证对象来检索访问令牌。这个令牌用在我们的授权令牌字符串中，正如我们前面看到的，它是在我们的头中传递的。如果应用由于某种原因未能生成访问令牌，我们将触发一个错误事件。

通过添加关联的 catch 子句来完成此方法。如果出现任何异常，我们希望引发新的错误事件。

我们需要在这个类中创建的最后一个方法叫做`SpeakAsync`方法。这个方法将实际执行对语音 API 的请求:

```
        public Task SpeakAsync(string textToSpeak, CancellationTokencancellationToken) 
        { 
            varcookieContainer = new CookieContainer(); 
            var handler = new HttpClientHandler() { 
                CookieContainer = cookieContainer 
            }; 
            var client = new HttpClient(handler);  
```

该方法有两个参数。一个是字符串，这将是我们想要说的文本。下一个是取消令牌。这可用于宣传应该取消给定的操作。

当进入该方法时，我们创建三个对象来执行请求。这些是来自。NET 库，我们将不再详细讨论它们。

我们之前生成了一些头，我们需要将它们添加到我们的 HTTP 客户端。我们通过在前面的`foreach`循环中添加头来实现这一点，基本上是遍历整个列表:

```
            foreach(var header in _headers) 
            { 
                client.DefaultRequestHeaders.TryAddWithoutValidation (header.Key, header.Value); 
            } 
```

接下来我们创建一个`HTTP Request Message`，指定我们将通过`POST`方法发送数据，并指定请求 URI。我们还使用之前创建的 SSML 模板指定内容，并添加正确的参数(性别、语音名称和我们希望朗读的文本):

```
            var request = new HttpRequestMessage(HttpMethod.Post, RequestUri) 
            { 
                Content = new StringContent(string.Format(SsmlTemplate, _gender, _voiceName, textToSpeak)) 
            }; 
```

我们使用 HTTP 客户端异步发送 HTTP 请求，如下所示:

```
            var httpTask = client.SendAsync(request, HttpCompletionOption.ResponseHeadersRead, cancellationToken); 
```

下面的代码是我们之前进行的异步发送调用的延续。这也将异步运行，并检查响应的状态。如果响应成功，它将把响应消息作为流读取，并触发音频事件。如果一切顺利，那么这个流应该包含我们的口语文本:

```
    var saveTask = httpTask.ContinueWith(async (responseMessage, token) => 
    { 
        try 
        { 
            if (responseMessage.IsCompleted && 
                responseMessage.Result != null &&   
                responseMessage.Result.IsSuccessStatusCode) { 
                var httpStream = await responseMessage. Result.Content.ReadAsStreamAsync().ConfigureAwait(false); 
                RaiseOnAudioAvailable(new AudioEventArgs (httpStream)); 
            } else { 
                RaiseOnError(new AudioErrorEventArgs($"Service returned {responseMessage.Result.StatusCode}")); 
            } 
        } 
        catch(Exception e) 
        { 
            RaiseOnError(new AudioErrorEventArgs (e.GetBaseException().Message)); 
        } 
    } 
```

如果响应指示除成功之外的任何事情，我们将引发错误事件。

我们还想添加一个 catch 子句和一个`finally`子句。如果捕获到异常，则抛出一个错误，并释放在`finally`子句中使用的所有对象。

我们需要的最后一段代码是指定延续任务附加到父任务。此外，我们还需要向该任务添加取消令牌。继续添加以下代码以结束该方法:

```
    }, TaskContinuationOptions.AttachedToParent, cancellationToken); 
    return saveTask; 
}  
```

有了它，我们现在就可以在我们的应用中利用这个类了，我们现在就要这么做。打开`MainViewModel.cs`文件，声明一个新的类变量，如下所示:

```
        private TextToSpeak _textToSpeak; 
```

将以下代码添加到构造函数中，以初始化新添加的对象。我们还需要调用一个函数来生成身份验证令牌，如下所示:

```
            _textToSpeak = new TextToSpeak(); 
            _textToSpeak.OnAudioAvailable +=  _textToSpeak_OnAudioAvailable; 
            _textToSpeak.OnError += _textToSpeak_OnError; 

            GenerateToken();
```

创建对象后，我们将这两个事件与事件处理程序挂钩。然后，我们通过创建一个包含以下内容的函数 GenerateToken 来生成一个身份验证令牌:

```
public async void GenerateToken()
{
    if (await _textToSpeak.GenerateAuthenticationToken("BING_SPEECH_API_KEY_HERE"))
        _textToSpeak.GenerateHeaders(); 
}
```

然后我们生成一个认证令牌，为 Bing 语音 API 指定 API 密钥。如果调用成功，我们将生成所需的 HTTP 头。

我们需要添加事件处理程序，所以首先创建名为`_textToSpeak_OnError`的方法，如下所示:

```
            private void _textToSpeak_OnError(object sender, AudioErrorEventArgs e) 
            { 
                StatusText = $"Status: Audio service failed -  {e.ErrorMessage}"; 
            } 
```

这应该相当简单，只需在状态文本字段中向用户输出错误消息。

接下来，我们需要创建一个`_textToSpeak_OnAudioAvailable`方法如下:

```
        private void _textToSpeak_OnAudioAvailable(object sender, AudioEventArgs e) 
        { 
            SoundPlayer player = new SoundPlayer(e.EventData); 
            player.Play(); 
            e.EventData.Dispose(); 
        } 
```

这里我们利用了。NET 框架。这允许我们直接添加流数据并简单地播放消息。

我们需要做的最后一件事是调用`SpeakAsync`方法。我们可以通过在我们的`DetectFace`方法的末尾添加以下内容来实现这一点:

```
    await _textToSpeak.SpeakAsync(textToSpeak, CancellationToken.None); 
```

有了这些，您现在应该能够编译和运行应用了。通过加载一张照片并点击“检测人脸”,你应该能够得到反馈给你的人脸数量。记得开着音响！



# 摘要

在本章中，您了解了微软认知服务的简要介绍。我们从创建一个模板项目开始，以便为接下来的章节轻松地创建新项目。我们通过为本章创建一个示例项目来尝试这个模板。然后，您学习了如何利用 Face API 检测图像中的人脸。从那里，我们快速浏览了一下认知服务提供了什么。最后，我们使用 Bing Speech API 为我们的应用添加了文本到语音的功能。

下一章将更详细地介绍 API 的视觉部分。在那里，您将学习如何使用计算机视觉 API 分析图像。您将深入学习 Face API，并学习如何使用 Emotion API 来检测面部表情。其中一些将用于开始构建我们的智能房屋应用。