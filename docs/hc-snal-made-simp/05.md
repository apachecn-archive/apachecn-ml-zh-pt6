

# 五、计算基础 Python 简介

本章将介绍用于分析的 Python。它主要面向不熟悉 Python 的程序员新手或开发人员。到本章结束时，你将基本熟悉 Python 基础语言的功能，这是医疗保健分析和机器学习不可或缺的。您还将了解如何开始使用`pandas`和`scikit-learn`，这两个用于分析的重要 Python 库。

如果您想继续使用 Jupyter 笔记本，我们建议您参考[第 1 章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)、*医疗保健分析介绍*中的说明，开始新的 Jupyter 会话。本章的笔记本也可以在本书的官方代码库中在线获得。



# 变量和类型

Python 中的基本变量类型由字符串和数值类型组成。让我们在这一部分看看这两种类型。



# 用线串

在 Python 中，**字符串**是一种变量类型，存储文本字符，如字母、数字、特殊字符和标点符号。在 Python 中，我们使用单引号或双引号来表示变量是字符串而不是数字:

```
var = 'Hello, World!'
print(var)
```

字符串不能用于数字的数学运算。但是它们可以用于其他有用的操作，正如我们在下面的示例中看到的:

```
string_1 = '1'
string_2 = '2'
string_sum = string_1 + string_2
print(string_sum)
```

前面代码的结果是打印字符串`'12'`，而不是`'3'`。在 Python 中，当对两个字符串进行操作时，`+`运算符执行连接(将第二个字符串追加到第一个字符串的末尾),而不是将两个数字相加。

其他作用于字符串的操作符包括`*`操作符(用于重复字符串![](img/14655201-6690-4b4c-ad90-85b3c37d6601.png)的次数，例如`string_1 * 3`)和`<`和`>`操作符(用于比较字符串的 ASCII 值)。

要将数据从数字类型转换成字符串，我们可以使用`str()`方法。

因为字符串是(字符的)序列，所以我们可以对它们进行索引和切片(就像我们对其他数据容器所做的那样，您将在后面看到)。切片是字符串的连续部分。为了对它们进行索引/切片，我们使用方括号中的整数来表示字符的位置:

```
test_string = 'Healthcare'
print(test_string[0])
```

输出如下所示:

```
H
```

为了分割字符串，我们在方括号中包括由冒号分隔的开始和结束位置。请注意，结束位置将包括从*到结束位置的所有字符，但不包括*，如下例所示:

```
print(test_string[0:6])
```

输出如下所示:

```
Health
```

前面我们提到了`str()`方法。对于字符串，还有许多其他的方法。在 www.python.org 的在线 Python 文档中可以找到它们的完整列表。方法包括大小写转换、查找特定子字符串和去除空白。我们将在这里讨论另一种方法——`split()`方法。`split()`方法作用于一个字符串并接受一个`separator`参数。

输出是字符串列表；列表中的每一项都是原始字符串的一个组成部分，由`separator`拆分。这对于解析由标点符号分隔的字符串非常有用，例如`,`或`;`。我们将在下一节讨论列表。下面是一个`split()`方法的例子:

```
test_split_string = 'Jones,Bill,49,Atlanta,GA,12345'
output = test_split_string.split(',')
print(output)
```

输出如下所示:

```
['Jones', 'Bill', '49', 'Atlanta', 'GA', '12345']
```



# 数字类型

Python 中对分析最有用的两种数值类型是**整数**和**浮点数**。要转换成这些类型，可以分别使用`int()`和`float()`函数。常用运算符支持对数字最常见的运算:`+`、`-`、`*`、`/`、`<`、`>`。包含对分析特别有用的数字类型的特殊方法的模块包括`math`和`random`。在线 Python 文档中提供了关于数字类型的更多信息(参见上一节中的链接)。

注意，在某些 Python 版本中，使用/运算符将两个整数相除会执行**底数除法**(省略小数点后的数字)；例如，`10/4`将等于`2`，而不是`2.5`。这是一个隐蔽而惊人的错误，可能会扰乱数值计算。然而，对于本书中我们使用的 Python 版本，我们不需要担心这个错误。

**布尔类型**是一种特殊的整数类型，可用于表示`True`和`False`值。要将整数转换为布尔类型，可以使用`bool()`函数。零被转换成`False`；任何其他整数都会被转换成`True`。布尔变量的行为类似于 1(真)和 0(假)，除了它们在转换成字符串时分别返回`True`和`False`。



# 数据结构和容器

在上一节中，我们讨论了存储单个值的变量类型。现在我们将继续讨论可以保存多个值的数据结构。这些数据结构是列表、元组、字典和集合。在 Python 中，列表和元组通常被称为序列。在本书中，我们将互换使用数据结构和数据容器这两个术语。



# 列表

列表是一种广泛使用的数据结构，可以保存多个值。让我们来看看列表的一些特性:

*   做一个列表，我们用方括号，`[]`。
    举例:`my_list = [1, 2, 3]`。
*   列表可以包含数字类型、字符串、布尔类型、元组、字典甚至其他列表的任意组合。
    举例:`my_diverse_list = [51, 'Health', True, [1, 2, 3]]`。
*   和字符串一样，列表也是序列，支持索引和切片。
    例如，在前面的例子中，`my_diverse_list[0]`等于`51`。`my_diverse_list[0:2]`等于`[51, 'Health']`。要访问嵌套列表的`3`，我们可以使用`my_diverse_list[3][2]`。
*   列表是**可变的**(不像字符串和元组)，这意味着我们可以使用索引来改变单个组件。
    例如，如果我们输入`my_diverse_list[2] = False`命令，我们的新`my_diverse_list`将等于`[51, 'Health', False, [1, 2, 3]]`。

用于分析的列表的显著优点包括它们大量的辅助方法，例如`append()`、`extend()`和`join()`，以及它们与`pandas`和`numpy`数据结构的可互换性。



# 元组

元组类似于列表。做一个元组，我们用圆括号，`()`。例子:`my_tuple = (1, 2, 3)`。元组和列表的主要区别在于元组是**不可变的**，所以我们不能改变一个元组的任何组件。如果我们尝试`my_tuple[0] = 4`，将会抛出一个错误。因为它们的值是不可变的，所以元组对于设置常量变量很有用。



# 字典

一个**字典**是 Python 中常见的数据结构。它用于存储从键到值的单向映射。例如，如果我们想要创建一个字典来存储患者姓名及其相应的房间号的列表，我们可以使用下面的代码:

```
rooms = {
    'Smith': '141-A',
    'Davis': '142',
    'Williams': '144',
    'Johnson': '145-B'
}
```

让我们更详细地讨论一下前面的代码片段:

*   `rooms`字典中的名称被称为**键**。字典中的关键字必须唯一。要访问它们，我们可以使用`keys()`函数`rooms.keys()`。
*   `rooms`字典中的房间号称为**值**。要访问所有的值，我们可以使用`values()`函数`rooms.values()`。要访问一个单独的值，我们只需在方括号中提供它的键的名称。比如`rooms['Smith']`会返回`'141-A'`。出于这个原因，我们说字典将键映射到它们的值。
*   要访问包含每个键及其对应值的嵌套元组列表，我们可以使用`items()`函数`rooms.items()`。
*   字典不一定只是字符串；事实上，这些值可以是任何数据类型/结构。密钥可以是特定的变量，如整数或字符串。虽然值是可变的，但键是不可变的。
*   字典没有内在的顺序，所以不支持按数字进行索引和切片。



# 设置

虽然在 Python 中，集合没有像它的流行表亲列表那样受到关注，但是集合在分析中起着重要的作用，所以我们在这里包括它们。要制作一个集合，我们使用内置的`set()`函数。关于器械包，您需要了解三件事:

*   它们是不可改变的
*   它们是无序的
*   集合中的元素是唯一的

因此，如果您熟悉基本的集合论，Python 中的集合与它们的数学对应物非常相似。设置方法也复制典型的设置操作，包括`union()`、`intersection()`、`add()`和`remove()`。当想要在数据结构(比如列表或元组)上执行典型的类似集合的操作时，在转换为集合之后，这些函数非常方便。



# Python 编程——一个例证

在前面的章节中，我们讨论了变量类型和数据容器。Python 编程还有很多方面，比如带有 if/else 语句、循环和理解的控制流；功能；类和面向对象的编程。通常，Python 程序被打包成**模块**，这些模块是独立的脚本，可以从命令行运行以执行计算任务。

让我们用我们自己的“模块”来介绍 Python 中的一些概念(您可以使用 Jupyter 笔记本来完成):

```
from math import pow

LB_TO_KG = 0.453592
IN_TO_M = 0.0254

class Patient:
    def __init__(self, name, weight_lbs, height_in):
        self.name = name
        self.weight_lbs = weight_lbs
        self.weight_kg = weight_lbs * LB_TO_KG
        self.height_in = height_in
        self.height_m = height_in * IN_TO_M

    def calculate_bmi(self):
        return self.weight_kg / pow(self.height_m, 2)

    def get_height_m(self):
        return self.height_m

if __name__ == '__main__':
    test_patients = [
        Patient('John Smith', 160, 68),
        Patient('Patty Johnson', 180, 73)
    ]
    heights = [patient.get_height_m() for patient in test_patients]
    print(
        "John's height: ", heights[0], '\n',
        "Patty's height: ", heights[1], '\n',
        "John's BMI: ", test_patients[0].calculate_bmi(), '\n',
        "Patty's BMI: ", test_patients[1].calculate_bmi()
    )
```

运行此代码时，您应该会看到以下输出:

```
John's height:  1.7271999999999998 

 Patty's height:  1.8541999999999998 

 John's BMI:  24.327647271211504 

 Patty's BMI:  23.74787410486812
```

前面的代码是一个 Python 模块，它打印两个模拟病人的身高和体重指数。让我们更详细地看看这段代码的每个元素:

*   代码块的第一行是一个**导入语句**。这允许我们导入已经在其他模块中编写的函数和类，这些模块或者是用 Python 发布的，或者是作为开源软件编写的，或者是我们自己编写的。一个**模块**可以简单地认为是一个包含 Python 函数、常量和/或类的文件。它有一个`.py`扩展名。为了完整地导入一个模块，我们可以简单地使用`import`这个词，后面跟着模块名，例如`import math`。注意，我们也使用了`from`关键字，因为我们只想导入一个特定的函数，即`pow()`函数。这也让我们免去了每次想要计算幂时必须输入`math.pow()`的麻烦。
*   接下来的两行包含**常量**，我们将使用它们来执行单位转换。常数通常用大写字母表示。
*   接下来，我们定义一个`Patient`类，它有一个**构造函数**和两个**方法**。构造函数接受三个参数——名称、高度和重量——并将特定`Patient`实例的三个属性设置为等于这三个值。它还将体重从磅转换为千克，将身高从英寸转换为米，并将这些值存储在两个额外的属性中。
*   这两种方法被编码为**函数**，使用`def`关键字。`calculate_bmi()`返回病人的身体质量指数，而`get_height()`只返回身高(米)。
*   接下来，我们有一个迷你`if`语句。这条`if`语句的意思是，只有当它是在命令行调用的主模块时，才运行后续代码。其他`if`语句可能有多个`elif`子句，也可能包含一个最终的`else`子句。
*   接下来，我们创建两个病人的列表，John Smith 和 Patty Johnson，他们的身高和体重在代码中列出。
*   以下代码行使用 list **comprehension** 创建两个患者的身高列表。理解在 Python 编程中非常流行，也可以用字典来执行。
*   最后，我们的`print`语句输出四个数字(两个高度和两个身体质量指数值)。

本章末尾给出了基本 Python 编程语言的更多参考资料。你也可以在 www.python.org 查阅在线文档。



# 熊猫简介

到目前为止，我们讨论的几乎所有特性都是 *base* Python 的特性；也就是说，不需要外部包或库。事实是，我们在这本书里写的大部分代码将属于几个常用于分析的*外部* Python 包之一。**熊猫【http://pandas.pydata.org】库()是后面编程章节不可或缺的一部分。熊猫对于机器学习的功能有三方面:**

*   将数据从平面文件导入 Python 会话
*   使用 pandas DataFrame 及其函数库来处理、操作、格式化和清理数据
*   将 Python 会话中的数据导出到平面文件

让我们依次回顾一下这些函数。

平面文件是存储医疗保健相关数据的流行方法(还有 HL7 格式，不在本书讨论范围内)。平面文件是数据的文本文件表示。使用平面文件，数据可以表示为行和列，类似于数据库，只是标点或空白用作列分隔符，而回车用作行分隔符。我们将在[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)、*在医疗保健*中看到一个平面文件示例。

pandas 允许我们将数据从各种其他 Python 结构和平面文件导入到一个称为 **DataFrame** 的表格 Python 数据结构中，包括 Python 字典、pickle 对象、**逗号分隔值** ( **csv** )文件、**固定宽度格式** ( **fwf** )文件、Microsoft Excel 文件、JSON 文件、HTML 文件，甚至 SQL 数据库表。

一旦数据进入 Python，您就可以使用其他函数来探索和转换数据。需要对一列执行数学函数，比如求它的和？需要执行类似 SQL 的操作，比如连接或者添加列(参见[第三章](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml)、*机器学习基础*)？需要按条件筛选行吗？所有的功能都在熊猫的 API 中。我们将在[第 6 章](023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml)、*测量医疗质量*和[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)、*制作医疗预测模型*中充分利用熊猫的一些功能。

最后，当我们完成对数据的探索、清理和争论后，如果我们可以选择将它导出为所列的大多数格式。或者我们可以将其转换为 NumPy 数组，并训练机器学习模型，就像我们在本书后面将要做的那样。



# 什么是熊猫数据框架？

熊猫数据帧可以被认为是由行和列组成的二维矩阵数据结构。pandas 数据帧类似于 R 中的数据帧或 SQL 中的表。与传统矩阵和其他 Python 数据结构相比，它的优势包括能够在同一个数据帧中包含不同类型的列，一系列预定义的函数便于数据操作，一行接口允许快速转换为其他文件格式，包括数据库、平面文件格式和 NumPy 数组(用于与 scikit-learn 的机器学习功能集成)。所以，`pandas`确实是把很多机器学习管道粘在一起的胶水，从数据导入到算法应用。

pandas 的局限性包括较慢的性能和缺少 pandas 功能的内置并行处理。因此，如果您正在处理数百万或数十亿个数据点，**Apache Spark**([https://spark.apache.org/](https://spark.apache.org/))可能是更好的选择，因为它的语言内置了并行处理。



# 导入数据

在本节中，我们将演示如何通过字典、平面文件和数据库将数据加载到 Python 中。



# 从 Python 数据结构向 pandas 导入数据

使用`pandas`数据帧的第一步是使用`pandas`构造函数`DataFrame()`创建一个数据帧。构造函数接受许多 Python 数据结构作为输入。它还将 NumPy 数组和 pandas **系列**作为输入，后者是另一种类似于列表的一维`pandas`数据结构。这里我们演示如何将列表字典转换成数据帧:

```
import pandas as pd
data = {
    'col1': [1, 2, 3],
    'col2': [4, 5, 6],
    'col3': ['x', 'y', 'z']
}

df = pd.DataFrame(data)
print(df)
```

输出如下所示:

```
   col1  col2 col3

0     1     4    x

1     2     5    y

2     3     6    z
```



# 从平面文件向 pandas 导入数据

因为医疗保健数据通常可以是平面文件格式，比如`.csv`或`.fwf`，所以了解分别将数据从这两种格式导入`pandas`的`read_csv()`和`read_fwf()`函数非常重要。这两个函数都将平面文件的完整路径作为强制参数，以及十多个附加的可选参数，这些参数指定的选项包括列的数据类型、标题行、要包含在数据帧中的列等(函数参数的完整列表可以在网上找到)。最简单的方法通常是将所有列作为字符串类型导入，然后再将这些列转换为其他数据类型。在下面的示例中，通过使用`read_csv()`函数读入包含一个标题行(`row #0`)的平面`.csv`文件，创建了一个名为`data`的数据帧:

```
pt_data = pd.read_csv(data_full_path,header=0,dtype='str')
```

因为固定宽度的文件没有显式的字符分隔符，所以`read_fwf()`函数需要一个额外的参数`widths`，它是一个整数列表，指定每一列的列宽。`widths`的长度应该与文件中的列数相匹配。作为替代，`colspecs`参数接受一个元组列表，指定每列的起点和终点:

```
pt_data = pd.read_fwf(source,widths=data_widths,header=None,dtype='str')
```



# 从数据库向 pandas 导入数据

`pandas`库还具有支持直接从 SQL 数据库导入表格的功能。能够实现这一点的功能包括`read_sql_query()`和`read_sql_table()`。在使用这些函数之前，必须建立到数据库的连接，以便可以将其传递给函数。在以下示例中，使用`read_sql_query()`函数将 SQLite 数据库中的表读入 DataFrame:

```
import sqlite3

conn = sqlite3.connect(pt_db_full_path)
table_name = 'TABLE1'
pt_data = pd.read_sql_query('SELECT * from ' + table_name + ';',conn) 
```

如果您希望连接到一个标准数据库，比如一个 MySQL 数据库，除了 connection 语句之外，代码是类似的，它将使用 MySQL 数据库的相应函数。



# 数据帧上的常见操作

在本节中，我们将讨论对执行分析有用的数据帧操作。关于额外操作的描述，请参考位于[https://pandas.pydata.org/](https://pandas.pydata.org/)的熊猫官方文档。



# 添加列

添加列是数据分析中的常见操作，无论是从头添加新列还是转换现有列。让我们在这里回顾一下这两种类型的操作。



# 添加空白或用户初始化的列

要添加数据帧的新列，您可以在数据帧的名称后面加上新列的名称(用单引号和方括号括起来),并将其设置为您喜欢的任何值。要添加一列空字符串或整数，可以分别设置该列等于`""`或`numpy.nan`(后者需要事先导入`numpy`)。要添加一列零，将该列设置为等于`0`。以下例子说明了这些观点:

```
df['new_col1'] = ""
df['new_col2'] = 0
print(df)
```

输出如下所示:

```
   col1  col2 col3 new_col1  new_col2

0     1     4    x                  0

1     2     5    y                  0

2     3     6    z                  0
```



# 通过转换现有列来添加新列

在某些情况下，您可能希望添加一个新列，该列是现有列的函数。在下面的示例中，标题为`example_new_column_3`的新列被添加为现有列`old_column_1`和`old_column_2`的总和。`axis=1`参数表示您希望对各列进行水平求和，而不是对各列进行垂直求和:

```
df['new_col3'] = df[[
    'col1','col2'
]].sum(axis=1)

print(df)
```

输出如下所示:

```
   col1  col2 col3 new_col1  new_col2  new_col3

0     1     4    x                  0         5

1     2     5    y                  0         7

2     3     6    z                  0         9
```

下面的第二个例子使用 pandas `apply()`函数完成了一个类似的任务。`apply()`是一个特殊的函数，因为它允许您对数据帧中的列应用任何函数(包括您自己的自定义函数):

```
old_column_list = ['col1','col2']
df['new_col4'] = df[old_column_list].apply(sum, axis=1)
print(df)
```

输出如下所示:

```
   col1  col2 col3 new_col1  new_col2  new_col3  new_col4

0     1     4    x                  0         5         5

1     2     5    y                  0         7         7

2     3     6    z                  0         9         9
```



# 删除列

要删除列，您可以使用熊猫的`drop()`功能。它接受一个列和一个列列表，在本例中，附加的可选参数指示哪个是要沿其放置的轴，以及是否在适当的位置放置列:

```
df.drop(['col1','col2'], axis=1, inplace=True)
print(df)
```

输出如下所示:

```
  col3 new_col1  new_col2  new_col3  new_col4

0    x                  0         5         5

1    y                  0         7         7

2    z                  0         9         9
```



# 将函数应用于多列

要对数据帧中的多列应用函数，可以使用一个`for`循环对列列表进行迭代。在以下示例中，预定义的列列表从字符串类型转换为数字类型:

```
df['new_col5'] = ['7', '8', '9']
df['new_col6'] = ['10', '11', '12']

for str_col in ['new_col5','new_col6']:
    df[[str_col]] = df[[str_col]].apply(pd.to_numeric)

print(df)
```

以下是输出:

```
  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6

0    x                  0         5         5         7        10

1    y                  0         7         7         8        11

2    z                  0         9         9         9        12
```



# 组合数据帧

数据帧也可以相互组合，只要它们在组合轴上有相同数量的条目。在此示例中，两个数据帧垂直连接(例如，它们包含相同数量的列，并且它们的行相互堆叠)。通过指定`axis`参数，数据帧也可以水平连接(如果它们包含相同数量的行)。请注意，数据帧中的列名和行名应该相互对应；如果没有，将形成新的列，并为任何缺少的值插入 NaN 值。

首先，我们创建一个新的数据帧名称，`df2`:

```
df2 = pd.DataFrame({
    'col3': ['a', 'b', 'c', 'd'],
    'new_col1': '',
    'new_col2': 0,
    'new_col3': [11, 13, 15, 17],
    'new_col4': [17, 19, 21, 23],
    'new_col5': [7.5, 8.5, 9.5, 10.5],
    'new_col6': [13, 14, 15, 16]
});
print(df2)
```

输出如下所示:

```
  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6

0    a                  0        11        17       7.5        13

1    b                  0        13        19       8.5        14

2    c                  0        15        21       9.5        15

3    d                  0        17        23      10.5        16
```

接下来，我们执行连接。我们将可选的`ignore_index`参数设置为等于`True`，以避免重复的行索引:

```
df3 = pd.concat([df, df2] ignore_index = True)
print(df3)
```

输出如下所示:

```
  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6

0    x                  0         5         5       7.0        10

1    y                  0         7         7       8.0        11

2    z                  0         9         9       9.0        12

3    a                  0        11        17       7.5        13

4    b                  0        13        19       8.5        14

5    c                  0        15        21       9.5        15

6    d                  0        17        23      10.5        16
```



# 将数据框架列转换为列表

要将一列的内容提取到一个列表中，可以使用`tolist()`函数。在转换成列表后，可以使用`for`循环和理解对数据进行迭代:

```
my_list = df3['new_col3'].tolist()
print(my_list)
```

输出如下所示:

```
[5, 7, 9, 11, 13, 15, 17]
```



# 获取和设置数据帧值

`pandas`库提供了两个主要方法来选择性地获取和设置数据帧中的值:`loc`和`iloc`。`loc`方法主要用于**基于标签的索引**(例如，分别使用它们的索引/列名来标识行/列)，而`iloc`方法主要用于**基于整数的索引**(例如，使用它们在数据帧中的整数位置来标识行/列)。您希望访问的行和列的特定标签/索引在数据帧名称后用方括号提供，行标签/索引在列标签/索引之前，用逗号分隔。让我们看一些例子。



# 使用基于标签的索引和 loc 获取/设置值

数据帧的`.loc`属性用于选择使用条目标签的值。它可用于从数据帧中检索单个标量值(对行和列都使用单个字符串标签)，或从数据帧中检索多个值(使用行/列标签列表)。单索引和多索引也可以结合使用，以便从单个行或列中获取多个值。以下代码行说明了从`df`数据帧中检索单个标量值:

```
value = df3.loc[0,'new_col5']
print(value)
```

输出将是`7.0`。

也可以使用`.loc`属性和等号设置单个/多个值:

```
df3.loc[[2,3,4],['new_col4','new_col5']] = 1
print(df3)
```

输出如下所示:

```
  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6

0    x                  0         5         5       7.0        10

1    y                  0         7         7       8.0        11

2    z                  0         9         1       1.0        12

3    a                  0        11         1       1.0        13

4    b                  0        13         1       1.0        14

5    c                  0        15        21       9.5        15

6    d                  0        17        23      10.5        16
```



# 通过 iloc 使用基于整数的标签获取/设置值

`.iloc`属性的工作方式与`.loc`属性非常相似，除了它使用被访问的行和列的整数位置，而不是它们的标签。在下面的例子中，第 101 行(不是第 100 行，因为索引从 0 开始)和第 100 列的值被传送到`scalar_value`:

```
value2 = df3.iloc[0,5]
print(value2)
```

输出为`7.0`。

注意，与`.loc`类似，包含多个值的列表可以传递给`.iloc`属性，以便一次更改一个数据帧的多个条目。



# 使用切片获取/设置多个连续值

有时，我们希望获取或设置的多个值恰好在相邻的列中。在这种情况下，我们可以使用方括号内的**切片**来选择多个值。通过切片，我们指定了希望访问的数据的起点和终点。我们可以用`.loc`和`.iloc`进行切片，尽管使用整数和`.iloc`进行切片更常见。下面几行代码演示了切片以检索数据帧的一部分(我们也可以使用等号分配元素)。请注意，切片也可以用于访问列表和元组中的值(如本章前面所述):

```
partial_df3 = df3.loc[1:3,'new_col2':'new_col4']
print(partial_df3)
```

输出如下所示:

```
   new_col2  new_col3  new_col4

1         0         7         7

2         0         9         1

3         0        11         1
```



# 使用 at 和 iat 快速获取/设置标量值

如果我们确定只希望在数据帧中获取/设置单个值，我们可以分别使用`.at`和`.iat`属性，以及单个标签/整数。只要记住，`.iloc`和`.iat`中的`i`代表“整数”:

```
value3 = df3.iat[3,3]
print(value3)
```

输出为`11`。



# 其他操作

另外两个常见的操作是使用布尔条件过滤行和对行进行排序。在这里，我们将回顾每一项操作。



# 使用布尔索引筛选行

到目前为止，我们已经讨论了使用标签、整数和切片来选择数据帧中的值。有时，在一个语句中选择满足特定条件的特定行会很方便。例如，如果我们想限制对年龄大于或等于 50 岁的人进行分析。

pandas 数据帧支持**布尔索引**，也就是说，如果布尔向量的长度等于数据帧中的行数，则使用布尔值向量来指示我们希望包含哪些值。因为包含 DataFrame 列的条件语句正好产生这样的结果，所以我们可以使用这样的条件语句来索引数据帧。在下面的示例中，`df`数据帧被过滤为仅包含`age`列的值等于或超过`50`的行:

```
df3_filt = df3[df3['new_col3'] > 10]
print(df3_filt)
```

输出如下所示:

```
  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6

3    a                  0        11         1       1.0        13

4    b                  0        13         1       1.0        14

5    c                  0        15        21       9.5        15

6    d                  0        17        23      10.5        16
```

条件语句可以使用逻辑运算符如`|`或`&`链接在一起。



# 排序行

如果您希望按照数据帧中某一列的值对数据帧进行排序，可以使用`sort_values()`函数来完成。只需将列名指定为第一个参数。`ascending`是可选参数，用于指定排序方向:

```
df3 = df3.sort_values('new_col4', ascending=True)
print(df3)
```

输出如下所示:

```
  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6

2    z                  0         9         1       1.0        12

3    a                  0        11         1       1.0        13

4    b                  0        13         1       1.0        14

0    x                  0         5         5       7.0        10

1    y                  0         7         7       8.0        11

5    c                  0        15        21       9.5        15

6    d                  0        17        23      10.5        16
```



# 类似 SQL 的操作

对于习惯于在 SQL 中使用异构类型表的人来说，切换到 Python 中的类似分析似乎是一项艰巨的任务。幸运的是，有许多`pandas`函数可以组合起来产生类似于普通 SQL 查询的结果，使用诸如分组和连接之类的操作。在`pandas`文档中甚至有一小节([https://pandas . pydata . org/pandas-docs/stable/comparison _ with _ sql . html](https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html))描述了如何使用`pandas`数据帧执行类似 SQL 的操作。我们在本节中提供了两个这样的例子。



# 获取聚合行数

有时，您可能希望获得某一列中特定值出现的计数或计数。例如，您可能有一个医疗保健数据集，并且您想知道在患者就诊期间使用了多少次特定的支付方式。在 SQL 中，您可以编写一个查询，将一个`GROUP BY`子句与一个聚合函数(在本例中为`COUNT(*)`)结合使用，以获得付款方式的记录:

```
SELECT payment, COUNT(*)
FROM data
GROUP BY payment;
```

在`pandas`中，同样的结果是通过将`groupby()`和`size()`函数链接在一起实现的:

```
tallies = df3.groupby('new_col4').size()
print(tallies)
```

输出如下所示:

```
new_col4

1     3

5     1

7     1

21    1

23    1

dtype: int64
```



# 连接数据框架

在第 4 章、*计算基础-数据库*中，我们讨论了使用`JOIN`操作合并两个数据库表中的数据。要使用联接操作，需要指定两个表的名称，以及联接类型(左、右、外或内)和要联接的列:

```
SELECT *
FROM left_table OUTER JOIN right_table
ON left_table.index = right_table.index;
```

在 pandas 中，您可以使用`merge()`或`join()`函数完成表连接。默认情况下，`join()`函数连接表索引上的数据；但是，通过指定`on`参数可以使用其他列。如果被连接的两个表中的列名重叠，您将需要指定一个`rsuffix`或`lsuffix`参数来重命名这些列，使它们不再具有相同的名称:

```
df_join_df2 = df.join(df2, how='outer', rsuffix='r')
print(df_join_df2)
```

输出如下(注意第 3 行中的`NaN`值，该行在`df`中不存在):

```
  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6 col3r  \

0    x                0.0       5.0       5.0       7.0      10.0     a   

1    y                0.0       7.0       7.0       8.0      11.0     b   

2    z                0.0       9.0       9.0       9.0      12.0     c   

3  NaN      NaN       NaN       NaN       NaN       NaN       NaN     d   

  new_col1r  new_col2r  new_col3r  new_col4r  new_col5r  new_col6r  

0                    0         11         17        7.5         13  

1                    0         13         19        8.5         14  

2                    0         15         21        9.5         15  

3                    0         17         23       10.5         16 
```



# scikit 简介-了解

整本书都写在**scikit-learn**([http://scikit-learn.org/stable/](http://scikit-learn.org/stable/))上。scikit-learn 库有许多子模块。本书中将只使用其中的几个子模块(在第 7 章、*医疗保健中的预测模型*中)。例如，这包括`sklearn.linear_model`和`sklearn.ensemble`子模块。这里我们将给出一些更常用的子模块的概述。为了方便起见，我们将相关模块分组到数据科学管道的各个部分，在[第 1 章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)、*医疗保健分析简介*、**中讨论。**



# 抽样资料

scikit-learn 在`sklearn.datasets`子模块中包括几个样本数据集。其中至少有两个数据集`sklearn.datasets.load_breast_cancer`和`sklearn.datasets.load_diabetes`与医疗保健相关。这些数据集已经过预处理，规模很小，仅涵盖几十个特征和数百名患者。我们将在[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)、*制作医疗保健预测模型*中使用的数据要大得多，并且类似于您可能从现代医疗保健组织收到的数据。然而，这些样本 sklearn 数据集对于试验 scikit-learn 函数是有用的。



# 数据预处理

数据预处理功能存在于`sklearn.preprocessing`子模块中。本模块的一些相关功能将在以下章节中讨论。



# 分类变量的一键编码

几乎每个数据集都包含一些分类数据。**分类数据**是离散数据，其中的值可以采用有限数量的可能值(通常编码为“字符串”)。因为 Python 的 scikit-learn 只能处理数字数据，所以在使用 scikit-learn 执行机器学习之前，我们必须找到编码分类变量的替代方法。

使用 **one-hot 编码**，也称为 **1-of-K 编码方案**，具有 *k* 个可能值的单个分类变量被转换为 *k* 个不同的二进制变量，当且仅当该列的观察值等于其代表的值时，每个变量为正。在[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)、*在医疗保健中建立预测模型*中，我们提供了一个关于什么是单热编码的详细示例，并使用一个名为`get_dummies()`的 pandas 函数在真实的临床数据集上执行单热编码。scikit-learn 也有一个用于执行一键编码的类，但是，它是`sklearn.preprocessing`模块中的`OneHotEncoder`类。

关于如何使用`OneHotEncoder`的说明，可以访问 scikit-learn 文档:[http://sci kit-learn . org/stable/modules/preprocessing . html # encoding-categorial-features](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)。



# 缩放和居中

对于一些机器学习算法，最好不仅转换分类变量(使用之前讨论过的一键编码)，而且转换连续变量。回想一下[第 1 章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)、*医疗保健分析简介*中的内容，连续变量是数值型的，可以采用任何合理的值(尽管在许多情况下它们被限制为整数)。一个特别常见的做法是**标准化**每个连续变量，使得变量的*均值为零，标准差为一*。例如，以`AGE`变量为例:它的典型范围是从 0 到 100，平均值可能是 40。让我们假设对于一个特定的人群，我们的`AGE`变量的平均值是 40，标准差是 20。如果我们将我们的`AGE`变量居中并重新调整，一个 40 岁的人在转换后的变量中将被表示为零。20 岁的人表示为-1，60 岁的人表示为 1，80 岁的人表示为 2，50 岁的人表示为 0.5。这种转换防止具有较大范围的变量在机器学习算法中被过度表示。

scikit-learn 有许多内置的类和函数，用于居中和缩放数据，包括`sklearn.preprocessing.StandardScaler()`、`sklearn.preprocessing.MinMaxScaler()`和`sklearn.preprocessing.RobustScaler()`。这些不同的工具专门用于集中和缩放不同类型的连续数据，例如正态分布变量或具有许多异常值的变量。

有关如何使用缩放类的说明，可以查看 scikit-learn 文档:[http://sci kit-learn . org/stable/modules/preprocessing . html # standardization-or-mean-removal-and-variance-scaling](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling)。



# 二值化

**二进制化**是另一种将连续变量转换成二进制变量的转换。例如，如果我们有一个名为`AGE,`的连续变量，我们可以将 50 岁左右的变量二进制化，将 50 岁以上的年龄阈值化为 1，将 50 岁以下的年龄阈值化为 0。当你有很多变量时，二值化有利于节省时间和内存；然而，在实践中，原始连续值通常表现更好，因为它们提供的信息更多。

虽然使用前面演示的代码也可以在 pandas 中执行二进制化，但是 scikit-learn 附带了一个`Binarizer`类，也可以用于二进制化特征。关于使用`Binarizer`类的说明，可以访问[http://sci kit-learn . org/stable/modules/preprocessing . html # binary ization](http://scikit-learn.org/stable/modules/preprocessing.html#binarization)。



# 归罪

在[第 1 章](b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml)、*医疗保健分析简介*中，我们提到了处理缺失数据的重要性。**插补**是一种处理缺失值的策略，其中缺失值由基于现有数据得出的估计值填充。在医疗保健领域，两种常见的插补类型是**零插补**，其中缺失数据被视为零(例如，如果某个特定诊断的值为`NULL`，很可能是因为它没有出现在患者图表中)和**均值插补**，其中缺失数据被视为当前数据分布的均值(例如，如果患者年龄缺失，我们可以将其插补为 40)。我们在[第 4 章](e1b89921-e75b-4b16-a567-8970a173db53.xhtml)、*计算基础-数据库*中演示了各种插补方法，我们将在[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)、*医疗保健中制作预测模型*中编写自己的自定义函数来执行插补。

Scikit-learn 附带了一个用于执行不同类型插补的`Imputer`类。您可以在[http://sci kit-learn . org/stable/modules/preprocessing . html # attutation-of-missing-values](http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values)上查看关于如何使用它的详细信息。



# 特征选择

在机器学习中，经常有一种误解，认为数据越多越好。对于观察值(例如，数据集中的行数)，这通常是正确的。然而，对于特性来说，越多并不总是越好。在某些情况下，特征越少，性能可能反而越好，因为具有高相关性的多个特征会使预测产生偏差，或者因为存在的特征多于观测值的数量。

在其他情况下，性能可能与一半的功能相同或稍微差一点，但由于多种原因，包括时间考虑、内存可用性或向其他非技术利益相关者解释和说明的方便性，较少数量的功能可能是理想的。在任何情况下，对数据执行一些特征选择几乎总是一个好主意。即使您不希望移除任何要素，执行要素选择并对要素重要性进行排序也可以让您深入了解模型并理解其预测行为和性能。

在`sklearn.feature_selection`模块中有许多为特征选择而构建的类和函数，不同的类集合对应于执行特征选择的不同方法。例如，单变量特征选择涉及测量每个预测变量和目标变量之间的统计相关性，这可以使用`SelectKBest`或`SelectPercentile`类等来完成。`VarianceThreshold`类移除观测值间方差较低的要素，例如，那些几乎总是为零的要素。在模型拟合之后，`SelectFromModel`类删除不满足某个强度要求(在系数或特征重要性方面)的特征。

有关 scikit-learn 中功能选择类的完整列表，请访问[http://sci kit-learn . org/stable/modules/feature _ selection . html # univariate-feature-selection](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)。



# 机器学习算法

机器学习算法为预测新的观察结果提供了一个数学框架。scikit-learn 支持几十种不同的 ML 算法，这些算法各有优缺点。我们将在这里简要讨论其中的一些算法及其相应的 scikit-learn API 功能。我们将在[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)、*中使用其中的一些算法，在医疗保健领域建立预测模型*。



# 广义线性模型

正如我们在[第 3 章](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml)、*机器学习基础*中所讨论的，一个**线性模型**可以被随意地认为是一个特征的加权组合(例如，一个加权和)来预测一个目标值。这些特征是通过观察确定的；每个特征的权重由模型决定。线性回归预测一个连续变量，而逻辑回归可以被认为是线性回归的一种扩展形式，其中预测的目标经过 **logit 变换**转换为一个范围在 0 到 1 之间的变量。这种转换对于执行二元分类任务很有用，例如当有两种可能的结果时。

在 scikit-learn 中，这两种算法由`sklearn.linear_model.LogisticRegression`和`sklearn.linear_model.LinearRegression`类表示。我们将在第 7 章、*中演示逻辑回归，在医疗保健中制作预测模型*。



# 集成方法

**集成方法**涉及使用不同 ML 模型的组合进行预测。例如，**随机森林**是决策树分类器的集合，这些分类器通过为每棵树选择和使用特定的特征集而彼此去相关。此外， **AdaBoost** 是一种算法，它适合许多弱学习者对数据进行有效预测。这些算法由`sklearn.ensemble`模块支持。



# 其他机器学习算法

其他一些流行的机器学习算法包括朴素贝叶斯算法、k-最近邻、神经网络、决策树和支持向量机。这些在 scikit-learn 中分别由`sklearn.naive_bayes`、`sklearn.neighbors`、`sklearn.neural_network`、`sklearn.tree`和`sklearn.svm`模块支持。在[第 7 章](d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml)、*在医疗保健领域制作预测模型*中，我们将在临床数据集上制作神经网络模型。



# 性能评价

最后，一旦我们使用我们期望的算法建立了模型，测量它的性能是很重要的。`sklearn.metrics`模块对此很有用。正如在[第 3 章](46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml)、*机器学习基础*中所讨论的，混淆矩阵对于分类任务尤其重要，它由`sklearn.metrics.confusion_matrix()`函数支持。确定受试者工作特性(ROC)曲线和计算曲线下的**面积( **AUC** )可分别使用`sklearn.metrics.roc_curve()`和`sklearn.metrics.roc_auc_score()`功能完成。精确召回曲线是 ROC 曲线的替代曲线，对于不平衡数据集很重要，它们受`sklearn.metrics.precision_recall_curve()`函数支持。**



# 附加分析库

这里我们提到三个常用于分析的重要包:NumPy、SciPy 和 matplotlib。



# 笨笨和笨笨

**NumPy**([www.numpy.org](http://www.numpy.org/))是 Python 的矩阵库。使用`numpy.array()`和类似的构造，可以创建大型矩阵，并对其执行各种数学运算(包括矩阵加法和乘法)。NumPy 也有许多操作矩阵形状的函数。NumPy 的另一个特性是存在熟悉的数学函数，如`sin()`、`cos()`和`exp()`。

**SciPy**([www.scipy.org](http://www.scipy.org))是一个包含许多高级数学模块的工具箱。其机器学习相关的子包有`cluster`、`stats`、`sparse`、`optimize`。SciPy 是在 Python 中实现科学计算的一个重要包。



# matplotlib

matplotlib([https://matplotlib.org](https://matplotlib.org))是一个流行的 Python 二维绘图库。根据它的网站，一个人“只需要几行代码就可以生成图表、直方图、功率谱、条形图、误差图、散点图等等。”它的绘图库提供了大量的选项和功能，支持高度定制。



# 摘要

在这一章中，我们快速浏览了基本的 Python 语言，以及对执行分析很重要的两个 Python 库:pandas 和 scikit-learn。我们现在已经完成了这本书的基础章节。

在[第 6 章](023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml)、*测量医疗质量*中，我们将深入一些真实世界的医疗服务提供者绩效数据，并使用 pandas 对其进行分析。