

# 六、使用多类逻辑回归分类树进木

多类逻辑回归是**机器学习** ( **ML** )算法，用于将事件、实体和行为分类到固定数量的类别中。当需要预测一个实体到多个组的分类时，它可以跨不同的行业和业务场景使用。一个典型的分类用例是希望根据公司的盈利能力和偏好对客户群进行细分，以便通过最有效的营销活动锁定正确的客户。

这种技术是二元逻辑回归的扩展，它允许我们克服两个可能标签的限制，并对我们可以找到多个类别进行识别的其他环境开放适用性。

在本章中，我们将看到利用 BigQuery ML 实现、评估和测试多类逻辑回归模型的所有必要步骤。

在本章中，我们将讨论以下主题:

*   介绍业务场景
*   发现多类逻辑回归
*   探索和理解数据集
*   训练多类逻辑回归模型
*   评估多类逻辑回归模型
*   使用多类逻辑回归模型
*   得出商业结论

# 技术要求

本章要求您访问网络浏览器，并能够利用以下功能:

*   访问谷歌云控制台的 GCP 帐户
*   托管 BigQuery 数据集的 GCP 项目

现在我们已经准备好了技术需求，让我们开始分析和开发我们的 BigQuery ML 逻辑回归模型。

看看下面的视频，看看代码是如何运行的:[https://bit.ly/3h4w7xG](https://bit.ly/3h4w7xG)

# 介绍业务场景

对于这个商业场景，我们可以想象自己是纽约市的一名 ML 专家。在城市应该开展的所有活动中，对树木进行普查并核实它们的状况是最耗时的工作之一。

这些树分布在纽约市的不同地区，收集每棵树信息的过程由志愿者或纽约市员工手动完成。收集信息后，数据将存储在数据库中，并通过 BigQuery 公共数据集公开提供，以供进一步分析([https://console . cloud . Google . com/market place/details/city-of-new-York/NYC-tree-census](https://console.cloud.google.com/marketplace/details/city-of-new-york/nyc-tree-census))。

在下图中，我们可以看到一张来自中央公园的图片，中央公园是纽约市树木较多的区域之一:

![Figure 6.1 – Trees in Central Park, New York City
](img/B16722_06_001.jpg)

图 6.1-纽约市中央公园的树木

为了支持并加快负责分类树木和评估其状况的人员的工作，您的一位经理可能会要求您建立一个 ML 模型。

ML 模型的目标是根据树木的特征，如位置、大小和健康状况，自动将树木分类为不同的种类。

对于这个用例，我们可以只关注城市中最常见的五种树木。

既然我们已经简要地解释和理解了业务场景，那么让我们来看看 ML 技术，我们可以用它来将对象或事件分类到多个类中。

# 发现多类逻辑回归

在这一部分，我们将学习多类逻辑回归的基础知识，以及何时可以应用这一技术。

**多类逻辑回归**是一种分类技术，可用于将事件、对象、客户或其他实体分为多个类别。与二元逻辑回归不同，这种 ML 算法可用于将输出值分为两个以上的离散类。

为了预测多个标签中的一个，该 ML 算法计算每个结果的概率，并选择具有最高概率的标签。

作为一种回归算法，标签的预测基于一组称为特征的自变量，这些自变量用于预测称为标签的因变量。

这种 ML 技术可用于回答业务问题，例如:

*   我的客户*的评论是中立*、*正面*还是*负面*？
*   我的客户属于*黄金*、*白银*还是*青铜*级别？
*   特定客户*流失的概率是高*、*中*还是*低*？
*   图像识别算法是否识别出一只*猫*，一只*狗*，一只*老鼠*，或者一只*牛*？

在我们的业务场景中，由于树木的种类有限，我们将只关注五个种类，所以我们可以利用多类逻辑回归。具体来说，我们感兴趣的是根据树的大小、位置和健康状况等特征将树分类为五个物种中的一个。

训练多类逻辑回归模型意味着尝试查找可在输入变量(称为要素)和输出变量(称为标注)之间的方程中使用的系数值。

在训练之后，我们将利用**混淆矩阵**来评估我们的多类逻辑回归模型的性能。在多类逻辑回归中，多行和多列构成混淆矩阵。

为了评估我们的 ML 模型的性能，我们将再次使用曲线 ( **AUC** ) **下的**区域接收器操作特性** ( **ROC** )。**

既然我们已经学习了多类逻辑回归的基础知识，是时候看看我们将用来构建 ML 模型的数据集了。

# 探索和理解数据集

正如我们在前面的用例中已经做的那样，在进入 ML 模型的开发之前，有必要分析可以用来解决我们用例的数据。

我们将从分析表结构开始，以便清楚地理解可以用于我们的业务场景的数据。

## 理解数据

在这一节中，我们将看一看数据，了解它的结构以及如何用它来构建我们的 ML 模型。

要开始研究数据，我们需要做以下工作:

1.  登录谷歌云控制台，从导航菜单访问 **BigQuery** 用户界面。
2.  在我们在第 2 章 、*设置您的 GCP 和 BigQuery 环境*中创建的项目下创建一个新的数据集。对于这个用例，我们将使用默认选项创建数据集`06_nyc_trees`。
3.  打开 GCP 项目`new_york_trees`。
4.  As we can see in the following screenshot, the BigQuery public dataset contains multiple tables to host the data collected every 10 years:![Figure 6.2 – The New York City Trees Public dataset contains the census 
    of the trees collected every 10 years
    ](img/B16722_06_002.jpg)

    图 6.2-纽约市树木公共数据集包含每 10 年收集的树木普查数据

5.  我们就用最近的一个:`tree_census_2015`。此表包含了所有在纽约市种植并在 2015 年注册的树木的信息。
6.  Let's click on the table name `tree_census_2015` in the BigQuery navigation menu to access the schema of the table:![Figure 6.3 – The structure of the tree_census_2015 table lists all the fields 
    that can be used as labels and features
    ](img/B16722_06_003.jpg)

    图 6.3-tree _ census _ 2015 表的结构列出了所有可用作标注和要素的字段

7.  Each field is well described in the **Description** column.

    该表包含由一个**字符串**表示的 **spc_latin** 列，该字符串表示每棵树的物种的学名。这个字段将是我们 ML 模型的标签。

    为了对每棵树进行分类，我们可以利用其他领域的信息。一些列描述了树的大小。例如， **tree_dbh** 测量树的直径， **stump_diam** 表示树桩的直径。我们还可以利用关于树的健康状况的信息。我们可以想象一些物种比其他物种更健壮，更适合纽约的天气。

    其他领域更多地与树在城市中的位置以及它生活的环境有关。为了训练我们的 ML 模型，我们可以使用树所在的 zip 区域: **zip_city** 。其他一些例子是 **boroname** 列，它包含种植这棵树的行政区的名称，以及 **nta_name** ，它表示这棵树所在的街区。

    我们还可以假设一些物种比其他物种更具侵入性——**人行道**字段指示与树相邻的人行道是否被树的根部损坏、裂开或抬起。

    从模式的角度来看，这个表包含了许多有用的信息，可以用来开发我们的分类模型。让我们继续分析，深入研究数据。

在本节中，我们已经分析了 **tree_census_2015** 表的元数据，现在是时候查看实际数据并开始查询它了。

## 检查数据质量

正如我们已经从前面的用例中了解到的，数据质量是构建有效的 ML 模型的基础。在本节中，我们将应用一些数据质量检查，以确定要使用的正确记录:

1.  First of all, we'll check if the table `tree_census_2015` contains records with `spc_latin` equals to NULL. This is fundamental because the field `spc_latin` will be used as label of our machine learning model:

    ```py
    SELECT  COUNT(*) total
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             spc_latin is NULL;
    ```

    代码块将计算字段`spc_latin`为空的表“`bigquery-public-data.new_york_trees.tree_census_2015`”中的所有记录。

    在下面的屏幕截图中，您可以看到查询结果，其中我们得到了一个大于 31000 的值:

    ![Figure 6.4 – The result of the query shows that some rows contain empty labels
    ](img/B16722_06_004.jpg)

    图 6.4-查询结果显示一些行包含空标签

    因此，在接下来的查询中，我们将排除字段`spc_latin`为空的记录。

2.  Focusing only on the rows where the field `spc_latin` is `NOT NULL`, we can check the presence of empty values on all the other fields that are potential features of our ML model:

    ```py
    SELECT  COUNT(*)
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             spc_latin is NOT NULL
             AND (
                zip_city is NULL OR
                tree_dbh is NULL OR
                boroname is NULL OR
                nta_name is NULL OR
                nta_name is NULL OR
                health is NULL OR
                sidewalk is NULL) ;
    ```

    此外，在这种情况下，查询结果不为零。事实上，我们可以很容易地识别出在`health`和`sidewalk`字段中呈现`NULL`值的三条记录。

    我们将在 ML 模型生命周期的以下阶段过滤这些记录。

现在我们已经对我们的数据集进行了一些质量检查，并且我们已经了解了应该过滤哪些记录,让我们将重点放在分割我们的数据集上，以将我们的 BigQuery ML 模型的创建集中在五个最常见的树种上。

## 分割数据集

在此部分，我们将准备用于训练、评估和测试 ML 模型的表格。

出于我们的目的，我们将提取数据集中出现频率最高的五个物种。之后，我们将创建 BigQuery 表，用于训练、评估和测试我们的 ML 模型:

1.  First of all, we'll identify only the five most frequent species in the `tree_census_2015` table with the following query:

    ```py
    SELECT   spc_latin,
             COUNT(*) total
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             spc_latin is NOT NULL
             AND zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
    GROUP BY
             spc_latin
    ORDER BY
             total desc
    LIMIT 5;
    ```

    SQL 语句使用`GROUP BY spc_latin`子句和`COUNT(*)`运算符计算每个物种在`tree_census_2015`表中出现的次数。

    该查询根据字段`total`的值以降序方式对记录进行排序，该字段包含`COUNT`的结果。最后，查询的结果集被限制为结果集的前五条记录，查询的末尾有一个`LIMIT 5`子句。

    SQL 语句基于 BigQuery 公共表`tree_census_2015`,该表通过我们在前面的*检查数据质量*小节中确定的数据质量检查进行了适当的过滤。

    在下面的屏幕截图中，我们可以看到查询结果和数据集中最常见的树种:

    ![Figure 6.5 – The result of the query shows the most common trees in New York City
    ](img/B16722_06_005.jpg)

    图 6.5-查询结果显示了纽约市最常见的树

    从查询结果中，我们可以很容易地读出从最常见到最不常见排序的树的拉丁名称。

2.  Since we'll use this subset of five species in the next SQL queries, we can add a `CREATE TABLE` statement at the beginning of our `SELECT` statement in order to materialize the results in the `top5_species` table:

    ```py
    CREATE OR REPLACE TABLE `06_nyc_trees.top5_species` AS
          SELECT   spc_latin,
             COUNT(*) total
          FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
          WHERE
                   spc_latin is NOT NULL
                   AND zip_city is NOT NULL
                   AND tree_dbh is NOT NULL
                   AND boroname is NOT NULL
                   AND nta_name is NOT NULL
                   AND health is NOT NULL
                   AND sidewalk is NOT NULL
          GROUP BY
                   spc_latin
          ORDER BY
                   total desc
          LIMIT 5;
    ```

    通过执行查询，我们将创建一个只包含两个字段和五条记录的新表。`spc_latin`表示树的种类，而`total`统计每个种类在原始数据集中出现的次数。

3.  Now, we can leverage the `top5_species` table to filter only the species on which we're focusing and create the training table:

    ```py
    CREATE OR REPLACE TABLE `06_nyc_trees.training_table` AS 
    SELECT  *
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
             AND spc_latin in 
             (SELECT spc_latin from  `06_nyc_trees.top5_species`)
             AND MOD(tree_id,11)<=8;
    ```

    该查询通过`SELECT *`语句创建一个包含原始数据集中所有可用列的表。它应用所有必要的过滤器来获取`spc_latin`标签和所有其他潜在特征的非空值。

    通过使用`IN`子句，`training_table`将只包含与数据集中最常见的五个物种相关的记录。

    带有子句`MOD(tree_id,11)<=8`的查询的最后一行，只允许我们从整个记录集中选取 80%的记录。`MOD`代表模，返回`tree_id`除以 11 的余数。

4.  With a similar approach, we can create the table that will be used for the evaluation of our ML model:

    ```py
    CREATE OR REPLACE TABLE `06_nyc_trees.evaluation_table` AS 
    SELECT  *
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
             AND spc_latin in 
             (SELECT spc_latin from `06_nyc_trees.top5_species`) 
             AND MOD(tree_id,11)=9;
    ```

    对于`evaluation_table`，我们将使用过滤器`MOD(tree_id,11)=9`只选取 10%的记录。

5.  Finally, we'll execute the following SQL statement in order to create the table that will be used to apply our multiclass classification model:

    ```py
    CREATE OR REPLACE TABLE `06_nyc_trees.classification_table` AS 
    SELECT  *
    FROM    `bigquery-public-data.new_york_trees.tree_census_2015`
    WHERE
             zip_city is NOT NULL
             AND tree_dbh is NOT NULL
             AND boroname is NOT NULL
             AND nta_name is NOT NULL
             AND health is NOT NULL
             AND sidewalk is NOT NULL
             AND spc_latin in 
             (SELECT spc_latin from `06_nyc_trees.top5_species`) 
             AND MOD(tree_id,11)=10;
    ```

    `classification_table`与前面的数据集片段非常相似，但是由于`MOD`函数将包含数据集剩余的 10%。

在这一节中，我们分析了`new_york_trees`数据集，它包含关于纽约市树木的信息。我们应用了一些数据质量检查来排除空值。然后，我们将数据分段，重点关注表格中出现的五种最常见的物种。现在我们已经完成了准备步骤，是时候继续前进，开始训练我们的 BigQuery ML 模型了。

# 训练多类逻辑回归模型

既然我们已经清楚地理解了数据的结构，并且我们已经将它分割成多个表以支持 ML 模型生命周期的不同阶段，那么让我们将注意力集中在我们的多类逻辑回归模型的训练上。我们将执行 SQL 查询来创建多类逻辑回归模型:

1.  Let's start creating the first version of our ML model:

    ```py
    CREATE OR REPLACE MODEL `06_nyc_trees.classification_model_version_1`
    OPTIONS
      ( model_type='LOGISTIC_REG',
        auto_class_weights=TRUE
      ) AS
    SELECT
      zip_city,
      tree_dbh,
      spc_latin as label
    FROM
      `06_nyc_trees.training_table` ;
    ```

    用于创建`classification_model_version_1`模型的查询只基于两个特征:邮政编码区域和树的直径。

    SQL 语句以用于运行训练的关键字`CREATE OR REPLACE MODEL`开始，后面是`OPTIONS`子句。在选项中，我们可以指定型号类型等于`LOGISTIC_REG`和`auto_class_weights=TRUE`。当我们面对不平衡的训练数据集，其中一些标签比其他标签出现得更频繁时，此选项会特别有用。在我们的例子中，最常见物种的出现次数是第五种的两倍多。为此，我们应用了这种调整。

    重要说明

    BigQuery ML 语法不区分二元逻辑回归和多类逻辑回归。在这两种情况下，BigQuery ML 模型类型都是`LOGISTIC_REG`。这种差异是由出现在定型数据集的列标签中的不同值的数量造成的。如果标签只显示两个值，BigQuery ML 将训练一个二元逻辑回归。如果标签包含两个以上不同的值，模型将被训练为多类逻辑回归。

2.  After the execution of the training, we can access the information of our first ML model by clicking on **classification_model_version_1** from the navigation menu and selecting the **Evaluation** tab.

    下面的屏幕截图展示了我们第一次尝试的关键性能指标:

    ![Figure 6.6 – The Evaluation tab shows the performance metrics related 
    to the selected BigQuery ML model
    ](img/B16722_06_006.jpg)

    图 6.6–评估选项卡显示了与所选 BigQuery ML 模型相关的性能指标

    为了对我们的 ML 模型的有效性有一个概念，我们可以看一下 **ROC AUC** 值 **0.7383** 。

    通过在**评估**标签中向下滚动鼠标，我们可以看到我们的多类逻辑回归模型的混淆矩阵。

    在下图中，混淆矩阵显示了训练数据集中预测标签和实际标签的百分比:

    ![Figure 6.7 – The Evaluation tab shows the confusion matrix related to the selected BigQuery ML model
    ](img/B16722_06_007.jpg)

    图 6.7–评估选项卡显示了与所选 BigQuery ML 模型相关的混淆矩阵

    查看混淆矩阵，我们可以直观地注意到我们的 ML 模型对一些物种工作得很好，但对另一些物种表现很差。例如，当实际的标签是**沼泽栎**时，在 40%的情况下，ML 模型建议不同的物种:**悬铃木**。

3.  Let's try to improve our model by adding new features with the following BigQuery ML SQL statement:

    ```py
    CREATE OR REPLACE MODEL `06_nyc_trees.classification_model_version_2`
    OPTIONS
      ( model_type='LOGISTIC_REG',
        auto_class_weights=TRUE
      ) AS
    SELECT
      zip_city,
      tree_dbh,
      boroname,
      nta_name,
      spc_latin as label
    FROM
      `06_nyc_trees.training_table` ;
    ```

    与第一次尝试相比，我们在模型的训练中加入了额外的功能。事实上，我们已经将包含在`boroname`字段和`nta_name`中的行政区名称添加到了特性列表中。

    在执行 SQL 语句之后，让我们访问新模型的**评估**选项卡，看看我们是否正在改进它的性能。看一下 **ROC AUC** 值 **0.7667** ，我们可以看到我们模型的性能略有提高。

4.  As a last attempt, we'll enrich our ML model with additional features. The new fields are related to the health of the tree and to the size of the roots:

    ```py
    CREATE OR REPLACE MODEL `06_nyc_trees.classification_model_version_3`
    OPTIONS
      ( model_type='LOGISTIC_REG',
        auto_class_weights=TRUE
      ) AS
    SELECT
      zip_city,
      tree_dbh,
      boroname,
      nta_name,
      health,
      sidewalk,
      spc_latin as label
    FROM
      `06_nyc_trees.training_table`;
    ```

    与之前的 ML 模型相比，在`classification_model_version_3`中，我们包含了描述我们的树的健康状态的字段`health`，以及用于指定树根是否正在损害相邻路面的字段`sidewalk`。

5.  Looking at the performance of our last ML model in the `0.7696`.

    小费

    尽管更多特征的使用可以增加 BigQuery ML 分类模型的 ROC AUC 值，但是我们需要考虑性能改进和实现它所花费的资源之间的平衡。在实际场景中，尤其是当数据量非常大时，我们需要只选择对 BigQuery ML 模型性能影响最大的特性。

在本节中，我们创建了不同的 ML 模型，试图在我们的数据集中使用不同的特征。在接下来的部分中，我们将使用具有最高 ROC AUC 值的模型:`classification_model_version_3`。

接下来，让我们利用评估数据集评估我们的 ML 模型的性能。

# 评估多类逻辑回归模型

在本节中，我们将执行查询来检查多类逻辑回归模型的性能。

对于我们的 BigQuery ML 模型的评估阶段，我们将使用`ML.EVALUATE`函数和`evaluation_table`表，专门创建它们来存放评估记录。

正如我们所见，评估是在模型训练阶段使用的相同字段上执行的，但这些字段是从与训练数据集完全分离的`evaluation_table`表中提取的。

外部`SELECT`语句提取由`ML.EVALUATE`函数返回的`roc_auc`值。它还提供了对模型质量的有意义的描述，该模型从`'POOR'`开始，经过`'NEEDS IMPROVEMENTS'`和`'GOOD'`等中间阶段，上升到`'EXCELLENT'`等级。

让我们执行以下查询来提取 ML 模型的关键性能指标:

```py
SELECT
  roc_auc,
  CASE
    WHEN roc_auc > .9 THEN 'EXCELLENT'
    WHEN roc_auc > .8 THEN 'VERY GOOD'
    WHEN roc_auc > .7 THEN 'GOOD'
    WHEN roc_auc > .6 THEN 'FINE'
    WHEN roc_auc > .5 THEN 'NEEDS IMPROVEMENTS'
  ELSE
  'POOR'
END
  AS model_quality
FROM 
  ML.EVALUATE(MODEL `06_nyc_trees.classification_model_version_3`,
    (
    SELECT
       zip_city,
       tree_dbh,
       boroname,
       nta_name,
       health,
       sidewalk,
       spc_latin as label
     FROM `06_nyc_trees.evaluation_table`));
```

从下面的截图中，我们可以看到查询的结果——**roc _ AUC**值达到了 0.77 以上。我们的 BigQuery ML 模型的结果可以被认为是好的:

![Figure 6.8 – The query extracts the ROC AUC value of the BigQuery ML model 
and a short description of the model quality
](img/B16722_06_008.jpg)

图 6.8–该查询提取 BigQuery ML 模型的 ROC AUC 值和模型质量的简短描述

既然我们已经验证了 ML 模型在不相交评估数据集上也保持了它的性能，我们可以开始使用它来对我们的`classification_table`表中的树进行分类。

# 使用多类逻辑回归模型

在这个部分，我们将测试我们的 ML 模型并分析结果。

为了使用我们的 BigQuery ML 模型，我们将使用`ML.PREDICT`函数和`classification_table`表来测试我们的模型，如下面的代码块所示:

```py
SELECT
  tree_id,
  actual_label,
  predicted_label_probs,
  predicted_label
FROM
  ML.PREDICT (MODEL `06_nyc_trees.classification_model_version_3`,
    (
    SELECT
       tree_id,
       zip_city,
       tree_dbh,
       boroname,
       nta_name,
       health,
       sidewalk,
       spc_latin as actual_label
    FROM
      `06_nyc_trees.classification_table`
     ));
```

查询语句由`SELECT`关键字组成，提取`tree_id`、字段中物种的实际值`actual_label`以及预测字段`predicted_label_probs`和`predicted_label`。

`ML.PREDICT`函数应用于`SELECT`语句，从`classification_table`中提取特征和实际物种。`actual_label`字段将仅用作我们预测的基准，而不是在预测阶段。

在下面的屏幕截图中，我们可以看到通过执行前面的查询获得的记录的结构:

![Figure 6.9 – A record of the output dataset generated by the classification model
](img/B16722_06_009.jpg)

图 6.9–分类模型生成的输出数据集的记录

在这种情况下， **tree_id** 等于 **857** ，树是 **Quercus palustris** ，由于 **predicted_label** 完全相同，被 BigQuery ML 模型正确分类。 **predicted_label_probs** 表示最高分类标签的置信度为 45%。所有其他可能的物种的特点是概率较低。

现在，我们已经应用了我们的模型，让我们制定一些关于我们的分类用例的最终考虑。

# 得出商业结论

使用我们从上一节得到的结果，*使用多类逻辑回归模型*，我们将得出一些关于我们的 ML 模型的有效性的结论。

用父`SELECT COUNT`语句丰富前面的查询，我们可以计算与记录总数相比有多少预测是正确的。

让我们执行以下查询来计算我们的 BigQuery ML 模型能够正确分类`classification_table`表中的树的频率:

```py
SELECT COUNT(*)
FROM (
      SELECT
        tree_id,
        actual_label,
        predicted_label_probs,
        predicted_label
      FROM
        ML.PREDICT (MODEL `06_nyc_trees.classification_model_version_3`,
          (
          SELECT
             tree_id,
             zip_city,
             tree_dbh,
             boroname,
             nta_name,
             health,
             sidewalk,
             spc_latin as actual_label
          FROM
            `06_nyc_trees.classification_table`
           )
        )
)
WHERE
      actual_label = predicted_label;
```

的结果`SELECT COUNT`查询返回 13，323 个带有正确预测标签的预测值。

考虑到`classification_table`表的总大小是 27，182，我们可以宣布，在 49%的情况下，我们的 ML 模型能够根据树的特征和位置来预测正确的树种。

这似乎是一个糟糕的结果，但我们需要考虑到多类逻辑回归比二元逻辑回归更复杂，因为有多个选项可能会欺骗我们模型的结果。

# 总结

在这一章中，我们已经建立了第一个多类分类模型。在简单介绍了用例之后，我们发现了什么是多类逻辑回归，以及如何使用它根据事件、行为和对象的特征将它们分成两个以上的类别。

在深入开发 ML 模型之前，我们分析了与纽约市的树相关的数据集的模式，并应用了一些必要的数据质量检查来构建有效的 ML 模型。

在训练阶段，我们使用不同的功能训练了三个不同的 ML 模型，以逐步提高 BigQuery ML 模型的性能。

然后，我们选择第三个 ML 模型，并根据评估数据集对其进行评估。在这一阶段，我们注意到 ML 模型也能够在新记录上保持其性能，并准备进入下一阶段。

在最后一步中，我们使用 ML 模型将纽约市的树木分为五个不同的类别，并利用它们的特征，如大小、健康状况和在城市中的位置。

我们还计算出，我们的分类模型能够在 49%的情况下对正确的树种进行分类。

在下一章，我们将介绍无监督的最大似然法和 K-均值聚类技术。

# 更多资源

*   **纽约市树木普查公共数据集**:[https://console . cloud . Google . com/market place/product/city-of-new York/NYC-tree-Census](https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tree-census)
*   **BigQuery ML 创建模型**:[https://cloud . Google . com/big query-ML/docs/reference/standard-SQL/bigqueryml-syntax-Create](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create)
*   **BigQuery ML 评估模型**:[https://cloud . Google . com/big query-ML/docs/reference/standard-SQL/bigqueryml-syntax-Evaluate](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate)
*   **big query ML Predict**:[https://cloud . Google . com/big query-ML/docs/reference/standard-SQL/bigqueryml-syntax-Predict](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict)
*   **BigQuery ML 多类逻辑示例**:[https://cloud . Google . com/big query-ML/docs/Logistic-regression-prediction](https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction)