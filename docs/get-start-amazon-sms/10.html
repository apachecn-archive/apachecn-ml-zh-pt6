<html><head/><body>


	
		<title>B17447_08_ePub_RK</title>
		
	
	
		<div><h1 id="_idParaDest-109"><em class="italic"> <a id="_idTextAnchor108"/>第 8 章</em>:用 SageMaker JumpStart 和 Autopilot 启动 ML</h1>
			<p><strong class="bold"> SageMaker JumpStart </strong>为选择的用例提供完整的解决方案，作为亚马逊 SageMaker 的<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)世界的入门套件，无需任何代码开发。SageMaker JumpStart 还将流行的预训练的<strong class="bold">计算机视觉</strong> ( <strong class="bold"> CV </strong>)和<strong class="bold">自然语言处理</strong> ( <strong class="bold"> NLP </strong>)模型编目，以便您轻松部署或微调您的数据集。<strong class="bold"> SageMaker Autopilot </strong>是一个 AutoML 解决方案，它可以探索您的数据，代表您设计功能，并根据各种算法和超参数训练最佳模型。你不用写任何代码:Autopilot 会帮你做，并返回笔记本给你看它是怎么做的。</p>
			<p>在本章中，我们将讨论以下主题:</p>
			<ul>
				<li>推出 SageMaker JumpStart 解决方案</li>
				<li>部署和微调 SageMaker JumpStart 模型动物园中的模型</li>
				<li>使用 SageMaker 自动驾驶仪创建高质量模型</li>
			</ul>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor109"/>技术要求</h1>
			<p>对于本章，您需要拥有使用 JumpStart 模板的权限。您可以从您的域和用户配置文件中确认。本章使用的代码可以在<a href="https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter08">https://github . com/packt publishing/Getting-Started-with-Amazon-sage maker-Studio/tree/main/chapter 08</a>找到。</p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor110"/>推出 SageMaker JumpStart 解决方案</h1>
			<p>如果你想学习一套关于 AWS 服务应该如何一起使用来创建 ML 解决方案的最佳实践，那么 SageMaker <a id="_idIndexMarker503"/> JumpStart 特别有用。你也可以这样做。让我们打开 JumpStart 浏览器。有多种打开方式，如图<em class="italic">图 8.1 </em>所示。您可以从右侧的 SageMaker Studio 启动器或左侧边栏的 JumpStart 资源浏览器中打开它。</p>
			<div><div><img src="img/B17447_08_001.jpg" alt="Figure 8.1 – Opening the JumpStart browser from the Launcher or the left sidebar&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.1–从启动器或左侧栏打开 JumpStart 浏览器</p>
			<p>一个名为<strong class="bold"> SageMaker JumpStart </strong>的新<a id="_idIndexMarker504"/>标签将在主工作区弹出。进入<strong class="bold">解决方案</strong>部分，点击<strong class="bold">查看全部</strong>，如图<em class="italic">图 8.2 </em>所示。</p>
			<div><div><img src="img/B17447_08_02.jpg" alt="Figure 8.2 – Viewing all solutions in JumpStart&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.2–查看 JumpStart 中的所有解决方案</p>
			<p>接下来，我们来看一下行业解决方案目录。</p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor111"/>行业解决方案目录</h2>
			<p>如<em class="italic">图 8.3 </em>所示，JumpStart 中有十几种解决方案。这些解决方案基于跨越多个行业的用例，包括制造业、零售业和金融业。</p>
			<div><div><img src="img/B17447_08_003.jpg" alt="Figure 8.3 – JumpStart solution catalog – Click each card to see more information&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.3–快速启动解决方案目录–单击每张卡片查看更多信息</p>
			<p>他们是由了解给定行业和用例的 AWS 开发人员和架构师创建的。点击卡片，了解每个使用案例的更多信息。您将看到一个欢迎页面，描述用例、方法、数据集、解决方案架构和任何其他外部资源。在每个解决方案页面上，您还应该看到一个<strong class="bold">启动</strong>按钮，它将从 CloudFormation 模板将解决方案和所有云资源部署到您的 AWS 帐户中。</p>
			<p>让我们以目录中的<strong class="bold">产品缺陷检测</strong>解决方案为例，我们将一起浏览部署和笔记本。</p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor112"/>部署产品缺陷检测解决方案</h2>
			<p>视觉检测作为制造过程中的质量控制措施被广泛采用。质量<a id="_idIndexMarker507"/>控制过去是一个手动过程，工作人员会在生产线上或通过摄像机捕捉的图像来目视检查产品。然而，人工检测不适用于当今工厂生产的大量产品。ML 是一个强大的工具，它可以以错误率识别产品缺陷，如果训练得当，甚至可能比人类检查员更好。<strong class="bold">产品缺陷检测</strong> SageMaker JumpStart 解决方案是一个很好的起点，可以快速启动您的 CV 项目，使用最先进的深度学习模型检测图像中的缺陷。您将看到 SageMaker 如何使用 PyTorch 脚本管理培训，以及如何使用模型托管。您还将学习如何对托管端点进行推理。该数据集是跨越六种类型的表面缺陷的平衡数据集，并且包含分类和绘制边界框的基础事实。请按照以下步骤通读笔记本的内容:</p>
			<ol>
				<li>请从<strong class="bold">解决方案</strong>目录中选择<strong class="bold">图像中的产品缺陷检测</strong>。如图<em class="italic">图 8.4 </em>所示，您可以在主页面上了解解决方案。您可以了解样本数据、算法和云解决方案架构。</li>
			</ol>
			<div><div><img src="img/B17447_08_04.jpg" alt="Figure 8.4 – Main page of the Product Defect Detection in Images solution&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.4–图像产品缺陷检测解决方案的主页</p>
			<ol>
				<li value="2">点击<strong class="bold">发射</strong>按钮，如图<em class="italic">图 8.4 </em>所示，开始展开。您应该会在屏幕上看到<a id="_idIndexMarker508"/>正在进行的部署。现在的情况是，我们刚刚在后台使用<strong class="bold"> AWS CloudFormation </strong>启动了资源部署<a id="_idIndexMarker509"/>。AWS CloudFormation 是一项服务，它通过 JSON 或 YAML 声明性代码中的模板，以有序的方式帮助创建、供应和管理 AWS 资源。此部署需要几分钟时间。</li>
				<li>一旦解成了<code>0_demo.ipynb</code>，从解。这款笔记本是四款笔记本中的第一款，它们作为 CloudFormation 设置的一部分在<code>S3Downloads/jumpstart-prod-dfd_xxxxxxx/notebooks/</code>部署到您的主目录中。笔记本需要<strong class="bold">SageMaker jump start PyTorch 1.0</strong>内核，因为我们要构建一个基于 py torch 的解决方案。如果这是第一次使用内核，内核启动可能需要一两分钟。</li>
				<li>运行<code>0_demo.ipynb</code>笔记本中的所有单元格。该笔记本将<code>NEU-DET</code>检测数据集下载到文件系统，并使用 SageMaker SDK 的<code>sagemaker.pytorch.PyTorchModel</code>类为<a id="_idIndexMarker510"/>预训练 PyTorch 模型创建一个 SageMaker 托管端点。在笔记本的最后，您应该会看到一张图，显示预训练模型检测到的补丁与地面真实情况的对比，如图<em class="italic">图 8.5 </em>所示。</li>
			</ol>
			<div><div><img src="img/B17447_08_05.jpg" alt="Figure 8.5 – Final output of the 0_demo.ipynb notebook, showing a steel surface example, the ground truth, and the model prediction by a pretrained model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.5–0 _ demo . ipynb 笔记本的最终输出，显示了钢表面示例、地面实况和预训练模型的模型预测</p>
			<p>这款笔记本展示了 SageMaker 提供的一个关键灵活性，也就是说，你可以从 SageMaker 外部带来一个经过训练的模型，并将其托管在 SageMaker 中。为了从 PyTorch 模型创建 SageMaker 模型，您需要在<code>model.tar.gz</code>归档中归档的模型文件<code>.pt</code> / <code>.pth</code>和一个入口点，在本例中是<code>detector.py</code>脚本，它指示应该如何进行推理。我们可以看一下<code>detector.py</code>脚本来了解更多。</p>
			<ol>
				<li value="5">(可选)添加一个新单元格，并填写以下命令:<pre>!aws s3 cp {sources}source_dir.tar.gz . !tar zxvf source_dir.tar.gz</pre></li>
			</ol>
			<p>这将在本地获得整个代码库。请打开<code>detector.py</code>文件并找到 SageMaker 用来进行推理的零件:</p>
			<pre>def model_fn(model_dir):
    backbone = "resnet34"
    num_classes = 7  # including the background
    mfn = load_checkpoint(Classification(backbone, num_classes - 1).mfn, model_dir, "mfn")
    rpn = load_checkpoint(RPN(), model_dir, "rpn")
    roi = load_checkpoint(RoI(num_classes), model_dir, "roi")
    model = Detection(mfn, rpn, roi)
    model = model.eval()
    freeze(model)
    return model</pre>
			<p>导入 PyTorch 模型时，SageMaker 至少需要一个<code>model_fn(model_dir)</code>函数来指示如何定义模型。在本例中，<code>Detection()</code>类是在<code>S3Downloads/jumpstart-prod-dfd_xxxxxx/notebooks/sagemaker_defect_detection/models/ddn.py</code>中定义的<code>GeneralizedRCNN</code>模型，其权重是从提供的模型中加载的。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">您可以实现的其他推理相关功能包括:</p>
			<p class="callout">将调用请求体反序列化为我们可以对其执行预测的对象:</p>
			<p class="callout"><code>input_object = input_fn(request_body, request_content_type)</code></p>
			<p class="callout">用加载的模型对反序列化的对象执行预测:</p>
			<p class="callout"><code>prediction = predict_fn(input_object, model)</code></p>
			<p class="callout">将预测结果序列化为所需的响应内容类型:</p>
			<p class="callout"><code>output = output_fn(prediction, response_content_type)</code></p>
			<p class="callout">如果您不覆盖这三个函数，SageMaker 会为它们提供默认的实现。如果您有一个定制的方法来进行推理，您可以覆盖这些函数。</p>
			<ol>
				<li value="6">继续<a id="_idIndexMarker512"/>到笔记本的末尾，点击<code>1_retrain_from_checkpoint.ipynb</code>。</li>
				<li>Run all the cells in <code>1_retrain_from_checkpoint.ipynb</code>. This notebook fine-tunes the pretrained model from a checkpoint with the downloaded dataset for a few more epochs. The solution includes training code in <code>detector.py</code> from <code>osp.join(sources, "source_dir.tar.gz")</code>. The solution uses the SageMaker SDK's PyTorch estimator to create a training job that launches an on-demand compute resource of one <code>ml.g4dn.2xlarge</code> instance and trains it from a provided pretrained checkpoint. The training takes about 10 minutes. The following lines of code show how you can feed the training data and a pretrained checkpoint to SageMaker PyTorch estimator to perform a model fine-tuning job:<pre>finetuned_model.fit(
    {
        "training": neu_det_prepared_s3,
        "pretrained_checkpoint": osp.join(s3_pretrained, "epoch=294-loss=0.654-main_score=0.349.ckpt"),
    }
)</pre><p class="callout-heading">注意</p><p class="callout">对<code>.fit()</code>调用的字典键的命名是通过设计完成的。这些键在训练容器中注册为带有 SM_CHANNEL_ 前缀的环境变量，可以在训练脚本中访问。这些密钥需要与<code>detector.py</code>文件中所写的相匹配，以便使这个<code>.fit()</code>培训呼叫工作。例如，参见<code>detector.py</code>中的第 310 行和第 349 行:</p><p class="callout"><code>aa("--data-path", metavar="DIR", type=str, default=os.environ["SM_CHANNEL_TRAINING"])</code></p><p class="callout"><code>aa("--resume-sagemaker-from-checkpoint", type=str, default=os.getenv("SM_CHANNEL_PRETRAINED_CHECKPOINT", None))</code></p></li>
			</ol>
			<p>在<a id="_idIndexMarker513"/>培训之后，模型被部署为 SageMaker 托管的端点，如<code>0_demo.ipynb</code>笔记本中所示。最后，对基础事实、来自<code>0_demo.ipynb</code>的预训练模型的推断以及来自微调模型的推断进行了可视化比较。我们可以看到，微调模型的推断少了一个假阳性，但仍然无法在样本图像的右侧拾取一个补丁。这应该被认为是假阴性。</p>
			<ol>
				<li value="8">继续点击<code>2_detection_from_scratch.ipynb</code>。</li>
				<li>Run all the cells in the <code>2_detection_from_scratch.ipynb</code> notebook. Instead of training from a checkpoint, we train a model from scratch with 10 epochs using the same dataset and compare the inference to that from the pretrained model. The model is significantly undertrained, as expected with the small epoch size used. You are encouraged to increase the epoch size (the <code>EPOCHS</code> variable) to 300 to achieve better performance. However, this will take significantly more than 10 minutes.<p class="callout-heading">注意</p><p class="callout">我们通过在字典中包含一个<code>pretrained_checkpoint</code>键到<code>.fit()</code>来控制我们是从一个检查点还是从零开始训练。</p></li>
				<li>继续点击<code>3_classification_from_scratch.ipynb</code>。</li>
			</ol>
			<p>在这个<a id="_idIndexMarker514"/>笔记本中，我们使用<code>classifier.py</code>训练了 50 个时期的分类模型，而不是使用 NEU-CLS 分类数据集从头开始的对象检测模型。分类模型不同于先前的对象检测模型。图像分类识别整个图像中的缺陷类型，而目标检测模型也可以定位缺陷的位置。如果您不需要知道缺陷的位置，图像分类是有用的，并且可以用作产品缺陷的分类模型。</p>
			<p>训练一个分类模型更快，从工作中可以看出。验证集上的分类精度达到了<code>0.99</code>，如训练作业的单元格输出所示，非常准确:</p>
			<pre><strong class="bold">Epoch 00016: val_acc reached 0.99219 (best 0.99219), saving model to /opt/ml/model/epoch=16-val_loss=0.028-val_acc=0.992.ckpt as top 1</strong></pre>
			<ol>
				<li value="11">这是解决方案的结尾。请确保执行每个笔记本中的最后一个单元格来删除模型和端点，尤其是<code>0_demo.ipynb</code>笔记本中的最后一个单元格，在那里删除被注释掉。请取消对此的注释，然后执行它以删除预训练的模型和端点。</li>
			</ol>
			<p>借助这款 SageMaker JumpStart 解决方案，您基于更快 RCNN 的 PyTorch 实现构建并训练了四个深度学习模型，以最少的编码工作检测和分类钢铁图像中的六种类型的<a id="_idIndexMarker515"/>缺陷。您还将它们托管为 SageMaker 端点，用于实时预测。您可以在 SageMaker JumpStart 中获得与其他解决方案类似的体验，以了解在解决常见用例的上下文中使用的 SageMaker 功能的不同方面。</p>
			<p>现在，让我们切换到 SageMaker JumpStart 模型动物园。</p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor113"/> SageMaker JumpStart 模型动物园</h1>
			<p>SageMaker JumpStart <a id="_idIndexMarker516"/>中有 200 多种受欢迎的预构建和预训练模型供您开箱即用或继续针对您的使用案例进行训练。它们有什么用？训练一个准确的深度学习模型是耗时且复杂的，即使是使用最强大的 GPU 机器。还需要大量的训练和标注数据。现在，有了这些由社区开发的模型，在大型数据集上进行了预先训练，你不必重新发明轮子。</p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor114"/>模型集合</h2>
			<p>SageMaker JumpStart 模型动物园里有两组模型:<strong class="bold">文字模型</strong>和<strong class="bold">视觉模型</strong>。这些型号是 ML 社区中最受欢迎的型号。您可以在 SageMaker JumpStart 中快速浏览型号，并选择符合您需求的型号。在每个模型页面上，您将看到对模型、其用法以及如何准备数据集以进行微调的介绍。您可以将模型部署到 AWS 中，作为您的用例的托管端点，或者使用您自己的数据集进一步微调模型。</p>
			<p>文本模型来源于以下三个中枢:TensorFlow 中枢、PyTorch 中枢和 Hugging Face。每个模型都是使用数据集(如文本分类、问题回答或文本生成)为特定类型的 NLP 任务专门训练的。值得注意的是，从变形金刚 ( <strong class="bold">伯特</strong>)、<strong class="bold">跨语言语言模型</strong> ( <strong class="bold"> XLM </strong>)、<strong class="bold">伊莱克特拉</strong>、以及<strong class="bold">生成式预训练变形金刚</strong> ( <strong class="bold"> GPT) </strong>中，有多种口味的<strong class="bold">双向编码器表示可供选择。</strong></p>
			<p>Vision <a id="_idIndexMarker519"/>模型来自 TensorFlow Hub、PyTorch <a id="_idIndexMarker520"/> Hub 和 Gluon CV。有进行图像分类、图像<a id="_idIndexMarker521"/>特征向量提取、<a id="_idIndexMarker522"/>物体<a id="_idIndexMarker523"/>检测的模型。<strong class="bold">盗梦空间</strong>、<strong class="bold"> SSD </strong>、<strong class="bold"> ResNet </strong>和<strong class="bold">更快的 R-CNN </strong>型号<a id="_idIndexMarker524"/>是 CV 领域最引人注目的<a id="_idIndexMarker525"/>和广泛使用的一些型号。</p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor115"/>部署模型</h2>
			<p>让我们找到一个问答模型，看看如何将它部署到我们的 AWS 帐户。在搜索栏中输入<code>question</code> <strong class="bold">回答</strong>点击<strong class="bold">返回</strong>，应该会看到返回给你的执行此类任务的机型列表，如图<em class="italic">图 8.6 </em>所示。</p>
			<div><div><img src="img/B17447_08_06.jpg" alt="Figure 8.6 – Searching for question-answering models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.6-搜索问答模型</p>
			<p>让我们找到<a id="_idIndexMarker527"/>并双击<code>OpenWebTextCorpus</code>，它是从 RoBERTa 模型检查点提取的。它有 6 层，768 个隐藏，12 个头，8200 万个参数。8200 万！当然，训练这么大的模型并不容易。幸运的是，有了 SageMaker JumpStart，我们有了一个可以开箱即用的模型。如图<em class="italic">8.7</em>所示，请展开<strong class="bold">展开配置</strong>部分，选择<strong class="bold"> Ml。M5.Xlarge </strong>作为机器类型，保留端点名称为默认<a id="_idIndexMarker528"/>，点击<strong class="bold">部署</strong>。Ml。M5.Xlarge 是一个通用的实例类型，它有 4 个 vCPU 和 16 GB 的内存，对于这个例子来说已经足够了。部署将需要几分钟时间。</p>
			<div><div><img src="img/B17447_08_07.jpg" alt="Figure 8.7 – Deploying a JumpStart DistilRoBERTa Base model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.7–部署 JumpStart DistilRoBERTa 基本模型</p>
			<p>一旦部署了模型，将会向您提供一个笔记本，向您展示如何对托管端点进行 API 调用(<em class="italic">图 8.8 </em>)。您可以在 JumpStart 左侧边栏中找到型号列表。</p>
			<div><div><img src="img/B17447_08_08.jpg" alt="Figure 8.8 – Opening a sample inference notebook after the model is deployed&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.8–在模型部署后打开一个示例推理笔记本</p>
			<p>在<a id="_idIndexMarker529"/>示例笔记本中，提供了来自<strong class="bold"> SQuAD v2 </strong>数据集的两个问题，该数据集是用于评估的最广泛使用的问答数据集<a id="_idIndexMarker530"/>之一，以展示如何进行推理。让我们也根据下面这段话问我们的模型其他问题(你能猜出你以前在哪里看过吗？没错，就是这一章的开篇陈述！):</p>
			<p>背景:</p>
			<p class="author-quote">SageMaker JumpStart 为选择的用例提供完整的解决方案，作为亚马逊 SageMaker 的机器学习(ML)世界的入门套件，无需任何代码开发。SageMaker JumpStart 还将流行的预训练计算机视觉(CV)和自然语言处理(NLP)模型编目，以便您轻松部署或微调您的数据集。SageMaker Autopilot 是一个 AutoML 解决方案，它可以探索您的数据，代表您设计功能，并从各种算法和超参数中训练出最佳模型。你不用写任何代码:Autopilot 会帮你做，并返回笔记本展示它是怎么做的。</p>
			<p>问题:</p>
			<ul>
				<li>【SageMaker JumpStart 是做什么的？</li>
				<li><em class="italic">什么是 NLP？</em></li>
			</ul>
			<p>在笔记本中，我们应该在第二个单元格中添加以下内容:</p>
			<pre>question_context3 = ["What does SageMaker JumpStart do?", "SageMaker JumpStart offers complete solutions for select use cases as a starter kit to the world of machine learning (ML) with Amazon SageMaker without any code development. SageMaker JumpStart also catalogs popular pretrained computer vision (CV) and natural language processing (NLP) models for you to easily deploy or fine-tune to your dataset. SageMaker Autopilot is an AutoML solution that explores your data, engineers features on your behalf and trains an optimal model from various algorithms and hyperparameters. You don't have to write any code: Autopilot does it for you and returns notebooks to show how it does it."]
question_context4 = ["What is NLP?", question_context3[-1]]</pre>
			<p>在<a id="_idIndexMarker531"/>第三个单元格中，将两个新的问题上下文对添加到<code>for</code>循环的列表中，并执行笔记本中的所有单元格:</p>
			<pre>for question_context in [question_context1, question_context2, question_context3, question_context4]:</pre>
			<p>瞧啊。我们从我们的模型中得到响应，回答了我们关于 SageMaker JumpStart 的功能和作为自然语言处理的 NLP 的完整形式的问题。</p>
			<h2 id="_idParaDest-117"><a id="_idTextAnchor116"/>微调模型</h2>
			<p>当您将预训练的模型从货架上取下以将<a id="_idIndexMarker532"/>模型暴露于您的数据集时，通常会执行模型微调，以便与没有这种暴露的性能相比，它可以在您的数据集上执行更好的性能。此外，与从头开始训练模型相比，模型微调需要更少的训练时间，并且需要更少量的标记数据。要从 SageMaker JumpStart 中微调预训练的模型，首先我们需要确保您想要使用的模型支持微调。您可以在概览卡中找到该属性。其次，您需要将数据集指向模型。以 DistilRoBERTa 基础模型为例，SageMaker JumpStart 提供了默认数据集<strong class="bold"> SQuAD-v2 </strong>，可以让你快速开始一项训练工作。您也可以按照 JumpStart 模型页面上的说明创建自己的数据集。我们正打算这么做。</p>
			<p>让我们<a id="_idIndexMarker533"/>用一些关于佛教的问题和答案来微调基础 DistilRoBERTa 基础模型，这是<code>SquAD-v2</code>数据集中的主题之一。请遵循以下步骤:</p>
			<ol>
				<li value="1">打开存储库中的<code>chapter08/1-prep_data_for_finetune.ipynb</code>笔记本，执行所有单元下载数据集，提取与佛学相关的段落，按照微调培训师的预期进行组织。这在<code>data.csv</code>文件的描述页有详细说明:<ul><li><code>data.csv</code>的第一栏应该有问题。</li><li>第二列应该有相应的上下文。</li><li>第三列应该有上下文中答案的整数字符起始位置。</li><li>第四列应该有上下文中答案的整数字符结束位置。</li></ul></li><li><strong class="bold">输出</strong>:训练好的模型，可以部署进行推理。</li>
				<li>笔记本结束后，<code>data.csv</code>文件会上传到你的 SageMaker 默认桶:<code>s3://sagemaker-&lt;region&gt;-&lt;accountID&gt;/chapter08/buddhism/data.csv</code>。</li>
				<li>完成后，让我们切换回模型页面并配置微调作业。如<em class="italic">图 8.9 </em>所示，选择型号名称上的<code>-buddhism</code>，机器类型和超参数为默认值，点击<strong class="bold">训练</strong>。默认<strong class="bold">毫升。P3.2xlarge </strong>实例类型，带有一个 NVIDIA Tesla V100 GPU，是快速模型微调的<a id="_idIndexMarker534"/>绝佳选择。默认的超参数设置使用 4 的<strong class="bold">批量、<strong class="bold">2e-5</strong>的学习速率和<strong class="bold"> 3 个时期</strong>进行微调。这足以让我们演示微调是如何工作的。您可以随意更改这里的值，以反映您的实际用例。</strong></li>
			</ol>
			<div><div><img src="img/B17447_08_09.jpg" alt="Figure 8.9 – Configuring a fine-tuning job for a custom dataset&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.9–为自定义数据集配置微调作业</p>
			<p>使用<strong class="bold"> Ml 进行培训大约需要 6 分钟。P3.2xlarge </strong>实例。</p>
			<ol>
				<li value="4">一旦任务完成，您就可以用一个<strong class="bold"> Ml 将模型部署到一个端点。M5.Xlarge </strong>实例，如图<em class="italic">图 8.10 </em>所示。Ml。M5 是一个通用的 CPU 实例，这是一个很好的模型托管的起点。</li>
			</ol>
			<div><div><img src="img/B17447_08_010.jpg" alt="Figure 8.10 – Deploying the fine-tuned model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.10–部署微调模型</p>
			<p>当然，我们现在需要测试微调后的模型在与佛和佛教相关的问题上表现如何。部署完成后，系统会提示您选择打开预构建的笔记本电脑以使用端点，类似于图 8.8 中的<em class="italic">所示。</em></p>
			<ol>
				<li value="5">我们可以用下面来自<a href="https://www.history.com/topics/religion/buddhism">https://www.history.com/topics/religion/buddhism</a>:<pre>question_context1 = ["When was Buddhism founded?", "Buddhism is a faith that was founded by Siddhartha Gautama ("the Buddha") more than 2,500 years ago in India. With about 470 million followers, scholars consider Buddhism one of the major world religions. Its practice has historically been most prominent in East and Southeast Asia, but its influence is growing in the West. Many Buddhist ideas and philosophies overlap with those of other faiths."] <strong class="bold">question_context2 = ["Where is Buddhism popular among?", question_context1[-1]]</strong></pre>的片段替换第二个单元格中的问题上下文对</li>
			</ol>
			<p>然后，执行笔记本中的单元格，您将看到我们的新模型执行得有多好。</p>
			<p>这不是我们想要的模型。这是由于使用了非常小的时期，可能还有未优化的批量大小和学习速率。当我们为模型提供新的数据点时，网络中的权重再次被更新，并且需要执行足够数量的时期的训练，以收敛于更低的损失，从而创建更准确的模型。这些超参数经常需要调整，以便即使在微调的情况下也能获得良好的模型。我们鼓励您进一步试验不同的超参数，看看该模型是否能更好地回答这些问题。</p>
			<p>我们刚刚创建了三个 ML 模型，它们被认为是复杂且难以训练的，根本没有多少编码。现在我们要学习如何使用 SageMaker Autopilot 自动创建一个高质量的模型，无需任何代码。</p>
			<h1 id="_idParaDest-118"><a id="_idTextAnchor117"/>使用 SageMaker 自动驾驶仪创建高质量模型</h1>
			<p>你有没有想过建立一个没有数据预处理、特性<a id="_idIndexMarker538"/>工程、探索<a id="_idIndexMarker539"/>算法和优化超参数麻烦的 ML 模型？你有没有想过，对于某些用例来说，你只是想快速地看到 ML 是否是某个业务用例的一种可能的方法？Amazon SageMaker Autopilot 让你不用任何代码就能轻松建立表格数据集的 ML 模型。</p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor118"/>葡萄酒质量预测</h2>
			<p>为了演示 SageMaker 自动驾驶，让我们使用一个葡萄酒质量预测用例。葡萄酒行业一直在寻找一种技术来帮助酿酒师和市场更快、更好地评估葡萄酒的质量。就生产和销售而言，葡萄酒质量评估和认证是葡萄酒市场的关键部分，可防止葡萄酒非法掺假。葡萄酒评估是由专业的酿酒师根据物理化学和感官测试进行的，这些测试会产生诸如密度、酒精含量和 pH 值等特征。然而，当涉及到人类时，标准会因酿酒师或测试试验的不同而不同。因此，拥有一种 ML 方法来支持酿酒师提供分析信息成为葡萄酒行业的一项重要任务。</p>
			<p>我们将训练一个 ML 模型，根据葡萄牙 2004 年至 2007 年间生产的 4，898 种白葡萄酒的理化感官值来预测葡萄酒质量。该数据集可从 https://archive.ics.uci.edu/ml/datasets/Wine+Quality.的 UCI 获得</p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor119"/>设置自动驾驶作业</h2>
			<p>让我们开始吧:</p>
			<ol>
				<li value="1">请<a id="_idIndexMarker543"/>从存储库中打开<a href="http://chapter08/2-prep_data_for_sm_autopilot.ipynb">chapter 08/2-prep _ data _ for _ sm _ auto pilot . ipynb</a>笔记本，并执行所有单元以从源中下载数据，展示测试集，并将训练数据上传到 S3 桶。请注意训练数据的路径。</li>
				<li>接下来，打开<a id="_idIndexMarker544"/>发射器<a id="_idIndexMarker545"/>，选择<strong class="bold">新自动驾驶仪实验</strong>，如图<em class="italic">图 8.11 </em>。</li>
			</ol>
			<div><div><img src="img/B17447_08_011.jpg" alt="Figure 8.11 – Creating a new Autopilot experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.11–创建新的自动驾驶仪实验</p>
			<p>将弹出一个新窗口，让我们配置自动驾驶作业。</p>
			<ol>
				<li value="3">如<em class="italic">图 8.12 </em>所示，提供一个<code>white-wine-predict-quality</code>。</li>
			</ol>
			<div><div><img src="img/B17447_08_012.jpg" alt="Figure 8.12 – Configuring an Autopilot job&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.12–配置自动驾驶作业</p>
			<ol>
				<li value="4">如<em class="italic">图 8.12 </em>中的<a id="_idIndexMarker546"/>所示，从<strong class="bold">数据集文件名</strong>下拉菜单中，从<code>sagemaker-studio-book/chapter08/winequality/winequality-white-train.csv</code>文件中向<a id="_idIndexMarker547"/>提供<code>sagemaker-&lt;region&gt;-&lt;accountID&gt;</code>中的训练数据。将<strong class="bold">目标</strong>设置为<strong class="bold">质量</strong>，用 CSV 文件中的其余属性预测葡萄酒的质量。</li>
				<li>在<a id="_idIndexMarker548"/>配置页面的下半部分，如图<em class="italic">图 8.13 </em>所示，提供保存<a id="_idIndexMarker549"/>输出数据的路径，勾选<code>sagemaker-&lt;region&gt;-&lt;accountID&gt;</code>从<code>sagemaker-studio-book/chapter08/winequality/</code>路径进入<strong class="bold">数据集目录名</strong>字段作为输出位置。此路径是我们存放培训 CSV 文件的位置。</li>
			</ol>
			<div><div><img src="img/B17447_08_013.jpg" alt="Figure 8.13 – Configuring an Autopilot job&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.13–配置自动驾驶作业</p>
			<ol>
				<li value="6">如图<em class="italic">图 8.13 </em>所示，从<strong class="bold">选择机器学习问题类型</strong>下拉菜单中选择<strong class="bold">多类分类</strong>。然后从<strong class="bold">客观指标</strong>下拉菜单中选择<strong class="bold">f1 宏</strong>，这样，如果数据偏向某个质量等级，我们就可以期待一个更平衡的模型。</li>
				<li>如<em class="italic">图 8.13 </em>所示，选择<strong class="bold">是</strong>为<strong class="bold">你要运行一个完整的实验吗？</strong>。然后将<strong class="bold">自动部署</strong>选项切换到<strong class="bold">关闭</strong>，因为我们希望在部署我们的最佳模型之前在 SageMaker Studio 中完成评估过程。</li>
				<li>如<em class="italic">图 8.13 </em>所示，展开<strong class="bold">最大候选数</strong>字段中的<code>100</code>。默认情况下，Autopilot 运行 250 个训练任务<a id="_idIndexMarker551"/>，使用不同的预处理步骤、训练算法和超参数。通过使用有限数量的候选者，我们应该期望整个实验比使用默认设置更快地完成。</li>
				<li>点击<strong class="bold">创建实验</strong>开始自动驾驶工作。</li>
			</ol>
			<p>您将看到一个新窗口，显示自动驾驶作业的进度。请让它处理一下数字，几分钟后回来。您将在进度选项卡中看到更多的进度和输出，如图<em class="italic">图 8.14 </em>所示。</p>
			<div><div><img src="img/B17447_08_014.jpg" alt="Figure 8.14 – Viewing the progress of an Autopilot experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.14–查看自动驾驶仪实验的进度</p>
			<p>很多<a id="_idIndexMarker552"/>正在这里<a id="_idIndexMarker553"/>进行。让我们开始吧。</p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor120"/>了解自动驾驶工作</h2>
			<p>亚马逊<a id="_idIndexMarker554"/> SageMaker Autopilot <a id="_idIndexMarker555"/>自动执行端到端的 ML 建模练习。它<a id="_idIndexMarker556"/>执行<strong class="bold">探索性数据分析</strong> ( <strong class="bold"> EDA </strong>)，进行数据预处理，并创建特征工程和模型训练配方。然后，它执行配方，以便找到给定条件下的最佳模型。您可以在<em class="italic">图 8.14 </em>的中间部分看到进度。</p>
			<p>Autopilot 的独特之处在于它提供的完全可见性。Autopilot 通过以 Jupyter 笔记本的形式向您提供 EDA 结果和 Autopilot 运行的代码来执行特征工程和 ML 建模，从而打开典型的 AutoML 黑盒。点击 EDA 结果的<strong class="bold">打开数据探索笔记本</strong>按钮和配方的<strong class="bold">打开候选生成笔记本</strong>按钮，可以访问这两个笔记本。</p>
			<p>数据探索笔记本有助于理解数据、分布以及 Autopilot 如何基于数据的特征构建配方。例如，Autopilot 查找数据集中缺失的值、数字特征的分布以及分类特征的基数。这些信息为数据科学家<a id="_idIndexMarker557"/>提供了对数据的基本理解，以及关于输入数据是否包含<a id="_idIndexMarker558"/>合理条目的可操作见解。如果您发现许多缺失值百分比很高的特征(缺失值百分比部分的<strong class="bold">，您可以采取建议的措施从数据创建的角度调查该问题，并应用某种程度的预处理来移除该特征或应用特定于域的插补。你可能会问，“<em class="italic">自动驾驶不是对数据进行数据预处理和特征工程吗？“是的，确实如此。但是，Autopilot 并不了解您的数据的特定领域。你应该期待一种更通用、以数据科学为导向的方法来解决自动驾驶仪出现的问题，这可能不会那么有效。</em></strong></p>
			<p>候选生成笔记本规定了如何基于数据的 EDA 构建和训练模型的方法。代码的数量可能看起来令人生畏，但如果你仔细阅读，你可以看到，例如，Autopilot 正在尝试的数据预处理步骤和建模方法，如<strong class="bold">候选管道</strong>部分所示。以下是这方面的一个例子:</p>
			<pre><strong class="bold">The SageMaker Autopilot Job has analyzed the dataset and has generated 9 machine learning pipeline(s) that use 3 algorithm(s).</strong></pre>
			<p>自动驾驶<a id="_idIndexMarker559"/>基于<a id="_idIndexMarker561"/>三种算法建立<a id="_idIndexMarker560"/>流水线:<strong class="bold"> XGBoost </strong>、<strong class="bold">线性学习器</strong>和<strong class="bold">多层感知器</strong> ( <strong class="bold"> MLP) </strong>。XGBoost 是一种流行的梯度增强树算法，它以有效和灵活的方式组合弱预测器的集合来形成最终的预测器。XGBoost 是 SageMaker 的内置算法之一。线性学习器，也是 SageMaker 内置算法，使用不同的超参数训练多个线性模型，并使用分布式随机梯度下降优化找到最佳模型。MLP 是一种基于神经网络的监督学习算法，可以具有多个隐藏层的神经元来创建非线性模型。</p>
			<p>您还可以<a id="_idIndexMarker562"/>看到自动驾驶仪正在探索的超参数<a id="_idIndexMarker563"/>和范围列表(<strong class="bold">多算法超参数调整</strong>部分)。Autopilot 不仅为你提供可视性，还能让你完全控制实验。您可以点击右上角的<strong class="bold">导入笔记本</strong>按钮来获得笔记本的副本，您可以实际定制并执行该副本来获得您的下一个最佳模型。</p>
			<h2 id="_idParaDest-122"><a id="_idTextAnchor121"/>评估自动驾驶模型</h2>
			<p>如果您看到标签页中的作业状态，如图<em class="italic">图 8.14 </em>所示，已经变为<strong class="bold">已完成</strong>，那么<a id="_idIndexMarker564"/>该评估自动驾驶仪<a id="_idIndexMarker565"/>已经生成的模型了。正如你在试验列表中看到的那样，Autopilot 已经使用各种功能工程，算法和超参数的混合物训练了 100 个模型。该排行榜还显示了性能指标，即随机验证分割中的 F1 分数，用于评估模型。您可以点击<strong class="bold">目标:F1 </strong>按分数对模型进行排序。</p>
			<p>让我们仔细看看最佳车型，即 F1 得分最高且在试用名称旁边有一颗星的车型。右键单击试验并选择<strong class="bold">在模型细节中打开</strong>查看更多信息。</p>
			<div><div><img src="img/B17447_08_015.jpg" alt="Figure 8.15 – Viewing Autopilot model details in SageMaker Studio&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.15–在 SageMaker Studio 中查看自动驾驶模型细节</p>
			<p>Autopilot 在这个页面上报告了很多细节，如图<em class="italic">图 8.15 </em>所示。首先我们可以看到这个模型是基于<strong class="bold"> XGBoost </strong>算法构建的。为了方便起见，我们还看到了 Autopilot 生成的功能重要性图表。该图表告诉我们<a id="_idIndexMarker566"/>模型如何考虑输入特征的重要性或贡献。自动驾驶仪使用该 XGBoost 模型和数据集的<strong class="bold"> SageMaker Clarify </strong>计算<strong class="bold"> SHapley 附加解释</strong> ( <strong class="bold"> SHAP </strong>)值。SHAP 值解释了特征如何有助于基于博弈论形成决策的模型。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">您可以将鼠标悬停在条形上以查看实际值。SageMaker 提供了更多详细信息，以便您可以在<strong class="bold">白皮书中了解这些 SHAP 值是如何计算的？</strong>小节。</p>
			<p>回到<a id="_idIndexMarker567"/>图表，您还可以下载一个自动生成的 PDF 报告，其中包含此<a id="_idIndexMarker568"/>图表，以供查看和分发(<strong class="bold">导出 PDF 报告</strong>)。如果您想要处理 JSON 格式的原始数据，以便在其他应用程序中集成 SHAP 值，您可以下载数据(<strong class="bold">下载原始数据</strong>)。通过点击这两个按钮，您将被重定向到 S3 控制台，如图<em class="italic">图 8.16 </em>所示。点击<strong class="bold">下载</strong>按钮，可以从控制台上的 S3 桶下载文件。</p>
			<div><div><img src="img/B17447_08_016.jpg" alt="Figure 8.16 – Downloading the feature importance PDF report in the S3 console&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 8.16–在 S3 控制台中下载功能重要性 PDF 报告</p>
			<p>除了特征的重要性之外，模型在训练集和验证集上的表现对于理解模型在现实生活中的表现也非常重要。您可以在<code>ObjectiveMetric</code>中看到在培训过程中获得的指标，这些指标用于在排行榜上对模型进行排名，我们看到了以下指标:</p>
			<ul>
				<li><code>train:f1</code></li>
				<li><code>train:merror</code></li>
				<li><code>validation:f1</code></li>
				<li><code>validation:merror</code></li>
			</ul>
			<p>它们是多类 f1 宏和数据训练和验证分割的多类错误。从相同的值可以看出，<code>ObjectiveMetric</code>本质上就是<code>validation:f1</code>。当<code>train:f1</code>大大高于<code>validation:f1</code>时，我们可以得出结论，模型过度适合训练数据集。但这是为什么呢？</p>
			<p>我们<a id="_idIndexMarker569"/>可以利用我们在<a id="_idIndexMarker570"/>开始时展示的测试数据，进一步更详细地验证模型性能。请从存储库中打开<code>chapter08/3-evaluate_autopilot_models.ipynb</code>笔记本并执行所有单元格。在本笔记本中，您将从自动驾驶作业中检索基于<code>ObjectiveMetric</code>的顶级车型，在云中使用<code>TOP_N_CANDIDATES</code>对不同的数字执行推理<a id="_idIndexMarker571"/>。您应该看到使用宏计算的 F1 分数、未加权平均值、加权方法、分类报告(来自 sklearn 函数)以及测试数据的混淆矩阵作为最后一个单元格的输出。</p>
			<p>对于顶级模特来说，有几件事让我眼前一亮。数据本质上是不平衡的。有更高的分数集中度<code>5</code>、<code>6</code>、<code>7</code>。很少有葡萄酒得到<code>3</code>、<code>4</code>或<code>8</code>的分数。混淆矩阵还显示，得分为<code>3</code>的葡萄酒都被错误地分类了。在这种情况下，<code>f1</code>宏观尺度会因为少数阶层的不正确分类而大幅降低。如果我们看一下<code>f1</code>分数的加权版本，我们会得到一个明显更高的分数，因为该分数对主导阶层的权重更大:</p>
			<pre>Candidate name:  white-wine-predict-qualitysZ1CBE-003-1a47413b
Objective metric name:  validation:f1
Objective metric value:  0.4073199927806854
f1 = 0.51, Precision = 0.59 (macro)
f1 = 0.67, Precision = 0.68 (weighted)
              precision    recall  f1-score   support
           3       0.00      0.00      0.00         3
           4       0.70      0.39      0.50        18
           5       0.63      0.67      0.65       144
           6       0.67      0.77      0.72       215
           7       0.76      0.57      0.65        94
           8       0.78      0.44      0.56        16
    accuracy                           0.67       490
   macro avg       0.59      0.47      0.51       490
weighted avg       0.68      0.67      0.67       490
[[  0   0   3   0   0   0]
 [  0   7   8   3   0   0]
 [  0   2  96  45   1   0]
 [  0   1  37 166  10   1]
 [  0   0   8  31  54   1]
 [  0   0   0   3   6   7]]</pre>
			<p>使用对用例最重要的指标来度量模型的性能<a id="_idIndexMarker572"/>也很重要<a id="_idIndexMarker573"/>。正如上述研究的作者在谈到精确测量的重要性时所说:</p>
			<p class="author-quote">此统计信息在实践中非常重要，因为在实际部署设置中，实际值是未知的，并且给定列中的所有预测都将被视为相同</p>
			<p>我们应该比较原始研究中使用的精度测量(在研究中的<em class="italic">表 3 </em>中，链接在<em class="italic">进一步阅读</em>部分)，其中各个精度如下:</p>
			<ul>
				<li>4: 63.3%</li>
				<li>5: 72.6%</li>
				<li>6: 60.3%</li>
				<li>7: 67.8%</li>
				<li>8: 85.5%</li>
			</ul>
			<p>当宽容<code>T = 0.5</code>为白葡萄酒。我们的第一个自动驾驶模型在某些类别的精度上表现出色，而在其他类别上表现不佳。</p>
			<p>找到更好地服务于业务问题的模型的另一个策略是，除了自动驾驶建议的最佳模型之外，评估更多的模型。我们可以看到另外两个(或者更多，取决于您对<code>TOP_N_CANDIDATES</code>的设置)的评估。我们发现，尽管第二个和第三个模型比第一个模型有更低的<code>validation:f1</code>(宏观)分数，但他们实际上在坚持测试集上有更高的 F1 分数。第三个模型的单个精度分数都比原始研究中的模型好<a id="_idIndexMarker574"/>，除了类别 5，高出 2.6%。多迷人啊！排行榜中的第三个型号<a id="_idIndexMarker575"/>实际上在测试数据上具有更好的性能，这是由 precision 指标衡量的，对用例来说最有意义。</p>
			<p>评估后，我们可以将最佳模型部署到一个端点中进行实时推理。Autopilot 可以轻松部署模型。在排行榜中，选择您想要部署的行项目，并点击<strong class="bold">部署型号</strong>按钮。将弹出一个新页面，让您配置端点。对于有经验的 SageMaker Studio 用户来说，大多数选项都是简单明了的。需要注意的两件事是，您可以启用数据捕获，如果您稍后想要设置 SageMaker Model Monitor，这将非常有用。如果您希望模型不仅仅返回<strong class="bold"> predicted_label </strong>，比如多类用例中获胜类的硬标签，您可以选择返回获胜标签的<strong class="bold">概率</strong>，所有类的<strong class="bold">标签</strong>，以及所有类的<strong class="bold">概率</strong>。选择的顺序也将决定输出的顺序。</p>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor122"/>总结</h1>
			<p>在这一章中，我们介绍了集成到 SageMaker Studio 中的两个特性——jump start 和 auto pilot——以及三个 ML 用例，为 ML 开发人员演示了低代码甚至无代码的 ML 选项。我们学习了如何在目录中浏览 JumpStart 解决方案，以及如何从 JumpStart 部署端到端 CV 解决方案来检测产品缺陷。我们还使用 JumpStart model zoo 中的 DistilRoBERTa 基础模型部署并微调了一个问答模型，没有任何 ML 编码。有了 Autopilot，我们只需将 Autopilot 指向存储在 S3 的数据集，并启动 Autopilot 作业，就可以构建一个白葡萄酒质量预测模型——不需要任何代码。事实证明，Autopilot 甚至优于最初的研究人员创建的模型，这可能需要几个月的研究。</p>
			<p>有了下一章，我们就开始本书的下一部分:<em class="italic">用 SageMaker Studio 进行机器学习的生产运营</em>。我们将了解如何通过 SageMaker 中的分布式培训从原型开发大规模转移到生产 ML 培训，如何通过 SageMaker 调试器轻松监控模型培训，如何通过管理现场培训节省培训成本..</p>
			<h1 id="_idParaDest-124"><a id="_idTextAnchor123"/>延伸阅读</h1>
			<p>有关更多信息，请查看以下资源:</p>
			<ul>
				<li>页（page 的缩写）科尔特斯、塞德伊拉、阿尔梅达、马托斯和雷伊斯。<em class="italic">通过物理化学特性的数据挖掘建立葡萄酒偏好模型</em>。在决策支持系统中，Elsevier，47(4):547-553，2009。<a href=" https://bit.ly/3enCZUz">https://bit.ly/3enCZUz</a></li>
			</ul>
		</div>
	

</body></html>