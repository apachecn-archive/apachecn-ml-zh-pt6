

# 二、亚马逊 SageMaker 工作室简介

正如我们刚刚在 [*第 1 章*](B17447_01_ePub_RK.xhtml#_idTextAnchor013)*中了解到的，机器学习及其在云中的生命周期*，一个 ML 的生命周期是复杂的、迭代的。即使大多数事情都是通过编码完成的，步骤也可能是相当手工的。拥有一个合适的 ML 项目工具对于你成功地交付 ML 模型用于云中生产是至关重要的。有了这一章，你就来对地方了！Amazon SageMaker Studio 是一个专门构建的 ML **集成开发环境** ( **IDE** )，它提供了覆盖端到端 ML 生命周期的功能，使开发人员和数据科学家在 AWS 云中的工作变得容易。

在本章中，我们将介绍以下内容:

*   介绍 SageMaker Studio 及其组件
*   设置 SageMaker Studio
*   浏览 SageMaker Studio 用户界面
*   揭开 SageMaker Studio 笔记本、实例和内核的神秘面纱
*   使用 SageMaker Python SDK

# 技术要求

对于本章，您需要有一个 AWS 帐户。如果没有，请重温 [*第一章*](B17447_01_ePub_RK.xhtml#_idTextAnchor013) 、*机器学习及其在云端的生命周期*中的*设置 AWS 环境*部分。

# 介绍 SageMaker Studio 及其组件

Amazon SageMaker 是 AWS 的一项人工智能服务，它具有专用于人工智能生命周期每个阶段的功能，我们在 [*第 1 章*](B17447_01_ePub_RK.xhtml#_idTextAnchor013) 、*机器学习及其在云中的生命周期*中讨论过。Amazon SageMaker Studio 是一个 ML IDE，专为使用 Amazon SageMaker 进行端到端 ML 开发而设计。您可以使用 SageMaker Studio IDE 或 SageMaker Python SDK 访问 Amazon SageMaker 特性，我们将在*使用 SageMaker Python SDK* 一节中讨论。下图提供了一个概述:

![Figure 2.1 – Amazon SageMaker Studio overview – four pillars represent the four stages in the ML life cycle
](img/B17447_02_01.jpg)

图 2.1-Amazon sage maker Studio 概述-四个支柱代表了 ML 生命周期的四个阶段

这张图表突出了书中涉及的 SageMaker 组件。让我们首先在本章中对 ML 生命周期阶段中的每个组件进行一个高层次的介绍。然后，我将提供后面章节的链接。

## 准备

亚马逊 SageMaker Studio 帮助数据科学家和开发人员快速构建高质量的 ML 数据集。您可以使用以下功能来探索、处理、转换、聚合数据，并将处理后的数据或 ML 功能存储在中央存储库中。

### SageMaker 数据辩论者

**Amazon sage maker Data Wrangler**帮助开发人员以一种快速、简单、可重复的方式探索和构建一个 ML 数据集。SageMaker Data Wrangler 将数据准备工作流程(从各种云存储和数据仓库导入、聚合多个表、了解数据偏差和目标泄漏以及通过可视化探索数据模式)放在一个易于使用的图形界面中，您只需点击即可创建可重复和可移植的数据配方。易于使用的图形界面是 SageMaker Studio 独有的。SageMaker Data Wrangler 有 300 多种内置数据转换，因此您无需重新发明 ML 中典型数据处理步骤的轮子。除了内置转换，SageMaker Data Wrangler 还支持用 Python、SQL 和 PySpark 编写的自定义转换，以丰富您的数据工程步骤。我们将在 [*第 3 章*](B17447_03_ePub_RK.xhtml#_idTextAnchor043) 、*使用 SageMaker 数据牧马人*进行数据准备中深入探讨 SageMaker 数据牧马人。

### SageMaker 澄清

**亚马逊 SageMaker Clarify** 帮助开发者发现训练数据中的潜在偏差，并从模型预测中解释特征重要性。**数据偏差**是指由于抽样误差或其他复杂原因而引入到训练数据中的不同组和类别(如年龄和教育水平)的训练数据的不平衡。数据偏差通常会被忽略，直到一个经过训练的模型对某个群体做出不正确或不公平的预测。众所周知，模型将学习数据中存在的内容，包括任何偏差，并将在其推理中复制该偏差。能够及早发现数据中的固有偏差并采取措施解决它们比以往任何时候都更加重要。SageMaker Clarify 计算各种指标来测量数据中的偏差，因此您不必成为 ML 偏差科学的专家。SageMaker Clarify 与 Amazon SageMaker Data Wrangler 集成，因此您可以在准备阶段检测偏差。SageMaker Clarify】还与**Amazon SageMaker Experiments**和**Amazon SageMaker Model Monitor**集成，以便您可以识别训练模型中的偏差和特性重要性以及生产中的推断数据。我们将在第六章 *中进一步了解 SageMaker Clarify，用 SageMaker Clarify* 检测 ML 偏差和解释模型。

### SageMaker 加工

**亚马逊 SageMaker 处理**是一个特性，它在 SageMaker 完全托管的计算实例中运行你的脚本和容器，而不是你有限的本地计算资源。它旨在使数据处理和模型评估变得简单和可扩展。它非常灵活，开发人员可以使用它在 ML 生命周期中的任何时间运行任何代码。SageMaker 处理还集成了几个 SageMaker 特性作为计算主干。SageMaker Data Wrangler 使用 SageMaker 处理来执行您的 SageMaker Data Wrangler 数据配方，并将处理后的特征保存到存储器中。SageMaker Clarify 使用 SageMaker 处理来计算偏差度量和特征重要性。SageMaker 模型监视器(将在本章后面的*部署*部分讨论)使用 SageMaker 处理来计算数据漂移。SageMaker 自动驾驶仪(稍后将在*构建*部分讨论)使用 SageMaker 处理数据探索和特征工程。

### SageMaker 功能商店

**Amazon sage maker Feature Store**是一个完全托管的 ML 特性存储库，允许 ML 开发者存储、更新、查询 ML 特性，并在其他 ML 开发者之间共享 ML 特性。拥有一个中央特征库作为组织中特征的单一来源，其中许多团队在特征工程上协作，但继续创建他们自己的模型，这加快了模型的开发，因为特征现在可以在团队之间共享和重用，以及用于训练和推理的应用。它减少了团队的功能开发时间和精力浪费。SageMaker 特征库提供**在线**和**离线特征库**，分别用于实时、低延迟的 ML 推理和查询模型训练的批量数据。SageMaker 功能库还具有版本控制和时间旅行功能，允许开发人员重用功能并审核过去的模型训练和推理。我们将在 [*第 4 章*](B17447_04_ePub_RK.xhtml#_idTextAnchor063) *中探讨更多关于 SageMaker 特性库的内容，用 SageMaker 特性库*构建一个特性库。

## 建造

Amazon SageMaker Studio 作为一个 ML 的 IDE 有许多特性和功能，可以帮助你根据你的用例和项目复杂性来构建 ML 模型。听说过一个 ML 算法但是不确定怎么实现？亚马逊 SageMaker Studio 有**低到无代码选项**——自动 ML ( **autoML** )、预建的 ML 解决方案和内置的训练算法——通过简单地插入数据来帮助您构建复杂的 ML 模型和解决方案。SageMaker Studio 笔记本重新发明了使用 Jupyter 笔记本开发 ML 模型的方式。

### SageMaker 自动驾驶仪

**亚马逊 SageMaker Autopilot** 探索、转换数据，并为您的输入数据集自动训练和调整 ML 模型。你只需要选择数据集位置和目标，就可以让 SageMaker Autopilot 在简单易用的图形界面中进行学习和预测。然后，它走了。SageMaker Autopilot 提供了对模型构建方式的完全控制和可见性。带有代码和探索性数据分析的 Jupyter 笔记本也给了你，让你了解 SageMaker 自动驾驶仪是如何在引擎盖下工作的。有了可用的代码，您还可以改进流程中的任何步骤，并重新运行作业以获得更好的结果。当模型被训练时，SageMaker Studio 用户界面使得浏览和选择最佳模型变得容易。您可以在 SageMaker Studio 中查看领先板，比较各种 ML 算法和其他超参数的性能，只需几次点击即可部署最佳模型。我们将在 [*第八章*](B17447_08_ePub_RK.xhtml#_idTextAnchor108) 、*用 SageMaker JumpStart 和 Autopilot* 来继续探索 SageMaker 自动驾驶仪。

### SageMaker JumpStart

**亚马逊 SageMaker JumpStart** 通过提供一系列为各行业最常见用例专门构建的解决方案和一个超过 150 个流行的开源深度学习模型的模型动物园，使 it 轻松开始使用 ML。SageMaker JumpStart 中的解决方案由端到端系统的参考架构组成，不仅仅是 ML 建模，它可以部署到您的 AWS 帐户。您可以简单地浏览 SageMaker Studio IDE 中的目录以找到合适的解决方案，只需一次点击即可部署，并查看如何在云中作为一个生产系统协同工作。至于来自 SageMaker JumpStart 的 ML model zoo，您也可以轻松地从目录中选择一个符合您的用例的模型，并单击一次进行部署，以在您的数据或应用中执行推理。您还可以使用自己的数据集对模型进行微调，以适应您的用例，训练完全由 SageMaker JumpStart 管理，无需任何编码。我们将在第 8 章 、*jump start ML with SageMaker jump start and auto pilot*中详细了解如何使用 SageMaker JumpStart。

### SageMaker 工作室笔记本

关于构建一个 ML 模型的话题,开发人员经常在 Jupyter 笔记本上写代码，因为它可以捕获代码，这样简单易读。Amazon SageMaker Studio 界面建立在 JupyterLab 之上，具有许多旨在增强体验的附加功能。与库存的普通笔记本相比，SageMaker Studio 笔记本提供了一种灵活和可扩展的方式来编写代码和构建 ML 模型。对于每台笔记本电脑，开发人员不仅可以选择运行笔记本电脑的笔记本电脑内核，还可以选择支持笔记本电脑的计算实例。因此，对于 data exploration 笔记本电脑，您可以配置一个具有 2 个 vCPU 和 4 GiB RAM 的实例，用于绘制和处理适量的数据。如果您需要加载更多数据或需要 GPU 进行快速实验，您可以创建一个具有不同计算实例的新笔记本，或者切换到现有笔记本上的不同实例。您可以在 https://aws.amazon.com/sagemaker/pricing/.的 **Studio 笔记本**选项卡中找到支持的 SageMaker 实例列表。我们将在本章后面的*揭开 SageMaker Studio 笔记本、实例和内核*部分以及 [*第 6 章*](B17447_06_ePub_RK.xhtml#_idTextAnchor090) 、*用 SageMaker Clarify 检测 ML 偏差并解释模型*中花更多时间讨论 SageMaker Studio 笔记本背后的基础设施。

### 训练算法

构建 ML 模型并不一定意味着你需要写很多代码。Amazon SageMaker 提供了 17 种可扩展、基础设施优化的内置算法，用于监督和非监督问题类型，以及表格、计算机视觉和自然语言处理(NLP)用例。**内置算法**被设计用于亚马逊 SageMaker 的完全托管计算。当使用内置算法进行训练时，您将算法和超参数指向 S3 桶上的数据集，SageMaker 在幕后提供训练实例，将您的数据和算法作为训练实例的 Docker 容器，并执行训练。通过可扩展和基础设施优化，我们指的是这些算法背后的代码库针对 AWS 计算基础设施进行了优化，并且能够使用多个实例运行分布式训练。内置算法最好的一点是，你不需要编写大量的代码。我们将在 [*第五章*](B17447_05_ePub_RK.xhtml#_idTextAnchor077) *“用 SageMaker Studio IDE* 构建和训练 ML 模型”中了解更多关于内置算法以及如何用它们训练模型的内容。

## 训练和调整

训练和调整 ML 模型可能会耗费数据科学家最多的时间和精力。为了帮助数据科学家专注于建模而不是基础架构，拥有一个全面管理、可靠且可扩展的计算环境对于他们以最佳状态运营至关重要。Amazon SageMaker Studio 通过以下特性使 ML 训练变得简单和可扩展。

### 管理训练

SageMaker- 托管训练使 ML 开发人员能够从任何地方访问按需计算资源，并使模型训练成为一种近乎无服务器的体验。您可以使用来自各种 SageMaker ML 实例的最佳计算资源来启动模型训练作业。在[https://aws.amazon.com/sagemaker/pricing/](https://aws.amazon.com/sagemaker/pricing/)中的**训练**页签下可以找到训练实例列表。对于需要强大 GPU 实例的深度学习模型，可以轻松指定一个**加速计算**实例，配备 GPU 设备。如果您手头有一个利用 CPU 而不是 GPU 的线性回归模型，您可以根据 CPU 和内存需求从**标准**或**计算优化**实例中选择一个实例。作为 SageMaker 管理的特性，您根本不需要进行服务器供应和管理。您提交一个训练作业，SageMaker 处理服务器供应，并在训练作业完成时关闭。监控训练工作很容易，因为训练指标和日志被推送到 **Amazon CloudWatch** 。这种体验使您能够专注于模型构建和训练，而不是基础设施。我们将在 [*第五章*](B17447_05_ePub_RK.xhtml#_idTextAnchor077) *用 SageMaker Studio IDE* 构建和训练 ML 模型中了解更多关于 SageMaker 托管训练和用 TensorFlow 和 PyTorch 等流行 ML 框架训练 ML 模型的例子。SageMaker managed training 还支持 spot 实例，因此您可以节省高达 90%的按需实例。我们将在第 9 章 、*SageMaker 工作室大规模训练 ML 模型中了解更多关于 sage maker 管理的现场训练。*。

### 分布式训练图书馆

随着深度学习模型变得越来越大，需要更多的数据，训练大型神经网络将对 GPU 的需求推至单个计算实例之外。您需要找到一种方法来将训练数据和大型神经网络模型分发到多个实例。**亚马逊 SageMaker 的分布式训练库**使得以分布式方式开发你的 ML 训练代码变得容易。SageMaker 分布式训练库有两种扩展技术——**数据并行**和**模型并行**。数据并行将大型数据集分布到实例中进行并发训练。模型并行性将太大而无法在单个 GPU 上安装的模型分割成跨多个 GPU 的部分，以便进行训练。SageMaker 的分布式训练库还优化了分发框架和分区算法，以便在 SageMaker 的 GPU 实例上快速训练，实现近乎线性的扩展效率。通过在训练代码基础上添加几行代码，您可以将模型训练转变为分布式训练，以便在多个实例上高效利用多个 GPU 设备。我们将在第 9 章 、*sage maker Studio 中大规模训练 ML 模型的 [*中，通过分布式训练库如何工作的例子来深入。*](B17447_09_ePub_RK.xhtml#_idTextAnchor125)*

### SageMaker 调试器

在模型训练工作期间，了解训练期间是否存在问题以及您的训练代码如何利用计算资源至关重要。此反馈信息允许您调整网络架构、更改超参数和修改其他参数，以便您可以训练更好的模型并停止失败的训练作业，而不会浪费更多的时间和资源。**亚马逊 SageMaker 调试器**让优化 ML 模型和训练实例利用率变得容易。SageMaker 调试器旨在实时捕获训练指标和计算资源利用率，并在出现问题时报告可操作的见解和问题。SageMaker Debugger 在 SageMaker Studio 中创建了一个交互式仪表板，您可以在训练进行时实时可视化该仪表板。这在训练复杂的神经网络模型时尤其有用。我们将在 [*第 9 章*](B17447_09_ePub_RK.xhtml#_idTextAnchor125) 、*在 SageMaker Studio 中按比例训练 ML 模型中讨论并展示如何使用 SageMaker 调试器。*

### 萨格马克实验

Amazonsage makerExperiments 是一个帮助你在 ML 生命周期中组织和跟踪工作的功能。当您着手一个 ML 项目时，您处理数据，应用带有参数的变换，并从各种算法和超参数中训练 ML 模型。当试验和实验的数量快速增长并变得无法控制时，你就会意识到这一点。开发人员可以使用 SageMaker Experiments Python SDK 来设置跟踪器，以跟踪数据源、处理步骤和参数。SageMaker Studio IDE 可以轻松搜索实验和试验，比较参数和模型性能，并创建图表来可视化进度。我们会在 [*第五章*](B17447_05_ePub_RK.xhtml#_idTextAnchor077) *更深入的探讨 SageMaker 实验，用 SageMaker Studio IDE 构建和训练 ML 模型。*

## 部署

ML 模型是为了服务和预测而创建的。部署 ML 模型是利用模型的起点。当你为你的 ML 应用创建一个反馈循环时，你如何服务一个模型来可靠地、大规模地、有成本效益地进行推理是 ML 生命周期中最重要的方面之一，因为我们知道，通常 90%或更多的 ML 成本花费在托管用于推理的模型上。

### 托管部署

SageMaker 托管模型部署消除了为模型推理而管理、供应和扩展计算实例的繁重工作。机器学习模型可以部署在 SageMaker 上进行实时推理和批量推理。如果 ML 推理是在线应用的一部分，则通常需要实时推理。部署的模型也应该以低延迟的方式返回一个推断。只需几行代码， **Amazon SageMaker 模型托管**特性就可以将您的模型部署到完全托管的 ML 实例中，作为低延迟实时推理的端点。您还可以设置端点的自动伸缩，以便当模型的流量增加时，SageMaker 将自动启动更多的实例来处理额外的负担，以免现有实例不堪重负。

如果您的 ML 项目需要您创建多个模型以提高每个模型的准确性，比如说，一个地理区域， **SageMaker 的多模型端点**是您部署模型的一个经济有效的选择。当您知道某些州的流量比其他州少时，您可以将 50 个模型整合到一个多模型端点中，以充分利用端点的计算能力并降低托管成本，而不是在 50 个端点上托管 50 个模型，用于具有来自美国 50 个州的数据的 ML 用例，并为 50 个端点付费。

至于批量推理， **SageMaker batch transform** 是一种经济高效且可扩展的方式，可以针对您的模型批量对大型数据集进行推理。SageMaker batch transform 可以高效地处理数据接收，因此您不必担心数据量会淹没计算实例。

模型部署和托管是一个大话题，我们将在 [*第 7 章*](B17447_07_ePub_RK.xhtml#_idTextAnchor099) 、*在云中托管 ML 模型:最佳实践*中讨论更多。

### SageMaker 模型监视器

正如 [*第一章*](B17447_01_ePub_RK.xhtml#_idTextAnchor013) 、*机器学习及其在云中的生命周期*中所讨论的，关闭 ML 反馈循环是确保模型质量并允许开发人员在为时已晚之前采取行动的一个步骤。**Amazon SageMaker Model Monitor**功能通过设置数据捕获、计算作为基线的输入数据统计，以及为您的实时端点监控**数据漂移**来关闭反馈回路，这些端点按计划托管在 sage maker 上。SageMaker Model Monitor 使用一组统计数据和指标来确定新的输入数据是否符合基线训练数据的统计和示意外观。您还可以定义自己的指标，并在 SageMaker Model Monitor 中使用它们。一旦为一个端点设置了模型监控，您就可以在 SageMaker Studio IDE 的一个仪表板中可视化数据漂移和任何数据问题。您还可以使用其他 AWS 服务设置警报和触发器，以便根据数据漂移或模型性能漂移采取行动。我们将在第 10 章 、*使用 SageMaker 模型监视器监视生产中的 ML 模型中了解更多信息并展示如何设置 SageMaker 模型监视。*

## MLOps

数据科学家过去花费太多的时间和精力来维护和手动管理 ML 管道，这个过程从数据处理、模型训练和评估开始，到模型托管和持续维护结束。SageMaker Studio 提供了一些功能，旨在将这种操作与**持续集成** ( **CI** )和**持续交付** ( **CD** )作为最佳实践进行精简。

### SageMaker 管道公司

**Amazon SageMaker Pipelines** 是一个编排层，它允许您为您的 ML 生命周期构建工作流，这些工作流可以在生产系统中自动化。您可以在一个管道中自动化各个步骤，包括数据处理、模型训练、调优、评估和部署。您可以将业务条件和逻辑应用到管道中，以便保持模型的质量。SageMaker Pipelines 为模型创建了审计跟踪，因为它将管道中每一步的信息都保存在一个地方。SageMaker Pipelines 的 ML 管道可以在任何时间、按计划或响应触发事件来执行。我们将在 [*第 11 章*](B17447_11_ePub_RK.xhtml#_idTextAnchor144) ，*中讨论并运行一个 SageMaker 管道的例子。*

### SageMaker 项目和模型注册中心

**Amazon SageMaker 项目**是一个特性，它帮助你把所有的 ML 工件放在一个地方，用 CI/CD 最佳实践来确保生产中的模型具有可再现性、可审计性和治理性。

SageMaker 项目将 ML 代码库、管道、实验、模型注册和部署的端点收集到一个单一的窗格中。SageMaker 提供了 MLOps 模板，让你在 AWS 中轻松上手 MLOps。您可以选择一个内置模板或基于您的使用案例创建自己的模板，部署模板，并开始填充您的 ML 工作流，以使您的 ML 工作流具备 CI/CD 最佳实践。其中包括以下内容:

*   版本控制的代码库
*   用于自动化模型训练的 ML 管道
*   验证代码提交是否有效的代码构建过程
*   用于版本控制的模型部署质量控制门和模型注册中心
*   自动化的模型部署过程

我们将在 [*第 11 章*](B17447_11_ePub_RK.xhtml#_idTextAnchor144) 、*中介绍特性和 MLOps 最佳实践，通过 SageMaker 项目、管道和模型注册*实施 ML 项目。

既然我们已经简要介绍了 SageMaker Studio 的许多组件，让我们准备好您的 AWS 帐户并学习如何设置 SageMaker Studio。

# 建立 SageMaker 工作室

核心特性出来了，让我们从 Amazon SageMaker Studio 开始吧。请使用您的 IAM 用户登录您的 AWS 帐户，并从**服务**下拉菜单转到 Amazon SageMaker 控制台页面。您将看到如图*图 2.2* 所示的页面:

![Figure 2.2 – Amazon SageMaker console page
](img/B17447_02_02.jpg)

图 2.2–亚马逊 SageMaker 控制台页面

点击 **SageMaker Studio** 按钮。

## 设置域名

因为这是我们第一次使用 Amazon SageMaker Studio，我们需要设置一个 SageMaker 域和一个用户配置文件。有快速入门设置和标准设置，您应该使用哪一种？嗯，这取决于你的需要。使用快速入门来完成本书中的所有练习和大多数个人项目就足够了。另一方面，标准设置提供了额外的选项来定制您的计算环境，以满足企业中常见的特定安全要求，如网络和身份验证方法。

使用标准设置，您可以配置以下内容:

*   *认证方式* : **单点登录** ( **SSO** )或者 **AWS 身份和访问管理** ( **IAM** )。SSO 是企业团队的一种流行方法，它允许您使用单点登录凭证从任何地方访问门户中的软件和云资源。在这种情况下，您不需要访问 AWS 控制台。但是，它要求您首先设置一个 SSO 帐户。IAM 方法允许您更快更简单地设置域。这也是快速启动设置中使用的方法。您需要首先使用 IAM 角色登录 AWS 控制台，以便访问 Studio。
*   *Permission* :一个默认的执行角色，它定义了权限，比如允许您访问哪些 S3 存储桶，以及您可以在 SageMaker Studio 中为域执行哪些操作。请注意，添加到 SageMaker Studio 域的每个新用户可以继承这个默认的执行角色，也可以拥有另一个具有不同权限的执行角色。
*   *笔记本共享配置*:笔记本共享是协作的一项重要功能。如果要加密可共享的笔记本并能够共享像元输出，您可以配置笔记本共享元数据在 S3 上的保存位置，也可以禁用笔记本共享。
*   *SageMaker 项目和 JumpStart* :您是否希望启用账户和/或用户的 SageMaker 项目模板和 JumpStart。
*   *网络和存储* : SageMaker Studio 作为一种云资源，可以在一个**虚拟私有云**(**VPC**)逻辑虚拟网络中启动，在这里你可以控制路由表、网络网关、公共互联网接入、可用性区域，以及更多关于网络安全的内容。这些选项允许对云安全性至关重要的企业在云中安全地运行 ML 工作负载。您可以选择在每个 AWS 帐户中创建的默认 VPC 或您自己的 VPC 中托管 SageMaker Studio。您可以选择一个或多个子网来实现高可用性。

许多组织需要在云中有一个治理良好的互联网访问策略。您可以选择是否允许公共 internet，以及应该实施哪一组控制入站和出站规则的安全组。最后但同样重要的是，您可以选择加密 SageMaker Studio 中使用的存储，即 EFS 文件系统。

*   *标签*:您可以在 Studio 域中添加键值对标签。这允许您或管理员根据附加的标签对资源进行分组，并了解云中的开销。

在回顾了标准选项之后，让我们回到**快速入门**，因为这对于我们在本书的上下文中来说已经足够并且更加简单明了:

1.  填写您的用户名。
2.  对于**执行角色**，我们创建一个新的。

![Figure 2.3 – Setting up a SageMaker Studio domain with Quick start 
](img/B17447_02_03.jpg)

图 2.3–使用快速入门设置 SageMaker Studio 域

1.  您有一个选项，允许访问任何 S3 存储桶、特定存储桶或没有额外的存储桶，下图中列出的其他四个规则除外。让我们选择 **None** 来练习最小特权访问。我们将使用一个 SageMaker 默认存储桶，它将在以后创建并满足现有规则。点击**创建角色**:

![Figure 2.4 – Creating an IAM role
](img/B17447_02_04.jpg)

图 2.4–创建 IAM 角色

1.  在您点击**提交**之前，请确保启用 Amazon SageMaker 项目模板和 JumpStart。选择**提交**。启动一个域和一个用户配置文件需要几分钟时间。请随意休息一下，稍后再回来:

![Figure 2.5 – SageMaker Studio Control Panel
](img/B17447_02_05.jpg)

图 2.5–sage maker Studio 控制面板

1.  准备就绪后，点击**打开工作室**。

当您第一次打开 Jupyter 服务器应用时，它将被创建，这将需要几分钟时间。

接下来，我们来探索一下 SageMaker Studio UI。

# 浏览 SageMaker Studio 用户界面

*图 2.6* 是 SageMaker 工作室 UI 和工作室**启动器**页面的截图。您可能会发现该界面与 JupyterLab 界面非常相似。SageMaker Studio 实际上构建在 JupyterLab 之上，并添加了许多附加功能，以便在 ide 中为您提供端到端的 ML 体验:

![Figure 2.6 – The SageMaker Studio UI – the left sidebar is indicated in the red box
](img/B17447_02_06.jpg)

图 2.6–sage maker Studio 用户界面–左侧边栏显示在红色框中

先说一下Studio UI 中的关键组件。

## 主要工作区域

主要工作区域是**启动器**页面、笔记本、代码编辑器、终端和控制台所在的地方。除了 JupyterLab 的这些基本功能，正如您将在整本书中了解到的，SageMaker Studio 自己的功能，如数据牧马人、自动驾驶、JumpStart、功能存储、管道、模型监视器和实验，也在主要工作区域提供丰富的用户体验。 **Launcher** 页面是您可能想要创建的所有新资源的门户，例如新的 JumpStart 解决方案、新的功能商店、新的 MLOps 项目、新的笔记本和新的终端。

## 侧栏

左侧的侧边栏有七个图标(打开笔记本时有八个),作为您拥有或可能需要的所有资源的门户，如图*图 2.6* 所示。从上到下，它们如下:

*   **文件浏览器**是你访问 EFS 文件系统主目录下的文件并上传新文件的地方。
*   **Git** 是您可以连接到 Git 存储库并交互地对您的代码库执行 Git 操作的地方。
*   **运行终端和内核**选项卡允许您查看、访问和关闭计算资源，如笔记本、内核和实例。
*   **命令**显示您可以在 Studio UI 中执行的命令和操作列表。
*   **网络工具**让您访问笔记本的元数据。只有当笔记本在主工作区打开时，它才会显示。
*   **打开标签**显示打开的标签列表。
*   **SageMaker JumpStart** 图标显示已启动的解决方案以及相关的训练工作和端点。
*   **SageMaker 组件和注册表**列出了您可以查看和访问的项目、Data Wrangler 文件、管道、实验、模型、端点和特性存储。每个组件中还有一个搜索栏，方便您查找资源。

主工作区右侧的侧边栏是**设置**窗格，当您从实验或模型监控作业中创建可视化分析时，它允许您编辑表格和图表属性，这也是 SageMaker Studio 的一个伟大特性。

## “你好世界！”在 SageMaker 工作室

让我们从一个非常基本的任务开始——打开一个笔记本，用 Python 运行一个每个编程书籍都会用到的非常简单的程序——*hello world！*”。

![Figure 2.7 – Creating a SageMaker Studio notebook
](img/B17447_02_07.jpg)

图 2.7–创建 SageMaker Studio 笔记本

1.  转到**笔记本和计算资源**，**选择一个 SageMaker 图像**(目前可选—**数据科学**默认图像很完美，但您可以选择另一个图像)，并单击**笔记本** | **Python 3** 框中的 **+** 图标。将弹出一个新的笔记本。
2.  如果你注意到右上角的 **Python 3** ( **数据科学**)旁边有一个**未知**，并且有**内核:正在启动...**在下方的状态栏中，如图*图 2.8* 所示，表示笔记本仍在连接计算资源。它应该需要大约一分钟。我们将在下一部分更深入地讨论幕后发生的事情，*揭开 SageMaker Studio 笔记本、实例和内核的神秘面纱*。

![Figure 2.8 – A kernel is starting for a new SageMaker Studio notebook 
](img/B17447_02_08.jpg)

图 2.8–一个新的 SageMaker Studio 笔记本的内核正在启动

1.  如果你在 **Python 3(数据科学)**内核镜像旁边看到 **2 vCPU + 4 GiB** ，那就意味着笔记本终于连接到了拥有 2 个虚拟 CPU(**vCPU**)和 4 GiB RAM 的实例。让我们在笔记本的第一个单元格中写下第一行代码:

    ```
    print('hello world!')
    ```

现在让我们执行，如下图所示:

![Figure 2.9 – The notebook has connected to the kernel and our "hello world!" program is working
](img/B17447_02_09.jpg)

图 2.9–笔记本已经连接到内核和我们的“hello world！”程序正在运行

太好了！我们刚刚在 SageMaker 工作室推出了一款弹性笔记本，并执行了我们的“hello world！”举例。然而，如果您执行得太快，并且在底部的状态栏仍然显示**内核:正在启动…** 时执行代码，您可能会得到以下错误:

```
Note: The kernel is still starting. Please execute this cell again after the kernel is started. 
```

这里发生了什么事？让我们换个话题来谈谈 SageMaker Studio 背后的基础设施。

# 揭开 SageMaker Studio 笔记本、实例和内核的神秘面纱

*图 2.10* 是 SageMaker Studio 领域的架构图，以及笔记本内核与其他组件的关系。这里我们需要理解四个实体:

*   **EC2 实例**:笔记本运行的硬件。您可以根据 vCPU、GPU 和内存量来选择要使用的实例类型。实例类型决定了定价率，这可以在[https://aws.amazon.com/sagemaker/pricing/](https://aws.amazon.com/sagemaker/pricing/)中找到。
*   **SageMaker image** :一个可以在 SageMaker Studio 上运行的容器映像。它包含运行笔记本所需的语言包和其他文件。您可以在 EC2 实例中运行多个映像。
*   内核网关应用:SageMaker图像作为内核网关应用运行。SageMaker 图像和 KernelGateway 应用之间存在一对一的关系。
*   **内核**:运行笔记本中代码的进程。一个 SageMaker 映像中可以有多个内核。

到目前为止，我们，as `ipynb`文件将被创建在**亚马逊 EFS 文件系统**上的 **User1** 主目录中。SageMaker Studio 将尝试将笔记本(前端)连接到满足需求的后端计算资源，即内核映像和 EC2 实例类型。在 SageMaker Studio 中，我们也将一个已启动的内核映像称为内核网关应用。

![Figure 2.10 – The infrastructure behind the SageMaker Studio IDE 
](img/B17447_02_10.jpg)

图 2.10–sage maker Studio IDE 背后的基础设施

重要说明

图片由以下链接提供:[https://docs . AWS . Amazon . com/sagemaker/latest/DG/notebooks . html](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html)。

如果请求的计算资源可用，笔记本电脑将立即连接并准备好进行编码。如果没有可用的，就像我们的例子一样，因为我们刚刚推出了该领域中的第一台笔记本电脑，SageMaker Studio 会启动一个计算实例(`ml.t3.medium`，默认情况下)，并将内核映像(我们选择的数据科学映像)作为容器附加到计算实例中。

这就是为什么我们看到`datascience-1-0-ml-t3-medium-xxxx` KernelGateway 应用处于待定状态。

![Figure 2.11 – A KernelGateway app is starting up in SageMaker Studio 
](img/B17447_02_11.jpg)

图 2.11–一个 KernelGateway 应用正在 SageMaker Studio 中启动

一旦 KernelGateway 应用准备好了，我们的笔记本就准备好了。SageMaker Studio 笔记本电脑背后的创新机制允许用户(多租户)为我们在同一屋檐下运行的每台笔记本电脑使用正确的计算资源。如果您点击 **2 vCPU + 4 GiB** ，您将能够看到您正在使用的实例类型以及您可以使用的实例类型，如下所示:

![Figure 2.12 – Selecting an instance for a notebook
](img/B17447_02_12.jpg)

图 2.12–为笔记本选择实例

有四种常用不同类别的实例类型为**快速启动**，即设计在 2 分钟内启动的实例。如果您取消选中仅**快速启动**复选框，您将看到 SageMaker Studio 中适用于您笔记本的所有实例类型，包括非快速启动类型的实例。可以随意切换到其他实例类型和内核映像进行实验。您可以在左侧边栏的**运行终端和内核**中看到所有正在运行的实例、应用和实时笔记本会话。您应该使用电源按钮关闭不再需要的**正在运行的应用**和**内核会话**，如下面的屏幕截图所示，以终止并回收正在运行的实例上的资源。同样，你应该关闭**运行实例**你不再需要停止招致费用。

![Figure 2.13 – Viewing Running Terminals and Kernels from the left sidebar
](img/B17447_02_13.jpg)

图 2.13–从左侧栏查看正在运行的终端和内核

现在我们已经很好地理解了笔记本如何处理实例和内核映像，让我们更深入地了解另一个主要资源，我们将在 SageMaker Studio 的书和 ML 开发生命周期中使用它。

# 使用 SageMaker Python SDK

SageMaker Studio 不仅仅是一个在笔记本上运行代码的地方。是的，SageMaker Studio 是一个在弹性笔记本上开始编码和训练 ML 模型的好地方，但是还有更多的功能，正如我们在本章的*介绍 SageMaker Studio 及其组件*一节中所讨论的。

有两种主要方式与 SageMaker 特性进行通信和工作。一种是通过有 UI 前端的组件，比如 SageMaker Data Wrangler 另一种是通过一个**软件开发包** ( **SDK** )。SDK 使开发者能够超越界面与 Amazon SageMaker 的世界互动。您可以访问 SageMaker 针对您的数据的可扩展的内置算法。您可以通过编程方式运行 SageMaker 自动驾驶作业。如果您使用 TensorFlow、PyTorch 或 MXNet 开发深度学习模型，您可以使用 SDK 与 SageMaker 计算基础架构进行交互，为它们训练、处理和托管模型。您可以使用 SDK 创建功能库。还有更多。我不会在这一节列举所有的功能，因为当我们需要编码时，我们将在以后的章节中主要使用和学习 SageMaker 特性的 SDK。

AWS 有几个使用 SageMaker 特性的 SDK，如下所示:

*   SageMaker Python SDK ，它提供了数据科学家熟悉的高级 API
*   **用于 Python 的 AWS SDK(boto 3)**，提供对 SageMaker API 和其他 AWS 服务的底层访问
*   其他编程语言的 AWS SDK([https://aws.amazon.com/sagemaker/resources/](https://aws.amazon.com/sagemaker/resources/))，取决于您的应用

对于许多数据科学家来说，SageMaker Python SDK 是更自然的选择，因为它的 API 设计。在本书中，我们将使用 SageMaker Python SDK。

SageMaker Python SDK 是所有完全托管的 SageMaker 内核映像的标准配置，因此您无需安装和管理不同的版本。你可以简单地在代码和笔记本中运行`import sagemaker`并使用这个库。您还可以在 SageMaker Studio 之外的任何地方使用 SageMaker Python SDK，例如在您的笔记本电脑上或在 AWS Lambda 上的无服务器应用中，与 SageMaker 对话，前提是您拥有正确的 IAM 权限配置。

因为 SageMaker 是 AWS 中的云服务，所以在使用该服务之前，有一些方面需要注意。以下代码是在给定环境中设置 SageMaker Python SDK 的典型方法。你会在整本书中看到更多的例子:

```
import sagemaker
session = sagemaker.Session()
bucket = session.default_bucket()
role = sagemaker.get_execution_role()
```

这段代码片段执行以下操作:

1.  将 SageMaker Python SDK 导入运行时。
2.  创建一个**会话**，允许您与 Amazon SageMaker API 和任何其他 AWS 服务进行交互。
3.  创建一个默认存储桶以供使用，并返回存储桶的名称。铲斗具有`sagemaker-{region}-{AWS account ID}`的形状。
4.  检索本地可用的执行角色。在 SageMaker Studio 上，它是我们在创建用户概要文件时分配的执行角色。为了正确使用 SDK，角色应该具有选择 S3 存储桶和执行 SageMaker 相关操作的权限。我们的角色附带了`AmazonSageMakerFullAccess`策略，因此我们受到保护。如果您在 PC 上使用 SDK，请确保您拥有 IAM 用户的 AWS 凭据，该凭据允许您执行与 SageMaker 相关的操作。

你可以打印出`bucket`和`role`，看看它们是什么。它们分别是 S3 存储桶和 IAM 角色的字符串值。所有与云对话并在云上执行操作的 API 都需要`role`值。这很重要，因为安全性是云中的首要任务。正如我们在 [*第 1 章*](B17447_01_ePub_RK.xhtml#_idTextAnchor013) 、*机器学习及其在云中的生命周期*中所讨论的，在 AWS 中，你需要拥有有效且适当的权限才能执行和访问任何云资源。当执行具有 SageMaker 功能的操作时，`role`将用于在继续之前验证您是否有足够的权限这样做。

作为一个开源库，你可以在 https://github.com/aws/sagemaker-python-sdk 获得源代码，在 https://sagemaker.readthedocs.io/en/stable/index.html 获得文档。

# 总结

在这一章中，我们介绍了 SageMaker Studio 的高级特性。我们将这些特性映射到典型 ML 生命周期的各个阶段，并讨论了为什么以及如何在 ML 生命周期中使用 SageMaker。我们建立了一个 SageMaker Studio 域，并在 SageMaker Studio 中执行了我们的第一个笔记本。我们学习了 SageMaker Studio 的基础设施，以及如何为笔记本选择正确的内核映像和计算实例。最后，我们讨论了关键工具 SageMaker Python SDK 背后的基本概念，以及它如何与云和 SageMaker 交互，因为这是我们未来在 SageMaker Studio 中的许多活动的基础。

在下一章中，我们将通过使用 SageMaker Data Wrangler 为 ML 用例准备数据集来启动我们的 ML 之旅。您将了解在 SageMaker Studio 中准备和处理数据是多么容易。