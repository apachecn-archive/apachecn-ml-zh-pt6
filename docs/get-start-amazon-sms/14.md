

# 十一、使用 SageMaker 项目、管道和模型注册来操作 ML 项目

数据科学家过去花费太多的时间和精力来维护和手动管理 ML 管道，这个过程从数据、处理、训练和评估开始，到模型托管和持续维护结束。SageMaker Studio 提供了旨在通过**持续集成和持续交付** ( **CI/CD** )最佳实践来简化这些操作的特性。您将学习如何实现 SageMaker 项目、管道和模型注册，以帮助使用 CI/CD 操作 ML 生命周期。

在本章中，我们将学习以下内容:

*   了解 ML 操作和 CI/CD
*   创建 SageMaker 项目
*   用 SageMaker 管道编排 ML 管道
*   在 SageMaker Studio 中运行 CI/CD

# 技术要求

对于本章，您需要确保在 Studio 设置中启用了 SageMaker 项目模板权限。如果你已经完成了 [*第八章*](B17447_08_ePub_RK.xhtml#_idTextAnchor108) ，*用 SageMaker JumpStart 和 auto pilot*jump starting ML，你应该有权限了。您可以通过以下步骤在 Studio **域**视图中验证它:

1.  如果任一权限被禁用，如图*图 11.1* 所示，您可以点击**编辑设置**进行更改。

![Figure 11.1 – Checking and editing the SageMaker projects permissions
](img/B17447_11_01.jpg)

图 11.1–检查和编辑 SageMaker 项目权限

1.  进入**步骤 2 工作室设置**打开 SageMaker 项目和 JumpStart 权限，如图*图 11.2* 所示。

![Figure 11.2 – Enabling SageMaker project templates for the account and users
](img/B17447_11_02.jpg)

图 11.2–为帐户和用户启用 SageMaker 项目模板

1.  然后点击**下一页**进入下一页，点击**提交**。

这确保为您启用了 SageMaker 项目模板权限。

# 了解 ML 运营和 CI/CD

在 ML 生命周期中，有许多步骤需要熟练的数据科学家全程亲自参与，例如争论数据集、训练和评估模型。这些手动步骤可能会影响 ML 团队在生产中部署模型的操作和速度。想象一下，你的模型训练工作需要很长时间，并且在半夜完成。您要么必须等待您的第一个数据科学家在白天到来，以评估模型并将模型部署到生产中，要么必须采用随叫随到的轮换方式，让某人随时待命，以监控模型训练和部署。但是如果你想要一个有效和高效的 ML 生命周期，这两种选择都不理想。

**机器学习操作** ( **MLOps** )对于一个想要保持精简和良好扩展的团队来说至关重要。MLOps 帮助您尽可能简化和减少人工干预。它有助于将您的 ML 生命周期转变为企业级。它帮助您扩展并保持投入生产的模型的质量，还帮助您通过自动化缩短模型交付时间。

那么，MLOps 到底是什么？

MLOps 是指将 DevOps 最佳实践应用于 ML 生命周期的方法。 **DevOps** 代表软件**开发** ( **Dev** )和 IT **运营** ( **Ops** )。DevOps 的目标是使用一套工程、实践和模式来提高团队高速度、高质量地交付应用的能力。它还在组织中推广一种新的文化和行为模式。MLOps 推荐以下实践，这些实践基于 DevOps 最佳实践，并针对 ML 的性质进行了一些修改:

*   **持续集成** ( **CI** ):在 DevOps 中，开发人员不断地将他们的代码变更提交并合并到一个中央存储库中，之后会自动运行测试来验证代码。在 ML 中，不仅代码需要集成和验证，训练数据和 ML 模型也是如此。训练数据需要被版本化，模型血统需要被跟踪以获得可追溯性，除了代码之外，对数据和模型的测试也需要被实现。
*   **连续交付** ( **CD** ):在 DevOps 中，这种是一种实践，在这种实践中，代码以自动的方式构建、测试并发布用于生产。在 MLOps 中，类似于关于持续集成的讨论，除了 ML 源代码之外，操作还包括数据和模型。
*   **一切如代码**:为了精简和自动化 CI 和 CD(简称 CI/CD)，一切都需要以代码的形式实现:流程、基础设施和配置，而不是任何手动设置和屏幕上的点击式流程。这种实践还支持您的过程、基础设施和配置的版本控制和可再现性。
*   **监控和记录**:这个实践鼓励你记录所有与你的软件/ML 系统相关的事情，以获得可见性和可审计性。您不仅要记录 ML 度量、数据沿袭、数据版本和模型版本，还要记录 CI/CD 过程以及用于调试和监控目的的任何错误。这使得下一个练习成为可能。
*   **沟通和协作**:因为一切都是代码，一切都是自动的和记录的，所以你有一个邀请协作和沟通的透明环境。你的整个团队可以在系统上更加紧密地一起工作，而不是像孤岛一样手动移交，这会导致摩擦和不透明。

MLOps 带来的主要优势如下:

*   **更快的上市时间**:因为现在您的模型部署是作为 CI/CD 流程的一部分自动创建和部署的，您的模型训练和部署是简化的，没有任何移交或手动流程。你可以期待在相同的时间框架内更多的细化迭代，以及一个成熟产品更快的周转时间。
*   **生产力**:数据科学家和 ML 开发人员的大量手动流程被取消，这样他们就可以专注于 ML 建模，而这些事情是无法自动化的。
*   **可重复性**:此外，因为一切都是代码，而且是自动化的，你的 ML 生命周期可以由任何人在任何时候执行，输出完全相同。
*   **可靠性**:通过在 CI/CD 过程中执行的测试和验证，你知道你的模型是高质量的。由于 CI/CD 提供的可重复性，您还可以始终如一地生产高质量的模型。
*   **可审计性**:当代码、数据和模型被版本化，并且谱系和过程被记录时，你可以准确地说出模型是如何被训练和部署的。
*   **更好的质量**:结合以上所有的好处，MLOps 使我们能够花更多的时间来创建更好的模型，并让系统快速、可靠、可重复地处理集成和交付。

你可能会想: *MLOps 似乎太完美了，不容易被采用*。是的，您确实需要将额外的技术整合到您的 ML 生命周期中，以支持 CI/CD 流程。是的，您需要实现许多细节来启用日志记录和监控。同样真实的是，要采用*一切如代码*的实践，一开始就需要对基础设施代码和配置进行多次迭代测试。好消息是，在 SageMaker Studio 中，为您的 ML 项目采用 MLOps 实践变得很容易。SageMaker Studio 已经为众多用例模板化了 CI/CD 流程，因此您可以轻松选择一个并采用模板化 ML 用例中的 MLOps 最佳实践和技术。启用 MLOps 和 CI/CD 的功能有 **SageMaker 项目**、 **SageMaker 管道**和 **SageMaker 模型注册表**。

让我们首先创建一个 SageMaker 项目。

# 创建 SageMaker 项目

一个 **SageMaker 项目**使能够从 SageMaker 提供的模板和您自己的定制模板中，使用 MLOps 和 CI/CD 自动化模型构建和部署管道。使用 SageMaker 提供的模板，所有的初始设置和资源供应都由 SageMaker 处理，因此您可以快速地将它应用到您的用例中。

在这一章中，我们将在 SageMaker Studio 中用 MLOps 和 CI/CD 运行一个 ML 示例。当我们在本章中关注 MLOps 和 CI/CD 时，我们使用来自鲍鱼数据集的简单回归问题([https://archive.ics.uci.edu/ml/datasets/abalone](https://archive.ics.uci.edu/ml/datasets/abalone))来从物理测量预测鲍鱼的年龄。我将向您展示如何从 SageMaker 项目创建一个项目，以及 MLOps 系统的每个部分是如何工作的。从 SageMaker projects 创建的 MLOps 系统通过代码提交的简单触发，实现了数据验证、模型构建、模型评估、部署和监控的自动化。这意味着无论何时我们对代码库进行任何修改，整个系统都将在 SageMaker 中运行完整的 ML 生命周期，这是我们在本书中自动学到的。您将看到 SageMaker 为您简化了多少 MLOps。让我们打开 SageMaker Studio，按照这里给出的步骤操作:

1.  在**启动器**页面，点击**新建项目**卡片上的*加号*，如图*图 11.3* 所示。

![Figure 11.3 – Opening a new project in Launcher
](img/B17447_11_03.jpg)

图 11.3–在启动器中打开一个新项目

1.  SageMaker 为各种用例创建的 MLOps 模板(在 **SageMaker 模板**下)供我们选择，如图*图 11.4* 所示。让我们选择 **MLOps 模板用于模型构建、训练、部署和监控**。该模板自动化了整个模型生命周期，包括模型构建、部署和监控工作流。点击**选择项目模板**。

![Figure 11.4 – Choosing SageMaker managed templates
](img/B17447_11_04.jpg)

图 11.4–选择 SageMaker 管理的模板

注意

名称中包含第三方 Git 库的**模板被设计为与您的外部 Git 库或 CI/CD 软件一起工作，例如 **Jenkins** 。在下一步中，您需要提供更多信息。**

1.  在**项目详情**页面上提供项目的名称、描述和标签。点击**创建项目**。

有了这个项目模板，SageMaker Studio 现在可以为 MLOps 提供云资源，并部署示例代码。让我们用*图 11.5* 中所示的图表来说明 MLOps 架构:

![Figure 11.5 – Architecture diagram of an MLOps setup with a SageMaker projects template
](img/B17447_11_05.jpg)

图 11.5–带有 SageMaker 项目模板的 MLOps 设置的架构图

创建的云资源包括以下内容:

*   AWS CodeCommit 中的三个代码仓库，这是托管私有 Git 仓库的托管源代码控制服务。它们也可以在 AWS CodeCommit 控制台中找到:[https://console . AWS . Amazon . com/code suite/code commit/repositories](https://console.aws.amazon.com/codesuite/codecommit/repositories)。记得从 URL 切换到您自己的 AWS 区域。
*   **AWS CodePipeline** 中的三个连续交付管道，这是一个帮助自动化构建、测试和发布管道的托管服务，可以在 AWS CodePipeline 控制台中找到:[https://console . AWS . Amazon . com/code suite/code pipeline/pipelines](https://console.aws.amazon.com/codesuite/codepipeline/pipelines)。记得从 URL 切换到您自己的 AWS 区域。
*   亚马逊 EventBridge**中的五个事件触发规则亚马逊 EventBridge** 是一个托管服务，可以更容易地构建事件驱动的应用，可以在亚马逊 event bridge 控制台中找到:【https://console.aws.amazon.com/events/home#/rules】T42。记得从 URL 切换到您自己的 AWS 区域。

这些本质上是 SageMaker Studio 中支持 MLOps 的主干 CI/CD 框架。CodeCommit 中的存储库是我们存储、开发和提交代码的地方。在 CodeCommit 中对代码存储库的每次提交都将触发(由 EventBridge 中的规则管理)CodePipeline 中相应管道的运行，以构建、测试和部署资源。

一旦项目创建完成，您可以在主工作区看到项目的门户，如图*图 11.6* 所示。

![Figure 11.6 – SageMaker project detail portal
](img/B17447_11_06.jpg)

图 11.6-sage maker 项目详细信息门户

这个门户包含所有与项目相关的重要资源和信息 CodeCommit 中的代码存储库、来自 SageMaker Pipelines 的 ML pipelines(我们很快会谈到)、使用 SageMaker 实验跟踪的实验、模型、托管端点和其他设置。

1.  我们可以将存储库从 CodeCommit 克隆到本地 SageMaker Studio 目录中。在我们继续描述 ML 管道之前的最后一步，让我们克隆`<project-name-prefix>-modelbuild`存储库，它包含使用鲍鱼数据集构建、训练和评估 ML 模型的 ML 管道。点击图 11.6 中用箭头突出显示的`<project-name-prefix>-modelbuild`存储库。

![Figure 11.7 – Cloning a repository from CodeCommit to a local SageMaker Studio directory
](img/B17447_11_07.jpg)

图 11.7–从 CodeCommit 克隆一个存储库到本地 SageMaker Studio 目录

1.  在*图 11.7* 所示的弹出窗口中，点击`~/<project-name-prefix>/<project-name-prefix>-modelbuild/`。

在深入研究 CI/CD 部分之前，让我们先看看这个鲍鱼示例中定义的 ML 管道。

# 通过 SageMaker 管道协调 ML 管道

我们正在使用的模板包含一个 ML 生命周期管道，它执行数据预处理、数据质量检查、模型训练、模型评估步骤，以及最终的模型注册。该管道是创建模型的 MLOps 过程的核心部分。使用 SageMaker 管道在`<project-name-prefix>-modelbuild`中定义管道。 **SageMaker Pipelines** 是 SageMaker 中 ML 工作流的编排工具。SageMaker Pipelines 集成了 SageMaker 处理、训练、实验、托管和模型注册。它提供了再现性、可重复性，并跟踪数据/模型的可审计性。最重要的是，您可以在 SageMaker Studio 中实时可视化工作流图和运行时。该管线可以在详情门户的**管线**页签下找到，如图*图 11.8* 所示。

![Figure 11.8 – A list of pipelines in the project 
](img/B17447_11_08.jpg)

图 11.8-项目中的管道列表

注意

在这一章中，我多次使用了术语**管道**。让我们一劳永逸地解决这个问题。我指的是来自 SageMaker Pipelines 的管道，如图*图 11.8* 和*图 11.9* 所示，称为 **ML 管道**。请不要将 ML 管道与 AWS CodePipeline 中的 CI/CD 管道相混淆，这在上一节中有简要介绍，并将在*在 SageMaker Studio* 中运行 CI/CD 一节中进一步讨论。

双击管道，我们可以看到管道的完整执行图和实时状态，如图*图 11.9* 所示。相应的管道代码在`~/<project-name-prefix>/<project-name-prefix>-modelbuild/pipelines/abalone/pipeline.py`。

![Figure 11.9 – Pipeline workflow and live status
](img/B17447_11_09.jpg)

图 11.9–管道工作流程和实时状态

让我们浏览一下管道以及在代码中是如何设置的。管道包含以下步骤(在图中从上到下):

1.  首先是用 SageMaker 处理(`pipeline.py`文件)预处理数据集，其中我们使用了`sagemaker.workflow`模块中的类和函数以及其他`sagemaker`类，scikit-learn 处理器被定义为在同一目录中运行脚本`preprocess.py`。另外，`ProcessingStep`是来自`sagemaker.workflow.steps`模块的一个类:

    ```
    # Line 209 in pipeline.py step_process = ProcessingStep(     name="PreprocessAbaloneData",     processor=sklearn_processor,     outputs=[         ProcessingOutput(output_name="train", source="/opt/ml/processing/train"),         ProcessingOutput(output_name="validation", source="/opt/ml/processing/validation"),         ProcessingOutput(output_name="test", source="/opt/ml/processing/test"),     ],     code=os.path.join(BASE_DIR, "preprocess.py"),     job_arguments=["--input-data", input_data], )
    ```

2.  在数据经过预处理后，管道检查之前注册的数据质量和偏差指标，和/或使用 SageMaker Clarify 计算数据质量和偏差。这里，前一步骤`step_process.properties.ProcessingOutputConfig.Outputs["train"]`的输出被用作输入基线数据。这里实例化了一个`QualityCheckStep()`步骤对象。该步骤从基线训练数据中计算数据质量统计，并在模型创建结束时将统计注册到模型注册表中:

    ```
    # Line 238 data_quality_check_config = DataQualityCheckConfig( baseline_dataset=step_process.properties.ProcessingOutputConfig.Outputs["train"].S3Output.S3Uri,     dataset_format=DatasetFormat.csv(header=False, output_columns_position="START"),     output_s3_uri=Join(on='/', values=['s3:/', default_bucket, base_job_prefix, ExecutionVariables.PIPELINE_EXECUTION_ID, 'dataqualitycheckstep']) ) data_quality_check_step = QualityCheckStep(     name="DataQualityCheckStep",     skip_check=skip_check_data_quality,     register_new_baseline=register_new_baseline_data_quality,     quality_check_config=data_quality_check_config,     check_job_config=check_job_config, supplied_baseline_statistics=supplied_baseline_statistics_data_quality, supplied_baseline_constraints=supplied_baseline_constraints_data_quality,     model_package_group_name=model_package_group_name )
    ```

3.  同时，管道也使用从`ClarifyCheckStep()`类:

    ```
    data_bias_check_config = DataBiasCheckConfig(     data_config=data_bias_data_config,     data_bias_config=data_bias_config, ) data_bias_check_step = ClarifyCheckStep(     name="DataBiasCheckStep",     clarify_check_config=data_bias_check_config,     check_job_config=check_job_config,     skip_check=skip_check_data_bias,     register_new_baseline=register_new_baseline_data_bias,     model_package_group_name=model_package_group_name )
    ```

    实例化的步骤来计算数据偏差

这两个检查步骤基于`skip_check`参数。`skip_check_data_quality`和`skip_check_data_bias`是流水线输入参数，可以为每次运行进行配置。对于第一次运行，您可以跳过检查，因为没有要检查的基线统计数据。`register_new_baseline`也取决于管道输入参数，但是大多数情况下当您有新数据集时，您会注册新的基线统计数据，除非您有特定的理由不更新统计数据。

1.  在数据质量和偏差检查之后，从 SageMaker 估计器创建训练作业。在这个例子中，使用了内置的 XGBoost 算法。`TrainingStep`依赖于`DataQualityCheckStep`和`DataBiasCheckStep`，意味着训练步骤在开始之前等待两个检查步骤完成，并从预处理步骤`step_process` :

    ```
    # Line 326 step_train = TrainingStep(     name="TrainAbaloneModel",     depends_on=["DataQualityCheckStep", "DataBiasCheckStep"],     estimator=xgb_train,     inputs={         "train": TrainingInput( s3_data=step_process.properties.ProcessingOutputConfig.Outputs["train"].S3Output.S3Uri,             content_type="text/csv",         ),         "validation": TrainingInput( s3_data=step_process.properties.ProcessingOutputConfig.Outputs["validation"].S3Output.S3Uri,             content_type="text/csv",         ),     }, )
    ```

    获取输出
2.  接下来是到使用`CreateModelStep()`从训练工作中创建一个 SageMaker 模型。`CreateModelInput()`接受用于托管目的的实例类型:

    ```
    # Line 346 model = Model(     image_uri=image_uri, model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,     sagemaker_session=sagemaker_session,     role=role, ) inputs = CreateModelInput(     instance_type="ml.m5.large",     accelerator_type="ml.eia1.medium", ) step_create_model = CreateModelStep(     name="AbaloneCreateModel",     model=model,     inputs=inputs, )
    ```

3.  Once the SageMaker Model is created, two branches of model evaluation are performed. One is applied on a held-out test set for evaluation purposes using SageMaker Batch Transform `Transformer`:

    ```
    # Line 364
    transformer = Transformer(
        model_name=step_create_model.properties.ModelName,
        instance_type="ml.m5.xlarge",
        instance_count=1,
        accept="text/csv",
        assemble_with="Line",
        output_path=f"s3://{default_bucket}/AbaloneTransform",
    )
    step_transform = TransformStep(
        name="AbaloneTransform",
        transformer=transformer,
        inputs=TransformInput(       data=step_process.properties.ProcessingOutputConfig.Outputs["test"].S3Output.S3Uri,
        ...)
    )
    ```

    注意

    `TransformInput()`类中的附加参数在文本中已被省略，但在`pipeline.py`中可用，用于配置批量转换输入/输出，并将输出结果与输入记录相关联。更多信息请见[https://docs . AWS . Amazon . com/sage maker/latest/DG/batch-transform-data-processing . html](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html)。

批量转换的输出，即预测，然后用于计算模型质量指标，如平均绝对误差、均方根误差和 r 平方值:

```
model_quality_check_config = ModelQualityCheckConfig(
    baseline_dataset=step_transform.properties.TransformOutput.S3OutputPath,
    dataset_format=DatasetFormat.csv(header=False),
    output_s3_uri=Join(on='/', values=['s3:/', default_bucket, base_job_prefix, ExecutionVariables.PIPELINE_EXECUTION_ID, 'modelqualitycheckstep']),
    problem_type='Regression',
    inference_attribute='_c0',
    ground_truth_attribute='_c1'
)
model_quality_check_step = QualityCheckStep(
    name="ModelQualityCheckStep",
    skip_check=skip_check_model_quality,
    register_new_baseline=register_new_baseline_model_quality,
    quality_check_config=model_quality_check_config,
    check_job_config=check_job_config,
supplied_baseline_statistics=supplied_baseline_statistics_model_quality,
supplied_baseline_constraints=supplied_baseline_constraints_model_quality,
    model_package_group_name=model_package_group_name
)
```

1.  另一条评估路线`EvaluateAbaloneModel`和`CheckMSEAbaloneEvalution`旨在评估测试数据集，并使用性能指标作为 ML 管道中的条件，以便仅在均方误差小于或等于`6.0` :

    ```
    # Line 650 cond_lte = ConditionLessThanOrEqualTo(     left=JsonGet(         step=step_eval,         property_file=evaluation_report,         json_path="regression_metrics.mse.value"     ),     right=6.0, ) step_cond = ConditionStep(     name="CheckMSEAbaloneEvaluation",     conditions=[cond_lte],     if_steps=[step_register],     else_steps=[], )
    ```

    时，才在模型注册中心注册模型
2.  另外两项检查也在`ModelBiasCheckStep`和`ModelExplainabilityCheckStep`的车型上进行。他们都使用 SageMaker Clarify 来计算模型偏差和模型可解释性:

    ```
    # Line 450 model_bias_check_step = ClarifyCheckStep(     name="ModelBiasCheckStep",     clarify_check_config=model_bias_check_config,     check_job_config=check_job_config,     skip_check=skip_check_model_bias,     register_new_baseline=register_new_baseline_model_bias, supplied_baseline_constraints=supplied_baseline_constraints_model_bias,     model_package_group_name=model_package_group_name )  # Line 494 model_explainability_check_step = ClarifyCheckStep(     name="ModelExplainabilityCheckStep",     clarify_check_config=model_explainability_check_config,     check_job_config=check_job_config,     skip_check=skip_check_model_explainability, register_new_baseline=register_new_baseline_model_explainability, supplied_baseline_constraints=supplied_baseline_constraints_model_explainability,     model_package_group_name=model_package_group_name )
    ```

3.  在检查到确认模型的性能后，模型与评估度量一起注册在 SageMaker 模型注册表中，存储在`model_metrics`变量中，在过程中捕获，包括测试数据、数据偏差和模型偏差的性能度量:

    ```
    # Line 635 step_register = RegisterModel(     name="RegisterAbaloneModel",     estimator=xgb_train, model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,     content_types=["text/csv"],     response_types=["text/csv"],     inference_instances=["ml.t2.medium", "ml.m5.large"],     transform_instances=["ml.m5.large"],     model_package_group_name=model_package_group_name,     approval_status=model_approval_status,     model_metrics=model_metrics,     drift_check_baselines=drift_check_baselines )
    ```

4.  定义了步骤后，它们被放入`Pipeline`对象的`steps`参数中。向用户公开的参数放在`parameters`参数中:

    ```
    # Line 666 pipeline = Pipeline(     name=pipeline_name,     parameters=[         processing_instance_type,         processing_instance_count,         ...],     steps=[step_process, data_quality_check_step, data_bias_check_step, step_train, step_create_model, step_transform, model_quality_check_step, model_bias_check_step, model_explainability_check_step, step_eval, step_cond],     sagemaker_session=sagemaker_session, )
    ```

你可能想知道 SageMaker 是如何确定步骤顺序的。SageMaker 根据数据依赖关系和任何显式的自定义依赖关系来确定顺序。我们将这些步骤放在一个`steps`参数的列表中，SageMaker 负责剩下的部分。

注意

创建项目后，三个 CodePipeline 管道将自动运行。只有第一个管道`<project-name-prefix>-modelbuild`会正确运行。另外两条管道`<project-name-prefix>-modeldeploy`和`<project-name-prefix>-modelmonitor`依赖于第一条管道的输出，因此它们将在第一次运行中失败。不用担心现在的失败状态。

1.  最后，一个成功执行的管道在 SageMaker Model 注册表中创建和注册了一个模型。您可以在左侧栏的模型注册表中看到该模型，如图*图 11.10* 所示。我们将在后面的章节中了解更多关于模型注册中心的内容。

![Figure 11.10 – Resulting model in SageMaker Model Registry
](img/B17447_11_010.jpg)

图 11.10-sage maker 模型注册表中的结果模型

有几种方法可以运行管道。一个是 CI/CD 流程，这是从模板部署后管道最初的运行方式。我们将在下一节*在 SageMaker Studio* 中运行 CI/CD 中更多地讨论 CI/CD 过程。下面显示了如何手动触发管道:

1.  如图*图 11.11* 所示，可以在 SageMaker Studio 界面中点击**开始执行**。

![Figure 11.11 – Starting an execution of a pipeline in the pipeline list
](img/B17447_11_011.jpg)

图 11.11-开始执行管道列表中的管道

1.  您可以指定用户输入，如实例类型、训练数据位置和其他检查条件，如图*图 11.12* 所示。点击**开始**为新数据集单独启动工作流程。

![Figure 11.12 – Starting the execution of a pipeline with user inputs
](img/B17447_11_012.jpg)

图 11.12-通过用户输入开始执行管道

1.  您还可以使用 SageMaker Python SDK 运行一个管道。模板化代码库`~/<project-name-prefix>/<project-name-prefix>-modelbuild/`有一个示例笔记本`sagemaker-pipelines-project.ipynb`，更详细地解释了代码结构，并展示了如何以编程方式运行管道。您可以打开笔记本，如图*图 11.13* 所示，作为备选运行。

![Figure 11.13 – A screenshot of the sagemaker-pipelines-project.ipynb notebook that shows you details such as code structure in the repository, and runs the pipeline programmatically
](img/B17447_11_013.jpg)

图 11.13–sage maker-pipelines-project . ipynb 笔记本的屏幕截图，向您显示了详细信息，如存储库中的代码结构，并以编程方式运行管道

有了 SageMaker 管道，我们可以编排使用 SageMaker 管理的特性来运行 ML 生命周期的步骤。在下一节中，让我们看看模板创建的 CI/CD 系统如何为 MLOps 使用 SageMaker 管道。

# 在 SageMaker Studio 中运行 CI/CD

我们之前看到运行的 ML 管道只是我们工作中的 CI/CD 系统的一部分。ML 管道由 AWS 代码管道中的 CI/CD 管道触发。让我们深入研究 SageMaker 项目模板为我们设置的三个 CI/CD 管道。

有三种代码管道:

*   `<project-name-prefix>-modelbuild`:这个管道的目的是运行 ML 管道，并在 SageMaker 模型注册中心创建一个 ML 模型。当由对存储库的提交触发时，这个 CI/CD 管道将 ML 管道作为构建步骤运行。SageMaker 模型注册表中的 ML 模型需要被批准，以便触发下一个管道`modeldeploy`。
*   `<project-name-prefix>-modeldeploy`:这个管道的目的是在 SageMaker 模型注册中心部署最新批准的 ML 模型作为 SageMaker 端点。构建过程首先部署一个临时端点，并在将模型部署到生产环境之前请求人工批准。这可确保模型和端点配置在部署到生产环境之前正常工作。一旦分段端点被部署并且变为具有`InService`状态的活动，它触发下一个管道`modelmonitor`。
*   `<project-name-prefix>-modelmonitor`:该管道的目的是将 SageMaker 模型监视器部署到`modeldeploy`管道中创建的两个 SageMaker 端点。每当一个临时端点上线，并在将模型监视器部署到生产端点之前要求对临时端点的模型监视部署进行手动批准时，就会触发该管道。

回到我们之前的 ML 管道执行，这是`modelbuild`构建过程的一部分，我们创建了一个模型，并在**模型注册表**中注册了。这是 CI/CD 系统的第一个检查点:*手动验证模型性能指标*。为了继续进行，我们需要进入如图*图 11.10* 所示的模型注册处查看结果。

1.  在*图 11.10* 中的视图中，双击模型注册表中的模型版本条目，可以看到该模型版本的更多详细信息，如图*图 11.14* 所示。

![Figure 11.14 – Detail page of a model version
](img/B17447_11_014.jpg)

图 11.14–模型版本的详细页面

1.  我们可以在**模型质量**选项卡中查看模型的性能，在**可说明性**选项卡中查看模型的可说明性，在**偏差报告**选项卡中查看数据偏差。这些都是相关的信息，可以帮助我们决定这是否是一个可接受的模型。
2.  审核后，点击右上角的**更新状态**按钮，批准或拒绝该型号。为了便于演示，我们批准该模型继续使用 MLOps 系统，如图*图 11.15* 所示。如果我们拒绝这个模型，从这一点上什么都不会发生。![Figure 11.15 – Approve or reject a model version. You can put a comment in the box too
    ](img/B17447_11_015.jpg)

图 11.15-批准或拒绝模型版本。你也可以在框中添加评论

1.  模型批准自动触发`modeldeploy`管道的执行。如果你去 CodePipeline 控制台，你可以看到它处于**进行中**状态，如图*图 11.16* 所示。

![Figure 11.16 – Model approval automatically triggers the modeldeploy pipeline
](img/B17447_11_016.jpg)

图 11.16–模型批准自动触发模型部署管道

1.  如前所述，`modeldeploy`管道首先部署一个 staging SageMaker 端点以供审查。一旦创建了端点(在 5-7 分钟内)，您可以在模型版本页面上看到一个新的事件，如图*图 11.17* 所示。点击**端点:<项目-名称-前缀>-分期**，了解更多关于端点的信息。您可以测试端点。

![Figure 11.17 – Model version showing the latest event in the deployment of the staging endpoint
](img/B17447_11_017.jpg)

图 11.17–模型版本显示了临时端点部署中的最新事件

1.  确认端点的状态后，我们可以在 CodePipeline 控制台中批准临时端点部署。从*图 11.16* 中点击管道名称。我们可以看到管道的当前进度正处于**部署阶段**，如图*图 11.18* 所示。在**批准部署**步骤中点击**审核**按钮，批准/拒绝部署。

![Figure 11.18 – Manual approval required by the modeldeploy pipeline
](img/B17447_11_018.jpg)

图 11.18-model deploy 管道要求的手动批准

1.  在弹出的*图 11.19* 中用任何注释批准或拒绝该部署。由于端点处于活动状态并正常工作，我们来批准试运行部署。

![Figure 11.19 – Approve/reject a staging deployment
](img/B17447_11_019.jpg)

图 11.19–批准/拒绝临时部署

1.  `modeldeploy`管道移动到最后一个阶段，**部署杆**，将模型部署到生产端点。一旦被部署，管道被更新为**成功**状态。在模型版本页面可以看到一个新事件，如图*图 11.20* 所示。还要注意的是**最后一级**现在是**产品**。

![Figure 11.20 – Model version is now updated to prod
](img/B17447_11_020.jpg)

图 11.20–型号版本现已更新为产品版本

1.  当我们批准登台部署时，会触发`modelmonitor`管道将 SageMaker 模型监视器部署到登台端点。在代码管道控制台中我们可以看到`modelmonitor`管道正在**进行**，如图*图 11.21* 所示。

![Figure 11.21 – Staging endpoint deployment triggers the modelmonitor pipeline
](img/B17447_11_021.jpg)

图 11.21–分段端点部署触发 modelmonitor 管道

1.  `modelmonitor`管道在部署阶段也需要人工批准。我们应该检查端点以查看是否启用了模型监视器。如*图 11.22* 所示，我们可以在**数据质量**页签中看到，Model Monitor 确实被启用并被调度。我们还没有端点的实时流量设置，监控时间表只会在整点开始，所以让我们继续在代码管道控制台中批准部署，类似于*步骤 6* 和*步骤 7* 。

![Figure 11.22 – Reviewing the Model Monitor schedule for the staging endpoint
](img/B17447_11_022.jpg)

图 11.22–查看登台端点的模型监视器计划

1.  最后， DeployProd 阶段还会将 SageMaker 模型监视器部署到生产端点。这标志着完整的 MLOps 和 CI/CD 系统的终结。

CodePipeline 中的三个 CI/CD 管道构成了一个通用的 MLOps 系统，该系统支持 ML 模型的持续集成和持续交付，以响应对`modelbuild`库的任何代码更改和任何手动 ML 管道运行。由于 SageMaker 项目模板，您不必担心复杂的实现，因为这些步骤会自动执行。

SageMaker 项目通过模板化的代码和存储库，可以轻松地将健壮的 MLOps 系统引入到您自己的 ML 用例中。你不必建立一个复杂的系统。您可以选择 SageMaker projects 提供的适合您的用例的模板，并按照 CodeCommit 中存储库中的自述文件为您自己的用例定制配置和代码。例如，我们可以更新`pipeline.py`中的模型训练，以使用不同的超参数集，如下面的代码块所示，并将更改提交到`modelbuild`存储库:

```
# Line 315 in pipeline.py
xgb_train.set_hyperparameters(
    objective="reg:linear",
    num_round=70, # was 50
    max_depth=7, # was 7
    eta=0.2,
    gamma=4,
    min_child_weight=6,
    subsample=0.7,
    silent=0)
```

您可以看到一个来自`modelbuild`管道的新执行，带有最新的提交消息，如图*图 11.23* 所示。

![Figure 11.23 – A new modelbuild execution is triggered by a commit to the repository
](img/B17447_11_023.jpg)

图 11.23–一个新的 modelbuild 的执行是由一个对存储库的提交触发的

在我们更新核心训练算法的版本后，CI/CD 管道将再次按照我们在本章中描述的方式运行，以自动交付新的模型/端点(手动批准步骤除外)。您可以将此应用于对 ML 管道、`modelbuild`管道或其他两个 CI/CD 管道中的配置的任何更改。

# 总结

在这一章中，我们描述了什么是 MLOps 以及它在 ML 生命周期中的作用。我们讨论了 MLOps 带来的好处。我们向您展示了如何通过 SageMaker Studio IDE 中的 SageMaker 项目轻松启动复杂的 MLOps 系统。我们从 SageMaker 项目部署了一个模型构建/部署/监控模板，体验了*一切如代码*的真正含义。

我们对 CI/CD 流程进行了一次完整的运行，以了解该 MLOps 系统的工作原理。我们详细了解了 ML 管道是如何用 SageMaker 管道和其他 SageMaker 管理的特性实现的。我们还学习了 SageMaker 模型注册中心如何对 ML 模型进行版本控制。

此外，我们展示了如何在 CodePipeline 中监控 CI/CD 过程和批准部署，这使您能够更好地控制模型和部署的质量。使用 MLOps 系统，您可以享受我们讨论的优势:更快的上市时间、生产率、可重复性、可靠性、可审计性和高质量的模型。

这个例子也完美地总结了我们在整本书中学到的关于 Amazon SageMaker Studio 的知识。Amazon SageMaker Studio 是一个专门构建的 ML IDE，通过其丰富的用户界面，可以轻松构建具有端到端 ML 生命周期的 ML 模型。通过本书中的 11 个章节、代码示例和真实的 ML 用例，您已经学会了如何使用 SageMaker Studio 和许多 SageMaker 特性来准备数据、构建、训练、部署 ML 模型，以及为生产级 ML 项目运行 MLOps 系统。现在，您可以在 Amazon SageMaker Studio 中开始构建自己的 ML 项目。